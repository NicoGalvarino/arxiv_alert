<!DOCTYPE html><html><head><meta charset='utf-8'><link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>
    body {font-family: 'Montserrat', sans-serif; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}
    h1 {font-size: 70px}
    a {color: #45ABC2}
    em {font-size: 120%}
    </style>
    </head><body><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 22 Nov 2025 to 24 Nov 2025</em></font><br><br><a href="https://arxiv.org/pdf/2511.19433v1" target="_blank"><h2>Mixture of Horizons in Action Chunking</h2></a><strong><u>Authors:</u></strong> Dong Jing, Gang Wang, Jiaqi Liu, Weiliang Tang, Zelong Sun, Yunchao Yao, Zhenyu Wei, Yunhui Liu, Zhiwu Lu, Mingyu Ding<br><strong><u>Categories:</u></strong> cs.RO, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> 15 pages, 14 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-language-action (VLA) models have shown remarkable capabilities in robotic manipulation, but their performance is sensitive to the $\textbf{action chunk length}$ used during training, termed $\textbf{horizon}$. Our empirical study reveals an inherent trade-off: longer horizons provide stronger global foresight but degrade fine-grained accuracy, while shorter ones sharpen local control yet struggle on long-term tasks, implying fixed choice of single horizons being suboptimal. To mitigate the trade-off, we propose a $\textbf{mixture of horizons (MoH)}$ strategy. MoH rearranges the action chunk into several segments with different horizons, processes them in parallel with a shared action transformer, and fuses outputs with a light linear gate. It has three appealing benefits. 1) MoH exploits long-term foresight and short-term precision jointly within a single model, improving both performance and generalizability to complex tasks. 2) MoH is plug-and-play for full-attention action modules with minimal training or inference overhead. 3) MoH enables dynamic inference with adaptive horizons, which selects stable actions through cross-horizon consensus, achieving 2.5$\times$ higher throughput than baselines while preserving superior performance. Extensive experiments over flow-based policies $π_0$, $π_{0.5}$, and one-step regression policy $π_{\text{reg}}$ demonstrate that MoH yields consistent and significant gains on both simulations and real-world tasks. Notably, under mixed-task setting, $π_{0.5}$ with MoH reaches a new state-of-the-art with 99$\%$ average success rate on LIBERO after only $30k$ training iterations. Project page: https://github.com/Timsty1/MixtureOfHorizons</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19423v1" target="_blank"><h2>Beyond Protein Language Models: An Agentic LLM Framework for Mechanistic Enzyme Design</h2></a><strong><u>Authors:</u></strong> Bruno Jacob, Khushbu Agarwal, Marcel Baer, Peter Rice, Simone Raugei<br><strong><u>Categories:</u></strong> q-bio.QM, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> We present Genie-CAT, a tool-augmented large-language-model (LLM) system designed to accelerate scientific hypothesis generation in protein design. Using metalloproteins (e.g., ferredoxins) as a case study, Genie-CAT integrates four capabilities -- literature-grounded reasoning through retrieval-augmented generation (RAG), structural parsing of Protein Data Bank files, electrostatic potential calculations, and machine-learning prediction of redox properties -- into a unified agentic workflow. By coupling natural-language reasoning with data-driven and physics-based computation, the system generates mechanistically interpretable, testable hypotheses linking sequence, structure, and function. In proof-of-concept demonstrations, Genie-CAT autonomously identifies residue-level modifications near [Fe--S] clusters that affect redox tuning, reproducing expert-derived hypotheses in a fraction of the time. The framework highlights how AI agents combining language models with domain-specific tools can bridge symbolic reasoning and numerical simulation, transforming LLMs from conversational assistants into partners for computational discovery.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19418v1" target="_blank"><h2>Chain-of-Visual-Thought: Teaching VLMs to See and Think Better with Continuous Visual Tokens</h2></a><strong><u>Authors:</u></strong> Yiming Qin, Bomin Wei, Jiaxin Ge, Konstantinos Kallidromitis, Stephanie Fu, Trevor Darrell, Xudong Wang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Project page:this https URL<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language Models (VLMs) excel at reasoning in linguistic space but struggle with perceptual understanding that requires dense visual perception, e.g., spatial reasoning and geometric awareness. This limitation stems from the fact that current VLMs have limited mechanisms to capture dense visual information across spatial dimensions. We introduce Chain-of-Visual-Thought (COVT), a framework that enables VLMs to reason not only in words but also through continuous visual tokens-compact latent representations that encode rich perceptual cues. Within a small budget of roughly 20 tokens, COVT distills knowledge from lightweight vision experts, capturing complementary properties such as 2D appearance, 3D geometry, spatial layout, and edge structure. During training, the VLM with COVT autoregressively predicts these visual tokens to reconstruct dense supervision signals (e.g., depth, segmentation, edges, and DINO features). At inference, the model reasons directly in the continuous visual token space, preserving efficiency while optionally decoding dense predictions for interpretability. Evaluated across more than ten diverse perception benchmarks, including CV-Bench, MMVP, RealWorldQA, MMStar, WorldMedQA, and HRBench, integrating COVT into strong VLMs such as Qwen2.5-VL and LLaVA consistently improves performance by 3% to 16% and demonstrates that compact continuous visual thinking enables more precise, grounded, and interpretable multimodal intelligence.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19417v1" target="_blank"><h2>Be My Eyes: Extending Large Language Models to New Modalities Through Multi-Agent Collaboration</h2></a><strong><u>Authors:</u></strong> James Y. Huang, Sheng Zhang, Qianchu Liu, Guanghui Qin, Tinghui Zhu, Tristan Naumann, Muhao Chen, Hoifung Poon<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) have demonstrated remarkable capabilities in challenging, knowledge-intensive reasoning tasks. However, extending LLMs to perceive and reason over a new modality (e.g., vision), often requires costly development of large-scale vision language models (VLMs) with LLMs as backbones. Smaller VLMs are more efficient and adaptable but often lack the broad knowledge and reasoning capabilities of frontier LLMs. In this work, we propose BeMyEyes, a modular, multi-agent framework for extending LLMs to multimodal reasoning by orchestrating collaboration between efficient, adaptable VLMs as perceivers and powerful LLMs as reasoners through conversations. We then introduce a data synthesis and supervised fine-tuning pipeline to train the perceiver agent to effectively collaborate with the reasoner agent. By combining the complementary strengths of perception and reasoning agents, BeMyEyes avoids the need for training large-scale multimodal models, preserves the generalization and reasoning capabilities of LLMs, and allows flexible extension to new domains and modalities. Experiments show that our framework unlocks the multimodal reasoning capabilities for LLMs, enabling a lightweight and fully open-source solution, i.e. equipping text-only DeepSeek-R1 with Qwen2.5-VL-7B perceiver, to outperform large-scale proprietary VLMs such as GPT-4o on a wide range of knowledge-intensive multimodal tasks. These results demonstrate the effectiveness, modularity, and scalability of our multi-agent approach for building future multimodal reasoning systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19413v1" target="_blank"><h2>UniGame: Turning a Unified Multimodal Model Into Its Own Adversary</h2></a><strong><u>Authors:</u></strong> Zhaolong Su, Wang Lu, Hao Chen, Sharon Li, Jindong Wang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Unified Multimodal Models (UMMs) have shown impressive performance in both understanding and generation with a single architecture. However, UMMs still exhibit a fundamental inconsistency: understanding favors compact embeddings, whereas generation favors reconstruction-rich representations. This structural trade-off produces misaligned decision boundaries, degraded cross-modal coherence, and heightened vulnerability under distributional and adversarial shifts. In this paper, we present UniGame, a self-adversarial post-training framework that directly targets the inconsistencies. By applying a lightweight perturber at the shared token interface, UniGame enables the generation branch to actively seek and challenge fragile understanding, turning the model itself into its own adversary. Experiments demonstrate that UniGame significantly improves the consistency (+4.6%). Moreover, it also achieves substantial improvements in understanding (+3.6%), generation (+0.02), out-of-distribution and adversarial robustness (+4.8% and +6.2% on NaturalBench and AdVQA). The framework is architecture-agnostic, introduces less than 1% additional parameters, and is complementary to existing post-training methods. These results position adversarial self-play as a general and effective principle for enhancing the coherence, stability, and unified competence of future multimodal foundation models. The official code is available at: https://github.com/AIFrontierLab/UniGame</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19367v1" target="_blank"><h2>An Anatomy Aware Hybrid Deep Learning Framework for Lung Cancer Tumor Stage Classification</h2></a><strong><u>Authors:</u></strong> Saniah Kayenat Chowdhury, Rusab Sarmun, Muhammad E. H. Chowdhury, Sohaib Bassam Zoghoul, Israa Al-Hashimi, Adam Mushtak, Amith Khandakar<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate lung cancer tumor staging is crucial for prognosis and treatment planning. However, it remains challenging for end-to-end deep learning approaches, as such approaches often overlook spatial and anatomical information that are central to the tumor-node-metastasis system. The tumor stage depends on multiple quantitative criteria, including the tumor size and its proximity to the nearest anatomical structures, and small variations can alter the staging outcome. We propose a medically grounded hybrid pipeline that performs staging by explicitly measuring the tumor's size and distance properties rather than treating it as a pure image classification task. Our method employs specialized encoder-decoder networks to precisely segment the lung and adjacent anatomy, including the lobes, tumor, mediastinum, and diaphragm. Subsequently, we extract the necessary tumor properties, i.e. measure the largest tumor dimension and calculate the distance between the tumor and neighboring anatomical structures by a quantitative analysis of the segmentation masks. Finally, we apply rule-based tumor staging aligned with the medical guidelines. This novel framework has been evaluated on the Lung-PET-CT-Dx dataset, demonstrating superior performance compared to traditional deep learning models, achieving an overall classification accuracy of 91.36%. We report the per-stage F1-scores of 0.93 (T1), 0.89 (T2), 0.96 (T3), and 0.90 (T4), a critical evaluation aspect often omitted in prior literature. To our knowledge, this is the first study that embeds explicit clinical context into tumor stage classification. Unlike standard convolutional neural networks that operate in an uninterpretable "black box" manner, our method offers both state-of-the-art performance and transparent decision support.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19365v1" target="_blank"><h2>DeCo: Frequency-Decoupled Pixel Diffusion for End-to-End Image Generation</h2></a><strong><u>Authors:</u></strong> Zehong Ma, Longhui Wei, Shuai Wang, Shiliang Zhang, Qi Tian<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Project Page:this https URL. Code Repository:this https URL<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> VAE (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Pixel diffusion aims to generate images directly in pixel space in an end-to-end fashion. This approach avoids the limitations of VAE in the two-stage latent diffusion, offering higher model capacity. Existing pixel diffusion models suffer from slow training and inference, as they usually model both high-frequency signals and low-frequency semantics within a single diffusion transformer (DiT). To pursue a more efficient pixel diffusion paradigm, we propose the frequency-DeCoupled pixel diffusion framework. With the intuition to decouple the generation of high and low frequency components, we leverage a lightweight pixel decoder to generate high-frequency details conditioned on semantic guidance from the DiT. This thus frees the DiT to specialize in modeling low-frequency semantics. In addition, we introduce a frequency-aware flow-matching loss that emphasizes visually salient frequencies while suppressing insignificant ones. Extensive experiments show that DeCo achieves superior performance among pixel diffusion models, attaining FID of 1.62 (256x256) and 2.22 (512x512) on ImageNet, closing the gap with latent diffusion methods. Furthermore, our pretrained text-to-image model achieves a leading overall score of 0.86 on GenEval in system-level comparison. Codes are publicly available at https://github.com/Zehong-Ma/DeCo.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19364v1" target="_blank"><h2>Neural surrogates for designing gravitational wave detectors</h2></a><strong><u>Authors:</u></strong> Carlos Ruiz-Gonzalez, Sören Arlt, Sebastian Lehner, Arturs Berzins, Yehonathan Drori, Rana X Adhikari, Johannes Brandstetter, Mario Krenn<br><strong><u>Categories:</u></strong> cs.LG, astro-ph.IM, gr-qc, quant-ph<br><strong><u>Comments:</u></strong> 20 pages, 7 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Physics simulators are essential in science and engineering, enabling the analysis, control, and design of complex systems. In experimental sciences, they are increasingly used to automate experimental design, often via combinatorial search and optimization. However, as the setups grow more complex, the computational cost of traditional, CPU-based simulators becomes a major limitation. Here, we show how neural surrogate models can significantly reduce reliance on such slow simulators while preserving accuracy. Taking the design of interferometric gravitational wave detectors as a representative example, we train a neural network to surrogate the gravitational wave physics simulator Finesse, which was developed by the LIGO community. Despite that small changes in physical parameters can change the output by orders of magnitudes, the model rapidly predicts the quality and feasibility of candidate designs, allowing an efficient exploration of large design spaces. Our algorithm loops between training the surrogate, inverse designing new experiments, and verifying their properties with the slow simulator for further training. Assisted by auto-differentiation and GPU parallelism, our method proposes high-quality experiments much faster than direct optimization. Solutions that our algorithm finds within hours outperform designs that take five days for the optimizer to reach. Though shown in the context of gravitational wave detectors, our framework is broadly applicable to other domains where simulator bottlenecks hinder optimization and discovery.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19347v1" target="_blank"><h2>Artificial Intelligence Driven Workflow for Accelerating Design of Novel Photosensitizers</h2></a><strong><u>Authors:</u></strong> Hongyi Wang, Xiuli Zheng, Weimin Liu, Zitian Tang, Sheng Gong<br><strong><u>Categories:</u></strong> cond-mat.mtrl-sci, cs.LG, physics.chem-ph<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> The discovery of high-performance photosensitizers has long been hindered by the time-consuming and resource-intensive nature of traditional trial-and-error approaches. Here, we present \textbf{A}I-\textbf{A}ccelerated \textbf{P}hoto\textbf{S}ensitizer \textbf{I}nnovation (AAPSI), a closed-loop workflow that integrates expert knowledge, scaffold-based molecule generation, and Bayesian optimization to accelerate the design of novel photosensitizers. The scaffold-driven generation in AAPSI ensures structural novelty and synthetic feasibility, while the iterative AI-experiment loop accelerates the discovery of novel photosensitizers. AAPSI leverages a curated database of 102,534 photosensitizer-solvent pairs and generate 6,148 synthetically accessible candidates. These candidates are screened via graph transformers trained to predict singlet oxygen quantum yield ($φ_Δ$) and absorption maxima ($λ_{max}$), following experimental validation. This work generates several novel candidates for photodynamic therapy (PDT), among which the hypocrellin-based candidate HB4Ph exhibits exceptional performance at the Pareto frontier of high quantum yield of singlet oxygen and long absorption maxima among current photosensitizers ($φ_Δ$=0.85, $λ_{max}$=650nm).</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19342v1" target="_blank"><h2>Explicit Tonal Tension Conditioning via Dual-Level Beam Search for Symbolic Music Generation</h2></a><strong><u>Authors:</u></strong> Maral Ebrahimzadeh, Gilberto Bernardes, Sebastian Stober<br><strong><u>Categories:</u></strong> cs.SD, cs.AI<br><strong><u>Comments:</u></strong> 12 pages, 2 Figures, Accepted at the 17th International Symposium on Computer Music Multidisciplinary Research (CMMR) 2025<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> State-of-the-art symbolic music generation models have recently achieved remarkable output quality, yet explicit control over compositional features, such as tonal tension, remains challenging. We propose a novel approach that integrates a computational tonal tension model, based on tonal interval vector analysis, into a Transformer framework. Our method employs a two-level beam search strategy during inference. At the token level, generated candidates are re-ranked using model probability and diversity metrics to maintain overall quality. At the bar level, a tension-based re-ranking is applied to ensure that the generated music aligns with a desired tension curve. Objective evaluations indicate that our approach effectively modulates tonal tension, and subjective listening tests confirm that the system produces outputs that align with the target tension. These results demonstrate that explicit tension conditioning through a dual-level beam search provides a powerful and intuitive tool to guide AI-generated music. Furthermore, our experiments demonstrate that our method can generate multiple distinct musical interpretations under the same tension condition.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19341v1" target="_blank"><h2>Systematic assessment of the Hubble tension via Bayesian jackknife testing <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Thomas Hughes, Michael J. Wilensky, Philip Bull<br><strong><u>Categories:</u></strong> astro-ph.CO<br><strong><u>Comments:</u></strong> 13 pages, 8 figures. For the busy reader: jump to figures 6 and 8<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Statistically-significant differences in the value of the Hubble parameter are found depending on the measurement method that is used, a result known as the Hubble tension. A variety of ways of comparing, grouping, and excluding measurements have been used to try to explain this, either in terms of physical effects or systematic errors. We present a systematic 'Bayesian jackknife' analysis of 16 independent measurements of the Hubble parameter in an attempt to identify whether the measurements fall into meaningful clusters that would help explain the origin of the tension. After evaluating evidence ratios for the commonly-used split into early- vs late-time measurements, we then study a range of simplified alternative physical scenarios that reflect different physical origins of an apparent bias or shift in the value of $H_0$, assigning phenomenological population parameters to each subset. These include scenarios where specific subsets are biased (e.g. due to unrecognised experimental systematics in the local distance ladder or cosmic microwave background measurements), as well as more cosmologically-motivated cases involving modifications to the expansion history. Many of these scenarios have similar marginal likelihood, but the model where no measurements are biased is strongly disfavoured. Finally, we marginalise over all these scenarios to estimate the 'model agnostic' posterior distribution of $H_0$. The resulting distribution is mildly multi-modal, but modestly favours values near $H_0=68$ km/s/Mpc, with a 95\% credible region of $66.7 < H_0 < 72.7$ km/s/Mpc.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19332v1" target="_blank"><h2>Revisiting model-independent constraints on spatial curvature and cosmic ladders calibration: updated and forecast analyses <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Arianna Favale, Adrià Gómez-Valent, Marina Migliaccio<br><strong><u>Categories:</u></strong> astro-ph.CO<br><strong><u>Comments:</u></strong> 15 pages, 5 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> VAE (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Model-independent approaches have gained increasing attention as powerful tools to investigate persistent tensions between cosmological observations and the predictions of $Λ$CDM. Notably, recent DESY5 Type Ia Supernovae (SNIa) and DESI Baryon Acoustic Oscillation (BAO) data challenge the validity of the cosmological constant, and they remain in tension with SH0ES local distance ladder measurements under standard pre-recombination physics. Building on our previous work, MNRAS 523 (2023) 3, 3406-3422, we present a follow-up analysis of the model-independent calibration of the local and inverse distance ladders using cosmic chronometers (CCH) data and Gaussian Processes. We jointly constrain the SNIa absolute magnitude, $M$, the comoving sound horizon at the baryon-drag epoch, $r_d$, and the spatial curvature parameter, $Ω_k$, using CCH with DESY5 and DESI DR1/DR2. We find this data combination compatible with a flat universe at $\sim1.7σ$, with $Ω_k=-0.143\pm0.085$, showing weaker compatibility than with Pantheon+, while the ladder calibrators read $M=-19.324_{-0.095}^{+0.092}$ and $r_d=(144.00^{+5.38}_{-4.88}$) Mpc. Although current uncertainties limit the precision of our constraints and prevent us from arbitrating the Hubble tension, it is nevertheless instructive to explore the constraining power of our methodology with future SNIa, CCH, and BAO from surveys such as LSST, Euclid, and DESI. We present the first forecast analysis for the triad $(M,Ω_k,r_d)$, finding that, in an optimistic scenario, upcoming data will improve agnostic constraints on $M$ by $\sim$54% and on $r_d$ by $\sim$66%, enabling a $\sim2$% determination of $H_0$. Precision on $Ω_k$ will increase by $\sim50$%. Our analysis outlines which improvements in future data - whether in quality, quantity, or redshift coverage - are likely to most effectively tighten these constraints.[abridged]</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19328v1" target="_blank"><h2>Understanding the Staged Dynamics of Transformers in Learning Latent Structure</h2></a><strong><u>Authors:</u></strong> Rohan Saha, Farzane Aminmansour, Alona Fyshe<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Preprint<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> While transformers can discover latent structure from context, the dynamics of how they acquire different components of the latent structure remain poorly understood. In this work, we use the Alchemy benchmark, to investigate the dynamics of latent structure learning. We train a small decoder-only transformer on three task variants: 1) inferring missing rules from partial contextual information, 2) composing simple rules to solve multi-step sequences, and 3) decomposing complex multi-step examples to infer intermediate steps. By factorizing each task into interpretable events, we show that the model acquires capabilities in discrete stages, first learning the coarse grained rules, before learning the complete latent structure. We also identify a crucial asymmetry, where the model can compose fundamental rules robustly, but struggles to decompose complex examples to discover the fundamental rules. These findings offer new insights into understanding how a transformer model learns latent structures, providing a granular view of how these capabilities evolve during training.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19313v1" target="_blank"><h2>The TEQUILA catalog of variables in TESS full-frame images: Differential photometry light curves from the first two years of observations</h2></a><strong><u>Authors:</u></strong> Bisi Bernard Ogunwale, Yossi Zaguri, Volker Perdelwitz, Marcel V"olschow, Sagi Yosef Azulay, Dafne Guetta, Lev Tal-Or<br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.IM<br><strong><u>Comments:</u></strong> Accepted: Astronomy and Astrophysics<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Stellar variability and transient events provide critical insights into astrophysics, accelerated by missions like CoRoT, Kepler, and K2. NASA's Transiting Exoplanet Survey Satellite (TESS) adds a unique combination of long baseline and all-sky coverage, though extracting light curves from full-frame images (FFIs) is challenging due to scattered light and blending. We processed TESS FFIs to produce TEQUILA (TESS quick-look and light curve analysis), a comprehensive catalog of variable point sources from the prime mission, enabling diverse studies without requiring raw data processing. We used difference image analysis, constructing reference images from quality-filtered FFIs for each CCD across sectors 1-26. Iterative subtraction mitigated systematics, and light curves were created using aperture photometry for sources varying in residual images. The pipeline yields over six million light curves, including stellar variables, transients, systematics, and moving objects. Approximately $6 \times 10^5$ span multiple sectors, with roughly $10^3$ from continuous viewing zones. We achieve median differential variability noise of $10^{-3}$ to $10^0$ for sources between 5.0 and 16.0 Tmag, while typical photometric RMS variability ranges from $10^{-2}$ to $10^1$. A convolutional neural network identifies light curves caused by instrumental noise, assigning a confidence score to each classification. To avoid confusion with astrophysical variables, we also flag light curves prompted by known Solar System objects (SSOs). All light curves are accessible via MAST as a High-Level Science Product. This catalog serves as a discovery tool for new variables; future work will refine methods and extend coverage to the TESS extended mission.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19289v1" target="_blank"><h2>Performance Guarantees for Quantum Neural Estimation of Entropies</h2></a><strong><u>Authors:</u></strong> Sreejith Sreekumar, Ziv Goldfeld, Mark M. Wilde<br><strong><u>Categories:</u></strong> quant-ph, cs.IT, cs.LG<br><strong><u>Comments:</u></strong> 42+4 pages<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Estimating quantum entropies and divergences is an important problem in quantum physics, information theory, and machine learning. Quantum neural estimators (QNEs), which utilize a hybrid classical-quantum architecture, have recently emerged as an appealing computational framework for estimating these measures. Such estimators combine classical neural networks with parametrized quantum circuits, and their deployment typically entails tedious tuning of hyperparameters controlling the sample size, network architecture, and circuit topology. This work initiates the study of formal guarantees for QNEs of measured (Rényi) relative entropies in the form of non-asymptotic error risk bounds. We further establish exponential tail bounds showing that the error is sub-Gaussian, and thus sharply concentrates about the ground truth value. For an appropriate sub-class of density operator pairs on a space of dimension $d$ with bounded Thompson metric, our theory establishes a copy complexity of $O(|Θ(\mathcal{U})|d/ε^2)$ for QNE with a quantum circuit parameter set $Θ(\mathcal{U})$, which has minimax optimal dependence on the accuracy $ε$. Additionally, if the density operator pairs are permutation invariant, we improve the dimension dependence above to $O(|Θ(\mathcal{U})|\mathrm{polylog}(d)/ε^2)$. Our theory aims to facilitate principled implementation of QNEs for measured relative entropies and guide hyperparameter tuning in practice.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19279v1" target="_blank"><h2>MapFormer: Self-Supervised Learning of Cognitive Maps with Input-Dependent Positional Embeddings</h2></a><strong><u>Authors:</u></strong> Victor Rambaud, Salvador Mascarenhas, Yair Lakretz<br><strong><u>Categories:</u></strong> cs.LG, cs.CL<br><strong><u>Comments:</u></strong> 19 pages (29 with appendix), 8 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> A cognitive map is an internal model which encodes the abstract relationships among entities in the world, giving humans and animals the flexibility to adapt to new situations, with a strong out-of-distribution (OOD) generalization that current AI systems still do not possess. To bridge this gap, we introduce MapFormers, new architectures based on Transformer models, which can learn cognitive maps from observational data and perform path integration in parallel, in a self-supervised manner. Cognitive maps are learned in the model by disentangling structural relationships in the inputs from their specific content, a property that can be achieved naturally by updating the positional encoding in Transformers with input-dependent matrices. We developed two variants of MapFormers that unify absolute and relative positional encoding to model episodic (EM) and working memory (WM), respectively. We tested MapFormers on several tasks, including a classic 2D navigation task, showing that our models can learn a cognitive map of the underlying space and generalize OOD (e.g., to longer sequences) with near-perfect performance, unlike current architectures. Together, these results demonstrate the superiority of models designed to learn a cognitive map, and the importance of introducing a structural bias for structure-content disentanglement, which can be achieved in Transformers with input-dependent positional encoding. MapFormers have broad applications in both neuroscience and AI, by explaining the neural mechanisms giving rise to cognitive maps, while allowing these relation models to be learned at scale.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19277v1" target="_blank"><h2>Closing Gaps in Emissions Monitoring with Climate TRACE</h2></a><strong><u>Authors:</u></strong> Brittany V. Lancellotti, Jordan M. Malof, Aaron Davitt, Gavin McCormick, Shelby Anderson, Pol Carbó-Mestre, Gary Collins, Verity Crane, Zoheyr Doctor, George Ebri, Kevin Foster, Trey M. Gowdy, Michael Guzzardi, John Heal, Heather Hunter, David Kroodsma, Khandekar Mahammad Galib, Paul J. Markakis, Gavin McDonald, Daniel P. Moore, Eric D. Nguyen, Sabina Parvu, Michael Pekala, Christine D. Piatko, Amy Piscopo, Mark Powell, Krsna Raniga, Elizabeth P. Reilly, Michael Robinette, Ishan Saraswat, Patrick Sicurello, Isabella Söldner-Rembold, Raymond Song, Charlotte Underwood, Kyle Bradbury<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Global greenhouse gas emissions estimates are essential for monitoring and mitigation planning. Yet most datasets lack one or more characteristics that enhance their actionability, such as accuracy, global coverage, high spatial and temporal resolution, and frequent updates. To address these gaps, we present Climate TRACE (climatetrace.org), an open-access platform delivering global emissions estimates with enhanced detail, coverage, and timeliness. Climate TRACE synthesizes existing emissions data, prioritizing accuracy, coverage, and resolution, and fills gaps using sector-specific estimation approaches. The dataset is the first to provide globally comprehensive emissions estimates for individual sources (e.g., individual power plants) for all anthropogenic emitting sectors. The dataset spans January 1, 2021, to the present, with a two-month reporting lag and monthly updates. The open-access platform enables non-technical audiences to engage with detailed emissions datasets for most subnational governments worldwide. Climate TRACE supports data-driven climate action at scales where decisions are made, representing a major breakthrough for emissions accounting and mitigation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19275v1" target="_blank"><h2>Dynamic Multi-Species Bird Soundscape Generation with Acoustic Patterning and 3D Spatialization</h2></a><strong><u>Authors:</u></strong> Ellie L. Zhang, Duoduo Liao, Callie C. Liao<br><strong><u>Categories:</u></strong> cs.SD, cs.AI, eess.AS, eess.SP<br><strong><u>Comments:</u></strong> Accepted by IEEE Big Data 2025<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Generation of dynamic, scalable multi-species bird soundscapes remains a significant challenge in computer music and algorithmic sound design. Birdsongs involve rapid frequency-modulated chirps, complex amplitude envelopes, distinctive acoustic patterns, overlapping calls, and dynamic inter-bird interactions, all of which require precise temporal and spatial control in 3D environments. Existing approaches, whether Digital Signal Processing (DSP)-based or data-driven, typically focus only on single species modeling, static call structures, or synthesis directly from recordings, and often suffer from noise, limited flexibility, or large data needs. To address these challenges, we present a novel, fully algorithm-driven framework that generates dynamic multi-species bird soundscapes using DSP-based chirp generation and 3D spatialization, without relying on recordings or training data. Our approach simulates multiple independently-moving birds per species along different moving 3D trajectories, supporting controllable chirp sequences, overlapping choruses, and realistic 3D motion in scalable soundscapes while preserving species-specific acoustic patterns. A visualization interface provides bird trajectories, spectrograms, activity timelines, and sound waves for analytical and creative purposes. Both visual and audio evaluations demonstrate the ability of the system to generate dense, immersive, and ecologically inspired soundscapes, highlighting its potential for computer music, interactive virtual environments, and computational bioacoustics research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19272v1" target="_blank"><h2>Tiny-TSM: Efficiently Training a Lightweight SOTA Time Series Foundation Model</h2></a><strong><u>Authors:</u></strong> Felix Birkel<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> We present Tiny-TSM, a time series foundation model characterized by small scale, economical training, and state-of-the-art performance. It comprises 23M total parameters, trained on a single A100 GPU in less than a week using a new synthetic data generation and data augmentation pipeline (SynthTS). Without any neural architecture search, hyperparameter tuning, or scaling up model size, Tiny-TSM achieves state-of-the-art performance on a wide range of time series benchmark datasets, often outperforming much larger models and even matching the performance of much larger, industrial-scale, likely highly tuned foundation models. Specifically, Tiny-TSM outperforms all other time series foundation models we evaluated on medium- and long-term forecasting tasks under MSE loss, while short-term accuracy is still competitive with state-of-the-art models.
  We also introduce a causal input normalization scheme that enables time series models to be trained with dense next-token prediction loss, significantly accelerating convergence speed and reducing training time.
  All experiments were conducted on a single A100 GPU, illustrating the practicality of the proposed approach in a resource-constrained setting.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19269v1" target="_blank"><h2>CDLM: Consistency Diffusion Language Models For Faster Sampling</h2></a><strong><u>Authors:</u></strong> Minseo Kim, Chenfeng Xu, Coleman Hooper, Harman Singh, Ben Athiwaratkun, Ce Zhang, Kurt Keutzer, Amir Gholami<br><strong><u>Categories:</u></strong> cs.LG, cs.CL<br><strong><u>Comments:</u></strong> 18 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Diffusion Language Models (DLMs) offer a promising parallel generation paradigm but suffer from slow inference due to numerous refinement steps and the inability to use standard KV caching. We introduce CDLM (Consistency Diffusion Language Models), a training-based acceleration method that simultaneously tackles both bottlenecks. CDLM integrates consistency modeling to drastically reduce the number of required sampling steps by enabling multi-token finalization. Furthermore, we enforce a block-wise causal attention mask during fine-tuning, making the model fully compatible with KV caching. Experiments show CDLM achieves 3.6x-14.5x lower latency while maintaining competitive accuracy on math and coding tasks. The full training and evaluation code is available at https://github.com/SqueezeAILab/CDLM.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19267v1" target="_blank"><h2>Leveraging Spatiotemporal Graph Neural Networks for Multi-Store Sales Forecasting</h2></a><strong><u>Authors:</u></strong> Manish Singh, Arpita Dayama<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 6 pages, 4 figures, 1 table<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> This work evaluates the effectiveness of spatiotemporal Graph Neural Networks (GNNs) for multi-store retail sales forecasting and compares their performance against ARIMA, LSTM, and XGBoost baselines. Using weekly sales data from 45 Walmart stores, we construct a relational forecasting framework that models inter-store dependencies through a learned adaptive graph. The proposed STGNN predicts log-differenced sales and reconstructs final values through a residual path, enabling stable training and improved generalisation. Experiments show that STGNN achieves the lowest overall forecasting error, outperforming all baselines in Normalised Total Absolute Error, P90 MAPE, and variance of MAPE across stores. Analysis of the learned adjacency matrix reveals meaningful functional store clusters and high-influence nodes that emerge without geographic metadata. These results demonstrate that relational structure significantly improves forecast quality in interconnected retail environments and establishes STGNNs as a robust modelling choice for multi-store demand prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19265v1" target="_blank"><h2>Unboxing the Black Box: Mechanistic Interpretability for Algorithmic Understanding of Neural Networks</h2></a><strong><u>Authors:</u></strong> Bianka Kowalska, Halina Kwaśnicka<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> explainable (abstract), neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> The black box nature of deep neural networks poses a significant challenge for the deployment of transparent and trustworthy artificial intelligence (AI) systems. With the growing presence of AI in society, it becomes increasingly important to develop methods that can explain and interpret the decisions made by these systems. To address this, mechanistic interpretability (MI) emerged as a promising and distinctive research program within the broader field of explainable artificial intelligence (XAI). MI is the process of studying the inner computations of neural networks and translating them into human-understandable algorithms. It encompasses reverse engineering techniques aimed at uncovering the computational algorithms implemented by neural networks. In this article, we propose a unified taxonomy of MI approaches and provide a detailed analysis of key techniques, illustrated with concrete examples and pseudo-code. We contextualize MI within the broader interpretability landscape, comparing its goals, methods, and insights to other strands of XAI. Additionally, we trace the development of MI as a research area, highlighting its conceptual roots and the accelerating pace of recent work. We argue that MI holds significant potential to support a more scientific understanding of machine learning systems -- treating models not only as tools for solving tasks, but also as systems to be studied and understood. We hope to invite new researchers into the field of mechanistic interpretability.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19263v1" target="_blank"><h2>Solar-GECO: Perovskite Solar Cell Property Prediction with Geometric-Aware Co-Attention</h2></a><strong><u>Authors:</u></strong> Lucas Li, Jean-Baptiste Puel, Florence Carton, Dounya Barrit, Jhony H. Giraldo<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted at the AI for Accelerated Materials Design (AI4Mat) Workshop at NeurIPS 2025. 14 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Perovskite solar cells are promising candidates for next-generation photovoltaics. However, their performance as multi-scale devices is determined by complex interactions between their constituent layers. This creates a vast combinatorial space of possible materials and device architectures, making the conventional experimental-based screening process slow and expensive. Machine learning models try to address this problem, but they only focus on individual material properties or neglect the important geometric information of the perovskite crystal. To address this problem, we propose to predict perovskite solar cell power conversion efficiency with a geometric-aware co-attention (Solar-GECO) model. Solar-GECO combines a geometric graph neural network (GNN) - that directly encodes the atomic structure of the perovskite absorber - with language model embeddings that process the textual strings representing the chemical compounds of the transport layers and other device components. Solar-GECO also integrates a co-attention module to capture intra-layer dependencies and inter-layer interactions, while a probabilistic regression head predicts both power conversion efficiency (PCE) and its associated uncertainty. Solar-GECO achieves state-of-the-art performance, significantly outperforming several baselines, reducing the mean absolute error (MAE) for PCE prediction from 3.066 to 2.936 compared to semantic GNN (the previous state-of-the-art model). Solar-GECO demonstrates that integrating geometric and textual information provides a more powerful and accurate framework for PCE prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19260v1" target="_blank"><h2>A Nutrition Multimodal Photoplethysmography Language Model</h2></a><strong><u>Authors:</u></strong> Kyle Verrier, Achille Nazaret, Joseph Futoma, Andrew C. Miller, Guillermo Sapiro<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> 21 pages, 2 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title)<br><p><strong><u>Abstract:</u></strong> Hunger and satiety dynamics shape dietary behaviors and metabolic health, yet remain difficult to capture in everyday settings. We present a Nutrition Photoplethysmography Language Model (NPLM), integrating continuous photoplethysmography (PPG) from wearables with meal descriptions. NPLM projects PPG into embeddings interpretable by language models, enabling joint reasoning over physiology and meal context. Trained on 19,340 participants and 1.1 million meal-PPG pairs, the model improved daily caloric intake prediction by 11% over text-only baselines, with accuracy maintained when 80% of meal text was removed. In an independent validation study (n=140) with controlled dining and detailed meal information, the model replicated these findings. These results demonstrate the value of integrating physiological measurements from consumer wearables with meal information for noninvasive dietary monitoring at scale.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19257v1" target="_blank"><h2>Medusa: Cross-Modal Transferable Adversarial Attacks on Multimodal Medical Retrieval-Augmented Generation</h2></a><strong><u>Authors:</u></strong> Yingjia Shang, Yi Liu, Huimin Wang, Furong Li, Wenfang Sun, Wu Chengyu, Yefeng Zheng<br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Accepted at KDD 2026 First Cycle (full version). Authors marked with * contributed equally. Yi Liu is the lead author<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> With the rapid advancement of retrieval-augmented vision-language models, multimodal medical retrieval-augmented generation (MMed-RAG) systems are increasingly adopted in clinical decision support. These systems enhance medical applications by performing cross-modal retrieval to integrate relevant visual and textual evidence for tasks, e.g., report generation and disease diagnosis. However, their complex architecture also introduces underexplored adversarial vulnerabilities, particularly via visual input perturbations. In this paper, we propose Medusa, a novel framework for crafting cross-modal transferable adversarial attacks on MMed-RAG systems under a black-box setting. Specifically, Medusa formulates the attack as a perturbation optimization problem, leveraging a multi-positive InfoNCE loss (MPIL) to align adversarial visual embeddings with medically plausible but malicious textual targets, thereby hijacking the retrieval process. To enhance transferability, we adopt a surrogate model ensemble and design a dual-loop optimization strategy augmented with invariant risk minimization (IRM). Extensive experiments on two real-world medical tasks, including medical report generation and disease diagnosis, demonstrate that Medusa achieves over 90% average attack success rate across various generation models and retrievers under appropriate parameter configuration, while remaining robust against four mainstream defenses, outperforming state-of-the-art baselines. Our results reveal critical vulnerabilities in the MMed-RAG systems and highlight the necessity of robustness benchmarking in safety-critical medical applications. The code and data are available at https://anonymous.4open.science/r/MMed-RAG-Attack-F05A.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19256v1" target="_blank"><h2>SimDiff: Simpler Yet Better Diffusion Model for Time Series Point Forecasting</h2></a><strong><u>Authors:</u></strong> Hang Ding, Xue Wang, Tian Zhou, Tao Yao<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Accepted by AAAI 2026<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Diffusion models have recently shown promise in time series forecasting, particularly for probabilistic predictions. However, they often fail to achieve state-of-the-art point estimation performance compared to regression-based methods. This limitation stems from difficulties in providing sufficient contextual bias to track distribution shifts and in balancing output diversity with the stability and precision required for point forecasts. Existing diffusion-based approaches mainly focus on full-distribution modeling under probabilistic frameworks, often with likelihood maximization objectives, while paying little attention to dedicated strategies for high-accuracy point estimation. Moreover, other existing point prediction diffusion methods frequently rely on pre-trained or jointly trained mature models for contextual bias, sacrificing the generative flexibility of diffusion models.
  To address these challenges, we propose SimDiff, a single-stage, end-to-end framework. SimDiff employs a single unified Transformer network carefully tailored to serve as both denoiser and predictor, eliminating the need for external pre-trained or jointly trained regressors. It achieves state-of-the-art point estimation performance by leveraging intrinsic output diversity and improving mean squared error accuracy through multiple inference ensembling. Key innovations, including normalization independence and the median-of-means estimator, further enhance adaptability and stability. Extensive experiments demonstrate that SimDiff significantly outperforms existing methods in time series point forecasting.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19254v1" target="_blank"><h2>Adversarial Patch Attacks on Vision-Based Cargo Occupancy Estimation via Differentiable 3D Simulation</h2></a><strong><u>Authors:</u></strong> Mohamed Rissal Hedna, Sesugh Samuel Nder<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 9 pages, 5 figures, 1 algorithm<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> Computer vision systems are increasingly adopted in modern logistics operations, including the estimation of trailer occupancy for planning, routing, and billing. Although effective, such systems may be vulnerable to physical adversarial attacks, particularly adversarial patches that can be printed and placed on interior surfaces. In this work, we study the feasibility of such attacks on a convolutional cargo-occupancy classifier using fully simulated 3D environments. Using Mitsuba 3 for differentiable rendering, we optimize patch textures across variations in geometry, lighting, and viewpoint, and compare their effectiveness to a 2D compositing baseline. Our experiments demonstrate that 3D-optimized patches achieve high attack success rates, especially in a denial-of-service scenario (empty to full), where success reaches 84.94 percent. Concealment attacks (full to empty) prove more challenging but still reach 30.32 percent. We analyze the factors influencing attack success, discuss implications for the security of automated logistics pipelines, and highlight directions for strengthening physical robustness. To our knowledge, this is the first study to investigate adversarial patch attacks for cargo-occupancy estimation in physically realistic, fully simulated 3D scenes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19246v1" target="_blank"><h2>Neural Architecture Search for Quantum Autoencoders</h2></a><strong><u>Authors:</u></strong> Hibah Agha, Samuel Yen-Chi Chen, Huan-Hsin Tseng, Shinjae Yoo<br><strong><u>Categories:</u></strong> quant-ph, cs.AI, cs.LG, cs.NE<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> In recent years, machine learning and deep learning have driven advances in domains such as image classification, speech recognition, and anomaly detection by leveraging multi-layer neural networks to model complex data. Simultaneously, quantum computing (QC) promises to address classically intractable problems via quantum parallelism, motivating research in quantum machine learning (QML). Among QML techniques, quantum autoencoders show promise for compressing high-dimensional quantum and classical data. However, designing effective quantum circuit architectures for quantum autoencoders remains challenging due to the complexity of selecting gates, arranging circuit layers, and tuning parameters.
  This paper proposes a neural architecture search (NAS) framework that automates the design of quantum autoencoders using a genetic algorithm (GA). By systematically evolving variational quantum circuit (VQC) configurations, our method seeks to identify high-performing hybrid quantum-classical autoencoders for data reconstruction without becoming trapped in local minima. We demonstrate effectiveness on image datasets, highlighting the potential of quantum autoencoders for efficient feature extraction within a noise-prone, near-term quantum era. Our approach lays a foundation for broader application of genetic algorithms to quantum architecture search, aiming for a robust, automated method that can adapt to varied data and hardware constraints.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19243v1" target="_blank"><h2>What do gravitational-wave observations tell us about Luminous Red Novae?</h2></a><strong><u>Authors:</u></strong> Dhruv Jain, Shasvath J. Kapadia, Kuntal Misra, Dimple, L. Resmi, Ajay Kumar Singh, K. G. Arun<br><strong><u>Categories:</u></strong> astro-ph.HE<br><strong><u>Comments:</u></strong> 7 Pages, 3 figures, 1 Table; To be Submitted in ApJL<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> VAE (title, abstract)<br><p><strong><u>Abstract:</u></strong> Luminous Red Novae (LRNe) have been argued to be related to the ejection of common envelopes (CEs) in binary star systems. Ejection of CEs leads to tightened stellar orbits capable of forming compact binaries that merge in Hubble time. As these mergers are seen by gravitational-wave (GW) detectors such as LIGO, Virgo and KAGRA (LVK), we ask what the merger rates of compact binaries in LVK tell us about the fraction of LRNe that lead to the formation of compact binaries that merge in Hubble time. Using the observed volumetric rates of LRNe from the Zwicky Transient Facility (ZTF) and of compact binary mergers from LVK observations, we derive limits on the fraction of LRNe that produce compact binaries that merge in Hubble time. Assuming the LRNe rate closely follows the star formation rate at any redshift, we use the delay time distribution models for compact binaries to compute the compact binary merger rate. A comparison of this merger rate with the latest volumetric rates of compact binary mergers from the fourth GW transient catalog (GWTC-4) at the present epoch of LVK allows us to constrain the above fraction. We find that only a fraction as small as $\sim 10^{-3}$ (median) of the LRNe correspond to the GW-observed binary neutron star (BNS) and neutron star-black hole (NSBH) mergers. This potentially implies that the majority of the LRNe population will not lead to mergers of compact objects, but other end products, such as stellar mergers.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19240v1" target="_blank"><h2>Empirical Comparison of Forgetting Mechanisms for UCB-based Algorithms on a Data-Driven Simulation Platform</h2></a><strong><u>Authors:</u></strong> Minxin Chen<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract)<br><p><strong><u>Abstract:</u></strong> Many real-world bandit problems involve non-stationary reward distributions, where the optimal decision may shift due to evolving environments. However, the performance of some typical Multi-Armed Bandit (MAB) models such as Upper Confidence Bound (UCB) algorithms degrades significantly in non-stationary environments where reward distributions change over time. To address this limitation, this paper introduces and evaluates FDSW-UCB, a novel dual-view algorithm that integrates a discount-based long-term perspective with a sliding-window-based short-term view. A data-driven semi-synthetic simulation platform, built upon the MovieLens-1M and Open Bandit datasets, is developed to test algorithm adaptability under abrupt and gradual drift scenarios. Experimental results demonstrate that a well-configured sliding-window mechanism (SW-UCB) is robust, while the widely used discounting method (D-UCB) suffers from a fundamental learning failure, leading to linear regret. Crucially, the proposed FDSW-UCB, when employing an optimistic aggregation strategy, achieves superior performance in dynamic settings, highlighting that the ensemble strategy itself is a decisive factor for success.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19236v1" target="_blank"><h2>SENTINEL: A Fully End-to-End Language-Action Model for Humanoid Whole Body Control</h2></a><strong><u>Authors:</u></strong> Yuxuan Wang, Haobin Jiang, Shiqing Yao, Ziluo Ding, Zongqing Lu<br><strong><u>Categories:</u></strong> cs.RO, cs.AI<br><strong><u>Comments:</u></strong> 23 pages, 8 figures, 11 tables<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Existing humanoid control systems often rely on teleoperation or modular generation pipelines that separate language understanding from physical execution. However, the former is entirely human-driven, and the latter lacks tight alignment between language commands and physical behaviors. In this paper, we present SENTINEL, a fully end-to-end language-action model for humanoid whole-body control. We construct a large-scale dataset by tracking human motions in simulation using a pretrained whole body controller, combined with their text annotations. The model directly maps language commands and proprioceptive inputs to low-level actions without any intermediate representation. The model generates action chunks using flow matching, which can be subsequently refined by a residual action head for real-world deployment. Our method exhibits strong semantic understanding and stable execution on humanoid robots in both simulation and real-world deployment, and also supports multi-modal extensions by converting inputs into texts.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19232v1" target="_blank"><h2>In Machina N400: Pinpointing Where a Causal Language Model Detects Semantic Violations</h2></a><strong><u>Authors:</u></strong> Christos-Nikolaos Zacharopoulos, Revekka Kyriakoglou<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> Accepted at AICS2025<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> How and where does a transformer notice that a sentence has gone semantically off the rails? To explore this question, we evaluated the causal language model (phi-2) using a carefully curated corpus, with sentences that concluded plausibly or implausibly. Our analysis focused on the hidden states sampled at each model layer. To investigate how violations are encoded, we utilized two complementary probes. First, we conducted a per-layer detection using a linear probe. Our findings revealed that a simple linear decoder struggled to distinguish between plausible and implausible endings in the lowest third of the model's layers. However, its accuracy sharply increased in the middle blocks, reaching a peak just before the top layers. Second, we examined the effective dimensionality of the encoded violation. Initially, the violation widens the representational subspace, followed by a collapse after a mid-stack bottleneck. This might indicate an exploratory phase that transitions into rapid consolidation. Taken together, these results contemplate the idea of alignment with classical psycholinguistic findings in human reading, where semantic anomalies are detected only after syntactic resolution, occurring later in the online processing sequence.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19229v1" target="_blank"><h2>Learning Plug-and-play Memory for Guiding Video Diffusion Models</h2></a><strong><u>Authors:</u></strong> Selena Song, Ziming Xu, Zijun Zhang, Kun Zhou, Jiaxian Guo, Lianhui Qin, Biwei Huang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Diffusion Transformer(DiT) based video generation models have recently achieved impressive visual quality and temporal coherence, but they still frequently violate basic physical laws and commonsense dynamics, revealing a lack of explicit world knowledge. In this work, we explore how to equip them with a plug-and-play memory that injects useful world knowledge. Motivated by in-context memory in Transformer-based LLMs, we conduct empirical studies to show that DiT can be steered via interventions on its hidden states, and simple low-pass and high-pass filters in the embedding space naturally disentangle low-level appearance and high-level physical/semantic cues, enabling targeted guidance. Building on these observations, we propose a learnable memory encoder DiT-Mem, composed of stacked 3D CNNs, low-/high-pass filters, and self-attention layers. The encoder maps reference videos into a compact set of memory tokens, which are concatenated as the memory within the DiT self-attention layers. During training, we keep the diffusion backbone frozen, and only optimize the memory encoder. It yields a rather efficient training process on few training parameters (150M) and 10K data samples, and enables plug-and-play usage at inference time. Extensive experiments on state-of-the-art models demonstrate the effectiveness of our method in improving physical rule following and video fidelity. Our code and data are publicly released here: https://thrcle421.github.io/DiT-Mem-Web/.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19207v1" target="_blank"><h2>Inclinations and Position Angles for Disc Galaxies in the SGA sample <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Megan H. Martinez, Michael S. Petersen, Carrie Filion, Rashid Yaaqib, Claire Larson<br><strong><u>Categories:</u></strong> astro-ph.GA, physics.data-an<br><strong><u>Comments:</u></strong> 12 pages, 9 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> We present a data-driven method for determining the inclination and position angle (PA) of disc galaxies using a Fourier-Laguerre basis decomposition of imaging data. We define a dimensionless metric, $η$, that characterises the ratio of the quadrupole and monopole coefficients in the Fourier-Laguerre basis function expansion. This metric serves as a robust measure which is related to the inclination of a galaxy. We find an empirical relationship between $η$ and inclination which is agnostic to the galaxy morphology. The PA is derived directly from the phase of the quadrupolar Fourier-Laguerre functions. Across a benchmark sample of galaxies, the method reproduces published inclination and PA values to within a median of 10$^\circ$ and 5$^\circ$, respectively, while also demonstrating essentially zero catastrophic failures. Applying this pipeline to galaxies from the Siena Galaxy Atlas (SGA), we report measurements of $η$, scale length and PA for three different bands of 133,942 disc galaxies. Our computationally inexpensive technique automates parametrisation analysis and returns reproducible results for large surveys. We release a Python package ready for application to next generation surveys.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19199v1" target="_blank"><h2>CLASH: A Benchmark for Cross-Modal Contradiction Detection</h2></a><strong><u>Authors:</u></strong> Teodora Popordanoska, Jiameng Li, Matthew B. Blaschko<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> First two authors contributed equally<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Contradictory multimodal inputs are common in real-world settings, yet existing benchmarks typically assume input consistency and fail to evaluate cross-modal contradiction detection - a fundamental capability for preventing hallucinations and ensuring reliability. We introduce CLASH, a novel benchmark for multimodal contradiction detection, featuring COCO images paired with contradictory captions containing controlled object-level or attribute-level contradictions. The samples include targeted questions evaluated in both multiple-choice and open-ended formats. The benchmark provides an extensive fine-tuning set filtered through automated quality checks, alongside a smaller human-verified diagnostic set. Our analysis of state-of-the-art models reveals substantial limitations in recognizing cross-modal conflicts, exposing systematic modality biases and category-specific weaknesses. Furthermore, we empirically demonstrate that targeted fine-tuning on CLASH substantially enhances conflict detection capabilities.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19190v1" target="_blank"><h2>A search for photometric variability towards the globular cluster M3 with the TWenty Inch Survey Telescope</h2></a><strong><u>Authors:</u></strong> Morgan A. Mitchell, Paul Chote, James McCormac, Don Pollacco, Ioannis Apergis, J. D. Lyman, Isobel S. Lockley, Samuel Gill, James A. Blake, Alastair B. Claringbold, D. T. H. Steeghs, J. Casares<br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.SR<br><strong><u>Comments:</u></strong> 21 pages, 19 figures, accepted for publication in MNRAS<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> time-domain (abstract)<br><p><strong><u>Abstract:</u></strong> We present the commissioning results and first scientific observations from the newly installed TWIST observatory - a 50 cm telescope equipped with an sCMOS camera providing a $36.1\times24.1$ arcmin$^2$ field of view - housed in the former SuperWASP-North enclosure. We conducted a 67-night, 199-day baseline white-light monitoring campaign centred on the globular cluster M3 aimed at characterizing stellar variability within the cluster while also assessing the photometric performance of the newly commissioned system. We report the discovery of four new SX Phoenicis variables (V301-304), confirm their cluster membership, and identify fundamental-mode pulsation in one, allowing an independent period-luminosity-based distance estimate to M3. We revisited 231 previously known RR Lyrae stars, providing updated period measurements for 203 and white-light amplitudes for 198. We detected Blazhko-like modulation in 53 stars and characterized the modulation parameters for 28. Notably, we measure periods and amplitudes for the unclassified variables V286 and V287 for the first time. We also identify three foreground flaring M dwarfs, and assess the feasibility of detecting microlensing events in M3, concluding that expected rates are negligible. Alongside the scientific results, we introduce a new correction technique for flat-field images affected by scattered light and present a full characterization of the observatory's photometric capabilities. These results demonstrate the scientific utility of TWIST for high-cadence time-domain surveys using modest-aperture instrumentation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19179v1" target="_blank"><h2>Separating the Inseparable: Constraining Arbitrary Primordial Bispectra with Cosmic Microwave Background Data <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Oliver H. E. Philcox, Kunhao Zhong, Salvatore Samuele Sirletti<br><strong><u>Categories:</u></strong> astro-ph.CO, gr-qc, hep-ph, hep-th<br><strong><u>Comments:</u></strong> 16 pages, 6 figures. Submitted to Phys Rev D<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> To efficiently probe primordial non-Gaussianity using Cosmic Microwave Background (CMB) data, we require theoretical predictions that are factorizable, \textit{i.e.}\ those whose kinematic dependence can be separated. This property does not hold for many models, hindering their application to data. In this work, we introduce a general framework for constructing separable approximations to primordial bispectra, enabling direct CMB constraints on arbitrary models including those computed using numerical tools. In contrast to other approaches such as modal decompositions, we learn the basis functions directly from the data, allowing high-fidelity representations with just a handful of terms. This is practically implemented using machine-learning techniques, utilizing neural network basis functions and a loss function designed to mimic the CMB cosine similarity. We validate our pipeline using a variety of input bispectra, demonstrating that the approximations are $>99.5\%$ correlated with the truth with just three terms. By incorporating the neural basis into the \textsc{PolySpec} code, we derive KSW-type CMB estimators, which reproduce local- and equilateral-type non-Gaussianity to within $0.1σ$. As a proof-of-concept, we constrain two inflationary bispectra from the `cosmological collider' scenario; these feature an additional strongly-mixed particle sector and cannot be computed analytically. By combining the numerical predictions from \textsc{CosmoFlow} with our factorizable approach (with just three terms), we place novel constraints on the collider models using \textit{Planck} PR4 data, finding no detection of non-Gaussianity. Our method facilitates detailed studies of the inflationary paradigm, connecting modern theoretical tools with high-resolution observational data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19176v1" target="_blank"><h2>From Raw Features to Effective Embeddings: A Three-Stage Approach for Multimodal Recipe Recommendation</h2></a><strong><u>Authors:</u></strong> Jeeho Shin, Kyungho Kim, Kijung Shin<br><strong><u>Categories:</u></strong> cs.LG, cs.IR<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Recipe recommendation has become an essential task in web-based food platforms. A central challenge is effectively leveraging rich multimodal features beyond user-recipe interactions. Our analysis shows that even simple uses of multimodal signals yield competitive performance, suggesting that systematic enhancement of these signals is highly promising. We propose TESMR, a 3-stage framework for recipe recommendation that progressively refines raw multimodal features into effective embeddings through: (1) content-based enhancement using foundation models with multimodal comprehension, (2) relation-based enhancement via message propagation over user-recipe interactions, and (3) learning-based enhancement through contrastive learning with learnable embeddings. Experiments on two real-world datasets show that TESMR outperforms existing methods, achieving 7-15% higher Recall@10.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19168v1" target="_blank"><h2>RAVEN++: Pinpointing Fine-Grained Violations in Advertisement Videos with Active Reinforcement Reasoning</h2></a><strong><u>Authors:</u></strong> Deyi Ji, Yuekui Yang, Liqun Liu, Peng Shu, Haiyang Wu, Shaogang Tang, Xudong Chen, Shaoping Ma, Tianrun Chen, Lanyun Zhu<br><strong><u>Categories:</u></strong> cs.LG, cs.CL<br><strong><u>Comments:</u></strong> EMNLP 2025 (Oral, Industry Track)<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> explainability (abstract)<br><p><strong><u>Abstract:</u></strong> Advertising (Ad) is a cornerstone of the digital economy, yet the moderation of video advertisements remains a significant challenge due to their complexity and the need for precise violation localization. While recent advancements, such as the RAVEN model, have improved coarse-grained violation detection, critical gaps persist in fine-grained understanding, explainability, and generalization. To address these limitations, we propose RAVEN++, a novel framework that introduces three key innovations: 1) Active Reinforcement Learning (RL), which dynamically adapts training to samples of varying difficulty; 2) Fine-Grained Violation Understanding, achieved through hierarchical reward functions and reasoning distillation; and 3) Progressive Multi-Stage Training, which systematically combines knowledge injection, curriculum-based passive RL, and active RL. Extensive experiments on both public and proprietary datasets, on both offline scenarios and online deployed A/B Testing, demonstrate that RAVEN++ outperforms general-purpose LLMs and specialized models like RAVEN in terms of fine-grained violation understanding, reasoning capabilities, and generalization ability.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19155v1" target="_blank"><h2>EEG-VLM: A Hierarchical Vision-Language Model with Multi-Level Feature Alignment and Visually Enhanced Language-Guided Reasoning for EEG Image-Based Sleep Stage Prediction</h2></a><strong><u>Authors:</u></strong> Xihe Qiu, Gengchen Ma, Haoyu Wang, Chen Zhan, Xiaoyu Tan, Shuo Li<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> Sleep stage classification based on electroencephalography (EEG) is fundamental for assessing sleep quality and diagnosing sleep-related disorders. However, most traditional machine learning methods rely heavily on prior knowledge and handcrafted features, while existing deep learning models still struggle to jointly capture fine-grained time-frequency patterns and achieve clinical interpretability. Recently, vision-language models (VLMs) have made significant progress in the medical domain, yet their performance remains constrained when applied to physiological waveform data, especially EEG signals, due to their limited visual understanding and insufficient reasoning capability. To address these challenges, we propose EEG-VLM, a hierarchical vision-language framework that integrates multi-level feature alignment with visually enhanced language-guided reasoning for interpretable EEG-based sleep stage classification. Specifically, a specialized visual enhancement module constructs high-level visual tokens from intermediate-layer features to extract rich semantic representations of EEG images. These tokens are further aligned with low-level CLIP features through a multi-level alignment mechanism, enhancing the VLM's image-processing capability. In addition, a Chain-of-Thought (CoT) reasoning strategy decomposes complex medical inference into interpretable logical steps, effectively simulating expert-like decision-making. Experimental results demonstrate that the proposed method significantly improves both the accuracy and interpretability of VLMs in EEG-based sleep stage classification, showing promising potential for automated and explainable EEG analysis in clinical settings.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19150v1" target="_blank"><h2>Feature Ranking in Credit-Risk with Qudit-Based Networks</h2></a><strong><u>Authors:</u></strong> Georgios Maragkopoulos, Lazaros Chavatzoglou, Aikaterini Mandilara, Dimitris Syvridis<br><strong><u>Categories:</u></strong> quant-ph, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> In finance, predictive models must balance accuracy and interpretability, particularly in credit risk assessment, where model decisions carry material consequences. We present a quantum neural network (QNN) based on a single qudit, in which both data features and trainable parameters are co-encoded within a unified unitary evolution generated by the full Lie algebra. This design explores the entire Hilbert space while enabling interpretability through the magnitudes of the learned coefficients. We benchmark our model on a real-world, imbalanced credit-risk dataset from Taiwan. The proposed QNN consistently outperforms LR and reaches the results of random forest models in macro-F1 score while preserving a transparent correspondence between learned parameters and input feature importance. To quantify the interpretability of the proposed model, we introduce two complementary metrics: (i) the edit distance between the model's feature ranking and that of LR, and (ii) a feature-poisoning test where selected features are replaced with noise. Results indicate that the proposed quantum model achieves competitive performance while offering a tractable path toward interpretable quantum learning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19147v1" target="_blank"><h2>Collaborative Learning with Multiple Foundation Models for Source-Free Domain Adaptation</h2></a><strong><u>Authors:</u></strong> Huisoo Lee, Jisu Han, Hyunsouk Cho, Wonjun Hwang<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 15 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> domain adaptation (title, abstract)<br><p><strong><u>Abstract:</u></strong> Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model to an unlabeled target domain without access to source data. Recent advances in Foundation Models (FMs) have introduced new opportunities for leveraging external semantic knowledge to guide SFDA. However, relying on a single FM is often insufficient, as it tends to bias adaptation toward a restricted semantic coverage, failing to capture diverse contextual cues under domain shift. To overcome this limitation, we propose a Collaborative Multi-foundation Adaptation (CoMA) framework that jointly leverages two different FMs (e.g., CLIP and BLIP) with complementary properties to capture both global semantics and local contextual cues. Specifically, we employ a bidirectional adaptation mechanism that (1) aligns different FMs with the target model for task adaptation while maintaining their semantic distinctiveness, and (2) transfers complementary knowledge from the FMs to the target model. To ensure stable adaptation under mini-batch training, we introduce Decomposed Mutual Information (DMI) that selectively enhances true dependencies while suppressing false dependencies arising from incomplete class coverage. Extensive experiments demonstrate that our method consistently outperforms existing state-of-the-art SFDA methods across four benchmarks, including Office-31, Office-Home, DomainNet-126, and VisDA, under the closed-set setting, while also achieving best results on partial-set and open-set variants.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19124v1" target="_blank"><h2>Uncertainty-Aware Deep Learning Framework for Remaining Useful Life Prediction in Turbofan Engines with Learned Aleatoric Uncertainty</h2></a><strong><u>Authors:</u></strong> Krishang Sharma<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 2 figures, 3 tables. Submitted to arXiv<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate Remaining Useful Life (RUL) prediction coupled with uncertainty quantification remains a critical challenge in aerospace prognostics. This research introduces a novel uncertainty-aware deep learning framework that learns aleatoric uncertainty directly through probabilistic modeling, an approach unexplored in existing CMAPSS-based literature. Our hierarchical architecture integrates multi-scale Inception blocks for temporal pattern extraction, bidirectional Long Short-Term Memory networks for sequential modeling, and a dual-level attention mechanism operating simultaneously on sensor and temporal dimensions. The innovation lies in the Bayesian output layer that predicts both mean RUL and variance, enabling the model to learn data-inherent uncertainty. Comprehensive preprocessing employs condition-aware clustering, wavelet denoising, and intelligent feature selection. Experimental validation on NASA CMAPSS benchmarks (FD001-FD004) demonstrates competitive overall performance with RMSE values of 16.22, 19.29, 16.84, and 19.98 respectively. Remarkably, our framework achieves breakthrough critical zone performance (RUL <= 30 cycles) with RMSE of 5.14, 6.89, 5.27, and 7.16, representing 25-40 percent improvements over conventional approaches and establishing new benchmarks for safety-critical predictions. The learned uncertainty provides well-calibrated 95 percent confidence intervals with coverage ranging from 93.5 percent to 95.2 percent, enabling risk-aware maintenance scheduling previously unattainable in CMAPSS literature.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19121v1" target="_blank"><h2>ReLU-Based and DNN-Based Generalized Maximum Score Estimators</h2></a><strong><u>Authors:</u></strong> Xiaohong Chen, Wayne Yuan Gao, Likang Wen<br><strong><u>Categories:</u></strong> econ.EM, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> We propose a new formulation of the maximum score estimator that uses compositions of rectified linear unit (ReLU) functions, instead of indicator functions as in Manski (1975,1985), to encode the sign alignment restrictions. Since the ReLU function is Lipschitz, our new ReLU-based maximum score criterion function is substantially easier to optimize using standard gradient-based optimization pacakges. We also show that our ReLU-based maximum score (RMS) estimator can be generalized to an umbrella framework defined by multi-index single-crossing (MISC) conditions, while the original maximum score estimator cannot be applied. We establish the $n^{-s/(2s+1)}$ convergence rate and asymptotic normality for the RMS estimator under order-$s$ Holder smoothness. In addition, we propose an alternative estimator using a further reformulation of RMS as a special layer in a deep neural network (DNN) architecture, which allows the estimation procedure to be implemented via state-of-the-art software and hardware for DNN.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19114v1" target="_blank"><h2>Physics-informed Neural Operator Learning for Nonlinear Grad-Shafranov Equation</h2></a><strong><u>Authors:</u></strong> Siqi Ding, Zitong Zhang, Guoyang Shi, Xingyu Li, Xiang Gu, Yanan Xu, Huasheng Xie, Hanyue Zhao, Yuejiang Shi, Tianyuan Liu<br><strong><u>Categories:</u></strong> physics.plasm-ph, cs.AI<br><strong><u>Comments:</u></strong> 42 pages, 17 figures, 8 tables,<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> As artificial intelligence emerges as a transformative enabler for fusion energy commercialization, fast and accurate solvers become increasingly critical. In magnetic confinement nuclear fusion, rapid and accurate solution of the Grad-Shafranov equation (GSE) is essential for real-time plasma control and analysis. Traditional numerical solvers achieve high precision but are computationally prohibitive, while data-driven surrogates infer quickly but fail to enforce physical laws and generalize poorly beyond training distributions. To address this challenge, we present a Physics-Informed Neural Operator (PINO) that directly learns the GSE solution operator, mapping shape parameters of last closed flux surface to equilibrium solutions for realistic nonlinear current profiles. Comprehensive benchmarking of five neural architectures identifies the novel Transformer-KAN (Kolmogorov-Arnold Network) Neural Operator (TKNO) as achieving highest accuracy (0.25% mean L2 relative error) under supervised training (only data-driven). However, all data-driven models exhibit large physics residuals, indicating poor physical consistency. Our unsupervised training can reduce the residuals by nearly four orders of magnitude through embedding physics-based loss terms without labeled data. Critically, semi-supervised learning--integrating sparse labeled data (100 interior points) with physics constraints--achieves optimal balance: 0.48% interpolation error and the most robust extrapolation performance (4.76% error, 8.9x degradation factor vs 39.8x for supervised models). Accelerated by TensorRT optimization, our models enable millisecond-level inference, establishing PINO as a promising pathway for next-generation fusion control systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19100v1" target="_blank"><h2>Extracting Robust Register Automata from Neural Networks over Data Sequences</h2></a><strong><u>Authors:</u></strong> Chih-Duo Hong, Hongjian Jiang, Anthony W. Lin, Oliver Markgraf, Julian Parsert, Tony Tan<br><strong><u>Categories:</u></strong> cs.AI, cs.FL, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Automata extraction is a method for synthesising interpretable surrogates for black-box neural models that can be analysed symbolically. Existing techniques assume a finite input alphabet, and thus are not directly applicable to data sequences drawn from continuous domains. We address this challenge with deterministic register automata (DRAs), which extend finite automata with registers that store and compare numeric values. Our main contribution is a framework for robust DRA extraction from black-box models: we develop a polynomial-time robustness checker for DRAs with a fixed number of registers, and combine it with passive and active automata learning algorithms. This combination yields surrogate DRAs with statistical robustness and equivalence guarantees. As a key application, we use the extracted automata to assess the robustness of neural networks: for a given sequence and distance metric, the DRA either certifies local robustness or produces a concrete counterexample. Experiments on recurrent neural networks and transformer architectures show that our framework reliably learns accurate automata and enables principled robustness evaluation. Overall, our results demonstrate that robust DRA extraction effectively bridges neural network interpretability and formal reasoning without requiring white-box access to the underlying network.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19090v1" target="_blank"><h2>Optimization of Deep Learning Models for Dynamic Market Behavior Prediction</h2></a><strong><u>Authors:</u></strong> Shenghan Zhao, Yuzhen Lin, Ximeng Yang, Qiaochu Lu, Haozhong Xue, Gaozhe Jiang<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> The advent of financial technology has witnessed a surge in the utilization of deep learning models to anticipate consumer conduct, a trend that has demonstrated considerable potential in enhancing lending strategies and bolstering market efficiency. We study multi-horizon demand forecasting on e-commerce transactions using the UCI Online Retail II dataset. Unlike prior versions of this manuscript that mixed financial-loan narratives with retail data, we focus exclusively on retail market behavior and define a clear prediction target: per SKU daily demand (or revenue) for horizons H=1,7,14. We present a hybrid sequence model that combines multi-scale temporal convolutions, a gated recurrent module, and time-aware self-attention. The model is trained with standard regression losses and evaluated under MAE, RMSE, sMAPE, MASE, and Theil's U_2 with strict time-based splits to prevent leakage. We benchmark against ARIMA/Prophet, LSTM/GRU, LightGBM, and state-of-the-art Transformer forecasters (TFT, Informer, Autoformer, N-BEATS). Results show consistent accuracy gains and improved robustness on peak/holiday periods. We further provide ablations and statistical significance tests to ensure the reliability of improvements, and we release implementation details to facilitate reproducibility.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19078v1" target="_blank"><h2>GraphMind: Theorem Selection and Conclusion Generation Framework with Dynamic GNN for LLM Reasoning</h2></a><strong><u>Authors:</u></strong> Yutong Li, Yitian Zhou, Xudong Wang, GuoChen, Caiyan Qin<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Large language models (LLMs) have demonstrated impressive capabilities in natural language understanding and generation, including multi-step reasoning such as mathematical proving. However, existing approaches often lack an explicit and dynamic mechanism to structurally represent and evolve intermediate reasoning states, which limits their ability to perform context-aware theorem selection and iterative conclusion generation. To address these challenges, we propose GraphMind, a novel dynamic graph-based framework that integrates the graph neural network (GNN) with LLMs to iteratively select theorems and generate intermediate conclusions for multi-step reasoning. Our method models the reasoning process as a heterogeneous evolving graph, where nodes represent conditions, theorems, and conclusions, while edges capture logical dependencies between nodes. By encoding the current reasoning state with GNN and leveraging semantic matching for theorem selection, our framework enables context-aware, interpretable, and structured reasoning in a closed-loop manner. Experiments on various question-answering (QA) datasets demonstrate that our proposed GraphMind method achieves consistent performance improvements and significantly outperforms existing baselines in multi-step reasoning, validating the effectiveness and generalizability of our approach.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19046v1" target="_blank"><h2>MedSAM3: Delving into Segment Anything with Medical Concepts</h2></a><strong><u>Authors:</u></strong> Anglin Liu, Rundong Xue, Xu R. Cao, Yifan Shen, Yi Lu, Xiang Li, Qianqian Chen, Jintai Chen<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Medical image segmentation is fundamental for biomedical discovery. Existing methods lack generalizability and demand extensive, time-consuming manual annotation for new clinical application. Here, we propose MedSAM-3, a text promptable medical segmentation model for medical image and video segmentation. By fine-tuning the Segment Anything Model (SAM) 3 architecture on medical images paired with semantic conceptual labels, our MedSAM-3 enables medical Promptable Concept Segmentation (PCS), allowing precise targeting of anatomical structures via open-vocabulary text descriptions rather than solely geometric prompts. We further introduce the MedSAM-3 Agent, a framework that integrates Multimodal Large Language Models (MLLMs) to perform complex reasoning and iterative refinement in an agent-in-the-loop workflow. Comprehensive experiments across diverse medical imaging modalities, including X-ray, MRI, Ultrasound, CT, and video, demonstrate that our approach significantly outperforms existing specialist and foundation models. We will release our code and model at https://github.com/Joey-S-Liu/MedSAM3.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19037v1" target="_blank"><h2>Resolving Node Identifiability in Graph Neural Processes via Laplacian Spectral Encodings</h2></a><strong><u>Authors:</u></strong> Zimo Yan, Zheng Xie, Chang Liu, Yuan Wang<br><strong><u>Categories:</u></strong> cs.LG, math.PR<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Message passing graph neural networks are widely used for learning on graphs, yet their expressive power is limited by the one-dimensional Weisfeiler-Lehman test and can fail to distinguish structurally different nodes. We provide rigorous theory for a Laplacian positional encoding that is invariant to eigenvector sign flips and to basis rotations within eigenspaces. We prove that this encoding yields node identifiability from a constant number of observations and establishes a sample-complexity separation from architectures constrained by the Weisfeiler-Lehman test. The analysis combines a monotone link between shortest-path and diffusion distance, spectral trilateration with a constant set of anchors, and quantitative spectral injectivity with logarithmic embedding size. As an instantiation, pairing this encoding with a neural-process style decoder yields significant gains on a drug-drug interaction task on chemical graphs, improving both the area under the ROC curve and the F1 score and demonstrating the practical benefits of resolving theoretical expressiveness limitations with principled positional information.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19035v1" target="_blank"><h2>CSD: Change Semantic Detection with only Semantic Change Masks for Damage Assessment in Conflict Zones</h2></a><strong><u>Authors:</u></strong> Kai Zhenga, Zhenkai Wu, Fupeng Wei, Miaolan Zhou, Kai Lie, Haitao Guo, Lei Ding, Wei Zhang, Hang-Cheng Dong<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Accurately and swiftly assessing damage from conflicts is crucial for humanitarian aid and regional stability. In conflict zones, damaged zones often share similar architectural styles, with damage typically covering small areas and exhibiting blurred boundaries. These characteristics lead to limited data, annotation difficulties, and significant recognition challenges, including high intra-class similarity and ambiguous semantic changes. To address these issues, we introduce a pre-trained DINOv3 model and propose a multi-scale cross-attention difference siamese network (MC-DiSNet). The powerful visual representation capability of the DINOv3 backbone enables robust and rich feature extraction from bi-temporal remote sensing images. We also release a new Gaza-change dataset containing high-resolution satellite image pairs from 2023-2024 with pixel-level semantic change annotations. It is worth emphasizing that our annotations only include semantic pixels of changed areas. Unlike conventional semantic change detection (SCD), our approach eliminates the need for large-scale semantic annotations of bi-temporal images, instead focusing directly on the changed regions. We term this new task change semantic detection (CSD). The CSD task represents a direct extension of binary change detection (BCD). Due to the limited spatial extent of semantic regions, it presents greater challenges than traditional SCD tasks. We evaluated our method under the CSD framework on both the Gaza-Change and SECOND datasets. Experimental results demonstrate that our proposed approach effectively addresses the CSD task, and its outstanding performance paves the way for practical applications in rapid damage assessment across conflict zones.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19024v1" target="_blank"><h2>Life-IQA: Boosting Blind Image Quality Assessment through GCN-enhanced Layer Interaction and MoE-based Feature Decoupling</h2></a><strong><u>Authors:</u></strong> Long Tang, Guoquan Zhen, Jie Hao, Jianbo Zhang, Huiyu Duan, Liang Yuan, Guangtao Zhai<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Blind image quality assessment (BIQA) plays a crucial role in evaluating and optimizing visual experience. Most existing BIQA approaches fuse shallow and deep features extracted from backbone networks, while overlooking the unequal contributions to quality prediction. Moreover, while various vision encoder backbones are widely adopted in BIQA, the effective quality decoding architectures remain underexplored. To address these limitations, this paper investigates the contributions of shallow and deep features to BIQA, and proposes a effective quality feature decoding framework via GCN-enhanced \underline{l}ayer\underline{i}nteraction and MoE-based \underline{f}eature d\underline{e}coupling, termed \textbf{(Life-IQA)}. Specifically, the GCN-enhanced layer interaction module utilizes the GCN-enhanced deepest-layer features as query and the penultimate-layer features as key, value, then performs cross-attention to achieve feature interaction. Moreover, a MoE-based feature decoupling module is proposed to decouple fused representations though different experts specialized for specific distortion types or quality dimensions. Extensive experiments demonstrate that Life-IQA shows more favorable balance between accuracy and cost than a vanilla Transformer decoder and achieves state-of-the-art performance on multiple BIQA benchmarks.The code is available at: \href{https://github.com/TANGLONG2/Life-IQA/tree/main}{\texttt{Life-IQA}}.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19023v1" target="_blank"><h2>OrdMoE: Preference Alignment via Hierarchical Expert Group Ranking in Multimodal Mixture-of-Experts LLMs</h2></a><strong><u>Authors:</u></strong> Yuting Gao, Weihao Chen, Lan Wang, Ruihan Xu, Qingpei Guo<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Preference learning has recently emerged as a pivotal strategy for post-training alignment of Multimodal Large Language Models (MLLMs). However, existing approaches predominantly rely on external human-annotated preference data, which is costly and labor-intensive to collect. In this work, we propose OrdMoE, a novel preference alignment framework that bypasses the reliance on external human preferences entirely by leveraging intrinsic signals within Mixture-of-Experts (MoE) architectures. Specifically, we observe that the router's expert selection scores implicitly encode a quality-aware ranking of responses (i.e. higher-scoring experts consistently generate higher-quality outputs). Building on this insight, OrdMoE constructs an internal preference hierarchy by grouping experts into ranked tiers based on their per-token routing scores and activating each tier separately to produce a sequence of responses with increasing quality. This yields a zero-cost, self-supervised preference ordering over generated responses, which can be directly optimized using standard preference learning objectives. Extensive experiments across multiple multimodal benchmarks demnstrate that OrdMoE significantly enhances both alignment and overall performance of multimodal Mixture-of-Experts LLMs, achieving competitive results without requiring any human-annotated preference data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19019v1" target="_blank"><h2>3D Dynamic Radio Map Prediction Using Vision Transformers for Low-Altitude Wireless Networks</h2></a><strong><u>Authors:</u></strong> Nguyen Duc Minh Quang, Chang Liu, Huy-Trung Nguyen, Shuangyang Li, Derrick Wing Kwan Ng, Wei Xiang<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 7 pages, 4 figures, submitted to IEEE ICC 2026<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Low-altitude wireless networks (LAWN) are rapidly expanding with the growing deployment of unmanned aerial vehicles (UAVs) for logistics, surveillance, and emergency response. Reliable connectivity remains a critical yet challenging task due to three-dimensional (3D) mobility, time-varying user density, and limited power budgets. The transmit power of base stations (BSs) fluctuates dynamically according to user locations and traffic demands, leading to a highly non-stationary 3D radio environment. Radio maps (RMs) have emerged as an effective means to characterize spatial power distributions and support radio-aware network optimization. However, most existing works construct static or offline RMs, overlooking real-time power variations and spatio-temporal dependencies in multi-UAV networks. To overcome this limitation, we propose a {3D dynamic radio map (3D-DRM)} framework that learns and predicts the spatio-temporal evolution of received power. Specially, a Vision Transformer (ViT) encoder extracts high-dimensional spatial representations from 3D RMs, while a Transformer-based module models sequential dependencies to predict future power distributions. Experiments unveil that 3D-DRM accurately captures fast-varying power dynamics and substantially outperforms baseline models in both RM reconstruction and short-term prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.19016v1" target="_blank"><h2>Lost and Found - A gallery of overlooked optical nuclear transients from the ZTF archive <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> E. Quintin, E. Russeil, M. Llamas Lanza, S. Karpov, E. E. O. Ishida, J. Peloton, M. V. Pruzhinskaya, A. Möller, M. Giustini, G. Miniutti, R. S. Saxton, P. Sánchez-Sáez, S. Zheltoukhov, A. Dodin, A. Belinski<br><strong><u>Categories:</u></strong> astro-ph.HE<br><strong><u>Comments:</u></strong> Submitted to A&A; 25 pages, 14 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> Tidal disruption events (TDEs) correspond to the destruction of a star by the tidal forces around a black hole, leading to outbursts which can last from months to years. These transients are rare, and increasing the current sample is paramount to understand them. As part of the Fink alert broker, we have developed an early detection system for TDEs for the Zwicky Transient Facility (ZTF) data. In this paper, we report on the optical transients we found either during the development of this tool, or when applying the classifier to the existing archive. We use this sample to anticipate what improvements to the TDE detection systems will need to be implemented for future surveys. For all the transients, we present optical and infrared archival photometry from ZTF, WISE, and Catalina, and assess the previous nuclear activity of the host. We fit the ZTF lightcurves with both a phenomenological and a physically-motivated model. We report on a total of 19 optical nuclear transients, out of which nine are in passive galaxies, eight in active galaxies, and two for which the activity of the host is uncertain. Two transients are newly discovered repeated TDE candidates, and we compare them to the current sample of repeated optical nuclear transients. One transient is exceptionally long-lived (over 5 years), in an until-now passive galaxy. Three of the TDE-like flares in active galaxies have absolute g-band magnitudes brighter than -24, making them new Extreme Nuclear Transient (ENT) candidates. One seemingly repeated object was revealed to be two independent supernovae in the same galaxy. This sample shows both the potential of our detection system for future discovery, and the relevance of archival searches to reveal overlooked transients. It also raises several points of concern and avenues of improvement for current and future classifiers.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18999v1" target="_blank"><h2>Enhancing low energy reconstruction and classification in KM3NeT/ORCA with transformers</h2></a><strong><u>Authors:</u></strong> Iván Mozún Mateo<br><strong><u>Categories:</u></strong> hep-ex, astro-ph.IM, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> The current KM3NeT/ORCA neutrino telescope, still under construction, has not yet reached its full potential in neutrino reconstruction capability. When training any deep learning model, no explicit information about the physics or the detector is provided, thus they remain unknown to the model. This study leverages the strengths of transformers by incorporating attention masks inspired by the physics and detector design, making the model understand both the telescope design and the neutrino physics measured on it. The study also shows the efficacy of transformers on retaining valuable information between detectors when doing fine-tuning from one configurations to another.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18992v1" target="_blank"><h2>Classification EM-PCA for clustering and embedding</h2></a><strong><u>Authors:</u></strong> Zineddine Tighidet, Lazhar Labiod, Mohamed Nadif<br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.CL, cs.LG<br><strong><u>Comments:</u></strong> Accepted at the IEEE conference on Big Data (Special Session on Machine Learning)<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract)<br><p><strong><u>Abstract:</u></strong> The mixture model is undoubtedly one of the greatest contributions to clustering. For continuous data, Gaussian models are often used and the Expectation-Maximization (EM) algorithm is particularly suitable for estimating parameters from which clustering is inferred. If these models are particularly popular in various domains including image clustering, they however suffer from the dimensionality and also from the slowness of convergence of the EM algorithm. However, the Classification EM (CEM) algorithm, a classifying version, offers a fast convergence solution while dimensionality reduction still remains a challenge. Thus we propose in this paper an algorithm combining simultaneously and non-sequentially the two tasks --Data embedding and Clustering-- relying on Principal Component Analysis (PCA) and CEM. We demonstrate the interest of such approach in terms of clustering and data embedding. We also establish different connections with other clustering approaches.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18989v1" target="_blank"><h2>Rethinking Plant Disease Diagnosis: Bridging the Academic-Practical Gap with Vision Transformers and Zero-Shot Learning</h2></a><strong><u>Authors:</u></strong> Wassim Benabbas, Mohammed Brahimi, Samir Akhrouf, Bilal Fortas<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), domain adaptation (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in deep learning have enabled significant progress in plant disease classification using leaf images. Much of the existing research in this field has relied on the PlantVillage dataset, which consists of well-centered plant images captured against uniform, uncluttered backgrounds. Although models trained on this dataset achieve high accuracy, they often fail to generalize to real-world field images, such as those submitted by farmers to plant diagnostic systems. This has created a significant gap between published studies and practical application requirements, highlighting the necessity of investigating and addressing this issue. In this study, we investigate whether attention-based architectures and zero-shot learning approaches can bridge the gap between curated academic datasets and real-world agricultural conditions in plant disease classification. We evaluate three model categories: Convolutional Neural Networks (CNNs), Vision Transformers, and Contrastive Language-Image Pre-training (CLIP)-based zero-shot models. While CNNs exhibit limited robustness under domain shift, Vision Transformers demonstrate stronger generalization by capturing global contextual features. Most notably, CLIP models classify diseases directly from natural language descriptions without any task-specific training, offering strong adaptability and interpretability. These findings highlight the potential of zero-shot learning as a practical and scalable domain adaptation strategy for plant health diagnosis in diverse field environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18987v1" target="_blank"><h2>Dynamic Mixture of Experts Against Severe Distribution Shifts</h2></a><strong><u>Authors:</u></strong> Donghu Kim<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The challenge of building neural networks that can continuously learn and adapt to evolving data streams is central to the fields of continual learning (CL) and reinforcement learning (RL). This lifelong learning problem is often framed in terms of the plasticity-stability dilemma, focusing on issues like loss of plasticity and catastrophic forgetting. Unlike neural networks, biological brains maintain plasticity through capacity growth, inspiring researchers to explore similar approaches in artificial networks, such as adding capacity dynamically. Prior solutions often lack parameter efficiency or depend on explicit task indices, but Mixture-of-Experts (MoE) architectures offer a promising alternative by specializing experts for distinct distributions. This paper aims to evaluate a DynamicMoE approach for continual and reinforcement learning environments and benchmark its effectiveness against existing network expansion methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18980v1" target="_blank"><h2>MOCLIP: A Foundation Model for Large-Scale Nanophotonic Inverse Design</h2></a><strong><u>Authors:</u></strong> S. Rodionov, A. Burguete-Lopez, M. Makarenko, Q. Wang, F. Getman, A. Fratalocchi<br><strong><u>Categories:</u></strong> physics.optics, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Foundation models (FM) are transforming artificial intelligence by enabling generalizable, data-efficient solutions across different domains for a broad range of applications. However, the lack of large and diverse datasets limits the development of FM in nanophotonics. This work presents MOCLIP (Metasurface Optics Contrastive Learning Pretrained), a nanophotonic foundation model that integrates metasurface geometry and spectra within a shared latent space. MOCLIP employs contrastive learning to align geometry and spectral representations using an experimentally acquired dataset with a sample density comparable to ImageNet-1K. The study demonstrates MOCLIP inverse design capabilities for high-throughput zero-shot prediction at a rate of 0.2 million samples per second, enabling the design of a full 4-inch wafer populated with high-density metasurfaces in minutes. It also shows generative latent-space optimization reaching 97 percent accuracy. Finally, we introduce an optical information storage concept that uses MOCLIP to achieve a density of 0.1 Gbit per square millimeter at the resolution limit, exceeding commercial optical media by a factor of six. These results position MOCLIP as a scalable and versatile platform for next-generation photonic design and data-driven applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18964v1" target="_blank"><h2>Synthesizing Visual Concepts as Vision-Language Programs</h2></a><strong><u>Authors:</u></strong> Antonia Wüst, Wolfgang Stammer, Hikaru Shindo, Lukas Helff, Devendra Singh Dhami, Kristian Kersting<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language models (VLMs) achieve strong performance on multimodal tasks but often fail at systematic visual reasoning tasks, leading to inconsistent or illogical outputs. Neuro-symbolic methods promise to address this by inducing interpretable logical rules, though they exploit rigid, domain-specific perception modules. We propose Vision-Language Programs (VLP), which combine the perceptual flexibility of VLMs with systematic reasoning of program synthesis. Rather than embedding reasoning inside the VLM, VLP leverages the model to produce structured visual descriptions that are compiled into neuro-symbolic programs. The resulting programs execute directly on images, remain consistent with task constraints, and provide human-interpretable explanations that enable easy shortcut mitigation. Experiments on synthetic and real-world datasets demonstrate that VLPs outperform direct and structured prompting, particularly on tasks requiring complex logical reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18960v1" target="_blank"><h2>AVA-VLA: Improving Vision-Language-Action models with Active Visual Attention</h2></a><strong><u>Authors:</u></strong> Lei Xiao, Jifeng Li, Juntao Gao, Feiyang Ye, Yan Jin, Jingjing Qian, Jing Zhang, Yong Wu, Xiaoyuan Yu<br><strong><u>Categories:</u></strong> cs.LG, cs.CV, cs.RO<br><strong><u>Comments:</u></strong> 18 pages, 10 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in embodied AI tasks. However, existing VLA models, often built upon Vision-Language Models (VLMs), typically process dense visual inputs independently at each timestep. This approach implicitly models the task as a Markov Decision Process (MDP). However, this history-agnostic design is suboptimal for effective visual token processing in dynamic sequential decision-making, as it fails to leverage the context of history. To address this limitation, we reformulate the problem from a Partially Observable Markov Decision Process (POMDP) perspective and propose a novel framework named AVA-VLA. Inspired by the POMDP that the action generation should be conditioned on the belief state. AVA-VLA introduces Active Visual Attention (AVA) to dynamically modulate visual processing. It achieves this by leveraging the recurrent state, which is a neural approximation of the agent's belief state derived from the previous decision step. Specifically, the AVA module uses the recurrent state to compute the soft weights to actively process task-relevant visual tokens based on its historical context. Comprehensive evaluations demonstrate that AVA-VLA achieves state-of-the-art performance across popular robotic benchmarks, including LIBERO and CALVIN. Furthermore, real-world deployments on a dual-arm robot platform validate the framework's practical applicability and robust sim-to-real transferability.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18945v1" target="_blank"><h2>MIST: Mutual Information Via Supervised Training</h2></a><strong><u>Authors:</u></strong> German Gritsai, Megan Richards, Maxime Méloux, Kyunghyun Cho, Maxime Peyrard<br><strong><u>Categories:</u></strong> cs.LG, cs.IT<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18936v1" target="_blank"><h2>SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression</h2></a><strong><u>Authors:</u></strong> Santhosh G S, Saurav Prakash, Balaraman Ravindran<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) face a significant bottleneck during autoregressive inference due to the massive memory footprint of the Key-Value (KV) cache. Existing compression techniques like token eviction, quantization, or other low-rank methods often risk information loss, have fixed limits, or introduce significant computational overhead from explicit decompression steps. In this work, we introduce SWAN, a novel, fine-tuning-free framework that eliminates this overhead. Our method uses an offline orthogonal matrix to rotate and prune the KV-cache, which is then used directly in the attention computation without any reconstruction. Our extensive experiments demonstrate that SWAN, augmented with a small dense buffer, offers a robust trade-off, maintaining performance close to the uncompressed baseline even at aggressive 50-60% memory savings per-token on KV-cache. A key advantage is its runtime-tunable compression level, allowing operators to dynamically adjust the memory footprint, a flexibility absent in methods requiring fixed offline configurations. This combination of a decompression-free design, high performance under compression, and adaptability makes SWAN a practical and efficient solution for serving LLMs with long contexts.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18934v1" target="_blank"><h2>Skeletons Matter: Dynamic Data Augmentation for Text-to-Query</h2></a><strong><u>Authors:</u></strong> Yuchen Ji, Bo Xu, Jie Shi, Jiaqing Liang, Deqing Yang, Yu Mao, Hai Chen, Yanghua Xiao<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.DB<br><strong><u>Comments:</u></strong> Accepted at EMNLP 2025<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data augmentation (title, abstract)<br><p><strong><u>Abstract:</u></strong> The task of translating natural language questions into query languages has long been a central focus in semantic parsing. Recent advancements in Large Language Models (LLMs) have significantly accelerated progress in this field. However, existing studies typically focus on a single query language, resulting in methods with limited generalizability across different languages. In this paper, we formally define the Text-to-Query task paradigm, unifying semantic parsing tasks across various query languages. We identify query skeletons as a shared optimization target of Text-to-Query tasks, and propose a general dynamic data augmentation framework that explicitly diagnoses model-specific weaknesses in handling these skeletons to synthesize targeted training data. Experiments on four Text-to-Query benchmarks demonstrate that our method achieves state-of-the-art performance using only a small amount of synthesized data, highlighting the efficiency and generality of our approach and laying a solid foundation for unified research on Text-to-Query tasks. We release our code at https://github.com/jjjycaptain/Skeletron.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18902v1" target="_blank"><h2>VADE: Variance-Aware Dynamic Sampling via Online Sample-Level Difficulty Estimation for Multimodal RL</h2></a><strong><u>Authors:</u></strong> Zengjie Hu, Jiantao Qiu, Tianyi Bai, Haojin Yang, Binhang Yuan, Qi Jing, Conghui He, Wentao Zhang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Group-based policy optimization methods like GRPO and GSPO have become standard for training multimodal models, leveraging group-wise rollouts and relative advantage estimation. However, they suffer from a critical \emph{gradient vanishing} problem when all responses within a group receive identical rewards, causing advantage estimates to collapse and training signals to diminish. Existing attempts to mitigate this issue fall into two paradigms: filtering-based and sampling-based methods. Filtering-based methods first generate rollouts broadly and then retroactively filter out uninformative groups, leading to substantial computational overhead. Sampling-based methods proactively select effective samples before rollout but rely on static criteria or prior dataset knowledge, lacking real-time adaptability. To address these issues, we propose \textbf{VADE}, a \textbf{V}ariance-\textbf{A}ware \textbf{D}ynamic sampling framework via online sample-level difficulty \textbf{E}stimation. Our framework integrates three key components: online sample-level difficulty estimation using Beta distributions, a Thompson sampler that maximizes information gain through the estimated correctness probability, and a two-scale prior decay mechanism that maintains robust estimation under policy evolution. This three components design enables VADE to dynamically select the most informative samples, thereby amplifying training signals while eliminating extra rollout costs. Extensive experiments on multimodal reasoning benchmarks show that VADE consistently outperforms strong baselines in both performance and sample efficiency, while achieving a dramatic reduction in computational overhead. More importantly, our framework can serves as a plug-and-play component to be seamlessly integrated into existing group-based RL algorithms. Code and models are available at https://VADE-RL.github.io.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18894v1" target="_blank"><h2>MetaDCSeg: Robust Medical Image Segmentation via Meta Dynamic Center Weighting</h2></a><strong><u>Authors:</u></strong> Chenyu Mu, Guihai Chen, Xun Yang, Erkun Yang, Cheng Deng<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Medical image segmentation is crucial for clinical applications, but it is frequently disrupted by noisy annotations and ambiguous anatomical boundaries, which lead to instability in model training. Existing methods typically rely on global noise assumptions or confidence-based sample selection, which inadequately mitigate the performance degradation caused by annotation noise, especially in challenging boundary regions. To address this issue, we propose MetaDCSeg, a robust framework that dynamically learns optimal pixel-wise weights to suppress the influence of noisy ground-truth labels while preserving reliable annotations. By explicitly modeling boundary uncertainty through a Dynamic Center Distance (DCD) mechanism, our approach utilizes weighted feature distances for foreground, background, and boundary centers, directing the model's attention toward hard-to-segment pixels near ambiguous boundaries. This strategy enables more precise handling of structural boundaries, which are often overlooked by existing methods, and significantly enhances segmentation performance. Extensive experiments across four benchmark datasets with varying noise levels demonstrate that MetaDCSeg consistently outperforms existing state-of-the-art methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18890v1" target="_blank"><h2>Nemotron-Flash: Towards Latency-Optimal Hybrid Small Language Models</h2></a><strong><u>Authors:</u></strong> Yonggan Fu, Xin Dong, Shizhe Diao, Matthijs Van keirsbilck, Hanrong Ye, Wonmin Byeon, Yashaswi Karnati, Lucas Liebenwein, Hannah Zhang, Nikolaus Binder, Maksim Khadkevich, Alexander Keller, Jan Kautz, Yingyan Celine Lin, Pavlo Molchanov<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted by NeurIPS 2025<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Efficient deployment of small language models (SLMs) is essential for numerous real-world applications with stringent latency constraints. While previous work on SLM design has primarily focused on reducing the number of parameters to achieve parameter-optimal SLMs, parameter efficiency does not necessarily translate into proportional real-device speed-ups. This work aims to identify the key determinants of SLMs' real-device latency and offer generalizable principles and methodologies for SLM design and training when real-device latency is the primary consideration. Specifically, we identify two central architectural factors: depth-width ratios and operator choices. The former is crucial for small-batch-size latency, while the latter affects both latency and large-batch-size throughput. In light of this, we first study latency-optimal depth-width ratios, with the key finding that although deep-thin models generally achieve better accuracy under the same parameter budget, they may not lie on the accuracy-latency trade-off frontier. Next, we explore emerging efficient attention alternatives to evaluate their potential as candidate building operators. Using the identified promising operators, we construct an evolutionary search framework to automatically discover latency-optimal combinations of these operators within hybrid SLMs, thereby advancing the accuracy-latency frontier. In addition to architectural improvements, we further enhance SLM training using a weight normalization technique that enables more effective weight updates and improves final convergence. Combining these methods, we introduce a new family of hybrid SLMs, called Nemotron-Flash, which significantly advances the accuracy-efficiency frontier of state-of-the-art SLMs, e.g., achieving over +5.5% average accuracy, 1.3x/1.9x lower latency, and 18.7x/45.6x higher throughput compared to Qwen3-1.7B/0.6B, respectively.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18874v1" target="_blank"><h2>GContextFormer: A global context-aware hybrid multi-head attention approach with scaled additive aggregation for multimodal trajectory prediction</h2></a><strong><u>Authors:</u></strong> Yuzhi Chen, Yuanchang Xie, Lei Zhao, Pan Liu, Yajie Zou, Chen Wang<br><strong><u>Categories:</u></strong> cs.AI, cs.CV, cs.LG, cs.MA, cs.RO, cs.SI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), transformer (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal trajectory prediction generates multiple plausible future trajectories to address vehicle motion uncertainty from intention ambiguity and execution variability. However, HD map-dependent models suffer from costly data acquisition, delayed updates, and vulnerability to corrupted inputs, causing prediction failures. Map-free approaches lack global context, with pairwise attention over-amplifying straight patterns while suppressing transitional patterns, resulting in motion-intention misalignment. This paper proposes GContextFormer, a plug-and-play encoder-decoder architecture with global context-aware hybrid attention and scaled additive aggregation achieving intention-aligned multimodal prediction without map reliance. The Motion-Aware Encoder builds scene-level intention prior via bounded scaled additive aggregation over mode-embedded trajectory tokens and refines per-mode representations under shared global context, mitigating inter-mode suppression and promoting intention alignment. The Hierarchical Interaction Decoder decomposes social reasoning into dual-pathway cross-attention: a standard pathway ensures uniform geometric coverage over agent-mode pairs while a neighbor-context-enhanced pathway emphasizes salient interactions, with gating module mediating their contributions to maintain coverage-focus balance. Experiments on eight highway-ramp scenarios from TOD-VT dataset show GContextFormer outperforms state-of-the-art baselines. Compared to existing transformer models, GContextFormer achieves greater robustness and concentrated improvements in high-curvature and transition zones via spatial distributions. Interpretability is achieved through motion mode distinctions and neighbor context modulation exposing reasoning attribution. The modular architecture supports extensibility toward cross-domain multimodal reasoning tasks. Source: https://fenghy-chen.github.io/sources/.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18871v1" target="_blank"><h2>Periodic Asynchrony: An Effective Method for Accelerating On-Policy Reinforcement Learning</h2></a><strong><u>Authors:</u></strong> Jian Lu<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Since the introduction of the GRPO algorithm, reinforcement learning (RL) has attracted increasing attention, with growing efforts to reproduce and apply it. However, training efficiency remains a critical challenge. In mainstream RL frameworks, inference and training are typically deployed on the same devices. While this approach reduces costs through resource consolidation, its synchronous execution imposes a computational coupling that prevents concurrent inference and training. In this study, we are returning to the strategy of separating inference and training deployment, and by introducing improvements in the data loader, we transform the conventional synchronous architecture into a periodically asynchronous framework, which allows for demand-driven, independent, and elastic scaling of each component, while the accuracy of the algorithm remains completely equivalent to the synchronization method, with both belonging to the on-policy strategy. It is worth emphasizing that we apply a unified tri-model architecture in the training phase, and we also proposed a shared-prompt attention mask to reduce repetitive computation. In practice, these works have achieved at least a threefold overall performance improvement in RL training on NPU platforms, indicating its potential for widespread application.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18859v1" target="_blank"><h2>Robust and Generalizable GNN Fine-Tuning via Uncertainty-aware Adapter Learning</h2></a><strong><u>Authors:</u></strong> Bo Jiang, Weijun Zhao, Beibei Wang, Xiao Wang, Jin Tang<br><strong><u>Categories:</u></strong> cs.LG, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Recently, fine-tuning large-scale pre-trained GNNs has yielded remarkable attention in adapting pre-trained GNN models for downstream graph learning tasks. One representative fine-tuning method is to exploit adapter (termed AdapterGNN) which aims to 'augment' the pre-trained model by inserting a lightweight module to make the 'augmented' model better adapt to the downstream tasks. However, graph data may contain various types of noise in downstream tasks, such as noisy edges and ambiguous node attributes. Existing AdapterGNNs are often prone to graph noise and exhibit limited generalizability. How to enhance the robustness and generalization ability of GNNs' fine tuning remains an open problem. In this paper, we show that the above problem can be well addressed by integrating uncertainty learning into the GNN adapter. We propose the Uncertainty-aware Adapter (UAdapterGNN) that fortifies pre-trained GNN models against noisy graph data in the fine-tuning process. Specifically, in contrast to regular AdapterGNN, our UAdapterGNN exploits Gaussian probabilistic adapter to augment the pre-trained GNN model. In this way, when the graph contains various noises,our method can automatically absorb the effects of changes in the variances of the Gaussian distribution, thereby significantly enhancing the model's robustness. Also, UAdapterGNN can further improve the generalization ability of the model on the downstream tasks. Extensive experiments on several benchmarks demonstrate the effectiveness, robustness and high generalization ability of the proposed UAdapterGNN method.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18847v1" target="_blank"><h2>Personalized Federated Segmentation with Shared Feature Aggregation and Boundary-Focused Calibration</h2></a><strong><u>Authors:</u></strong> Ishmam Tashdeed, Md. Atiqur Rahman, Sabrina Islam, Md. Azam Hossain<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Personalized federated learning (PFL) possesses the unique capability of preserving data confidentiality among clients while tackling the data heterogeneity problem of non-independent and identically distributed (Non-IID) data. Its advantages have led to widespread adoption in domains such as medical image segmentation. However, the existing approaches mostly overlook the potential benefits of leveraging shared features across clients, where each client contains segmentation data of different organs. In this work, we introduce a novel personalized federated approach for organ agnostic tumor segmentation (FedOAP), that utilizes cross-attention to model long-range dependencies among the shared features of different clients and a boundary-aware loss to improve segmentation consistency. FedOAP employs a decoupled cross-attention (DCA), which enables each client to retain local queries while attending to globally shared key-value pairs aggregated from all clients, thereby capturing long-range inter-organ feature dependencies. Additionally, we introduce perturbed boundary loss (PBL) which focuses on the inconsistencies of the predicted mask's boundary for each client, forcing the model to localize the margins more precisely. We evaluate FedOAP on diverse tumor segmentation tasks spanning different organs. Extensive experiments demonstrate that FedOAP consistently outperforms existing state-of-the-art federated and personalized segmentation methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18845v1" target="_blank"><h2>UNeMo: Collaborative Visual-Language Reasoning and Navigation via a Multimodal World Model</h2></a><strong><u>Authors:</u></strong> Changxin Huang, Lv Tang, Zhaohuan Zhan, Lisha Yu, Runhao Zeng, Zun Liu, Zhengjie Wang, Jianqiang Li<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Vision-and-Language Navigation (VLN) requires agents to autonomously navigate complex environments via visual images and natural language instruction--remains highly challenging. Recent research on enhancing language-guided navigation reasoning using pre-trained large language models (LLMs) has shown promising prospects. However, the reasoning of such methods is limited to the linguistic modality, lacking visual reasoning capabilities. Moreover, existing reasoning modules are optimized separately from navigation policies, leading to incompatibility and potential conflicts in optimization objectives. To tackle these challenges, we introduce UNeMo, a novel framework designed for the collaborative optimization of visual state reasoning and navigational decision-making. It introduces a Multimodal World Model (MWM) that takes visual features, language instructions, and navigational actions as inputs to jointly predict subsequent visual states, enabling cross-modal reasoning. Via a Hierarchical Prediction-Feedback (HPN) mechanism, MWM collaborates with navigation policies: the first layer generates actions using current vision-and-language features; MWM then infers post-action visual states to guide the second layer's fine-grained decisions. This forms a dynamic bidirectional promotion mechanism where MWM reasoning optimizes navigation policies, while policy decisions feedback to improve MWM's reasoning accuracy. Experiments on R2R and REVERIE datasets show UNeMo outperforms state-of-the-art methods by 2.1% and 0.7% in navigation accuracy for unseen scenes, validating its effectiveness.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18841v1" target="_blank"><h2>Federated style aware transformer aggregation of representations</h2></a><strong><u>Authors:</u></strong> Mincheol Jeon, Euinam Huh<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.DC<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Personalized Federated Learning (PFL) faces persistent challenges, including domain heterogeneity from diverse client data, data imbalance due to skewed participation, and strict communication constraints. Traditional federated learning often lacks personalization, as a single global model cannot capture client-specific characteristics, leading to biased predictions and poor generalization, especially for clients with highly divergent data distributions.
  To address these issues, we propose FedSTAR, a style-aware federated learning framework that disentangles client-specific style factors from shared content representations. FedSTAR aggregates class-wise prototypes using a Transformer-based attention mechanism, allowing the server to adaptively weight client contributions while preserving personalization.
  Furthermore, by exchanging compact prototypes and style vectors instead of full model parameters, FedSTAR significantly reduces communication overhead. Experimental results demonstrate that combining content-style disentanglement with attention-driven prototype aggregation improves personalization and robustness in heterogeneous environments without increasing communication cost.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18839v1" target="_blank"><h2>Enhancing Multi-Label Thoracic Disease Diagnosis with Deep Ensemble-Based Uncertainty Quantification</h2></a><strong><u>Authors:</u></strong> Yasiru Laksara, Uthayasanker Thayasivam<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> The utility of deep learning models, such as CheXNet, in high stakes clinical settings is fundamentally constrained by their purely deterministic nature, failing to provide reliable measures of predictive confidence. This project addresses this critical gap by integrating robust Uncertainty Quantification (UQ) into a high performance diagnostic platform for 14 common thoracic diseases on the NIH ChestX-ray14 dataset. Initial architectural development failed to stabilize performance and calibration using Monte Carlo Dropout (MCD), yielding an unacceptable Expected Calibration Error (ECE) of 0.7588. This technical failure necessitated a rigorous architectural pivot to a high diversity, 9-member Deep Ensemble (DE). This resulting DE successfully stabilized performance and delivered superior reliability, achieving a State-of-the-Art (SOTA) average Area Under the Receiver Operating Characteristic Curve (AUROC) of 0.8559 and an average F1 Score of 0.3857. Crucially, the DE demonstrated superior calibration (Mean ECE of 0.0728 and Negative Log-Likelihood (NLL) of 0.1916) and enabled the reliable decomposition of total uncertainty into its Aleatoric (irreducible data noise) and Epistemic (reducible model knowledge) components, with a mean Epistemic Uncertainty (EU) of 0.0240. These results establish the Deep Ensemble as a trustworthy and explainable platform, transforming the model from a probabilistic tool into a reliable clinical decision support system.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18835v1" target="_blank"><h2>Auto-ML Graph Neural Network Hypermodels for Outcome Prediction in Event-Sequence Data</h2></a><strong><u>Authors:</u></strong> Fang Wang, Lance Kosca, Adrienne Kosca, Marko Gacesa, Ernesto Damiani<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 6 pages<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title)<br><p><strong><u>Abstract:</u></strong> This paper introduces HGNN(O), an AutoML GNN hypermodel framework for outcome prediction on event-sequence data. Building on our earlier work on graph convolutional network hypermodels, HGNN(O) extends four architectures-One Level, Two Level, Two Level Pseudo Embedding, and Two Level Embedding-across six canonical GNN operators. A self-tuning mechanism based on Bayesian optimization with pruning and early stopping enables efficient adaptation over architectures and hyperparameters without manual configuration. Empirical evaluation on both balanced and imbalanced event logs shows that HGNN(O) achieves accuracy exceeding 0.98 on the Traffic Fines dataset and weighted F1 scores up to 0.86 on the Patients dataset without explicit imbalance handling. These results demonstrate that the proposed AutoML-GNN approach provides a robust and generalizable benchmark for outcome prediction in complex event-sequence data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18830v1" target="_blank"><h2>Leveraging Duration Pseudo-Embeddings in Multilevel LSTM and GCN Hypermodels for Outcome-Oriented PPM</h2></a><strong><u>Authors:</u></strong> Fang Wang, Paolo Ceravolo, Ernesto Damiani<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 12 pages<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Existing deep learning models for Predictive Process Monitoring (PPM) struggle with temporal irregularities, particularly stochastic event durations and overlapping timestamps, limiting their adaptability across heterogeneous datasets. We propose a dual input neural network strategy that separates event and sequence attributes, using a duration-aware pseudo-embedding matrix to transform temporal importance into compact, learnable representations. This design is implemented across two baseline families: B-LSTM and B-GCN, and their duration-aware variants D-LSTM and D-GCN. All models incorporate self-tuned hypermodels for adaptive architecture selection. Experiments on balanced and imbalanced outcome prediction tasks show that duration pseudo-embedding inputs consistently improve generalization, reduce model complexity, and enhance interpretability. Our results demonstrate the benefits of explicit temporal encoding and provide a flexible design for robust, real-world PPM applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18820v1" target="_blank"><h2>Solution of Incompressible Flow Equations with Physics and Equality Constrained Artificial Neural Networks</h2></a><strong><u>Authors:</u></strong> Qifeng Hu, Inanc Senocak<br><strong><u>Categories:</u></strong> physics.flu-dyn, cs.LG<br><strong><u>Comments:</u></strong> 21 pages, 13 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> We present a meshless method for the solution of incompressible Navier-Stokes equations in advection-dominated regimes using physics- and equality-constrained artificial neural networks combined with a conditionally adaptive augmented Lagrangian formulation. A single neural network parameterizes both the velocity and pressure fields, and is trained by minimizing the residual of a Poisson's equation for pressure, constrained by the momentum and continuity equations, together with boundary conditions on the velocity field. No boundary conditions are imposed on the pressure field aside from anchoring the pressure at a point to prevent its unbounded development. The training is performed from scratch without labeled data, relying solely on the governing equations and constraints. To enhance accuracy in advection-dominated flows, we employ a single Fourier feature mapping of the input coordinates. The proposed method is demonstrated for the canonical lid-driven cavity flow up to a Reynolds number of 7,500 and for laminar flow over a circular cylinder with inflow-outflow boundary conditions, achieving excellent agreement with benchmark solutions. We further compare the present formulation against alternative objective-function constructions based on different arrangements of the flow equations, thereby highlighting the algorithmic advantages of the proposed formulation centered around the Poisson's equation for pressure.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18813v1" target="_blank"><h2>Uncertainty of Network Topology with Applications to Out-of-Distribution Detection</h2></a><strong><u>Authors:</u></strong> Sing-Yuan Yeh, Chun-Hao Yang<br><strong><u>Categories:</u></strong> stat.ML, cs.LG, stat.ME<br><strong><u>Comments:</u></strong> Submitted for journal publication<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Persistent homology (PH) is a crucial concept in computational topology, providing a multiscale topological description of a space. It is particularly significant in topological data analysis, which aims to make statistical inference from a topological perspective. In this work, we introduce a new topological summary for Bayesian neural networks, termed the predictive topological uncertainty (pTU). The proposed pTU measures the uncertainty in the interaction between the model and the inputs. It provides insights from the model perspective: if two samples interact with a model in a similar way, then they are considered identically distributed. We also show that the pTU is insensitive to the model architecture. As an application, pTU is used to solve the out-of-distribution (OOD) detection problem, which is critical to ensure model reliability. Failure to detect OOD input can lead to incorrect and unreliable predictions. To address this issue, we propose a significance test for OOD based on the pTU, providing a statistical framework for this issue. The effectiveness of the framework is validated through various experiments, in terms of its statistical power, sensitivity, and robustness.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18787v1" target="_blank"><h2>Understanding Task Transfer in Vision-Language Models</h2></a><strong><u>Authors:</u></strong> Bhuvan Sachdeva, Karan Uppal, Abhinav Java, Vineeth N. Balasubramanian<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language Models (VLMs) perform well on multimodal benchmarks but lag behind humans and specialized models on visual perception tasks like depth estimation or object counting. Finetuning on one task can unpredictably affect performance on others, making task-specific finetuning challenging. In this paper, we address this challenge through a systematic study of task transferability. We examine how finetuning a VLM on one perception task affects its zero-shot performance on others. To quantify these effects, we introduce Perfection Gap Factor (PGF), a metric that captures both the breadth and magnitude of transfer. Using three open-weight VLMs evaluated across 13 perception tasks, we construct a task-transfer graph that reveals previously unobserved relationships among perception tasks. Our analysis uncovers patterns of positive and negative transfer, identifies groups of tasks that mutually influence each other, organizes tasks into personas based on their transfer behavior and demonstrates how PGF can guide data selection for more efficient training. These findings highlight both opportunities for positive transfer and risks of negative interference, offering actionable guidance for advancing VLMs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18784v1" target="_blank"><h2>TDLight: A Framework for Incremental Light Curve Management and Smart Classification</h2></a><strong><u>Authors:</u></strong> Xinghang Yu, Ce Yu, Zeguang Shao, Bin Yang<br><strong><u>Categories:</u></strong> astro-ph.IM<br><strong><u>Comments:</u></strong> 8 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> time-domain (abstract)<br><p><strong><u>Abstract:</u></strong> With the exponential growth of time-domain surveys, the volume of light curves has increased rapidly. However, many survey projects, such as Gaia, still rely on offline batch-processing workflows in which data are calibrated, merged, and released only after an observing phase is completed. This latency delays scientific analysis and causes many high-value transient events to be buried in archival data, missing the window for timely follow-up. While existing alert brokers handle heterogeneous data streams, it remains difficult to deploy a unified framework that combines high-performance incremental storage with real-time classification on local infrastructure. To address this challenge, we propose TDLight, a scalable system that adapts the time-series database TDengine (a high-performance IoT database) for astronomical data using a one-table-per-source schema. This architecture supports high-throughput ingestion, achieving 954,000 rows s^-1 for archived data and 541,000 rows s^-1 for incremental streams, while Hierarchical Equal Area isoLatitude Pixelization (HEALPix) indexing enables efficient cone-search queries. Building on this storage layer, we integrate the pre-trained hierarchical Random Forest classifier from the LEAVES framework to construct an incremental classification pipeline. Using the LEAVES dataset, we simulate data accumulation and evaluate a trigger-based strategy that performs early classification at specific observational milestones. In addition, by monitoring the evolution of classification probabilities, the system identifies "high-value candidates" -- sources that show high early confidence but later undergo significant label shifts. TDLight is released as an open-source Dockerized environment, providing a deployable infrastructure for next-generation time-domain surveys.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18783v1" target="_blank"><h2>Hypergraph Contrastive Learning for both Homophilic and Heterophilic Hypergraphs</h2></a><strong><u>Authors:</u></strong> Renchu Guan, Xuyang Li, Yachao Zhang, Wei Pang, Fausto Giunchiglia, Ximing Li, Yonghao Liu, Xiaoyue Feng<br><strong><u>Categories:</u></strong> cs.LG, cs.SI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Hypergraphs, as a generalization of traditional graphs, naturally capture high-order relationships. In recent years, hypergraph neural networks (HNNs) have been widely used to capture complex high-order relationships. However, most existing hypergraph neural network methods inherently rely on the homophily assumption, which often does not hold in real-world scenarios that exhibit significant heterophilic structures. To address this limitation, we propose \textbf{HONOR}, a novel unsupervised \textbf{H}ypergraph c\textbf{ON}trastive learning framework suitable for both hom\textbf{O}philic and hete\textbf{R}ophilic hypergraphs. Specifically, HONOR explicitly models the heterophilic relationships between hyperedges and nodes through two complementary mechanisms: a prompt-based hyperedge feature construction strategy that maintains global semantic consistency while suppressing local noise, and an adaptive attention aggregation module that dynamically captures the diverse local contributions of nodes to hyperedges. Combined with high-pass filtering, these designs enable HONOR to fully exploit heterophilic connection patterns, yielding more discriminative and robust node and hyperedge representations. Theoretically, we demonstrate the superior generalization ability and robustness of HONOR. Empirically, extensive experiments further validate that HONOR consistently outperforms state-of-the-art baselines under both homophilic and heterophilic datasets.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18780v1" target="_blank"><h2>ConceptGuard: Proactive Safety in Text-and-Image-to-Video Generation through Multimodal Risk Detection</h2></a><strong><u>Authors:</u></strong> Ruize Ma, Minghong Cai, Yilei Jiang, Jiaming Han, Yi Feng, Yingshui Tan, Xiaoyong Zhu, Bo Zhang, Bo Zheng, Xiangyu Yue<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Recent progress in video generative models has enabled the creation of high-quality videos from multimodal prompts that combine text and images. While these systems offer enhanced controllability, they also introduce new safety risks, as harmful content can emerge from individual modalities or their interaction. Existing safety methods are often text-only, require prior knowledge of the risk category, or operate as post-generation auditors, struggling to proactively mitigate such compositional, multimodal risks. To address this challenge, we present ConceptGuard, a unified safeguard framework for proactively detecting and mitigating unsafe semantics in multimodal video generation. ConceptGuard operates in two stages: First, a contrastive detection module identifies latent safety risks by projecting fused image-text inputs into a structured concept space; Second, a semantic suppression mechanism steers the generative process away from unsafe concepts by intervening in the prompt's multimodal conditioning. To support the development and rigorous evaluation of this framework, we introduce two novel benchmarks: ConceptRisk, a large-scale dataset for training on multimodal risks, and T2VSafetyBench-TI2V, the first benchmark adapted from T2VSafetyBench for the Text-and-Image-to-Video (TI2V) safety setting. Comprehensive experiments on both benchmarks show that ConceptGuard consistently outperforms existing baselines, achieving state-of-the-art results in both risk detection and safe video generation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18777v1" target="_blank"><h2>SAOT: An Enhanced Locality-Aware Spectral Transformer for Solving PDEs</h2></a><strong><u>Authors:</u></strong> Chenhong Zhou, Jie Chen, Zaifeng Yang<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Accepted to AAAI 2026 (Main Technical Track)<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Neural operators have shown great potential in solving a family of Partial Differential Equations (PDEs) by modeling the mappings between input and output functions. Fourier Neural Operator (FNO) implements global convolutions via parameterizing the integral operators in Fourier space. However, it often results in over-smoothing solutions and fails to capture local details and high-frequency components. To address these limitations, we investigate incorporating the spatial-frequency localization property of Wavelet transforms into the Transformer architecture. We propose a novel Wavelet Attention (WA) module with linear computational complexity to efficiently learn locality-aware features. Building upon WA, we further develop the Spectral Attention Operator Transformer (SAOT), a hybrid spectral Transformer framework that integrates WA's localized focus with the global receptive field of Fourier-based Attention (FA) through a gated fusion block. Experimental results demonstrate that WA significantly mitigates the limitations of FA and outperforms existing Wavelet-based neural operators by a large margin. By integrating the locality-aware and global spectral representations, SAOT achieves state-of-the-art performance on six operator learning benchmarks and exhibits strong discretization-invariant ability.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18772v1" target="_blank"><h2>Re-Key-Free, Risky-Free: Adaptable Model Usage Control</h2></a><strong><u>Authors:</u></strong> Zihan Wang, Zhongkui Ma, Xinguo Feng, Chuan Yan, Dongge Liu, Ruoxi Sun, Derui Wang, Minhui Xue, Guangdong Bai<br><strong><u>Categories:</u></strong> cs.CR, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Deep neural networks (DNNs) have become valuable intellectual property of model owners, due to the substantial resources required for their development. To protect these assets in the deployed environment, recent research has proposed model usage control mechanisms to ensure models cannot be used without proper authorization. These methods typically lock the utility of the model by embedding an access key into its parameters. However, they often assume static deployment, and largely fail to withstand continual post-deployment model updates, such as fine-tuning or task-specific adaptation. In this paper, we propose ADALOC, to endow key-based model usage control with adaptability during model evolution. It strategically selects a subset of weights as an intrinsic access key, which enables all model updates to be confined to this key throughout the evolution lifecycle. ADALOC enables using the access key to restore the keyed model to the latest authorized states without redistributing the entire network (i.e., adaptation), and frees the model owner from full re-keying after each model update (i.e., lock preservation). We establish a formal foundation to underpin ADALOC, providing crucial bounds such as the errors introduced by updates restricted to the access key. Experiments on standard benchmarks, such as CIFAR-100, Caltech-256, and Flowers-102, and modern architectures, including ResNet, DenseNet, and ConvNeXt, demonstrate that ADALOC achieves high accuracy under significant updates while retaining robust protections. Specifically, authorized usages consistently achieve strong task-specific performance, while unauthorized usage accuracy drops to near-random guessing levels (e.g., 1.01% on CIFAR-100), compared to up to 87.01% without ADALOC. This shows that ADALOC can offer a practical solution for adaptive and protected DNN deployment in evolving real-world scenarios.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18766v1" target="_blank"><h2>Unsupervised Multi-View Visual Anomaly Detection via Progressive Homography-Guided Alignment</h2></a><strong><u>Authors:</u></strong> Xintao Chen, Xiaohao Xu, Bozhong Zheng, Yun Liu, Yingna Wu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)<br><p><strong><u>Abstract:</u></strong> Unsupervised visual anomaly detection from multi-view images presents a significant challenge: distinguishing genuine defects from benign appearance variations caused by viewpoint changes. Existing methods, often designed for single-view inputs, treat multiple views as a disconnected set of images, leading to inconsistent feature representations and a high false-positive rate. To address this, we introduce ViewSense-AD (VSAD), a novel framework that learns viewpoint-invariant representations by explicitly modeling geometric consistency across views. At its core is our Multi-View Alignment Module (MVAM), which leverages homography to project and align corresponding feature regions between neighboring views. We integrate MVAM into a View-Align Latent Diffusion Model (VALDM), enabling progressive and multi-stage alignment during the denoising process. This allows the model to build a coherent and holistic understanding of the object's surface from coarse to fine scales. Furthermore, a lightweight Fusion Refiner Module (FRM) enhances the global consistency of the aligned features, suppressing noise and improving discriminative power. Anomaly detection is performed by comparing multi-level features from the diffusion model against a learned memory bank of normal prototypes. Extensive experiments on the challenging RealIAD and MANTA datasets demonstrate that VSAD sets a new state-of-the-art, significantly outperforming existing methods in pixel, view, and sample-level visual anomaly proving its robustness to large viewpoint shifts and complex textures.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18746v1" target="_blank"><h2>Any4D: Open-Prompt 4D Generation from Natural Language and Images</h2></a><strong><u>Authors:</u></strong> Hao Li, Qiao Sun<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> While video-generation-based embodied world models have gained increasing attention, their reliance on large-scale embodied interaction data remains a key bottleneck. The scarcity, difficulty of collection, and high dimensionality of embodied data fundamentally limit the alignment granularity between language and actions and exacerbate the challenge of long-horizon video generation--hindering generative models from achieving a \textit{"GPT moment"} in the embodied domain. There is a naive observation: \textit{the diversity of embodied data far exceeds the relatively small space of possible primitive motions}. Based on this insight, we propose \textbf{Primitive Embodied World Models} (PEWM), which restricts video generation to fixed shorter horizons, our approach \textit{1) enables} fine-grained alignment between linguistic concepts and visual representations of robotic actions, \textit{2) reduces} learning complexity, \textit{3) improves} data efficiency in embodied data collection, and \textit{4) decreases} inference latency. By equipping with a modular Vision-Language Model (VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further enables flexible closed-loop control and supports compositional generalization of primitive-level policies over extended, complex tasks. Our framework leverages the spatiotemporal vision priors in video models and the semantic awareness of VLMs to bridge the gap between fine-grained physical interaction and high-level reasoning, paving the way toward scalable, interpretable, and general-purpose embodied intelligence.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18739v1" target="_blank"><h2>A Problem-Oriented Taxonomy of Evaluation Metrics for Time Series Anomaly Detection</h2></a><strong><u>Authors:</u></strong> Kaixiang Yang, Jiarong Liu, Yupeng Song, Shuanghua Yang, Yujue Zhou<br><strong><u>Categories:</u></strong> cs.AI, cs.LG, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)<br><p><strong><u>Abstract:</u></strong> Time series anomaly detection is widely used in IoT and cyber-physical systems, yet its evaluation remains challenging due to diverse application objectives and heterogeneous metric assumptions. This study introduces a problem-oriented framework that reinterprets existing metrics based on the specific evaluation challenges they are designed to address, rather than their mathematical forms or output structures. We categorize over twenty commonly used metrics into six dimensions: 1) basic accuracy-driven evaluation; 2) timeliness-aware reward mechanisms; 3) tolerance to labeling imprecision; 4) penalties reflecting human-audit cost; 5) robustness against random or inflated scores; and 6) parameter-free comparability for cross-dataset benchmarking. Comprehensive experiments are conducted to examine metric behavior under genuine, random, and oracle detection scenarios. By comparing their resulting score distributions, we quantify each metric's discriminative ability -- its capability to distinguish meaningful detections from random noise. The results show that while most event-level metrics exhibit strong separability, several widely used metrics (e.g., NAB, Point-Adjust) demonstrate limited resistance to random-score inflation. These findings reveal that metric suitability must be inherently task-dependent and aligned with the operational objectives of IoT applications. The proposed framework offers a unified analytical perspective for understanding existing metrics and provides practical guidance for selecting or developing more context-aware, robust, and fair evaluation methodologies for time series anomaly detection.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18732v1" target="_blank"><h2>OceanForecastBench: A Benchmark Dataset for Data-Driven Global Ocean Forecasting</h2></a><strong><u>Authors:</u></strong> Haoming Jia, Yi Han, Xiang Wang, Huizan Wang, Wei Wu, Jianming Zheng, Peikun Xiao<br><strong><u>Categories:</u></strong> cs.LG, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract)<br><p><strong><u>Abstract:</u></strong> Global ocean forecasting aims to predict key ocean variables such as temperature, salinity, and currents, which is essential for understanding and describing oceanic phenomena. In recent years, data-driven deep learning-based ocean forecast models, such as XiHe, WenHai, LangYa and AI-GOMS, have demonstrated significant potential in capturing complex ocean dynamics and improving forecasting efficiency. Despite these advancements, the absence of open-source, standardized benchmarks has led to inconsistent data usage and evaluation methods. This gap hinders efficient model development, impedes fair performance comparison, and constrains interdisciplinary collaboration. To address this challenge, we propose OceanForecastBench, a benchmark offering three core contributions: (1) A high-quality global ocean reanalysis data over 28 years for model training, including 4 ocean variables across 23 depth levels and 4 sea surface variables. (2) A high-reliability satellite and in-situ observations for model evaluation, covering approximately 100 million locations in the global ocean. (3) An evaluation pipeline and a comprehensive benchmark with 6 typical baseline models, leveraging observations to evaluate model performance from multiple perspectives. OceanForecastBench represents the most comprehensive benchmarking framework currently available for data-driven ocean forecasting, offering an open-source platform for model development, evaluation, and comparison. The dataset and code are publicly available at: https://github.com/Ocean-Intelligent-Forecasting/OceanForecastBench.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18730v1" target="_blank"><h2>Large-Scale In-Game Outcome Forecasting for Match, Team and Players in Football using an Axial Transformer Neural Network</h2></a><strong><u>Authors:</u></strong> Michael Horton, Patrick Lucey<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 25 pages, 7 figures, 1 table<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Football (soccer) is a sport that is characterised by complex game play, where players perform a variety of actions, such as passes, shots, tackles, fouls, in order to score goals, and ultimately win matches. Accurately forecasting the total number of each action that each player will complete during a match is desirable for a variety of applications, including tactical decision-making, sports betting, and for television broadcast commentary and analysis. Such predictions must consider the game state, the ability and skill of the players in both teams, the interactions between the players, and the temporal dynamics of the game as it develops. In this paper, we present a transformer-based neural network that jointly and recurrently predicts the expected totals for thirteen individual actions at multiple time-steps during the match, and where predictions are made for each individual player, each team and at the game-level. The neural network is based on an \emph{axial transformer} that efficiently captures the temporal dynamics as the game progresses, and the interactions between the players at each time-step. We present a novel axial transformer design that we show is equivalent to a regular sequential transformer, and the design performs well experimentally. We show empirically that the model can make consistent and reliable predictions, and efficiently makes $\sim$75,000 live predictions at low latency for each game.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18718v1" target="_blank"><h2>AIRHILT: A Human-in-the-Loop Testbed for Multimodal Conflict Detection in Aviation</h2></a><strong><u>Authors:</u></strong> Omar Garib, Jayaprakash D. Kambhampaty, Olivia J. Pinon Fischer, Dimitri N. Mavris<br><strong><u>Categories:</u></strong> cs.RO, cs.AI<br><strong><u>Comments:</u></strong> 9 pages, 4 figures, 1 table, 1 algorithm<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> We introduce AIRHILT (Aviation Integrated Reasoning, Human-in-the-Loop Testbed), a modular and lightweight simulation environment designed to evaluate multimodal pilot and air traffic control (ATC) assistance systems for aviation conflict detection. Built on the open-source Godot engine, AIRHILT synchronizes pilot and ATC radio communications, visual scene understanding from camera streams, and ADS-B surveillance data within a unified, scalable platform. The environment supports pilot- and controller-in-the-loop interactions, providing a comprehensive scenario suite covering both terminal area and en route operational conflicts, including communication errors and procedural mistakes. AIRHILT offers standardized JSON-based interfaces that enable researchers to easily integrate, swap, and evaluate automatic speech recognition (ASR), visual detection, decision-making, and text-to-speech (TTS) models. We demonstrate AIRHILT through a reference pipeline incorporating fine-tuned Whisper ASR, YOLO-based visual detection, ADS-B-based conflict logic, and GPT-OSS-20B structured reasoning, and present preliminary results from representative runway-overlap scenarios, where the assistant achieves an average time-to-first-warning of approximately 7.7 s, with average ASR and vision latencies of approximately 5.9 s and 0.4 s, respectively. The AIRHILT environment and scenario suite are openly available, supporting reproducible research on multimodal situational awareness and conflict detection in aviation; code and scenarios are available at https://github.com/ogarib3/airhilt.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18716v1" target="_blank"><h2>GRIT-LP: Graph Transformer with Long-Range Skip Connection and Partitioned Spatial Graphs for Accurate Ice Layer Thickness Prediction</h2></a><strong><u>Authors:</u></strong> Zesheng Liu, Maryam Rahnemoonfar<br><strong><u>Categories:</u></strong> cs.LG, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Graph transformers have demonstrated remarkable capability on complex spatio-temporal tasks, yet their depth is often limited by oversmoothing and weak long-range dependency modeling. To address these challenges, we introduce GRIT-LP, a graph transformer explicitly designed for polar ice-layer thickness estimation from polar radar imagery. Accurately estimating ice layer thickness is critical for understanding snow accumulation, reconstructing past climate patterns and reducing uncertainties in projections of future ice sheet evolution and sea level rise. GRIT-LP combines an inductive geometric graph learning framework with self-attention mechanism, and introduces two major innovations that jointly address challenges in modeling the spatio-temporal patterns of ice layers: a partitioned spatial graph construction strategy that forms overlapping, fully connected local neighborhoods to preserve spatial coherence and suppress noise from irrelevant long-range links, and a long-range skip connection mechanism within the transformer that improves information flow and mitigates oversmoothing in deeper attention layers. We conducted extensive experiments, demonstrating that GRIT-LP outperforms current state-of-the-art methods with a 24.92\% improvement in root mean squared error. These results highlight the effectiveness of graph transformers in modeling spatiotemporal patterns by capturing both localized structural features and long-range dependencies across internal ice layers, and demonstrate their potential to advance data-driven understanding of cryospheric processes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18715v1" target="_blank"><h2>HuggingR$^{4}$: A Progressive Reasoning Framework for Discovering Optimal Model Companions</h2></a><strong><u>Authors:</u></strong> Shaoyin Ma, Jie Song, Huiqiong Wang, Li Sun, Mingli Song<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> 19 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) have made remarkable progress in their ability to interact with external interfaces. Selecting reasonable external interfaces has thus become a crucial step in constructing LLM agents. In contrast to invoking API tools, directly calling AI models across different modalities from the community (e.g., HuggingFace) poses challenges due to the vast scale (> 10k), metadata gaps, and unstructured descriptions. Current methods for model selection often involve incorporating entire model descriptions into prompts, resulting in prompt bloat, wastage of tokens and limited scalability. To address these issues, we propose HuggingR$^4$, a novel framework that combines Reasoning, Retrieval, Refinement, and Reflection, to efficiently select models. Specifically, We first perform multiple rounds of reasoning and retrieval to get a coarse list of candidate models. Then, we conduct fine-grained refinement by analyzing candidate model descriptions, followed by reflection to assess results and determine if retrieval scope expansion is necessary. This method reduces token consumption considerably by decoupling user query processing from complex model description handling. Through a pre-established vector database, complex model descriptions are stored externally and retrieved on-demand, allowing the LLM to concentrate on interpreting user intent while accessing only relevant candidate models without prompt bloat. In the absence of standardized benchmarks, we construct a multimodal human-annotated dataset comprising 14,399 user requests across 37 tasks and conduct a thorough evaluation. HuggingR$^4$ attains a workability rate of 92.03% and a reasonability rate of 82.46%, surpassing existing method by 26.51% and 33.25% respectively on GPT-4o-mini.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18714v1" target="_blank"><h2>MAGMA-Edu: Multi-Agent Generative Multimodal Framework for Text-Diagram Educational Question Generation</h2></a><strong><u>Authors:</u></strong> Zhenyu Wu, Jian Li, Hua Huang<br><strong><u>Categories:</u></strong> cs.AI, cs.CY<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Educational illustrations play a central role in communicating abstract concepts, yet current multimodal large language models (MLLMs) remain limited in producing pedagogically coherent and semantically consistent educational visuals. We introduce MAGMA-Edu, a self-reflective multi-agent framework that unifies textual reasoning and diagrammatic synthesis for structured educational problem generation. Unlike existing methods that treat text and image generation independently, MAGMA-Edu employs a two-stage co-evolutionary pipeline: (1) a generation-verification-reflection loop that iteratively refines question statements and solutions for mathematical accuracy, and (2) a code-based intermediate representation that enforces geometric fidelity and semantic alignment during image rendering. Both stages are guided by internal self-reflection modules that evaluate and revise outputs until domain-specific pedagogical constraints are met. Extensive experiments on multimodal educational benchmarks demonstrate the superiority of MAGMA-Edu over state-of-the-art MLLMs. Compared to GPT-4o, MAGMA-Edu improves the average textual metric from 57.01 to 92.31 (+35.3 pp) and boosts image-text consistency (ITC) from 13.20 to 85.24 (+72 pp). Across all model backbones, MAGMA-Edu achieves the highest scores (Avg-Text 96.20, ITC 99.12), establishing a new state of the art for multimodal educational content generation and demonstrating the effectiveness of self-reflective multi-agent collaboration in pedagogically aligned vision-language reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18711v1" target="_blank"><h2>Modality-Collaborative Low-Rank Decomposers for Few-Shot Video Domain Adaptation</h2></a><strong><u>Authors:</u></strong> Yuyang Wanyan, Xiaoshan Yang, Weiming Dong, Changsheng Xu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), domain adaptation (title, abstract)<br><p><strong><u>Abstract:</u></strong> In this paper, we study the challenging task of Few-Shot Video Domain Adaptation (FSVDA). The multimodal nature of videos introduces unique challenges, necessitating the simultaneous consideration of both domain alignment and modality collaboration in a few-shot scenario, which is ignored in previous literature. We observe that, under the influence of domain shift, the generalization performance on the target domain of each individual modality, as well as that of fused multimodal features, is constrained. Because each modality is comprised of coupled features with multiple components that exhibit different domain shifts. This variability increases the complexity of domain adaptation, thereby reducing the effectiveness of multimodal feature integration. To address these challenges, we introduce a novel framework of Modality-Collaborative LowRank Decomposers (MC-LRD) to decompose modality-unique and modality-shared features with different domain shift levels from each modality that are more friendly for domain alignment. The MC-LRD comprises multiple decomposers for each modality and Multimodal Decomposition Routers (MDR). Each decomposer has progressively shared parameters across different modalities. The MDR is leveraged to selectively activate the decomposers to produce modality-unique and modality-shared features. To ensure efficient decomposition, we apply orthogonal decorrelation constraints separately to decomposers and subrouters, enhancing their diversity. Furthermore, we propose a cross-domain activation consistency loss to guarantee that target and source samples of the same category exhibit consistent activation preferences of the decomposers, thereby facilitating domain alignment. Extensive experimental results on three public benchmarks demonstrate that our model achieves significant improvements over existing methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18701v1" target="_blank"><h2>ObjectAlign: Neuro-Symbolic Object Consistency Verification and Correction</h2></a><strong><u>Authors:</u></strong> Mustafa Munir, Harsh Goel, Xiwen Wei, Minkyu Choi, Sahil Shah, Kartikeya Bhardwaj, Paul Whatmough, Sandeep Chinchali, Radu Marculescu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.FL, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Video editing and synthesis often introduce object inconsistencies, such as frame flicker and identity drift that degrade perceptual quality. To address these issues, we introduce ObjectAlign, a novel framework that seamlessly blends perceptual metrics with symbolic reasoning to detect, verify, and correct object-level and temporal inconsistencies in edited video sequences. The novel contributions of ObjectAlign are as follows: First, we propose learnable thresholds for metrics characterizing object consistency (i.e. CLIP-based semantic similarity, LPIPS perceptual distance, histogram correlation, and SAM-derived object-mask IoU). Second, we introduce a neuro-symbolic verifier that combines two components: (a) a formal, SMT-based check that operates on masked object embeddings to provably guarantee that object identity does not drift, and (b) a temporal fidelity check that uses a probabilistic model checker to verify the video's formal representation against a temporal logic specification. A frame transition is subsequently deemed "consistent" based on a single logical assertion that requires satisfying both the learned metric thresholds and this unified neuro-symbolic constraint, ensuring both low-level stability and high-level temporal correctness. Finally, for each contiguous block of flagged frames, we propose a neural network based interpolation for adaptive frame repair, dynamically choosing the interpolation depth based on the number of frames to be corrected. This enables reconstruction of the corrupted frames from the last valid and next valid keyframes. Our results show up to 1.4 point improvement in CLIP Score and up to 6.1 point improvement in warp error compared to SOTA baselines on the DAVIS and Pexels video datasets.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18699v1" target="_blank"><h2>Dendritic Convolution for Noise Image Recognition</h2></a><strong><u>Authors:</u></strong> Jiarui Xue, Dongjian Yang, Ye Sun, Gang Liu<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 11 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> In real-world scenarios of image recognition, there exists substantial noise interference. Existing works primarily focus on methods such as adjusting networks or training strategies to address noisy image recognition, and the anti-noise performance has reached a bottleneck. However, little is known about the exploration of anti-interference solutions from a neuronal perspective.This paper proposes an anti-noise neuronal convolution. This convolution mimics the dendritic structure of neurons, integrates the neighborhood interaction computation logic of dendrites into the underlying design of convolutional operations, and simulates the XOR logic preprocessing function of biological dendrites through nonlinear interactions between input features, thereby fundamentally reconstructing the mathematical paradigm of feature extraction. Unlike traditional convolution where noise directly interferes with feature extraction and exerts a significant impact, DDC mitigates the influence of noise by focusing on the interaction of neighborhood information. Experimental results demonstrate that in image classification tasks (using YOLOv11-cls, VGG16, and EfficientNet-B0) and object detection tasks (using YOLOv11, YOLOv8, and YOLOv5), after replacing traditional convolution with the dendritic convolution, the accuracy of the EfficientNet-B0 model on noisy datasets is relatively improved by 11.23%, and the mean Average Precision (mAP) of YOLOv8 is increased by 19.80%. The consistency between the computation method of this convolution and the dendrites of biological neurons enables it to perform significantly better than traditional convolution in complex noisy environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18698v1" target="_blank"><h2>Multimodal Real-Time Anomaly Detection and Industrial Applications</h2></a><strong><u>Authors:</u></strong> Aman Verma, Keshav Samdani, Mohd. Samiuddin Shafi<br><strong><u>Categories:</u></strong> cs.SD, cs.AI, cs.CV, cs.LG, cs.MM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), multimodal (title, abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> This paper presents the design, implementation, and evolution of a comprehensive multimodal room-monitoring system that integrates synchronized video and audio processing for real-time activity recognition and anomaly detection. We describe two iterations of the system: an initial lightweight implementation using YOLOv8, ByteTrack, and the Audio Spectrogram Transformer (AST), and an advanced version that incorporates multi-model audio ensembles, hybrid object detection, bidirectional cross-modal attention, and multi-method anomaly detection. The evolution demonstrates significant improvements in accuracy, robustness, and industrial applicability. The advanced system combines three audio models (AST, Wav2Vec2, and HuBERT) for comprehensive audio understanding, dual object detectors (YOLO and DETR) for improved accuracy, and sophisticated fusion mechanisms for enhanced cross-modal learning. Experimental evaluation shows the system's effectiveness in general monitoring scenarios as well as specialized industrial safety applications, achieving real-time performance on standard hardware while maintaining high accuracy.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18689v1" target="_blank"><h2>QuantKAN: A Unified Quantization Framework for Kolmogorov Arnold Networks</h2></a><strong><u>Authors:</u></strong> Kazi Ahmed Asif Fuad, Lizhong Chen<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Kolmogorov Arnold Networks (KANs) represent a new class of neural architectures that replace conventional linear transformations and node-based nonlinearities with spline-based function approximations distributed along network edges. Although KANs offer strong expressivity and interpretability, their heterogeneous spline and base branch parameters hinder efficient quantization, which remains unexamined compared to CNNs and Transformers. In this paper, we present QuantKAN, a unified framework for quantizing KANs across both quantization aware training (QAT) and post-training quantization (PTQ) regimes. QuantKAN extends modern quantization algorithms, such as LSQ, LSQ+, PACT, DoReFa, QIL, GPTQ, BRECQ, AdaRound, AWQ, and HAWQ-V2, to spline based layers with branch-specific quantizers for base, spline, and activation components. Through extensive experiments on MNIST, CIFAR 10, and CIFAR 100 across multiple KAN variants (EfficientKAN, FastKAN, PyKAN, and KAGN), we establish the first systematic benchmarks for low-bit spline networks. Our results show that KANs, particularly deeper KAGN variants, are compatible with low-bit quantization but exhibit strong method architecture interactions: LSQ, LSQ+, and PACT preserve near full precision accuracy at 4 bit for shallow KAN MLP and ConvNet models, while DoReFa provides the most stable behavior for deeper KAGN under aggressive low-bit settings. For PTQ, GPTQ and Uniform consistently deliver the strongest overall performance across datasets, with BRECQ highly competitive on simpler regimes such as MNIST. Our proposed QuantKAN framework thus unifies spline learning and quantization, and provides practical tools and guidelines for efficiently deploying KANs in real-world, resource-constrained environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18678v1" target="_blank"><h2>Fast Radio Bursts from White Dwarf Binary Mergers: Isolated and Triple-Induced Channels</h2></a><strong><u>Authors:</u></strong> Cheyanne Shariat, Claire S. Ye, Smadar Naoz, Sanaea Rose<br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA, astro-ph.SR<br><strong><u>Comments:</u></strong> 11 pages, 3 figures; Submitted to ApJL, all comments are welcome!<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> The detection of fast radio bursts (FRBs) in both young and old stellar populations suggests multiple formation pathways, beyond just young magnetars from core-collapse supernovae. A promising delayed channel involves the formation of FRB-emitting neutron stars through merger- or accretion-induced collapse of a massive white dwarf (WD). By simulating a realistic stellar population with both binaries and triples, we identify pathways to WD collapse that could produce FRB candidates. We find that (i) triple dynamics open new merger channels inaccessible to isolated binaries, significantly enhancing the overall merger rate; (ii) triple-induced mergers broaden the delay-time distribution, producing long-delay ($\gtrsim1$-8~Gyr) events largely independent of metallicity, alongside a shorter-delay population ($\lesssim100$~Myr) of rapid mergers; (iii) these long delays naturally yield FRBs in older environments such as quiescent host galaxies and galactic halos; (iv) when convolved with the cosmic star-formation history, binary channels track the star-formation rate ($z_{\rm peak} \sim 2$), while triple channels peak later ($z_{\rm peak} \sim 1$), giving a combined local source rate of $R_0 \approx 2\times10^4~{\rm Gpc^{-3}~yr^{-1}}$, consistent with observations; and (v) applying the same framework to Type~Ia supernovae, we find that triples extend the delay-time tail and roughly double the Ia efficiency relative to binaries, yielding rates and redshift evolution in good agreement with observations. If FRBs originate from the collapse of WDs, our results establish triples, alongside binaries, as a crucial and previously overlooked formation pathway whose predicted rates, host demographics, and redshift evolution offer clear tests for upcoming surveys.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18670v1" target="_blank"><h2>Deterministic Continuous Replacement: Fast and Stable Module Replacement in Pretrained Transformers</h2></a><strong><u>Authors:</u></strong> Rowan Bradbury, Aniket Srinivasan Ashok, Sai Ram Kasanagottu, Gunmay Jhingran, Shuai Meng<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> Accepted to NeurIPS 2025 ScaleOPT Workshop; 8 pages; includes figures<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> transformer (title), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Replacing modules in pretrained models, especially swapping quadratic self-attention for efficient attention alternatives, poses a hard optimization problem: cold-start reinitialization destabilizes frozen backbones. We isolate this core stability challenge in a controlled study. Deterministic Continuous Replacement (DCR) blends teacher and student outputs with a deterministic, annealed weight. Theoretically, DCR eliminates gate-induced gradient variance inherent to stochastic replacement. In a single-seed study, DCR attains faster convergence and stronger alignment than stochastic gating and distillation baselines on controlled attention replacement, establishing a foundation for heterogeneous operator swaps.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18667v1" target="_blank"><h2>Equivariant Deep Equilibrium Models for Imaging Inverse Problems</h2></a><strong><u>Authors:</u></strong> Alexander Mehta, Ruangrawee Kitichotkul, Vivek K Goyal, Julián Tachella<br><strong><u>Categories:</u></strong> eess.IV, cs.LG, eess.SP<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-24<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Equivariant imaging (EI) enables training signal reconstruction models without requiring ground truth data by leveraging signal symmetries. Deep equilibrium models (DEQs) are a powerful class of neural networks where the output is a fixed point of a learned operator. However, training DEQs with complex EI losses requires implicit differentiation through fixed-point computations, whose implementation can be challenging. We show that backpropagation can be implemented modularly, simplifying training. Experiments demonstrate that DEQs trained with implicit differentiation outperform those trained with Jacobian-free backpropagation and other baseline methods. Additionally, we find evidence that EI-trained DEQs approximate the proximal map of an invariant prior.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18657v1" target="_blank"><h2>How Complex is Dark Energy? A Bayesian Analysis of CPL Extensions with Recent DESI BAO Measurements <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Mohammad Malekjani, Saeed Pourojaghi, Zahra Davari<br><strong><u>Categories:</u></strong> astro-ph.CO, gr-qc, hep-th<br><strong><u>Comments:</u></strong> 13 Pages, 2 Figures, and 12 Tables<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> The nature of dark energy is one of the big puzzling issues in cosmology. While $Λ$CDM provides a good fit to the observational data, evolving dark energy scenarios, such as the CPL parametrization, offer a compelling alternative. In this paper, we present a Bayesian model comparison of various dark energy parametrizations using a joint analysis of Cosmic Microwave Background data, DESI Baryon Acoustic Oscillation measurements, and the PantheonPlus (or Union3) Supernovae type Ia sample. We find that while the $Λ$CDM model is initially favored over a constant $w$CDM model, the CPL parametrization is significantly preferred over $w$CDM, reinforcing recent evidence for an evolving dark energy component, consistent with DESI collaboration findings. Crucially, when testing higher-order CPL extensions, the so-called CPL$^+$ and CPL$^{++}$, our Bayesian analysis shows that the observational data do not favor these more complex scenarios compared to the standard CPL. This result indicates that adding excessive complexity to the CPL form is unwarranted by current observations. Interestingly, similar to the CPL parametrization, alternative two-parameter forms, specifically $w_{de}(a) = w_0 + w_b(1-a)^2$ and $w_{de}(a) = w_0 + w_c(1-a)^3$, yield a better fit to observational data than the standard $Λ$CDM cosmology. Our results challenge the necessity for overly complex CPL extensions and confirm that well-chosen two-parameter $w_0w_a$ parametrizations effectively capture DE evolution with current cosmological data, supporting the recent signals for dynamical dark energy by DESI collaboration.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18651v1" target="_blank"><h2>Lean 5.0: A Predictive, Human-AI, and Ethically Grounded Paradigm for Construction Management</h2></a><strong><u>Authors:</u></strong> Atena Khoshkonesh, Mohsen Mohammadagha, Navid Ebrahimi, Narges Sadeghigolshan<br><strong><u>Categories:</u></strong> cs.CE, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> literature review (abstract)<br><p><strong><u>Abstract:</u></strong> This paper introduces Lean 5.0, a human-centric evolution of Lean-Digital integration that connects predictive analytics, AI collaboration, and continuous learning within Industry 5.0 and Construction 5.0 contexts. A systematic literature review (2019-2024) and a 12-week empirical validation study demonstrate measurable performance gains, including a 13% increase in Plan Percent Complete (PPC), 22% reduction in rework, and 42% improvement in forecast accuracy. The study adopts a mixed-method Design Science Research (DSR) approach aligned with PRISMA 2020 guidelines. The paper also examines integration with digital twin and blockchain technologies to improve traceability, auditability, and lifecycle transparency. Despite limitations related to sample size, single-case design, and study duration, the findings show that Lean 5.0 provides a transformative paradigm connecting human cognition with predictive control in construction management.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18633v1" target="_blank"><h2>Bridging Philosophy and Machine Learning: A Structuralist Framework for Classifying Neural Network Representations</h2></a><strong><u>Authors:</u></strong> Yildiz Culcu<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> 7 pages, 1 figure, 1 table. Developed from the author's bachelor thesis but substantially revised and reformulated for research publication<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Machine learning models increasingly function as representational systems, yet the philosoph- ical assumptions underlying their internal structures remain largely unexamined. This paper develops a structuralist decision framework for classifying the implicit ontological commitments made in machine learning research on neural network representations. Using a modified PRISMA protocol, a systematic review of the last two decades of literature on representation learning and interpretability is conducted. Five influential papers are analysed through three hierarchical criteria derived from structuralist philosophy of science: entity elimination, source of structure, and mode of existence. The results reveal a pronounced tendency toward structural idealism, where learned representations are treated as model-dependent constructions shaped by architec- ture, data priors, and training dynamics. Eliminative and non-eliminative structuralist stances appear selectively, while structural realism is notably absent. The proposed framework clarifies conceptual tensions in debates on interpretability, emergence, and epistemic trust in machine learning, and offers a rigorous foundation for future interdisciplinary work between philosophy of science and machine learning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18632v1" target="_blank"><h2>The Locally Deployable Virtual Doctor: LLM Based Human Interface for Automated Anamnesis and Database Conversion</h2></a><strong><u>Authors:</u></strong> Jan Benedikt Ruhland, Doguhan Bahcivan, Jan-Peter Sowa, Ali Canbay, Dominik Heider<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in large language models made it possible to achieve high conversational performance with substantially reduced computational demands, enabling practical on-site deployment in clinical environments. Such progress allows for local integration of AI systems that uphold strict data protection and patient privacy requirements, yet their secure implementation in medicine necessitates careful consideration of ethical, regulatory, and technical constraints.
  In this study, we introduce MedChat, a locally deployable virtual physician framework that integrates an LLM-based medical chatbot with a diffusion-driven avatar for automated and structured anamnesis. The chatbot was fine-tuned using a hybrid corpus of real and synthetically generated medical dialogues, while model efficiency was optimized via Low-Rank Adaptation. A secure and isolated database interface was implemented to ensure complete separation between patient data and the inference process. The avatar component was realized through a conditional diffusion model operating in latent space, trained on researcher video datasets and synchronized with mel-frequency audio features for realistic speech and facial animation.
  Unlike existing cloud-based systems, this work demonstrates the feasibility of a fully offline, locally deployable LLM-diffusion framework for clinical anamnesis. The autoencoder and diffusion networks exhibited smooth convergence, and MedChat achieved stable fine-tuning with strong generalization to unseen data. The proposed system thus provides a privacy-preserving, resource-efficient foundation for AI-assisted clinical anamnesis, also in low-cost settings.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18627v1" target="_blank"><h2>Functional Localization Enforced Deep Anomaly Detection Using Fundus Images</h2></a><strong><u>Authors:</u></strong> Jan Benedikt Ruhland, Thorsten Papenbrock, Jan-Peter Sowa, Ali Canbay, Nicole Eter, Bernd Freisleben, Dominik Heider<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (title), explainability (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Reliable detection of retinal diseases from fundus images is challenged by the variability in imaging quality, subtle early-stage manifestations, and domain shift across datasets. In this study, we systematically evaluated a Vision Transformer (ViT) classifier under multiple augmentation and enhancement strategies across several heterogeneous public datasets, as well as the AEyeDB dataset, a high-quality fundus dataset created in-house and made available for the research community. The ViT demonstrated consistently strong performance, with accuracies ranging from 0.789 to 0.843 across datasets and diseases. Diabetic retinopathy and age-related macular degeneration were detected reliably, whereas glaucoma remained the most frequently misclassified disease. Geometric and color augmentations provided the most stable improvements, while histogram equalization benefited datasets dominated by structural subtlety. Laplacian enhancement reduced performance across different settings.
  On the Papila dataset, the ViT with geometric augmentation achieved an AUC of 0.91, outperforming previously reported convolutional ensemble baselines (AUC of 0.87), underscoring the advantages of transformer architectures and multi-dataset training. To complement the classifier, we developed a GANomaly-based anomaly detector, achieving an AUC of 0.76 while providing inherent reconstruction-based explainability and robust generalization to unseen data. Probabilistic calibration using GUESS enabled threshold-independent decision support for future clinical implementation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18618v1" target="_blank"><h2>A Unified BERT-CNN-BiLSTM Framework for Simultaneous Headline Classification and Sentiment Analysis of Bangla News</h2></a><strong><u>Authors:</u></strong> Mirza Raquib, Munazer Montasir Akash, Tawhid Ahmed, Saydul Akbar Murad, Farida Siddiqi Prity, Mohammad Amzad Hossain, Asif Pervez Polok, Nick Rahimi<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transfer learning (abstract)<br><p><strong><u>Abstract:</u></strong> In our daily lives, newspapers are an essential information source that impacts how the public talks about present-day issues. However, effectively navigating the vast amount of news content from different newspapers and online news portals can be challenging. Newspaper headlines with sentiment analysis tell us what the news is about (e.g., politics, sports) and how the news makes us feel (positive, negative, neutral). This helps us quickly understand the emotional tone of the news. This research presents a state-of-the-art approach to Bangla news headline classification combined with sentiment analysis applying Natural Language Processing (NLP) techniques, particularly the hybrid transfer learning model BERT-CNN-BiLSTM. We have explored a dataset called BAN-ABSA of 9014 news headlines, which is the first time that has been experimented with simultaneously in the headline and sentiment categorization in Bengali newspapers. Over this imbalanced dataset, we applied two experimental strategies: technique-1, where undersampling and oversampling are applied before splitting, and technique-2, where undersampling and oversampling are applied after splitting on the In technique-1 oversampling provided the strongest performance, both headline and sentiment, that is 78.57\% and 73.43\% respectively, while technique-2 delivered the highest result when trained directly on the original imbalanced dataset, both headline and sentiment, that is 81.37\% and 64.46\% respectively. The proposed model BERT-CNN-BiLSTM significantly outperforms all baseline models in classification tasks, and achieves new state-of-the-art results for Bangla news headline classification and sentiment analysis. These results demonstrate the importance of leveraging both the headline and sentiment datasets, and provide a strong baseline for Bangla text classification in low-resource.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18613v1" target="_blank"><h2>KAN vs LSTM Performance in Time Series Forecasting</h2></a><strong><u>Authors:</u></strong> Tabish Ali Rather, S M Mahmudul Hasan Joy, Nadezda Sukhorukova, Federico Frascoli<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> This paper compares Kolmogorov-Arnold Networks (KANs) and LSTMs for forecasting stock prices, highlighting that LSTMs provide superior predictive accuracy while KANs offer better interpretability and efficiency in limited-resource settings. Practical findings and future research directions are discussed<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> sequential data (abstract)<br><p><strong><u>Abstract:</u></strong> This paper compares Kolmogorov-Arnold Networks (KAN) and Long Short-Term Memory networks (LSTM) for forecasting non-deterministic stock price data, evaluating predictive accuracy versus interpretability trade-offs using Root Mean Square Error (RMSE).LSTM demonstrates substantial superiority across all tested prediction horizons, confirming their established effectiveness for sequential data modelling. Standard KAN, while offering theoretical interpretability through the Kolmogorov-Arnold representation theorem, exhibits significantly higher error rates and limited practical applicability for time series forecasting. The results confirm LSTM dominance in accuracy-critical time series applications while identifying computational efficiency as KANs' primary advantage in resource-constrained scenarios where accuracy requirements are less stringent. The findings support LSTM adoption for practical financial forecasting while suggesting that continued research into specialised KAN architectures may yield future improvements.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18611v1" target="_blank"><h2>CycleSL: Server-Client Cyclical Update Driven Scalable Split Learning</h2></a><strong><u>Authors:</u></strong> Mengdi Wang, Efe Bozkir, Enkelejda Kasneci<br><strong><u>Categories:</u></strong> cs.LG, cs.DC<br><strong><u>Comments:</u></strong> The IEEE/CVF Winter Conference on Applications of Computer Vision 2026 (WACV-26)<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Split learning emerges as a promising paradigm for collaborative distributed model training, akin to federated learning, by partitioning neural networks between clients and a server without raw data exchange. However, sequential split learning suffers from poor scalability, while parallel variants like parallel split learning and split federated learning often incur high server resource overhead due to model duplication and aggregation, and generally exhibit reduced model performance and convergence owing to factors like client drift and lag. To address these limitations, we introduce CycleSL, a novel aggregation-free split learning framework that enhances scalability and performance and can be seamlessly integrated with existing methods. Inspired by alternating block coordinate descent, CycleSL treats server-side training as an independent higher-level machine learning task, resampling client-extracted features (smashed data) to mitigate heterogeneity and drift. It then performs cyclical updates, namely optimizing the server model first, followed by client updates using the updated server for gradient computation. We integrate CycleSL into previous algorithms and benchmark them on five publicly available datasets with non-iid data distribution and partial client attendance. Our empirical findings highlight the effectiveness of CycleSL in enhancing model performance. Our source code is available at https://gitlab.lrz.de/hctl/CycleSL.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18606v1" target="_blank"><h2>How to Train Your Latent Control Barrier Function: Smooth Safety Filtering Under Hard-to-Model Constraints</h2></a><strong><u>Authors:</u></strong> Kensuke Nakamura, Arun L. Bishop, Steven Man, Aaron M. Johnson, Zachary Manchester, Andrea Bajcsy<br><strong><u>Categories:</u></strong> cs.RO, cs.LG<br><strong><u>Comments:</u></strong> 3 figures, 10 tables, 22 pages<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Latent safety filters extend Hamilton-Jacobi (HJ) reachability to operate on latent state representations and dynamics learned directly from high-dimensional observations, enabling safe visuomotor control under hard-to-model constraints. However, existing methods implement "least-restrictive" filtering that discretely switch between nominal and safety policies, potentially undermining the task performance that makes modern visuomotor policies valuable. While reachability value functions can, in principle, be adapted to be control barrier functions (CBFs) for smooth optimization-based filtering, we theoretically and empirically show that current latent-space learning methods produce fundamentally incompatible value functions. We identify two sources of incompatibility: First, in HJ reachability, failures are encoded via a "margin function" in latent space, whose sign indicates whether or not a latent is in the constraint set. However, representing the margin function as a classifier yields saturated value functions that exhibit discontinuous jumps. We prove that the value function's Lipschitz constant scales linearly with the margin function's Lipschitz constant, revealing that smooth CBFs require smooth margins. Second, reinforcement learning (RL) approximations trained solely on safety policy data yield inaccurate value estimates for nominal policy actions, precisely where CBF filtering needs them. We propose the LatentCBF, which addresses both challenges through gradient penalties that lead to smooth margin functions without additional labeling, and a value-training procedure that mixes data from both nominal and safety policy distributions. Experiments on simulated benchmarks and hardware with a vision-based manipulation policy demonstrate that LatentCBF enables smooth safety filtering while doubling the task-completion rate over prior switching methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18595v1" target="_blank"><h2>Stage-Specific Benchmarking of Deep Learning Models for Glioblastoma Follow-Up MRI</h2></a><strong><u>Authors:</u></strong> Wenhao Guo, Golrokh Mirzaei<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 17 pages, 11 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Differentiating true tumor progression (TP) from treatment-related pseudoprogression (PsP) in glioblastoma remains challenging, especially at early follow-up. We present the first stage-specific, cross-sectional benchmarking of deep learning models for follow-up MRI using the Burdenko GBM Progression cohort (n = 180). We analyze different post-RT scans independently to test whether architecture performance depends on time-point. Eleven representative DL families (CNNs, LSTMs, hybrids, transformers, and selective state-space models) were trained under a unified, QC-driven pipeline with patient-level cross-validation. Across both stages, accuracies were comparable (~0.70-0.74), but discrimination improved at the second follow-up, with F1 and AUC increasing for several models, indicating richer separability later in the care pathway. A Mamba+CNN hybrid consistently offered the best accuracy-efficiency trade-off, while transformer variants delivered competitive AUCs at substantially higher computational cost and lightweight CNNs were efficient but less reliable. Performance also showed sensitivity to batch size, underscoring the need for standardized training protocols. Notably, absolute discrimination remained modest overall, reflecting the intrinsic difficulty of TP vs. PsP and the dataset's size imbalance. These results establish a stage-aware benchmark and motivate future work incorporating longitudinal modeling, multi-sequence MRI, and larger multi-center cohorts.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18594v1" target="_blank"><h2>Autoencoder for Position-Assisted Beam Prediction in mmWave ISAC Systems</h2></a><strong><u>Authors:</u></strong> Ahmad A. Aziz El-Banna, Octavia A. Dobre<br><strong><u>Categories:</u></strong> eess.SP, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Integrated sensing and communication and millimeter wave (mmWave) have emerged as pivotal technologies for 6G networks. However, the narrow nature of mmWave beams requires precise alignments that typically necessitate large training overhead. This overhead can be reduced by incorporating the position information with beam adjustments. This letter proposes a lightweight autorencoder (LAE) model that addresses the position-assisted beam prediction problem while significantly reducing computational complexity compared to the conventional baseline method, i.e., deep fully connected neural network. The proposed LAE is designed as a three-layer undercomplete network to exploit its dimensionality reduction capabilities and thereby mitigate the computational requirements of the trained model. Simulation results show that the proposed model achieves a similar beam prediction accuracy to the baseline with an 83% complexity reduction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18590v1" target="_blank"><h2>From Simulations to Surveys: Domain Adaptation for Galaxy Observations <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Kaley Brauer, Aditya Prasad Dash, Meet J. Vyas, Ahmed Salim, Stiven Briand Massala<br><strong><u>Categories:</u></strong> astro-ph.GA, cs.LG<br><strong><u>Comments:</u></strong> 8 pages, 4 figures. Will be presented at NeurIPS 2025 ML4PS<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> domain adaptation (title, abstract)<br><p><strong><u>Abstract:</u></strong> Large photometric surveys will image billions of galaxies, but we currently lack quick, reliable automated ways to infer their physical properties like morphology, stellar mass, and star formation rates. Simulations provide galaxy images with ground-truth physical labels, but domain shifts in PSF, noise, backgrounds, selection, and label priors degrade transfer to real surveys. We present a preliminary domain adaptation pipeline that trains on simulated TNG50 galaxies and evaluates on real SDSS galaxies with morphology labels (elliptical/spiral/irregular). We train three backbones (CNN, $E(2)$-steerable CNN, ResNet-18) with focal loss and effective-number class weighting, and a feature-level domain loss $L_D$ built from GeomLoss (entropic Sinkhorn OT, energy distance, Gaussian MMD, and related metrics). We show that a combination of these losses with an OT-based "top_$k$ soft matching" loss that focuses $L_D$ on the worst-matched source-target pairs can further enhance domain alignment. With Euclidean distance, scheduled alignment weights, and top-$k$ matching, target accuracy (macro F1) rises from $\sim$46% ($\sim$30%) at no adaptation to $\sim$87% ($\sim$62.6%), with a domain AUC near 0.5, indicating strong latent-space mixing.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18578v1" target="_blank"><h2>Re(Visiting) Time Series Foundation Models in Finance</h2></a><strong><u>Authors:</u></strong> Eghbal Rahimikia, Hao Ni, Weiguan Wang<br><strong><u>Categories:</u></strong> q-fin.CP, cs.AI, cs.LG, q-fin.PM, q-fin.PR<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> Financial time series forecasting is central to trading, portfolio optimization, and risk management, yet it remains challenging due to noisy, non-stationary, and heterogeneous data. Recent advances in time series foundation models (TSFMs), inspired by large language models, offer a new paradigm for learning generalizable temporal representations from large and diverse datasets. This paper presents the first comprehensive empirical study of TSFMs in global financial markets. Using a large-scale dataset of daily excess returns across diverse markets, we evaluate zero-shot inference, fine-tuning, and pre-training from scratch against strong benchmark models. We find that off-the-shelf pre-trained TSFMs perform poorly in zero-shot and fine-tuning settings, whereas models pre-trained from scratch on financial data achieve substantial forecasting and economic improvements, underscoring the value of domain-specific adaptation. Increasing the dataset size, incorporating synthetic data augmentation, and applying hyperparameter tuning further enhance performance.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18571v1" target="_blank"><h2>SAMBA: Toward a Long-Context EEG Foundation Model via Spatial Embedding and Differential Mamba</h2></a><strong><u>Authors:</u></strong> Jiazhen Hong, Geoffrey Mackellar, Soheila Ghane<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Long-sequence electroencephalogram (EEG) modeling is essential for developing generalizable EEG representation models. This need arises from the high sampling rate of EEG data and the long recording durations required to capture extended neurological patterns in brain activity. Transformer-based models have shown promise in modeling short sequences of a few seconds; however, their quadratic complexity limits scalability to longer contexts. Moreover, variability in electrode montage across available datasets, along with inter-subject differences in brain signals, pose significant challenges to developing a generalizable and robust foundation model. We propose \textit{SAMBA}, a self-supervised learning framework with a Mamba-based U-shaped encoder-decoder architecture, which effectively captures long-range temporal dependencies and spatial variability in EEG data. Leveraging the inherent ability of Mamba in processing long context sizes, we introduce: (1) \textit{Temporal Semantic Random Masking} for semantic-level sequence reconstruction, (2) a \textit{Multi-Head Differential Mamba} module to suppress redundancy and emphasize salient temporal structures, and (3) a \textit{Spatial-Adaptive Input Embedding} that learns unified embeddings in a three-dimensional Euclidean space, enabling robustness across devices. Experiments on thirteen EEG datasets across diverse tasks, electrode configurations, and sequence durations demonstrate that SAMBA consistently outperforms state-of-the-art methods while maintaining low memory consumption and inference time. We also show the learned spatial weight maps from our embedding module align closely with task-relevant neurophysiological regions, demonstrating the learnability and interpretability of SAMBA. These results highlight SAMBA's scalability and practical potential as a foundation model for real-time brain-computer interface applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18567v1" target="_blank"><h2>In Search of Goodness: Large Scale Benchmarking of Goodness Functions for the Forward-Forward Algorithm</h2></a><strong><u>Authors:</u></strong> Arya Shah, Vaibhav Tripathi<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 24 pages, 5 tables, 17 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The Forward-Forward (FF) algorithm offers a biologically plausible alternative to backpropagation, enabling neural networks to learn through local updates. However, FF's efficacy relies heavily on the definition of "goodness", which is a scalar measure of neural activity. While current implementations predominantly utilize a simple sum-of-squares metric, it remains unclear if this default choice is optimal. To address this, we benchmarked 21 distinct goodness functions across four standard image datasets (MNIST, FashionMNIST, CIFAR-10, STL-10), evaluating classification accuracy, energy consumption, and carbon footprint. We found that certain alternative goodness functions inspired from various domains significantly outperform the standard baseline. Specifically, \texttt{game\_theoretic\_local} achieved 97.15\% accuracy on MNIST, \texttt{softmax\_energy\_margin\_local} reached 82.84\% on FashionMNIST, and \texttt{triplet\_margin\_local} attained 37.69\% on STL-10. Furthermore, we observed substantial variability in computational efficiency, highlighting a critical trade-off between predictive performance and environmental cost. These findings demonstrate that the goodness function is a pivotal hyperparameter in FF design. We release our code on \href{https://github.com/aryashah2k/In-Search-of-Goodness}{Github} for reference and reproducibility.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18565v1" target="_blank"><h2>Optimizing the potential of KM3NeT in detecting core-collapse supernovae <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> KM3NeT Collaboration, O. Adriani, A. Albert, A. R. Alhebsi, S. Alshalloudi, M. Alshamsi, S. Alves Garre, F. Ameli, M. Andre, L. Aphecetche, M. Ardid, S. Ardid, J. Aublin, F. Badaracco, L. Bailly-Salins, B. Baret, A. Bariego-Quintana, Y. Becherini, M. Bendahman, F. Benfenati Gualandi, M. Benhassi, D. M. Benoit, Z. Beňušová, E. Berbee, E. Berti, V. Bertin, P. Betti, S. Biagi, M. Boettcher, D. Bonanno, M. Bondì, S. Bottai, A. B. Bouasla, J. Boumaaza, M. Bouta, M. Bouwhuis, C. Bozza, R. M. Bozza, H. Brânzaš, F. Bretaudeau, M. Breuhaus, R. Bruijn, J. Brunner, R. Bruno, E. Buis, R. Buompane, I. Burriel, J. Busto, B. Caiffi, D. Calvo, A. Capone, F. Carenini, V. Carretero, T. Cartraud, P. Castaldi, V. Cecchini, S. Celli, L. Cerisy, M. Chabab, A. Chen, S. Cherubini, T. Chiarusi, W. Chung, M. Circella, R. Clark, R. Cocimano, J. A. B. Coelho, A. Coleiro, A. Condorelli, R. Coniglione, P. Coyle, A. Creusot, G. Cuttone, R. Dallier, A. De Benedittis, G. De Wasseige, V. Decoene, P. Deguire, I. Del Rosso, L. S. Di Mauro, I. Di Palma, A. F. Díaz, D. Diego-Tortosa, C. Distefano, A. Domi, C. Donzaud, D. Dornic, E. Drakopoulou, D. Drouhin, J. -G. Ducoin, P. Duverne, R. Dvornický, T. Eberl, E. Eckerová, A. Eddymaoui, T. van Eeden, M. Eff, D. van Eijk, I. El Bojaddaini, S. El Hedri, S. El Mentawi, V. Ellajosyula, A. Enzenhöfer, M. Farino, G. Ferrara, M. D. Filipović, F. Filippini, D. Franciotti, L. A. Fusco, T. Gal, J. García Méndez, A. Garcia Soto, C. Gatius Oliver, N. Geißelbrecht, E. Genton, H. Ghaddari, L. Gialanella, B. K. Gibson, E. Giorgio, I. Goos, P. Goswami, S. R. Gozzini, R. Gracia, B. Guillon, C. Haack, C. Hanna, H. van Haren, E. Hazelton, A. Heijboer, L. Hennig, J. J. Hernández-Rey, A. Idrissi, W. Idrissi Ibnsalih, G. Illuminati, R. Jaimes, O. Janik, D. Joly, M. de Jong, P. de Jong, B. J. Jung, P. Kalaczyński, U. F. Katz, J. Keegans, V. Kikvadze, G. Kistauri, C. Kopper, A. Kouchner, Y. Y. Kovalev, L. Krupa, V. Kueviakoe, V. Kulikovskiy, R. Kvatadze, M. Labalme, R. Lahmann, M. Lamoureux, A. Langella, G. Larosa, C. Lastoria, J. Lazar, A. Lazo, G. Lehaut, V. Lemaître, E. Leonora, N. Lessing, G. Levi, M. Lindsey Clark, F. Longhitano, S. Madarapu, F. Magnani, L. Malerba, F. Mamedov, A. Manfreda, A. Manousakis, M. Marconi, A. Margiotta, A. Marinelli, C. Markou, L. Martin, M. Mastrodicasa, S. Mastroianni, J. Mauro, K. C. K. Mehta, G. Miele, P. Migliozzi, E. Migneco, M. L. Mitsou, C. M. Mollo, L. Morales-Gallegos, N. Mori, A. Moussa, I. Mozun Mateo, R. Muller, M. R. Musone, M. Musumeci, S. Navas, A. Nayerhoda, C. A. Nicolau, B. Nkosi, B. Ó Fearraigh, V. Oliviero, A. Orlando, E. Oukacha, L. Pacini, D. Paesani, J. Palacios González, G. Papalashvili, P. Papini, V. Parisi, A. Parmar, C. Pastore, A. M. Păun, G. E. Păvălaš, S. Peña Martínez, M. Perrin-Terrin, V. Pestel, M. Petropavlova, P. Piattelli, A. Plavin, C. Poirè, V. Popa, T. Pradier, J. Prado, S. Pulvirenti, C. A. Quiroz-Rangel, N. Randazzo, A. Ratnani, S. Razzaque, I. C. Rea, D. Real, G. Riccobene, J. Robinson, A. Romanov, E. Ros, A. Šaina, F. Salesa Greus, D. F. E. Samtleben, A. Sánchez Losa, S. Sanfilippo, M. Sanguineti, D. Santonocito, P. Sapienza, M. Scaringella, M. Scarnera, J. Schnabel, J. Schumann, J. Seneca, P. A. Sevle Myhr, I. Sgura, R. Shanidze, Chengyu Shao, A. Sharma, Y. Shitov, F. Šimkovic, A. Simonelli, A. Sinopoulou, B. Spisso, M. Spurio, O. Starodubtsev, D. Stavropoulos, I. Štekl, D. Stocco, M. Taiuti, Y. Tayalati, H. Thiersen, S. Thoudam, I. Tosta e Melo, B. Trocmé, V. Tsourapis, C. Tully, E. Tzamariudaki, A. Ukleja, A. Vacheret, V. Valsecchi, V. Van Elewyck, G. Vannoye, E. Vannuccini, G. Vasileiadis, F. Vazquez de Sola, A. Veutro, S. Viola, D. Vivolo, A. van Vliet, E. de Wolf, I. Lhenry-Yvon, S. Zavatarelli, D. Zito, J. D. Zornoza, J. Zúñiga<br><strong><u>Categories:</u></strong> astro-ph.HE<br><strong><u>Comments:</u></strong> 24 pages, 11 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> VAE (title, abstract)<br><p><strong><u>Abstract:</u></strong> Core-collapse supernovae mark the end of life of massive stars. However, despite their importance in astrophysics, their underlying mechanisms remain unclear. Neutrinos that emerge from the dense core of the star offer a promising way to study supernova dynamics. A strategy is presented to improve the potential of the KM3NeT neutrino telescope to detect core-collapse supernovae in our Galaxy or the Large Magellanic Cloud by further exploiting the properties of its optical modules equipped with multiple photomultipliers. A supernova burst is expected to produce a sudden hit rate increase in the KM3NeT detectors. New observables have been defined for individual optical modules that exploit the geometry and time distribution of the detected hits, enabling a better discrimination between signal and background signatures. In addition, a thorough investigation of the related systematic uncertainties is presented for the first time. When implemented, this new methodology allowed KM3NeT to probe 46% more Galactic core-collapse supernova candidates than with the previous trigger strategy, reaching the dense Galactic bulge. It is now expected that, once completed, KM3NeT will achieve full Galactic sensitivity to core-collapse supernovae.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18530v1" target="_blank"><h2>Transforming Conditional Density Estimation Into a Single Nonparametric Regression Task</h2></a><strong><u>Authors:</u></strong> Alexander G. Reisach, Olivier Collier, Alex Luedtke, Antoine Chambaz<br><strong><u>Categories:</u></strong> stat.ML, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> We propose a way of transforming the problem of conditional density estimation into a single nonparametric regression task via the introduction of auxiliary samples. This allows leveraging regression methods that work well in high dimensions, such as neural networks and decision trees. Our main theoretical result characterizes and establishes the convergence of our estimator to the true conditional density in the data limit. We develop condensité, a method that implements this approach. We demonstrate the benefit of the auxiliary samples on synthetic data and showcase that condensité can achieve good out-of-the-box results. We evaluate our method on a large population survey dataset and on a satellite imaging dataset. In both cases, we find that condensité matches or outperforms the state of the art and yields conditional densities in line with established findings in the literature on each dataset. Our contribution opens up new possibilities for regression-based conditional density estimation and the empirical results indicate strong promise for applied research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18521v1" target="_blank"><h2>Hyperspectral Variational Autoencoders for Joint Data Compression and Component Extraction</h2></a><strong><u>Authors:</u></strong> Core Francisco Park, Manuel Perez-Carrasco, Caroline Nowlan, Cecilia Garraffo<br><strong><u>Categories:</u></strong> cs.LG, astro-ph.EP, astro-ph.IM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), VAE (abstract), latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Geostationary hyperspectral satellites generate terabytes of data daily, creating critical challenges for storage, transmission, and distribution to the scientific community. We present a variational autoencoder (VAE) approach that achieves x514 compression of NASA's TEMPO satellite hyperspectral observations (1028 channels, 290-490nm) with reconstruction errors 1-2 orders of magnitude below the signal across all wavelengths. This dramatic data volume reduction enables efficient archival and sharing of satellite observations while preserving spectral fidelity. Beyond compression, we investigate to what extent atmospheric information is retained in the compressed latent space by training linear and nonlinear probes to extract Level-2 products (NO2, O3, HCHO, cloud fraction). Cloud fraction and total ozone achieve strong extraction performance (R^2 = 0.93 and 0.81 respectively), though these represent relatively straightforward retrievals given their distinct spectral signatures. In contrast, tropospheric trace gases pose genuine challenges for extraction (NO2 R^2 = 0.20, HCHO R^2 = 0.51) reflecting their weaker signals and complex atmospheric interactions. Critically, we find the VAE encodes atmospheric information in a semi-linear manner - nonlinear probes substantially outperform linear ones - and that explicit latent supervision during training provides minimal improvement, revealing fundamental encoding challenges for certain products. This work demonstrates that neural compression can dramatically reduce hyperspectral data volumes while preserving key atmospheric signals, addressing a critical bottleneck for next-generation Earth observation systems. Code - https://github.com/cfpark00/Hyperspectral-VAE</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18517v1" target="_blank"><h2>Foundations of Artificial Intelligence Frameworks: Notion and Limits of AGI</h2></a><strong><u>Authors:</u></strong> Khanh Gia Bui<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> 49 pages, 4 pictures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Within the limited scope of this paper, we argue that artificial general intelligence cannot emerge from current neural network paradigms regardless of scale, nor is such an approach healthy for the field at present. Drawing on various notions, discussions, present-day developments and observations, current debates and critiques, experiments, and so on in between philosophy, including the Chinese Room Argument and Gödelian argument, neuroscientific ideas, computer science, the theoretical consideration of artificial intelligence, and learning theory, we address conceptually that neural networks are architecturally insufficient for genuine understanding. They operate as static function approximators of a limited encoding framework - a 'sophisticated sponge' exhibiting complex behaviours without structural richness that constitute intelligence. We critique the theoretical foundations the field relies on and created of recent times; for example, an interesting heuristic as neural scaling law (as an example, arXiv:2001.08361 ) made prominent in a wrong way of interpretation, The Universal Approximation Theorem addresses the wrong level of abstraction and, in parts, partially, the question of current architectures lacking dynamic restructuring capabilities. We propose a framework distinguishing existential facilities (computational substrate) from architectural organization (interpretive structures), and outline principles for what genuine machine intelligence would require, and furthermore, a conceptual method of structuralizing the richer framework on which the principle of neural network system takes hold.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18515v1" target="_blank"><h2>RRaPINNs: Residual Risk-Aware Physics Informed Neural Networks</h2></a><strong><u>Authors:</u></strong> Ange-Clément Akazan, Issa Karambal, Jean Medard Ngnotchouye, Abebe Geletu Selassie. W<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Physics-informed neural networks (PINNs) typically minimize average residuals, which can conceal large, localized errors. We propose Residual Risk-Aware Physics-Informed Neural Networks PINNs (RRaPINNs), a single-network framework that optimizes tail-focused objectives using Conditional Value-at-Risk (CVaR), we also introduced a Mean-Excess (ME) surrogate penalty to directly control worst-case PDE residuals. This casts PINN training as risk-sensitive optimization and links it to chance-constrained formulations. The method is effective and simple to implement. Across several partial differential equations (PDEs) such as Burgers, Heat, Korteweg-de-Vries, and Poisson (including a Poisson interface problem with a source jump at x=0.5) equations, RRaPINNs reduce tail residuals while maintaining or improving mean errors compared to vanilla PINNs, Residual-Based Attention and its variant using convolution weighting; the ME surrogate yields smoother optimization than a direct CVaR hinge. The chance constraint reliability level $α$ acts as a transparent knob trading bulk accuracy (lower $α$ ) for stricter tail control (higher $α$ ). We discuss the framework limitations, including memoryless sampling, global-only tail budgeting, and residual-centric risk, and outline remedies via persistent hard-point replay, local risk budgets, and multi-objective risk over BC/IC terms. RRaPINNs offer a practical path to reliability-aware scientific ML for both smooth and discontinuous PDEs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18507v1" target="_blank"><h2>Multimodal Continual Learning with MLLMs from Multi-scenario Perspectives</h2></a><strong><u>Authors:</u></strong> Kai Jiang, Siqi Huang, Xiangyu Chen, Jiawei Shao, Hongyuan Zhang, Xuelong Li<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 18 pages, 16 figures. This is a preprint version of a paper submitted to CVPR 2026<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Continual learning in visual understanding aims to deal with catastrophic forgetting in Multimodal Large Language Models (MLLMs). MLLMs deployed on devices have to continuously adapt to dynamic scenarios in downstream tasks, such as variations in background and perspective, to effectively perform complex visual tasks. To this end, we construct a multimodal visual understanding dataset (MSVQA) encompassing four different scenarios and perspectives including high altitude, underwater, low altitude and indoor, to investigate the catastrophic forgetting in MLLMs under the dynamics of scenario shifts in real-world data streams. Furthermore, we propose mUltimodal coNtInual learning with MLLMs From multi-scenarIo pERspectives (UNIFIER) to address visual discrepancies while learning different scenarios. Specifically, it decouples the visual information from different scenarios into distinct branches within each vision block and projects them into the same feature space. A consistency constraint is imposed on the features of each branch to maintain the stability of visual representations across scenarios. Extensive experiments on the MSVQA dataset demonstrate that UNIFIER effectively alleviates forgetting of cross-scenario tasks and achieves knowledge accumulation within the same scenario.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18493v1" target="_blank"><h2>Shape-Adapting Gated Experts: Dynamic Expert Routing for Colonoscopic Lesion Segmentation</h2></a><strong><u>Authors:</u></strong> Gia Huy Thai, Hoang-Nguyen Vu, Anh-Minh Phan, Quang-Thinh Ly, Tram Dinh, Thi-Ngoc-Truc Nguyen, Nhat Ho<br><strong><u>Categories:</u></strong> eess.IV, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> The substantial diversity in cell scale and form remains a primary challenge in computer-aided cancer detection on gigapixel Whole Slide Images (WSIs), attributable to cellular heterogeneity. Existing CNN-Transformer hybrids rely on static computation graphs with fixed routing, which consequently causes redundant computation and limits their adaptability to input variability. We propose Shape-Adapting Gated Experts (SAGE), an input-adaptive framework that enables dynamic expert routing in heterogeneous visual networks. SAGE reconfigures static backbones into dynamically routed expert architectures. SAGE's dual-path design features a backbone stream that preserves representation and selectively activates an expert path through hierarchical gating. This gating mechanism operates at multiple hierarchical levels, performing a two-level, hierarchical selection between shared and specialized experts to modulate model logits for Top-K activation. Our Shape-Adapting Hub (SA-Hub) harmonizes structural and semantic representations across the CNN and the Transformer module, effectively bridging diverse modules. Embodied as SAGE-UNet, our model achieves superior segmentation on three medical benchmarks: EBHI, DigestPath, and GlaS, yielding state-of-the-art Dice Scores of 95.57%, 95.16%, and 94.17%, respectively, and robustly generalizes across domains by adaptively balancing local refinement and global context. SAGE provides a scalable foundation for dynamic expert routing, enabling flexible visual reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18487v1" target="_blank"><h2>InstructAudio: Unified speech and music generation with natural language instruction</h2></a><strong><u>Authors:</u></strong> Chunyu Qiang, Kang Yin, Xiaopeng Wang, Yuzhe Liang, Jiahui Zhao, Ruibo Fu, Tianrui Wang, Cheng Gong, Chen Zhang, Longbiao Wang, Jianwu Dang<br><strong><u>Categories:</u></strong> eess.AS, cs.AI, cs.CL, cs.SD<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Text-to-speech (TTS) and text-to-music (TTM) models face significant limitations in instruction-based control. TTS systems usually depend on reference audio for timbre, offer only limited text-level attribute control, and rarely support dialogue generation. TTM systems are constrained by input conditioning requirements that depend on expert knowledge annotations. The high heterogeneity of these input control conditions makes them difficult to joint modeling with speech synthesis. Despite sharing common acoustic modeling characteristics, these two tasks have long been developed independently, leaving open the challenge of achieving unified modeling through natural language instructions. We introduce InstructAudio, a unified framework that enables instruction-based (natural language descriptions) control of acoustic attributes including timbre (gender, age), paralinguistic (emotion, style, accent), and musical (genre, instrument, rhythm, atmosphere). It supports expressive speech, music, and dialogue generation in English and Chinese. The model employs joint and single diffusion transformer layers with a standardized instruction-phoneme input format, trained on 50K hours of speech and 20K hours of music data, enabling multi-task learning and cross-modal alignment. Fig. 1 visualizes performance comparisons with mainstream TTS and TTM models, demonstrating that InstructAudio achieves optimal results on most metrics. To our best knowledge, InstructAudio represents the first instruction-controlled framework unifying speech and music generation. Audio samples are available at: https://qiangchunyu.github.io/InstructAudio/</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18477v1" target="_blank"><h2>A Deep Multimodal Multi--Head Neural Network for Joint Estimation of Stellar Age, Lifetime, and Evolutionary Stage</h2></a><strong><u>Authors:</u></strong> Jing Rou Puah, Sasa Arsovski<br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.SR<br><strong><u>Comments:</u></strong> 8 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (title), multimodal (title, abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate estimation of stellar parameters -- stellar age, lifetime, and evolutionary stage -- remains a fundamental challenge in astrophysics. We introduce a hybrid deep learning architecture combining multimodal spectroscopic and photometric data from SDSS DR17. The model comprises a Multi-Layer Perceptron for numerical features and a CNN with a Vision Transformer for spectra, with three output heads for age, lifetime, and evolutionary stage prediction. Training labels are derived from MIST v1.2 isochrones, with evolutionary stage binned into five classes (Hot, Medium, Cool, Subgiant, Red Giant). We conduct multi-phase evaluation: Phase I explores model architectures and data balancing strategies, Phase II tunes architectural complexity, and Phase III optimizes the multi-task loss composition. The final model achieves a balance between precision (Age RMSE 0.093 in $\log(\mathrm{yrs})$) and physical realism. Monte Carlo Dropout confirms well-calibrated uncertainties, enabling meaningful astrophysical interpretation and establishing a new benchmark for multimodal stellar parameter estimation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18474v1" target="_blank"><h2>Adaptive Mesh-Quantization for Neural PDE Solvers</h2></a><strong><u>Authors:</u></strong> Winfried van den Dool, Maksim Zhdanov, Yuki M. Asano, Max Welling<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Physical systems commonly exhibit spatially varying complexity, presenting a significant challenge for neural PDE solvers. While Graph Neural Networks can handle the irregular meshes required for complex geometries and boundary conditions, they still apply uniform computational effort across all nodes regardless of the underlying physics complexity. This leads to inefficient resource allocation where computationally simple regions receive the same treatment as complex phenomena. We address this challenge by introducing Adaptive Mesh Quantization: spatially adaptive quantization across mesh node, edge, and cluster features, dynamically adjusting the bit-width used by a quantized model. We propose an adaptive bit-width allocation strategy driven by a lightweight auxiliary model that identifies high-loss regions in the input mesh. This enables dynamic resource distribution in the main model, where regions of higher difficulty are allocated increased bit-width, optimizing computational resource utilization. We demonstrate our framework's effectiveness by integrating it with two state-of-the-art models, MP-PDE and GraphViT, to evaluate performance across multiple tasks: 2D Darcy flow, large-scale unsteady fluid dynamics in 2D, steady-state Navier-Stokes simulations in 3D, and a 2D hyper-elasticity problem. Our framework demonstrates consistent Pareto improvements over uniformly quantized baselines, yielding up to 50% improvements in performance at the same cost.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18454v1" target="_blank"><h2>RegDeepLab: A Two-Stage Decoupled Framework for Interpretable Embryo Fragmentation Grading</h2></a><strong><u>Authors:</u></strong> Ming-Jhe Lee<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 7 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> explainability (abstract)<br><p><strong><u>Abstract:</u></strong> The degree of embryo fragmentation serves as a critical morphological indicator for assessing embryo developmental potential in In Vitro Fertilization (IVF) clinical decision-making. However, current manual grading processes are not only time-consuming but also limited by significant inter-observer variability and efficiency bottlenecks. Although deep learning has demonstrated potential in automated grading in recent years, existing solutions face a significant challenge: pure regression models lack the visual explainability required for clinical practice, while pure segmentation models struggle to directly translate pixel-level masks into precise clinical grades. This study proposes RegDeepLab, a dual-branch Multi-Task Learning (MTL) framework that integrates State-of-the-Art (SOTA) semantic segmentation (DeepLabV3+) with a multi-scale regression head. Addressing the common issues of "Gradient Conflict" and "Negative Transfer" in multi-task training, we propose a "Two-Stage Decoupled Training Strategy." Experimental results demonstrate that while standard end-to-end MTL training can minimize grading error (MAE=0.046) through our designed "Feature Injection" mechanism, it compromises the integrity of segmentation boundaries. In contrast, our decoupled strategy successfully provides robust and high-precision grading predictions while preserving SOTA-level segmentation accuracy (Dice=0.729). Furthermore, we introduce a "Range Loss" to effectively utilize large-scale discrete grading data for semi-supervised learning. This study ultimately presents a dual-module clinical auxiliary solution that combines high accuracy with visual explainability.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18450v1" target="_blank"><h2>ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints</h2></a><strong><u>Authors:</u></strong> Rui Xu, Dakuan Lu, Zicheng Zhao, Xiaoyu Tan, Xintao Wang, Siyu Yuan, Jiangjie Chen, Yinghui Xu<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Spatial reasoning is a key capability in the field of artificial intelligence, especially crucial in areas such as robotics, computer vision, and natural language understanding. However, evaluating the ability of multimodal large language models(MLLMs) in complex spatial reasoning still faces challenges, particularly in scenarios requiring multi-step reasoning and precise mathematical constraints. This paper introduces ORIGAMISPACE, a new dataset and benchmark designed to evaluate the multi-step spatial reasoning ability and the capacity to handle mathematical constraints of MLLMs through origami tasks. The dataset contains 350 data instances,each comprising a strictly formatted crease pattern (CP diagram), the Compiled Flat Pattern, the complete Folding Process, and the final Folded Shape Image. We propose four evaluation tasks: Pattern Prediction, Multi-step Spatial Reasoning, Spatial Relationship Prediction, and End-to-End CP Code Generation. For the CP code generation task, we design an interactive environment and explore the possibility of using reinforcement learning methods to train MLLMs. Through experiments on existing MLLMs, we initially reveal the strengths and weaknesses of these models in handling complex spatial reasoning tasks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18434v1" target="_blank"><h2>DocPTBench: Benchmarking End-to-End Photographed Document Parsing and Translation</h2></a><strong><u>Authors:</u></strong> Yongkun Du, Pinxuan Chen, Xuye Ying, Zhineng Chen<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> The advent of Multimodal Large Language Models (MLLMs) has unlocked the potential for end-to-end document parsing and translation. However, prevailing benchmarks such as OmniDocBench and DITrans are dominated by pristine scanned or digital-born documents, and thus fail to adequately represent the intricate challenges of real-world capture conditions, such as geometric distortions and photometric variations. To fill this gap, we introduce DocPTBench, a comprehensive benchmark specifically designed for Photographed Document Parsing and Translation. DocPTBench comprises over 1,300 high-resolution photographed documents from multiple domains, includes eight translation scenarios, and provides meticulously human-verified annotations for both parsing and translation. Our experiments demonstrate that transitioning from digital-born to photographed documents results in a substantial performance decline: popular MLLMs exhibit an average accuracy drop of 18% in end-to-end parsing and 12% in translation, while specialized document parsing models show significant average decrease of 25%. This substantial performance gap underscores the unique challenges posed by documents captured in real-world conditions and reveals the limited robustness of existing models. Dataset and code are available at https://github.com/Topdu/DocPTBench.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18422v1" target="_blank"><h2>NeuroVascU-Net: A Unified Multi-Scale and Cross-Domain Adaptive Feature Fusion U-Net for Precise 3D Segmentation of Brain Vessels in Contrast-Enhanced T1 MRI</h2></a><strong><u>Authors:</u></strong> Mohammad Jafari Vayeghan, Niloufar Delfan, Mehdi Tale Masouleh, Mansour Parvaresh Rizi, Behzad Moshiri<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Precise 3D segmentation of cerebral vasculature from T1-weighted contrast-enhanced (T1CE) MRI is crucial for safe neurosurgical planning. Manual delineation is time-consuming and prone to inter-observer variability, while current automated methods often trade accuracy for computational cost, limiting clinical use. We present NeuroVascU-Net, the first deep learning architecture specifically designed to segment cerebrovascular structures directly from clinically standard T1CE MRI in neuro-oncology patients, addressing a gap in prior work dominated by TOF-MRA-based approaches. NeuroVascU-Net builds on a dilated U-Net and integrates two specialized modules: a Multi-Scale Contextual Feature Fusion ($MSC^2F$) module at the bottleneck and a Cross-Domain Adaptive Feature Fusion ($CDA^2F$) module at deeper hierarchical layers. $MSC^2F$ captures both local and global information via multi-scale dilated convolutions, while $CDA^2F$ dynamically integrates domain-specific features, enhancing representation while keeping computation low. The model was trained and validated on a curated dataset of T1CE scans from 137 brain tumor biopsy patients, annotated by a board-certified functional neurosurgeon. NeuroVascU-Net achieved a Dice score of 0.8609 and precision of 0.8841, accurately segmenting both major and fine vascular structures. Notably, it requires only 12.4M parameters, significantly fewer than transformer-based models such as Swin U-NetR. This balance of accuracy and efficiency positions NeuroVascU-Net as a practical solution for computer-assisted neurosurgical planning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18417v1" target="_blank"><h2>Categorical Equivariant Deep Learning: Category-Equivariant Neural Networks and Universal Approximation Theorems</h2></a><strong><u>Authors:</u></strong> Yoshihiro Maruyama<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, cs.RO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> We develop a theory of category-equivariant neural networks (CENNs) that unifies group/groupoid-equivariant networks, poset/lattice-equivariant networks, graph and sheaf neural networks. Equivariance is formulated as naturality in a topological category with Radon measures, formulating linear and nonlinear layers in the categorical setup. We prove the equivariant universal approximation theorem in the general setting: the class of finite-depth CENNs is dense in the space of continuous equivariant transformations. We instantiate the framework for groups/groupoids, posets/lattices, graphs and cellular sheaves, deriving universal approximation theorems for them in a systematic manner. Categorical equivariant deep learning thus allows us to expand the horizons of equivariant deep learning beyond group actions, encompassing not only geometric symmetries but also contextual and compositional symmetries.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18405v1" target="_blank"><h2>A Multimodal Conversational Agent for Tabular Data Analysis</h2></a><strong><u>Authors:</u></strong> Mohammad Nour Al Awad, Sergey Ivanov, Olga Tikhonova, Ivan Khodnenko<br><strong><u>Categories:</u></strong> cs.AI, cs.HC, cs.IR<br><strong><u>Comments:</u></strong> \c{opyright} 2025 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Large language models (LLMs) can reshape information processing by handling data analysis, visualization, and interpretation in an interactive, context-aware dialogue with users, including voice interaction, while maintaining high performance. In this article, we present Talk2Data, a multimodal LLM-driven conversational agent for intuitive data exploration. The system lets users query datasets with voice or text instructions and receive answers as plots, tables, statistics, or spoken explanations. Built on LLMs, the suggested design combines OpenAI Whisper automatic speech recognition (ASR) system, Qwen-coder code generation LLM/model, custom sandboxed execution tools, and Coqui library for text-to-speech (TTS) within an agentic orchestration loop. Unlike text-only analysis tools, it adapts responses across modalities and supports multi-turn dialogues grounded in dataset context. In an evaluation of 48 tasks on three datasets, our prototype achieved 95.8% accuracy with model-only generation time under 1.7 seconds (excluding ASR and execution time). A comparison across five LLM sizes (1.5B-32B) revealed accuracy-latency-cost trade-offs, with a 7B model providing the best balance for interactive use. By routing between conversation with user and code execution, constrained to a transparent sandbox, with simultaneously grounding prompts in schema-level context, the Talk2Data agent reliably retrieves actionable insights from tables while making computations verifiable. In the article, except for the Talk2Data agent itself, we discuss implications for human-data interaction, trust in LLM-driven analytics, and future extensions toward large-scale multimodal assistants.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18404v1" target="_blank"><h2>Pre-training Graph Neural Networks on 2D and 3D Molecular Structures by using Multi-View Conditional Information Bottleneck</h2></a><strong><u>Authors:</u></strong> Van Thuy Hoang, O-Joun Lee<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Recent pre-training strategies for molecular graphs have attempted to use 2D and 3D molecular views as both inputs and self-supervised signals, primarily aligning graph-level representations. However, existing studies remain limited in addressing two main challenges of multi-view molecular learning: (1) discovering shared information between two views while diminishing view-specific information and (2) identifying and aligning important substructures, e.g., functional groups, which are crucial for enhancing cross-view consistency and model expressiveness. To solve these challenges, we propose a Multi-View Conditional Information Bottleneck framework, called MVCIB, for pre-training graph neural networks on 2D and 3D molecular structures in a self-supervised setting. Our idea is to discover the shared information while minimizing irrelevant features from each view under the MVCIB principle, which uses one view as a contextual condition to guide the representation learning of its counterpart. To enhance semantic and structural consistency across views, we utilize key substructures, e.g., functional groups and ego-networks, as anchors between the two views. Then, we propose a cross-attention mechanism that captures fine-grained correlations between the substructures to achieve subgraph alignment across views. Extensive experiments in four molecular domains demonstrated that MVCIB consistently outperforms baselines in both predictive performance and interpretability. Moreover, MVCIB achieved the 3d Weisfeiler-Lehman expressiveness power to distinguish not only non-isomorphic graphs but also different 3D geometries that share identical 2D connectivity, such as isomers.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18387v1" target="_blank"><h2>Scaling Implicit Fields via Hypernetwork-Driven Multiscale Coordinate Transformations</h2></a><strong><u>Authors:</u></strong> Plein Versace<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Implicit Neural Representations (INRs) have emerged as a powerful paradigm for representing signals such as images, 3D shapes, signed distance fields, and radiance fields. While significant progress has been made in architecture design (e.g., SIREN, FFC, KAN-based INRs) and optimization strategies (meta-learning, amortization, distillation), existing approaches still suffer from two core limitations: (1) a representation bottleneck that forces a single MLP to uniformly model heterogeneous local structures, and (2) limited scalability due to the absence of a hierarchical mechanism that dynamically adapts to signal complexity. This work introduces Hyper-Coordinate Implicit Neural Representations (HC-INR), a new class of INRs that break the representational bottleneck by learning signal-adaptive coordinate transformations using a hypernetwork. HC-INR decomposes the representation task into two components: (i) a learned multiscale coordinate transformation module that warps the input domain into a disentangled latent space, and (ii) a compact implicit field network that models the transformed signal with significantly reduced complexity. The proposed model introduces a hierarchical hypernetwork architecture that conditions coordinate transformations on local signal features, enabling dynamic allocation of representation capacity. We theoretically show that HC-INR strictly increases the upper bound of representable frequency bands while maintaining Lipschitz stability. Extensive experiments across image fitting, shape reconstruction, and neural radiance field approximation demonstrate that HC-INR achieves up to 4 times higher reconstruction fidelity than strong INR baselines while using 30--60\% fewer parameters.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18385v1" target="_blank"><h2>Can a Second-View Image Be a Language? Geometric and Semantic Cross-Modal Reasoning for X-ray Prohibited Item Detection</h2></a><strong><u>Authors:</u></strong> Chuang Peng, Renshuai Tao, Zhongwei Ren, Xianglong Liu, Yunchao Wei<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Automatic X-ray prohibited items detection is vital for security inspection and has been widely studied. Traditional methods rely on visual modality, often struggling with complex threats. While recent studies incorporate language to guide single-view images, human inspectors typically use dual-view images in practice. This raises the question: can the second view provide constraints similar to a language modality? In this work, we introduce DualXrayBench, the first comprehensive benchmark for X-ray inspection that includes multiple views and modalities. It supports eight tasks designed to test cross-view reasoning. In DualXrayBench, we introduce a caption corpus consisting of 45,613 dual-view image pairs across 12 categories with corresponding captions. Building upon these data, we propose the Geometric (cross-view)-Semantic (cross-modality) Reasoner (GSR), a multimodal model that jointly learns correspondences between cross-view geometry and cross-modal semantics, treating the second-view images as a "language-like modality". To enable this, we construct the GSXray dataset, with structured Chain-of-Thought sequences: <top>, <side>, <conclusion>. Comprehensive evaluations on DualXrayBench demonstrate that GSR achieves significant improvements across all X-ray tasks, offering a new perspective for real-world X-ray inspection.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18375v1" target="_blank"><h2>Progressive Localisation in Localist LLMs</h2></a><strong><u>Authors:</u></strong> Joachim Diederich<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> This paper demonstrates that progressive localization, the gradual increase of attention locality from early distributed layers to late localized layers, represents the optimal architecture for creating interpretable large language models while preserving performance. Through systematic experimentation with GPT-2 fine tuned on The Psychology of Artificial Superintelligence, we evaluate seven locality configurations ranging from fully distributed to strictly localist, with five progressive schedules implementing polynomial increases (linear through quintic). Our key finding is that late-layer localization is critical for AI safety applications: the progressive quintic schedule achieves perplexity of 14.64, only 1.89 times worse than the fully distributed baseline while providing interpretable attention patterns in output layers where safety-critical decisions are made. This represents an 84.2% improvement over previous localist implementations and narrows the performance gap from 6.6 times to 1.89 times. The systematic relationship between localization schedule steepness and performance validates the hypothesis that early layers require distributed processing for feature extraction while late layers benefit from localized, interpretable attention for decision-making. These findings establish progressive localization as the principled approach for building transparent AI systems in safety-critical domains, where human oversight of model reasoning is essential.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18368v1" target="_blank"><h2>Wireless Power Transfer and Intent-Driven Network Optimization in AAVs-assisted IoT for 6G Sustainable Connectivity</h2></a><strong><u>Authors:</u></strong> Yue Hu, Xiaoming He, Rui Yuan, Shahid Mumtaz<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Autonomous Aerial Vehicle (AAV)-assisted Internet of Things (IoT) represents a collaborative architecture in which AAV allocate resources over 6G links to jointly enhance user-intent interpretation and overall network performance. Owing to this mutual dependence, improvements in intent inference and policy decisions on one component reinforce the efficiency of others, making highly reliable intent prediction and low-latency action execution essential. Although numerous approaches can model intent relationships, they encounter severe obstacles when scaling to high-dimensional action sequences and managing intensive on-board computation. We propose an Intent-Driven Framework for Autonomous Network Optimization comprising prediction and decision modules. First, implicit intent modeling is adopted to mitigate inaccuracies arising from ambiguous user expressions. For prediction, we introduce Hyperdimensional Transformer (HDT), which embeds data into a Hyperdimensional space via Hyperdimensional vector encoding and replaces standard matrix and attention operations with symbolic Hyperdimensional computations. For decision-making, where AAV must respond to user intent while planning trajectories, we design Double Actions based Multi-Agent Proximal Policy Optimization (DA-MAPPO). Building upon MAPPO, it samples actions through two independently parameterized networks and cascades the user-intent network into the trajectory network to maintain action dependencies. We evaluate our framework on a real IoT action dataset with authentic wireless data. Experimental results demonstrate that HDT and DA-MAPPO achieve superior performance across diverse scenarios.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18326v1" target="_blank"><h2>General vs Domain-Specific CNNs: Understanding Pretraining Effects on Brain MRI Tumor Classification</h2></a><strong><u>Authors:</u></strong> Helia Abedini, Saba Rahimi, Reza Vaziri<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), transfer learning (abstract)<br><p><strong><u>Abstract:</u></strong> Brain tumor detection from MRI scans plays a crucial role in early diagnosis and treatment planning. Deep convolutional neural networks (CNNs) have demonstrated strong performance in medical imaging tasks, particularly when pretrained on large datasets. However, it remains unclear which type of pretrained model performs better when only a small dataset is available: those trained on domain-specific medical data or those pretrained on large general datasets. In this study, we systematically evaluate three pretrained CNN architectures for brain tumor classification: RadImageNet DenseNet121 with medical-domain pretraining, EfficientNetV2S, and ConvNeXt-Tiny, which are modern general-purpose CNNs. All models were trained and fine-tuned under identical conditions using a limited-size brain MRI dataset to ensure a fair comparison. Our results reveal that ConvNeXt-Tiny achieved the highest accuracy, followed by EfficientNetV2S, while RadImageNet DenseNet121, despite being pretrained on domain-specific medical data, exhibited poor generalization with lower accuracy and higher loss. These findings suggest that domain-specific pretraining may not generalize well under small-data conditions. In contrast, modern, deeper general-purpose CNNs pretrained on large-scale datasets can offer superior transfer learning performance in specialized medical imaging tasks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18325v1" target="_blank"><h2>Brain-MGF: Multimodal Graph Fusion Network for EEG-fMRI Brain Connectivity Analysis Under Psilocybin</h2></a><strong><u>Authors:</u></strong> Sin-Yee Yap, Fuad Noman, Junn Yong Loo, Devon Stoliker, Moein Khajehnejad, Raphaël C. -W. Phan, David L. Dowe, Adeel Razi, Chee-Ming Ting<br><strong><u>Categories:</u></strong> q-bio.NC, cs.LG<br><strong><u>Comments:</u></strong> 5 pages<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Psychedelics, such as psilocybin, reorganise large-scale brain connectivity, yet how these changes are reflected across electrophysiological (electroencephalogram, EEG) and haemodynamic (functional magnetic resonance imaging, fMRI) networks remains unclear. We present Brain-MGF, a multimodal graph fusion network for joint EEG-fMRI connectivity analysis. For each modality, we construct graphs with partial-correlation edges and Pearson-profile node features, and learn subject-level embeddings via graph convolution. An adaptive softmax gate then fuses modalities with sample-specific weights to capture context-dependent contributions. Using the world's largest single-site psilocybin dataset, PsiConnect, Brain-MGF distinguishes psilocybin from no-psilocybin conditions in meditation and rest. Fusion improves over unimodal and non-adaptive variants, achieving 74.0% accuracy and 76.5% F1 score on meditation, and 76.0% accuracy with 85.8% ROC-AUC on rest. UMAP visualisations reveal clearer class separation for fused embeddings. These results indicate that adaptive graph fusion effectively integrates complementary EEG-fMRI information, providing an interpretable framework for characterising psilocybin-induced alterations in large-scale neural organisation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18322v1" target="_blank"><h2>Learning Visually Interpretable Oscillator Networks for Soft Continuum Robots from Video</h2></a><strong><u>Authors:</u></strong> Henrik Krauss, Johann Licher, Naoya Takeishi, Annika Raatz, Takehisa Yairi<br><strong><u>Categories:</u></strong> cs.RO, cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), latent space (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Data-driven learning of soft continuum robot (SCR) dynamics from high-dimensional observations offers flexibility but often lacks physical interpretability, while model-based approaches require prior knowledge and can be computationally expensive. We bridge this gap by introducing (1) the Attention Broadcast Decoder (ABCD), a plug-and-play module for autoencoder-based latent dynamics learning that generates pixel-accurate attention maps localizing each latent dimension's contribution while filtering static backgrounds. (2) By coupling these attention maps to 2D oscillator networks, we enable direct on-image visualization of learned dynamics (masses, stiffness, and forces) without prior knowledge. We validate our approach on single- and double-segment SCRs, demonstrating that ABCD-based models significantly improve multi-step prediction accuracy: 5.7x error reduction for Koopman operators and 3.5x for oscillator networks on the two-segment robot. The learned oscillator network autonomously discovers a chain structure of oscillators. Unlike standard methods, ABCD models enable smooth latent space extrapolation beyond training data. This fully data-driven approach yields compact, physically interpretable models suitable for control applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18319v1" target="_blank"><h2>Weakly-supervised Latent Models for Task-specific Visual-Language Control</h2></a><strong><u>Authors:</u></strong> Xian Yeow Lee, Lasitha Vidyaratne, Gregory Sin, Ahmed Farahat, Chetan Gupta<br><strong><u>Categories:</u></strong> cs.AI, cs.LG, eess.SY<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Autonomous inspection in hazardous environments requires AI agents that can interpret high-level goals and execute precise control. A key capability for such agents is spatial grounding, for example when a drone must center a detected object in its camera view to enable reliable inspection. While large language models provide a natural interface for specifying goals, using them directly for visual control achieves only 58\% success in this task. We envision that equipping agents with a world model as a tool would allow them to roll out candidate actions and perform better in spatially grounded settings, but conventional world models are data and compute intensive. To address this, we propose a task-specific latent dynamics model that learns state-specific action-induced shifts in a shared latent space using only goal-state supervision. The model leverages global action embeddings and complementary training losses to stabilize learning. In experiments, our approach achieves 71\% success and generalizes to unseen images and instructions, highlighting the potential of compact, domain-specific latent dynamics models for spatial alignment in autonomous inspection.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18314v1" target="_blank"><h2>AnyExperts: On-Demand Expert Allocation for Multimodal Language Models with Mixture of Expert</h2></a><strong><u>Authors:</u></strong> Yuting Gao, Wang Lan, Hengyuan Zhao, Linjiang Huang, Si Liu, Qingpei Guo<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Mixture-of-Experts (MoE) models offer a promising path toward scalable and efficient large vision-language systems. However, existing approaches rely on rigid routing strategies (typically activating a fixed number of experts per token) ignoring the inherent heterogeneity in semantic importance across modalities. This leads to suboptimal compute allocation, where redundant tokens consume as many resources as critical ones. To address this, we propose AnyExperts, a novel on-demand, budget-aware dynamic routing framework that allocates a variable total number of expert slots per token based on its semantic importance. Crucially, to prevent uncontrolled compute growth, the total slots per token are constrained within a fixed range, and each slot is filled by either a real expert or a virtual expert, with the virtual share capped at a small maximum (e.g., 20%). The model then adaptively balances the real-to-virtual ratio per token, assigning more real experts to semantically rich regions and relying more on virtual experts for redundant content. Evaluated across diverse tasks in visual understanding, audio understanding, and NLP understanding, AnyExperts improves performance under the same compute budget. Notably, on general image/video tasks, it achieves comparable accuracy with 40% fewer real expert activations; on text-dense tasks (OCR and NLP), it maintains performance while reducing real expert usage by 10%. These results demonstrate that fine-grained, importance-driven expert allocation significantly enhances both the efficiency and effectiveness of multimodal MoE models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18307v1" target="_blank"><h2>ScriptViT: Vision Transformer-Based Personalized Handwriting Generation</h2></a><strong><u>Authors:</u></strong> Sajjan Acharya, Rajendra Baskota<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Styled handwriting generation aims to synthesize handwritten text that looks both realistic and aligned with a specific writer's style. While recent approaches involving GAN, transformer and diffusion-based models have made progress, they often struggle to capture the full spectrum of writer-specific attributes, particularly global stylistic patterns that span long-range spatial dependencies. As a result, capturing subtle writer-specific traits such as consistent slant, curvature or stroke pressure, while keeping the generated text accurate is still an open problem. In this work, we present a unified framework designed to address these limitations. We introduce a Vision Transformer-based style encoder that learns global stylistic patterns from multiple reference images, allowing the model to better represent long-range structural characteristics of handwriting. We then integrate these style cues with the target text using a cross-attention mechanism, enabling the system to produce handwritten images that more faithfully reflect the intended style. To make the process more interpretable, we utilize Salient Stroke Attention Analysis (SSAA), which reveals the stroke-level features the model focuses on during style transfer. Together, these components lead to handwriting synthesis that is not only more stylistically coherent, but also easier to understand and analyze.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18302v1" target="_blank"><h2>The Catastrophic Paradox of Human Cognitive Frameworks in Large Language Model Evaluation: A Comprehensive Empirical Analysis of the CHC-LLM Incompatibility</h2></a><strong><u>Authors:</u></strong> Mohan Reddy<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> This investigation presents an empirical analysis of the incompatibility between human psychometric frameworks and Large Language Model evaluation. Through systematic assessment of nine frontier models including GPT-5, Claude Opus 4.1, and Gemini 3 Pro Preview using the Cattell-Horn-Carroll theory of intelligence, we identify a paradox that challenges the foundations of cross-substrate cognitive evaluation. Our results show that models achieving above-average human IQ scores ranging from 85.0 to 121.4 simultaneously exhibit binary accuracy rates approaching zero on crystallized knowledge tasks, with an overall judge-binary correlation of r = 0.175 (p = 0.001, n = 1800). This disconnect appears most strongly in the crystallized intelligence domain, where every evaluated model achieved perfect binary accuracy while judge scores ranged from 25 to 62 percent, which cannot occur under valid measurement conditions. Using statistical analyses including Item Response Theory modeling, cross-vendor judge validation, and paradox severity indexing, we argue that this disconnect reflects a category error in applying biological cognitive architectures to transformer-based systems. The implications extend beyond methodology to challenge assumptions about intelligence, measurement, and anthropomorphic biases in AI evaluation. We propose a framework for developing native machine cognition assessments that recognize the non-human nature of artificial intelligence.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18298v1" target="_blank"><h2>Cross-Disciplinary Knowledge Retrieval and Synthesis: A Compound AI Architecture for Scientific Discovery</h2></a><strong><u>Authors:</u></strong> Svitlana Volkova, Peter Bautista, Avinash Hiriyanna, Gabriel Ganberg, Isabel Erickson, Zachary Klinefelter, Nick Abele, Hsien-Te Kao, Grant Engberson<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> The exponential growth of scientific knowledge has created significant barriers to cross-disciplinary knowledge discovery, synthesis and research collaboration. In response to this challenge, we present BioSage, a novel compound AI architecture that integrates LLMs with RAG, orchestrated specialized agents and tools to enable discoveries across AI, data science, biomedical, and biosecurity domains. Our system features several specialized agents including the retrieval agent with query planning and response synthesis that enable knowledge retrieval across domains with citation-backed responses, cross-disciplinary translation agents that align specialized terminology and methodologies, and reasoning agents that synthesize domain-specific insights with transparency, traceability and usability. We demonstrate the effectiveness of our BioSage system through a rigorous evaluation on scientific benchmarks (LitQA2, GPQA, WMDP, HLE-Bio) and introduce a new cross-modal benchmark for biology and AI, showing that our BioSage agents outperform vanilla and RAG approaches by 13\%-21\% powered by Llama 3.1. 70B and GPT-4o models. We perform causal investigations into compound AI system behavior and report significant performance improvements by adding RAG and agents over the vanilla models. Unlike other systems, our solution is driven by user-centric design principles and orchestrates specialized user-agent interaction workflows supporting scientific activities including but not limited to summarization, research debate and brainstorming. Our ongoing work focuses on multimodal retrieval and reasoning over charts, tables, and structured scientific data, along with developing comprehensive multimodal benchmarks for cross-disciplinary discovery. Our compound AI solution demonstrates significant potential for accelerating scientific advancement by reducing barriers between traditionally siloed domains.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18297v1" target="_blank"><h2>GROOT: Graph Edge Re-growth and Partitioning for the Verification of Large Designs in Logic Synthesis</h2></a><strong><u>Authors:</u></strong> Kiran Thorat, Hongwu Peng, Yuebo Luo, Xi Xie, Shaoyi Huang, Amit Hasan, Jiahui Zhao, Yingjie Li, Zhijie Shi, Cunxi Yu, Caiwen Ding<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Traditional verification methods in chip design are highly time-consuming and computationally demanding, especially for large scale circuits. Graph neural networks (GNNs) have gained popularity as a potential solution to improve verification efficiency. However, there lacks a joint framework that considers all chip design domain knowledge, graph theory, and GPU kernel designs. To address this challenge, we introduce GROOT, an algorithm and system co-design framework that contains chip design domain knowledge and redesigned GPU kernels, to improve verification efficiency. More specifically, we create node features utilizing the circuit node types and the polarity of the connections between the input edges to nodes in And-Inverter Graphs (AIGs). We utilize a graph partitioning algorithm to divide the large graphs into smaller sub-graphs for fast GPU processing and develop a graph edge re-growth algorithm to recover verification accuracy. We carefully profile the EDA graph workloads and observe the uniqueness of their polarized distribution of high degree (HD) nodes and low degree (LD) nodes. We redesign two GPU kernels (HD-kernel and LD-kernel), to fit the EDA graph learning workload on a single GPU. We compare the results with state-of-the-art (SOTA) methods: GAMORA, a GNN-based approach, and the traditional ABC framework. Results show that GROOT achieves a significant reduction in memory footprint (59.38 %), with high accuracy (99.96%) for a very large CSA multiplier, i.e. 1,024 bits with a batch size of 16, which consists of 134,103,040 nodes and 268,140,544 edges. We compare GROOT with GPU-based GPU Kernel designs SOTAs such as cuSPARSE, MergePath-SpMM, and GNNAdvisor. We achieve up to 1.104x, 5.796x, and 1.469x improvement in runtime, respectively.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18296v1" target="_blank"><h2>Deep Learning Decision Support System for Open-Pit Mining Optimisation: GPU-Accelerated Planning Under Geological Uncertainty</h2></a><strong><u>Authors:</u></strong> Iman Rahimi<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> 67 pages<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (abstract)<br><p><strong><u>Abstract:</u></strong> This study presents Part II of an AI-enhanced Decision Support System (DSS), extending Rahimi (2025, Part I) by introducing a fully uncertainty-aware optimization framework for long-term open-pit mine planning. Geological uncertainty is modelled using a Variational Autoencoder (VAE) trained on 50,000 spatial grade samples, enabling the generation of probabilistic, multi-scenario orebody realizations that preserve geological continuity and spatial correlation. These scenarios are optimized through a hybrid metaheuristic engine integrating Genetic Algorithms (GA), Large Neighborhood Search (LNS), Simulated Annealing (SA), and reinforcement-learning-based adaptive control. An ε-constraint relaxation strategy governs the population exploration phase, allowing near-feasible schedule discovery early in the search and gradual tightening toward strict constraint satisfaction. GPU-parallel evaluation enables the simultaneous assessment of 65,536 geological scenarios, achieving near-real-time feasibility analysis. Results demonstrate up to 1.2 million-fold runtime improvement over IBM CPLEX and significantly higher expected NPV under geological uncertainty, confirming the DSS as a scalable and uncertainty-resilient platform for intelligent mine planning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18294v1" target="_blank"><h2>MultiDiffNet: A Multi-Objective Diffusion Framework for Generalizable Brain Decoding</h2></a><strong><u>Authors:</u></strong> Mengchun Zhang, Kateryna Shapovalenko, Yucheng Shao, Eddie Guo, Parusha Pradhan<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.HC, q-bio.NC<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> Neural decoding from electroencephalography (EEG) remains fundamentally limited by poor generalization to unseen subjects, driven by high inter-subject variability and the lack of large-scale datasets to model it effectively. Existing methods often rely on synthetic subject generation or simplistic data augmentation, but these strategies fail to scale or generalize reliably. We introduce \textit{MultiDiffNet}, a diffusion-based framework that bypasses generative augmentation entirely by learning a compact latent space optimized for multiple objectives. We decode directly from this space and achieve state-of-the-art generalization across various neural decoding tasks using subject and session disjoint evaluation. We also curate and release a unified benchmark suite spanning four EEG decoding tasks of increasing complexity (SSVEP, Motor Imagery, P300, and Imagined Speech) and an evaluation protocol that addresses inconsistent split practices in prior EEG research. Finally, we develop a statistical reporting framework tailored for low-trial EEG settings. Our work provides a reproducible and open-source foundation for subject-agnostic EEG decoding in real-world BCI systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18290v1" target="_blank"><h2>SwiftVGGT: A Scalable Visual Geometry Grounded Transformer for Large-Scale Scenes</h2></a><strong><u>Authors:</u></strong> Jungho Lee, Minhyeok Lee, Sunghun Yang, Minseok Kang, Sangyoun Lee<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Project Page:this https URL<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> transformer (title)<br><p><strong><u>Abstract:</u></strong> 3D reconstruction in large-scale scenes is a fundamental task in 3D perception, but the inherent trade-off between accuracy and computational efficiency remains a significant challenge. Existing methods either prioritize speed and produce low-quality results, or achieve high-quality reconstruction at the cost of slow inference times. In this paper, we propose SwiftVGGT, a training-free method that significantly reduce inference time while preserving high-quality dense 3D reconstruction. To maintain global consistency in large-scale scenes, SwiftVGGT performs loop closure without relying on the external Visual Place Recognition (VPR) model. This removes redundant computation and enables accurate reconstruction over kilometer-scale environments. Furthermore, we propose a simple yet effective point sampling method to align neighboring chunks using a single Sim(3)-based Singular Value Decomposition (SVD) step. This eliminates the need for the Iteratively Reweighted Least Squares (IRLS) optimization commonly used in prior work, leading to substantial speed-ups. We evaluate SwiftVGGT on multiple datasets and show that it achieves state-of-the-art reconstruction quality while requiring only 33% of the inference time of recent VGGT-based large-scale reconstruction approaches.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18258v1" target="_blank"><h2>Hybrid Agentic AI and Multi-Agent Systems in Smart Manufacturing</h2></a><strong><u>Authors:</u></strong> Mojtaba A. Farahani, Md Irfan Khan, Thorsten Wuest<br><strong><u>Categories:</u></strong> cs.MA, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> explainability (abstract)<br><p><strong><u>Abstract:</u></strong> The convergence of Agentic AI and MAS enables a new paradigm for intelligent decision making in SMS. Traditional MAS architectures emphasize distributed coordination and specialized autonomy, while recent advances in agentic AI driven by LLMs introduce higher order reasoning, planning, and tool orchestration capabilities. This paper presents a hybrid agentic AI and multi agent framework for a Prescriptive Maintenance use case, where LLM based agents provide strategic orchestration and adaptive reasoning, complemented by rule based and SLMs agents performing efficient, domain specific tasks on the edge. The proposed framework adopts a layered architecture that consists of perception, preprocessing, analytics, and optimization layers, coordinated through an LLM Planner Agent that manages workflow decisions and context retention. Specialized agents autonomously handle schema discovery, intelligent feature analysis, model selection, and prescriptive optimization, while a HITL interface ensures transparency and auditability of generated maintenance recommendations. This hybrid design supports dynamic model adaptation, cost efficient maintenance scheduling, and interpretable decision making. An initial proof of concept implementation is validated on two industrial manufacturing datasets. The developed framework is modular and extensible, supporting seamless integration of new agents or domain modules as capabilities evolve. The results demonstrate the system capability to automatically detect schema, adapt preprocessing pipelines, optimize model performance through adaptive intelligence, and generate actionable, prioritized maintenance recommendations. The framework shows promise in achieving improved robustness, scalability, and explainability for RxM in smart manufacturing, bridging the gap between high level agentic reasoning and low level autonomous execution.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18244v1" target="_blank"><h2>Developing an AI Course for Synthetic Chemistry Students</h2></a><strong><u>Authors:</u></strong> Zhiling Zheng<br><strong><u>Categories:</u></strong> cs.AI, cond-mat.mtrl-sci, physics.ed-ph<br><strong><u>Comments:</u></strong> 17 pages, 3 figures<br><strong><u>Published:</u></strong> 2025-11-23<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Artificial intelligence (AI) and data science are transforming chemical research, yet few formal courses are tailored to synthetic and experimental chemists, who often face steep entry barriers due to limited coding experience and lack of chemistry-specific examples. We present the design and implementation of AI4CHEM, an introductory data-driven chem-istry course created for students on the synthetic chemistry track with no prior programming background. The curricu-lum emphasizes chemical context over abstract algorithms, using an accessible web-based platform to ensure zero-install machine learning (ML) workflow development practice and in-class active learning. Assessment combines code-guided homework, literature-based mini-reviews, and collaborative projects in which students build AI-assisted workflows for real experimental problems. Learning gains include increased confidence with Python, molecular property prediction, reaction optimization, and data mining, and improved skills in evaluating AI tools in chemistry. All course materials are openly available, offering a discipline-specific, beginner-accessible framework for integrating AI into synthetic chemistry training.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18221v1" target="_blank"><h2>Enhancing Large Language Models for Automated Homework Assessment in Undergraduate Circuit Analysis</h2></a><strong><u>Authors:</u></strong> Liangliang Chen, Huiru Xie, Zhihao Qin, Yiming Guo, Jacqueline Rohde, Ying Zhang<br><strong><u>Categories:</u></strong> cs.CY, cs.AI, cs.HC<br><strong><u>Comments:</u></strong> Accepted to 2025 Frontiers in Education (FIE) Conference<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> This research full paper presents an enhancement pipeline for large language models (LLMs) in assessing homework for an undergraduate circuit analysis course, aiming to improve LLMs' capacity to provide personalized support to electrical engineering students. Existing evaluations have demonstrated that GPT-4o possesses promising capabilities in assessing student homework in this domain. Building on these findings, we enhance GPT-4o's performance through multi-step prompting, contextual data augmentation, and the incorporation of targeted hints. These strategies effectively address common errors observed in GPT-4o's responses when using simple prompts, leading to a substantial improvement in assessment accuracy. Specifically, the correct response rate for GPT-4o increases from 74.71% to 97.70% after applying the enhanced prompting and augmented data on entry-level circuit analysis topics. This work lays a foundation for the effective integration of LLMs into circuit analysis instruction and, more broadly, into engineering education.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18214v1" target="_blank"><h2>Deep Gaussian Process Proximal Policy Optimization</h2></a><strong><u>Authors:</u></strong> Matthijs van der Lende, Juan Cardenas-Cartagena<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Uncertainty estimation for Reinforcement Learning (RL) is a critical component in control tasks where agents must balance safe exploration and efficient learning. While deep neural networks have enabled breakthroughs in RL, they often lack calibrated uncertainty estimates. We introduce Deep Gaussian Process Proximal Policy Optimization (GPPO), a scalable, model-free actor-critic algorithm that leverages Deep Gaussian Processes (DGPs) to approximate both the policy and value function. GPPO maintains competitive performance with respect to Proximal Policy Optimization on standard high-dimensional continuous control benchmarks while providing well-calibrated uncertainty estimates that can inform safer and more effective exploration.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18213v1" target="_blank"><h2>Typing Reinvented: Towards Hands-Free Input via sEMG</h2></a><strong><u>Authors:</u></strong> Kunwoo Lee, Dhivya Sreedhar, Pushkar Saraf, Chaeeun Lee, Kateryna Shapovalenko<br><strong><u>Categories:</u></strong> cs.HC, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> We explore surface electromyography (sEMG) as a non-invasive input modality for mapping muscle activity to keyboard inputs, targeting immersive typing in next-generation human-computer interaction (HCI). This is especially relevant for spatial computing and virtual reality (VR), where traditional keyboards are impractical. Using attention-based architectures, we significantly outperform the existing convolutional baselines, reducing online generic CER from 24.98% -> 20.34% and offline personalized CER from 10.86% -> 10.10%, while remaining fully causal. We further incorporate a lightweight decoding pipeline with language-model-based correction, demonstrating the feasibility of accurate, real-time muscle-driven text input for future wearable and spatial interfaces.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18192v1" target="_blank"><h2>ARIAL: An Agentic Framework for Document VQA with Precise Answer Localization</h2></a><strong><u>Authors:</u></strong> Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha, Rajiv Ramnath<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> Document Visual Question Answering (VQA) requires models to not only extract accurate textual answers but also precisely localize them within document images, a capability critical for interpretability in high-stakes applications. However, existing systems achieve strong textual accuracy while producing unreliable spatial grounding, or sacrifice performance for interpretability. We present ARIAL (Agentic Reasoning for Interpretable Answer Localization), a modular framework that orchestrates specialized tools through an LLM-based planning agent to achieve both precise answer extraction and reliable spatial grounding. ARIAL decomposes Document VQA into structured subtasks: OCR-based text extraction with TrOCR, retrieval-augmented context selection using semantic search, answer generation via a fine-tuned Gemma 3-27B model, and explicit bounding-box localization through text-to-region alignment. This modular architecture produces transparent reasoning traces, enabling tool-level auditability and independent component optimization. We evaluate ARIAL on four benchmarks (DocVQA, FUNSD, CORD, and SROIE) using both textual accuracy (ANLS) and spatial precision (mAP at IoU 0.50 to 0.95). ARIAL achieves state-of-the-art results across all datasets: 88.7 ANLS and 50.1 mAP on DocVQA, 90.0 ANLS and 50.3 mAP on FUNSD, 85.5 ANLS and 60.2 mAP on CORD, and 93.1 ANLS on SROIE, surpassing the previous best method (DLaVA) by +2.8 ANLS and +3.9 mAP on DocVQA. Our work demonstrates how agentic orchestration of specialized tools can simultaneously improve performance and interpretability, providing a pathway toward trustworthy, explainable document AI systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18191v1" target="_blank"><h2>Accelerating Time Series Foundation Models with Speculative Decoding</h2></a><strong><u>Authors:</u></strong> Pranav Subbaraman, Fang Sun, Yue Yao, Huacong Tang, Xiao Luo, Yizhou Sun<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 14 pages, 7 figures<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Modern web applications--from real-time content recommendation and dynamic pricing to CDN optimization--increasingly rely on time-series forecasting to deliver personalized experiences to billions of users. Large-scale Transformer-based models have achieved state-of-the-art performance in time-series forecasting but suffer from high computational costs, limiting their deployment in latency-sensitive web applications. To address this challenge, we propose a general inference acceleration framework that adapts speculative decoding to autoregressive time-series models. Our approach employs a smaller "draft" model to propose future time-series patches, which are then verified in parallel by a larger "target" model, reducing the number of sequential forward passes required. We address key technical challenges in adapting this technique from discrete language tokens to continuous time-series distributions, including the design of acceptance criteria for multivariate Gaussian patches and practical variants that balance efficiency with accuracy. Through experiments on time series forecasting benchmarks relevant to web applications, we demonstrate significant inference speedups while maintaining competitive accuracy. The framework requires no architectural modifications to existing foundation models, making it immediately applicable to accelerate deployed time-series forecasting systems. Our implementation can be found at https://github.com/PranavSubbaraman/STRIDE</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18182v1" target="_blank"><h2>The Workflow as Medium: A Framework for Navigating Human-AI Co-Creation</h2></a><strong><u>Authors:</u></strong> Lee Ackerman<br><strong><u>Categories:</u></strong> cs.CY, cs.AI<br><strong><u>Comments:</u></strong> 57 pages, 13 images, 6 tables<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> This paper introduces the Creative Intelligence Loop (CIL), a novel socio-technical framework for responsible human-AI co-creation. Rooted in the 'Workflow as Medium' paradigm, the CIL proposes a disciplined structure for dynamic human-AI collaboration, guiding the strategic integration of diverse AI teammates who function as collaborators while the human remains the final arbiter for ethical alignment and creative integrity. The CIL was empirically demonstrated through the practice-led creation of two graphic novellas, investigating how AI could serve as an effective creative colleague within a subjective medium lacking objective metrics. The process required navigating multifaceted challenges including AI's 'jagged frontier' of capabilities, sycophancy, and attention-scarce feedback environments. This prompted iterative refinement of teaming practices, yielding emergent strategies: a multi-faceted critique system integrating adversarial AI roles to counter sycophancy, and prioritizing 'feedback-ready' concrete artifacts to elicit essential human critique. The resulting graphic novellas analyze distinct socio-technical governance failures: 'The Steward' examines benevolent AI paternalism in smart cities, illustrating how algorithmic hubris can erode freedom; 'Fork the Vote' probes democratic legitimacy by comparing centralized AI opacity with emergent collusion in federated networks. This work contributes a self-improving framework for responsible human-AI co-creation and two graphic novellas designed to foster AI literacy and dialogue through accessible narrative analysis of AI's societal implications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18181v1" target="_blank"><h2>MOMA-AC: A preference-driven actor-critic framework for continuous multi-objective multi-agent reinforcement learning</h2></a><strong><u>Authors:</u></strong> Adam Callaghan, Karl Mason, Patrick Mannion<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 23 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> This paper addresses a critical gap in Multi-Objective Multi-Agent Reinforcement Learning (MOMARL) by introducing the first dedicated inner-loop actor-critic framework for continuous state and action spaces: Multi-Objective Multi-Agent Actor-Critic (MOMA-AC). Building on single-objective, single-agent algorithms, we instantiate this framework with Twin Delayed Deep Deterministic Policy Gradient (TD3) and Deep Deterministic Policy Gradient (DDPG), yielding MOMA-TD3 and MOMA-DDPG. The framework combines a multi-headed actor network, a centralised critic, and an objective preference-conditioning architecture, enabling a single neural network to encode the Pareto front of optimal trade-off policies for all agents across conflicting objectives in a continuous MOMARL setting. We also outline a natural test suite for continuous MOMARL by combining a pre-existing multi-agent single-objective physics simulator with its multi-objective single-agent counterpart. Evaluating cooperative locomotion tasks in this suite, we show that our framework achieves statistically significant improvements in expected utility and hypervolume relative to outer-loop and independent training baselines, while demonstrating stable scalability as the number of agents increases. These results establish our framework as a foundational step towards robust, scalable multi-objective policy learning in continuous multi-agent domains.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18172v1" target="_blank"><h2>MEDIC: a network for monitoring data quality in collider experiments</h2></a><strong><u>Authors:</u></strong> Juvenal Bassa, Arghya Chattopadhyay, Sudhir Malik, Mario Escabi Rivera<br><strong><u>Categories:</u></strong> hep-ex, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> 17 pages, 1 appendix<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), anomaly detection (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Data Quality Monitoring (DQM) is a crucial component of particle physics experiments and ensures that the recorded data is of the highest quality, and suitable for subsequent physics analysis. Due to the extreme environmental conditions, unprecedented data volumes, and the sheer scale and complexity of the detectors, DQM orchestration has become a very challenging task. Therefore, the use of Machine Learning (ML) to automate anomaly detection, improve efficiency, and reduce human error in the process of collecting high-quality data is unavoidable. Since DQM relies on real experimental data, it is inherently tied to the specific detector substructure and technology in operation. In this work, a simulation-driven approach to DQM is proposed, enabling the study and development of data-quality methodologies in a controlled environment. Using a modified version of Delphes -- a fast, multi-purpose detector simulation -- the preliminary realization of a framework is demonstrated which leverages ML to identify detector anomalies as well as localize the malfunctioning components responsible. We introduce MEDIC (Monitoring for Event Data Integrity and Consistency), a neural network designed to learn detector behavior and perform DQM tasks to look for potential faults. Although the present implementation adopts a simplified setup for computational ease, where large detector regions are deliberately deactivated to mimic faults, this work represents an initial step toward a comprehensive ML-based DQM framework. The encouraging results underline the potential of simulation-driven studies as a foundation for developing more advanced, data-driven DQM systems for future particle detectors.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18153v1" target="_blank"><h2>A Coordinated Dual-Arm Framework for Delicate Snap-Fit Assemblies</h2></a><strong><u>Authors:</u></strong> Shreyas Kumar, Barat S, Debojit Das, Yug Desai, Siddhi Jain, Rajesh Kumar, Harish J. Palanthandalam-Madapusi<br><strong><u>Categories:</u></strong> cs.RO, cs.LG<br><strong><u>Comments:</u></strong> 10 pages, 9 figures<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Delicate snap-fit assemblies, such as inserting a lens into an eye-wear frame or during electronics assembly, demand timely engagement detection and rapid force attenuation to prevent overshoot-induced component damage or assembly failure. We address these challenges with two key contributions. First, we introduce SnapNet, a lightweight neural network that detects snap-fit engagement from joint-velocity transients in real-time, showing that reliable detection can be achieved using proprioceptive signals without external sensors. Second, we present a dynamical-systems-based dual-arm coordination framework that integrates SnapNet driven detection with an event-triggered impedance modulation, enabling accurate alignment and compliant insertion during delicate snap-fit assemblies. Experiments across diverse geometries on a heterogeneous bimanual platform demonstrate high detection accuracy (over 96% recall) and up to a 30% reduction in peak impact forces compared to standard impedance control.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18152v1" target="_blank"><h2>UnfoldLDM: Deep Unfolding-based Blind Image Restoration with Latent Diffusion Priors</h2></a><strong><u>Authors:</u></strong> Chunming He, Rihan Zhang, Zheng Chen, Bowen Yang, CHengyu Fang, Yunlong Lin, Fengyang Xiao, Sina Farsiu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 6 figures, 11 tables<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Deep unfolding networks (DUNs) combine the interpretability of model-based methods with the learning ability of deep networks, yet remain limited for blind image restoration (BIR). Existing DUNs suffer from: (1) \textbf{Degradation-specific dependency}, as their optimization frameworks are tied to a known degradation model, making them unsuitable for BIR tasks; and (2) \textbf{Over-smoothing bias}, resulting from the direct feeding of gradient descent outputs, dominated by low-frequency content, into the proximal term, suppressing fine textures. To overcome these issues, we propose UnfoldLDM to integrate DUNs with latent diffusion model (LDM) for BIR. In each stage, UnfoldLDM employs a multi-granularity degradation-aware (MGDA) module as the gradient descent step. MGDA models BIR as an unknown degradation estimation problem and estimates both the holistic degradation matrix and its decomposed forms, enabling robust degradation removal. For the proximal step, we design a degradation-resistant LDM (DR-LDM) to extract compact degradation-invariant priors from the MGDA output. Guided by this prior, an over-smoothing correction transformer (OCFormer) explicitly recovers high-frequency components and enhances texture details. This unique combination ensures the final result is degradation-free and visually rich. Experiments show that our UnfoldLDM achieves a leading place on various BIR tasks and benefits downstream tasks. Moreover, our design is compatible with existing DUN-based methods, serving as a plug-and-play framework. Code will be released.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18150v1" target="_blank"><h2>Graph Neural Networks vs Convolutional Neural Networks for Graph Domination Number Prediction</h2></a><strong><u>Authors:</u></strong> Randy Davila, Beyzanur Ispir<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, math.CO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> We investigate machine learning approaches to approximating the \emph{domination number} of graphs, the minimum size of a dominating set. Exact computation of this parameter is NP-hard, restricting classical methods to small instances. We compare two neural paradigms: Convolutional Neural Networks (CNNs), which operate on adjacency matrix representations, and Graph Neural Networks (GNNs), which learn directly from graph structure through message passing. Across 2,000 random graphs with up to 64 vertices, GNNs achieve markedly higher accuracy ($R^2=0.987$, MAE $=0.372$) than CNNs ($R^2=0.955$, MAE $=0.500$). Both models offer substantial speedups over exact solvers, with GNNs delivering more than $200\times$ acceleration while retaining near-perfect fidelity. Our results position GNNs as a practical surrogate for combinatorial graph invariants, with implications for scalable graph optimization and mathematical discovery.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18138v1" target="_blank"><h2>Vulnerability-Aware Robust Multimodal Adversarial Training</h2></a><strong><u>Authors:</u></strong> Junrui Zhang, Xinyu Zhao, Jie Peng, Chenjie Wang, Jianmin Ji, Tianlong Chen<br><strong><u>Categories:</u></strong> cs.LG, cs.CR<br><strong><u>Comments:</u></strong> Accepted by AAAI26<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal learning has shown significant superiority on various tasks by integrating multiple modalities. However, the interdependencies among modalities increase the susceptibility of multimodal models to adversarial attacks. Existing methods mainly focus on attacks on specific modalities or indiscriminately attack all modalities. In this paper, we find that these approaches ignore the differences between modalities in their contribution to final robustness, resulting in suboptimal robustness performance. To bridge this gap, we introduce Vulnerability-Aware Robust Multimodal Adversarial Training (VARMAT), a probe-in-training adversarial training method that improves multimodal robustness by identifying the vulnerability of each modality. To be specific, VARMAT first explicitly quantifies the vulnerability of each modality, grounded in a first-order approximation of the attack objective (Probe). Then, we propose a targeted regularization term that penalizes modalities with high vulnerability, guiding robust learning while maintaining task accuracy (Training). We demonstrate the enhanced robustness of our method across multiple multimodal datasets involving diverse modalities. Finally, we achieve {12.73%, 22.21%, 11.19%} robustness improvement on three multimodal datasets, revealing a significant blind spot in multimodal adversarial training.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18123v1" target="_blank"><h2>Bias Is a Subspace, Not a Coordinate: A Geometric Rethinking of Post-hoc Debiasing in Vision-Language Models</h2></a><strong><u>Authors:</u></strong> Dachuan Zhao, Weiyue Li, Zhenda Shen, Yushu Qiu, Bowen Xu, Haoyu Chen, Yongchao Chen<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language Models (VLMs) have become indispensable for multimodal reasoning, yet their representations often encode and amplify demographic biases, resulting in biased associations and misaligned predictions in downstream tasks. Such behavior undermines fairness and distorts the intended alignment between vision and language. Recent post-hoc approaches attempt to mitigate bias by replacing the most attribute-correlated embedding coordinates with neutral values. However, our systematic analysis reveals three critical failures of this coordinate-wise approach: feature entanglement, poor cross-dataset generalization, and incomplete bias removal. We find that bias is not localized to a few coordinates but is instead distributed across a few linear subspaces. To address these limitations, we propose $\textbf{S}$ubspace $\textbf{P}$rojection $\textbf{D}$ebiasing ($\textbf{SPD}$), a geometrically principled framework that identifies and removes the entire subspace of linearly decodable bias while reinserting a neutral mean component to preserve semantic fidelity. Extensive experiments across zero-shot classification, text-to-image retrieval, and image generation validate the effectiveness of SPD: our method achieves more robust debiasing with an average improvement of $18.5\%$ across four fairness metrics, while maintaining minimal loss in task performance compared to the best debiasing baseline.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18121v1" target="_blank"><h2>VCU-Bridge: Hierarchical Visual Connotation Understanding via Semantic Bridging</h2></a><strong><u>Authors:</u></strong> Ming Zhong, Yuanlei Wang, Liuzhou Zhang, Arctanx An, Renrui Zhang, Hao Liang, Ming Lu, Ying Shen, Wentao Zhang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> While Multimodal Large Language Models (MLLMs) excel on benchmarks, their processing paradigm differs from the human ability to integrate visual information. Unlike humans who naturally bridge details and high-level concepts, models tend to treat these elements in isolation. Prevailing evaluation protocols often decouple low-level perception from high-level reasoning, overlooking their semantic and causal dependencies, which yields non-diagnostic results and obscures performance bottlenecks. We present VCU-Bridge, a framework that operationalizes a human-like hierarchy of visual connotation understanding: multi-level reasoning that advances from foundational perception through semantic bridging to abstract connotation, with an explicit evidence-to-inference trace from concrete cues to abstract conclusions. Building on this framework, we construct HVCU-Bench, a benchmark for hierarchical visual connotation understanding with explicit, level-wise diagnostics. Comprehensive experiments demonstrate a consistent decline in performance as reasoning progresses to higher levels. We further develop a data generation pipeline for instruction tuning guided by Monte Carlo Tree Search (MCTS) and show that strengthening low-level capabilities yields measurable gains at higher levels. Interestingly, it not only improves on HVCU-Bench but also brings benefits on general benchmarks (average +2.53%), especially with substantial gains on MMStar (+7.26%), demonstrating the significance of the hierarchical thinking pattern and its effectiveness in enhancing MLLM capabilities. The project page is at https://vcu-bridge.github.io .</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18105v1" target="_blank"><h2>AdaPerceiver: Transformers with Adaptive Width, Depth, and Tokens</h2></a><strong><u>Authors:</u></strong> Purvish Jajal, Nick John Eliopoulos, Benjamin Shiue-Hal Chou, George K. Thiruvathukal, Yung-Hsiang Lu, James C. Davis<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Modern transformer architectures achieve remarkable performance across tasks and domains but remain rigid in how they allocate computation at inference time. Real-world deployment often requires models to adapt to diverse hardware and latency constraints, yet most approaches to dynamic computation focus on a single axis -- such as reducing the number of tokens. We present a novel capability: AdaPerceiver, the first transformer architecture with unified adaptivity across depth, width, and tokens within a single model. We propose an architecture that supports adaptivity along these axes. We couple this with an efficient joint training regime that ensures the model maintains performance across its various configurations. We evaluate AdaPerceiver on image classification, semantic segmentation, and depth estimation tasks. On image classification, AdaPerceiver expands the accuracy-throughput Pareto front. It achieves 85.4% accuracy while yielding 36% higher throughput than FlexiViT-L. On dense prediction, AdaPerceiver matches ViT-H/14 while having $\sim$26x fewer encoder FLOPs (floating-point operations) on semantic segmentation and depth estimation. Finally, we show how AdaPerceiver equipped with a policy can maintain ImageNet1K accuracy ($\pm0.1$ percentage points) while reducing FLOPs by $24-33$%.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18093v1" target="_blank"><h2>A New Error Temporal Difference Algorithm for Deep Reinforcement Learning in Microgrid Optimization</h2></a><strong><u>Authors:</u></strong> Fulong Yao, Wanqing Zhao, Matthew Forshaw<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Have been accepted by 2024 9th International Conference on Renewable Energy and Conservation (ICREC 2024)<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Predictive control approaches based on deep reinforcement learning (DRL) have gained significant attention in microgrid energy optimization. However, existing research often overlooks the issue of uncertainty stemming from imperfect prediction models, which can lead to suboptimal control strategies. This paper presents a new error temporal difference (ETD) algorithm for DRL to address the uncertainty in predictions,aiming to improve the performance of microgrid operations. First,a microgrid system integrated with renewable energy sources (RES) and energy storage systems (ESS), along with its Markov decision process (MDP), is modelled. Second, a predictive control approach based on a deep Q network (DQN) is presented, in which a weighted average algorithm and a new ETD algorithm are designed to quantify and address the prediction uncertainty, respectively. Finally, simulations on a realworld US dataset suggest that the developed ETD effectively improves the performance of DRL in optimizing microgrid operations.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18055v1" target="_blank"><h2>IE-Critic-R1: Advancing the Explanatory Measurement of Text-Driven Image Editing for Human Perception Alignment</h2></a><strong><u>Authors:</u></strong> Bowen Qu, Shangkun Sun, Xiaoyu Liang, Wei Gao<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> 18 pages, 10 figures, 8 tables<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in text-driven image editing have been significant, yet the task of accurately evaluating these edited images continues to pose a considerable challenge. Different from the assessment of text-driven image generation, text-driven image editing is characterized by simultaneously conditioning on both text and a source image. The edited images often retain an intrinsic connection to the original image, which dynamically change with the semantics of the text. However, previous methods tend to solely focus on text-image alignment or have not well aligned with human perception. In this work, we introduce the Text-driven Image Editing Benchmark suite (IE-Bench) to enhance the assessment of text-driven edited images. IE-Bench includes a database contains diverse source images, various editing prompts and the corresponding edited results from different editing methods, and nearly 4,000 samples with corresponding Mean Opinion Scores (MOS) provided by 15 human subjects. Furthermore, we introduce IE-Critic-R1, which, benefiting from Reinforcement Learning from Verifiable Rewards (RLVR), provides more comprehensive and explainable quality assessment for text-driven image editing that aligns with human perception. Extensive experiments demonstrate IE-Critic-R1's superior subjective-alignments on the text-driven image editing task compared with previous metrics. Related data and codes are available to the public.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18047v1" target="_blank"><h2>Fidelity-Aware Recommendation Explanations via Stochastic Path Integration</h2></a><strong><u>Authors:</u></strong> Oren Barkan, Yahlly Schein, Yehonatan Elisha, Veronika Bogina, Mikhail Baklanov, Noam Koenigstein<br><strong><u>Categories:</u></strong> cs.IR, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> VAE (abstract), explainability (abstract)<br><p><strong><u>Abstract:</u></strong> Explanation fidelity, which measures how accurately an explanation reflects a model's true reasoning, remains critically underexplored in recommender systems. We introduce SPINRec (Stochastic Path Integration for Neural Recommender Explanations), a model-agnostic approach that adapts path-integration techniques to the sparse and implicit nature of recommendation data. To overcome the limitations of prior methods, SPINRec employs stochastic baseline sampling: instead of integrating from a fixed or unrealistic baseline, it samples multiple plausible user profiles from the empirical data distribution and selects the most faithful attribution path. This design captures the influence of both observed and unobserved interactions, yielding more stable and personalized explanations. We conduct the most comprehensive fidelity evaluation to date across three models (MF, VAE, NCF), three datasets (ML1M, Yahoo! Music, Pinterest), and a suite of counterfactual metrics, including AUC-based perturbation curves and fixed-length diagnostics. SPINRec consistently outperforms all baselines, establishing a new benchmark for faithful explainability in recommendation. Code and evaluation tools are publicly available at https://github.com/DeltaLabTLV/SPINRec.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18025v1" target="_blank"><h2>Correlated-Sequence Differential Privacy</h2></a><strong><u>Authors:</u></strong> Yifan Luo, Meng Zhang, Jin Xu, Junting Chen, Jianwei Huang<br><strong><u>Categories:</u></strong> cs.CR, cs.IT, cs.LG<br><strong><u>Comments:</u></strong> 11 pages, 5 figures. Published in 2025 34th International Conference on Computer Communications and Networks (ICCCN), IEEE, August 2025<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> sequential data (abstract)<br><p><strong><u>Abstract:</u></strong> Data streams collected from multiple sources are rarely independent. Values evolve over time and influence one another across sequences. These correlations improve prediction in healthcare, finance, and smart-city control yet violate the record-independence assumption built into most Differential Privacy (DP) mechanisms. To restore rigorous privacy guarantees without sacrificing utility, we introduce Correlated-Sequence Differential Privacy (CSDP), a framework specifically designed for preserving privacy in correlated sequential data. CSDP addresses two linked challenges: quantifying the extra information an attacker gains from joint temporal and cross-sequence links, and adding just enough noise to hide that information while keeping the data useful. We model multivariate streams as a Coupling Markov Chain, yielding the derived loose leakage bound expressed with a few spectral terms and revealing a counterintuitive result: stronger coupling can actually decrease worst-case leakage by dispersing perturbations across sequences. Guided by these bounds, we build the Freshness-Regulated Adaptive Noise (FRAN) mechanism--combining data aging, correlation-aware sensitivity scaling, and Laplace noise--that runs in linear time. Tests on two-sequence datasets show that CSDP improves the privacy-utility trade-off by approximately 50% over existing correlated-DP methods and by two orders of magnitude compared to the standard DP approach.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18014v1" target="_blank"><h2>Modeling Retinal Ganglion Cells with Neural Differential Equations</h2></a><strong><u>Authors:</u></strong> Kacper Dobek, Daniel Jankowski, Krzysztof Krawiec<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Accepted to the AAAI-26 Student Abstract and Poster Program, with supplementary material<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> This work explores Liquid Time-Constant Networks (LTCs) and Closed-form Continuous-time Networks (CfCs) for modeling retinal ganglion cell activity in tiger salamanders across three datasets. Compared to a convolutional baseline and an LSTM, both architectures achieved lower MAE, faster convergence, smaller model sizes, and favorable query times, though with slightly lower Pearson correlation. Their efficiency and adaptability make them well suited for scenarios with limited data and frequent retraining, such as edge deployments in vision prosthetics.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.18000v1" target="_blank"><h2>Reward Engineering for Spatial Epidemic Simulations: A Reinforcement Learning Platform for Individual Behavioral Learning</h2></a><strong><u>Authors:</u></strong> Radman Rakhshandehroo, Daniel Coombs<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, q-bio.PE<br><strong><u>Comments:</u></strong> 35 pages, 15 figures and 14 tables<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> We present ContagionRL, a Gymnasium-compatible reinforcement learning platform specifically designed for systematic reward engineering in spatial epidemic simulations. Unlike traditional agent-based models that rely on fixed behavioral rules, our platform enables rigorous evaluation of how reward function design affects learned survival strategies across diverse epidemic scenarios. ContagionRL integrates a spatial SIRS+D epidemiological model with configurable environmental parameters, allowing researchers to stress-test reward functions under varying conditions including limited observability, different movement patterns, and heterogeneous population dynamics. We evaluate five distinct reward designs, ranging from sparse survival bonuses to a novel potential field approach, across multiple RL algorithms (PPO, SAC, A2C). Through systematic ablation studies, we identify that directional guidance and explicit adherence incentives are critical components for robust policy learning. Our comprehensive evaluation across varying infection rates, grid sizes, visibility constraints, and movement patterns reveals that reward function choice dramatically impacts agent behavior and survival outcomes. Agents trained with our potential field reward consistently achieve superior performance, learning maximal adherence to non-pharmaceutical interventions while developing sophisticated spatial avoidance strategies. The platform's modular design enables systematic exploration of reward-behavior relationships, addressing a knowledge gap in models of this type where reward engineering has received limited attention. ContagionRL is an effective platform for studying adaptive behavioral responses in epidemic contexts and highlight the importance of reward design, information structure, and environmental predictability in learning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17990v1" target="_blank"><h2>How Far Can LLMs Emulate Human Behavior?: A Strategic Analysis via the Buy-and-Sell Negotiation Game</h2></a><strong><u>Authors:</u></strong> Mingyu Jeon, Jaeyoung Suh, Suwan Cho, Dohyeon Kim<br><strong><u>Categories:</u></strong> cs.AI, cs.GT<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> With the rapid advancement of Large Language Models (LLMs), recent studies have drawn attention to their potential for handling not only simple question-answer tasks but also more complex conversational abilities and performing human-like behavioral imitations. In particular, there is considerable interest in how accurately LLMs can reproduce real human emotions and behaviors, as well as whether such reproductions can function effectively in real-world scenarios. However, existing benchmarks focus primarily on knowledge-based assessment and thus fall short of sufficiently reflecting social interactions and strategic dialogue capabilities. To address these limitations, this work proposes a methodology to quantitatively evaluate the human emotional and behavioral imitation and strategic decision-making capabilities of LLMs by employing a Buy and Sell negotiation simulation. Specifically, we assign different personas to multiple LLMs and conduct negotiations between a Buyer and a Seller, comprehensively analyzing outcomes such as win rates, transaction prices, and SHAP values. Our experimental results show that models with higher existing benchmark scores tend to achieve better negotiation performance overall, although some models exhibit diminished performance in scenarios emphasizing emotional or social contexts. Moreover, competitive and cunning traits prove more advantageous for negotiation outcomes than altruistic and cooperative traits, suggesting that the assigned persona can lead to significant variations in negotiation strategies and results. Consequently, this study introduces a new evaluation approach for LLMs' social behavior imitation and dialogue strategies, and demonstrates how negotiation simulations can serve as a meaningful complementary metric to measure real-world interaction capabilities-an aspect often overlooked in existing benchmarks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17989v1" target="_blank"><h2>Privacy Auditing of Multi-domain Graph Pre-trained Model under Membership Inference Attacks</h2></a><strong><u>Authors:</u></strong> Jiayi Luo, Qingyun Sun, Yuecen Wei, Haonan Yuan, Xingcheng Fu, Jianxin Li<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CR<br><strong><u>Comments:</u></strong> Accepted by AAAI 2026(Oral)<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Multi-domain graph pre-training has emerged as a pivotal technique in developing graph foundation models. While it greatly improves the generalization of graph neural networks, its privacy risks under membership inference attacks (MIAs), which aim to identify whether a specific instance was used in training (member), remain largely unexplored. However, effectively conducting MIAs against multi-domain graph pre-trained models is a significant challenge due to: (i) Enhanced Generalization Capability: Multi-domain pre-training reduces the overfitting characteristics commonly exploited by MIAs. (ii) Unrepresentative Shadow Datasets: Diverse training graphs hinder the obtaining of reliable shadow graphs. (iii) Weakened Membership Signals: Embedding-based outputs offer less informative cues than logits for MIAs. To tackle these challenges, we propose MGP-MIA, a novel framework for Membership Inference Attacks against Multi-domain Graph Pre-trained models. Specifically, we first propose a membership signal amplification mechanism that amplifies the overfitting characteristics of target models via machine unlearning. We then design an incremental shadow model construction mechanism that builds a reliable shadow model with limited shadow graphs via incremental learning. Finally, we introduce a similarity-based inference mechanism that identifies members based on their similarity to positive and negative samples. Extensive experiments demonstrate the effectiveness of our proposed MGP-MIA and reveal the privacy risks of multi-domain graph pre-training.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17986v1" target="_blank"><h2>Plan-X: Instruct Video Generation via Semantic Planning</h2></a><strong><u>Authors:</u></strong> Lun Huang, You Xie, Hongyi Xu, Tianpei Gu, Chenxu Zhang, Guoxian Song, Zenan Li, Xiaochen Zhao, Linjie Luo, Guillermo Sapiro<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> The project page is atthis https URL<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Diffusion Transformers have demonstrated remarkable capabilities in visual synthesis, yet they often struggle with high-level semantic reasoning and long-horizon planning. This limitation frequently leads to visual hallucinations and mis-alignments with user instructions, especially in scenarios involving complex scene understanding, human-object interactions, multi-stage actions, and in-context motion reasoning. To address these challenges, we propose Plan-X, a framework that explicitly enforces high-level semantic planning to instruct video generation process. At its core lies a Semantic Planner, a learnable multimodal language model that reasons over the user's intent from both text prompts and visual context, and autoregressively generates a sequence of text-grounded spatio-temporal semantic tokens. These semantic tokens, complementary to high-level text prompt guidance, serve as structured "semantic sketches" over time for the video diffusion model, which has its strength at synthesizing high-fidelity visual details. Plan-X effectively integrates the strength of language models in multimodal in-context reasoning and planning, together with the strength of diffusion models in photorealistic video synthesis. Extensive experiments demonstrate that our framework substantially reduces visual hallucinations and enables fine-grained, instruction-aligned video generation consistent with multimodal context.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17982v1" target="_blank"><h2>Towards Effective, Stealthy, and Persistent Backdoor Attacks Targeting Graph Foundation Models</h2></a><strong><u>Authors:</u></strong> Jiayi Luo, Qingyun Sun, Lingjuan Lyu, Ziwei Zhang, Haonan Yuan, Xingcheng Fu, Jianxin Li<br><strong><u>Categories:</u></strong> cs.CR, cs.AI<br><strong><u>Comments:</u></strong> Accepted by AAAI 2026<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Graph Foundation Models (GFMs) are pre-trained on diverse source domains and adapted to unseen targets, enabling broad generalization for graph machine learning. Despite that GFMs have attracted considerable attention recently, their vulnerability to backdoor attacks remains largely underexplored. A compromised GFM can introduce backdoor behaviors into downstream applications, posing serious security risks. However, launching backdoor attacks against GFMs is non-trivial due to three key challenges. (1) Effectiveness: Attackers lack knowledge of the downstream task during pre-training, complicating the assurance that triggers reliably induce misclassifications into desired classes. (2) Stealthiness: The variability in node features across domains complicates trigger insertion that remains stealthy. (3) Persistence: Downstream fine-tuning may erase backdoor behaviors by updating model parameters. To address these challenges, we propose GFM-BA, a novel Backdoor Attack model against Graph Foundation Models. Specifically, we first design a label-free trigger association module that links the trigger to a set of prototype embeddings, eliminating the need for knowledge about downstream tasks to perform backdoor injection. Then, we introduce a node-adaptive trigger generator, dynamically producing node-specific triggers, reducing the risk of trigger detection while reliably activating the backdoor. Lastly, we develop a persistent backdoor anchoring module that firmly anchors the backdoor to fine-tuning-insensitive parameters, enhancing the persistence of the backdoor under downstream adaptation. Extensive experiments demonstrate the effectiveness, stealthiness, and persistence of GFM-BA.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17978v1" target="_blank"><h2>Federated Anomaly Detection and Mitigation for EV Charging Forecasting Under Cyberattacks</h2></a><strong><u>Authors:</u></strong> Oluleke Babayomi, Dong-Seong Kim<br><strong><u>Categories:</u></strong> cs.LG, cs.CR<br><strong><u>Comments:</u></strong> 6 pages<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)<br><p><strong><u>Abstract:</u></strong> Electric Vehicle (EV) charging infrastructure faces escalating cybersecurity threats that can severely compromise operational efficiency and grid stability. Existing forecasting techniques are limited by the lack of combined robust anomaly mitigation solutions and data privacy preservation. Therefore, this paper addresses these challenges by proposing a novel anomaly-resilient federated learning framework that simultaneously preserves data privacy, detects cyber-attacks, and maintains trustworthy demand prediction accuracy under adversarial conditions. The proposed framework integrates three key innovations: LSTM autoencoder-based distributed anomaly detection deployed at each federated client, interpolation-based anomalous data mitigation to preserve temporal continuity, and federated Long Short-Term Memory (LSTM) networks that enable collaborative learning without centralized data aggregation. The framework is validated on real-world EV charging infrastructure datasets combined with real-world DDoS attack datasets, providing robust validation of the proposed approach under realistic threat scenarios. Experimental results demonstrate that the federated approach achieves superior performance compared to centralized models, with 15.2% improvement in R2 accuracy while maintaining data locality. The integrated cyber-attack detection and mitigation system produces trustworthy datasets that enhance prediction reliability, recovering 47.9% of attack-induced performance degradation while maintaining exceptional precision (91.3%) and minimal false positive rates (1.21%). The proposed architecture enables enhanced EV infrastructure planning, privacy-preserving collaborative forecasting, cybersecurity resilience, and rapid recovery from malicious threats across distributed charging networks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17971v1" target="_blank"><h2>Comprehensive Design Space Exploration for Tensorized Neural Network Hardware Accelerators</h2></a><strong><u>Authors:</u></strong> Jinsong Zhang, Minghe Li, Jiayi Tian, Jinming Lu, Zheng Zhang<br><strong><u>Categories:</u></strong> cs.AR, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> High-order tensor decomposition has been widely adopted to obtain compact deep neural networks for edge deployment. However, existing studies focus primarily on its algorithmic advantages such as accuracy and compression ratio-while overlooking the hardware deployment efficiency. Such hardware-unaware designs often obscure the potential latency and energy benefits of tensorized models. Although several works attempt to reduce computational cost by optimizing the contraction sequence based on the number of multiply-accumulate operations, they typically neglect the underlying hardware characteristics, resulting in suboptimal real-world performance. We observe that the contraction path, hardware architecture, and dataflow mapping are tightly coupled and must be optimized jointly within a unified design space to maximize deployment efficiency on real devices. To this end, we propose a co-exploration framework that unifies these dimensions within a unified design space for efficient training and inference of tensorized neural networks on edge platforms. The framework formulates a latency oriented search objective and solves it via a global latency-driven exploration across the unified design space to achieve end-to-end model efficiency. The optimized configurations are implemented on a configurable FPGA kernel, achieving up to 4 and 3.85 lower inference and training latency compared with the dense baseline.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17970v1" target="_blank"><h2>Controllability Analysis of State Space-based Language Model</h2></a><strong><u>Authors:</u></strong> Mohamed Mabrok, Yalda Zafari<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> State-space models (SSMs), particularly Mamba, have become powerful architectures for sequence modeling, yet their internal dynamics remain poorly understood compared to attention-based models. We introduce and validate the Influence Score, a controllability-based metric derived from the discretized state-space parameters of Mamba and computed through a backward recurrence analogous to system observability. The score quantifies how strongly a token at position k affects all later states and outputs. We evaluate this measure across three Mamba variants: mamba-130m, mamba-2.8b, and mamba-2.8b-slimpj, using six experiments that test its sensitivity to temperature, prompt complexity, token type, layer depth, token position, and input perturbations. The results show three main insights: (1) the Influence Score increases with model size and training data, reflecting model capacity; (2) Mamba exhibits consistent architectural patterns, including recency bias and concentrated influence in mid-to-late layers; and (3) emergent behaviors appear only at scale, with mamba-2.8b-slimpj uniquely prioritizing content words and reducing internal influence in the presence of noise. These findings establish the Influence Score as a practical diagnostic tool for interpreting and comparing SSM-based language models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17962v1" target="_blank"><h2>VITAL: Vision-Encoder-centered Pre-training for LMMs in Visual Quality Assessment</h2></a><strong><u>Authors:</u></strong> Ziheng Jia, Linhan Cao, Jinliang Han, Zicheng Zhang, Jiaying Qian, Jiarui Wang, Zijian Chen, Guangtao Zhai, Xiongkuo Min<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Developing a robust visual quality assessment (VQualA) large multi-modal model (LMM) requires achieving versatility, powerfulness, and transferability.
  However, existing VQualA LMMs typically focus on a single task and rely on full-parameter fine-tuning, which makes them prone to overfitting on specific modalities or task types, thereby limiting their generalization capacity and transferability. To address this, we propose a vision-encoder-centered generative pre-training pipeline and develop the VITAL-Series LMMs. (1) We adopt a machine-executed annotation-scrutiny paradigm, constructing over 4.5M vision-language (VL) pairs-the largest VQualA training dataset to date. (2) We employ a multi-task training workflow that simultaneously enhances the model's quantitative scoring precision and strengthens its capability for quality interpretation across both image and video modalities. (3) Building upon the vision encoder, we realize an efficient model zoo extension: the model zoo exhibits strong zero-shot performance, and each paired decoder requires only a swift warm-up using less than 1/1000 of the pre-training data to achieve performance comparable to the fully trained counterpart. Overall, our work lays a cornerstone for advancing toward the foundation LMM for VQualA.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17938v1" target="_blank"><h2>SPINE: Token-Selective Test-Time Reinforcement Learning with Entropy-Band Regularization</h2></a><strong><u>Authors:</u></strong> Jianghao Wu, Yasmeen George, Jin Ye, Yicheng Wu, Daniel F. Schmidt, Jianfei Cai<br><strong><u>Categories:</u></strong> cs.CL, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Large language models (LLMs) and multimodal LLMs (MLLMs) excel at chain-of-thought reasoning but face distribution shift at test-time and a lack of verifiable supervision. Recent test-time reinforcement learning (TTRL) methods derive label-free pseudo-rewards from self-consistency voting over sampled trajectories, yet they often collapse: the majority-vote reward prevails, responses shorten, and Pass@1 declines. We trace this to uniform sequence updates in which most tokens are low-entropy followers, while a small high-entropy subset determines the reasoning branches. Thus we propose SPINE, a token-selective test-time reinforcement learning framework that (i) updates only forking tokens, the high-entropy branch points identified from forward-pass statistics, and (ii) applies an entropy-band regularizer at those tokens to sustain exploration when entropy is too low and to suppress noisy supervision when it is too high. SPINE plugs into GRPO-style objectives, optionally with a KL anchor, and requires no labels or reward models. Across ten benchmarks spanning multimodal VQA, general and expert QA, mathematical reasoning, and medical QA, SPINE consistently improves Pass@1 over TTRL while avoiding response-length collapse and yielding more stable training dynamics on both LLM and MLLM backbones. These results indicate that aligning updates with chain-of-thought branch points is a simple and label-free mechanism for stable and effective test-time adaptation in reasoning models. Code is available at https://github.com/JianghaoWu/SPINE.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17927v1" target="_blank"><h2>PA-FAS: Towards Interpretable and Generalizable Multimodal Face Anti-Spoofing via Path-Augmented Reinforcement Learning</h2></a><strong><u>Authors:</u></strong> Yingjie Ma, Xun Lin, Yong Xu, Weicheng Xie, Zitong Yu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Accepted by AAAI 2026 (Oral)<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Face anti-spoofing (FAS) has recently advanced in multimodal fusion, cross-domain generalization, and interpretability. With large language models and reinforcement learning (RL), strategy-based training offers new opportunities to jointly model these aspects. However, multimodal reasoning is more complex than unimodal reasoning, requiring accurate feature representation and cross-modal verification while facing scarce, high-quality annotations, which makes direct application of RL sub-optimal. We identify two key limitations of supervised fine-tuning plus RL (SFT+RL) for multimodal FAS: (1) limited multimodal reasoning paths restrict the use of complementary modalities and shrink the exploration space after SFT, weakening the effect of RL; and (2) mismatched single-task supervision versus diverse reasoning paths causes reasoning confusion, where models may exploit shortcuts by mapping images directly to answers and ignoring the intended reasoning. To address this, we propose PA-FAS, which enhances reasoning paths by constructing high-quality extended reasoning sequences from limited annotations, enriching paths and relaxing exploration constraints. We further introduce an answer-shuffling mechanism during SFT to force comprehensive multimodal analysis instead of using superficial cues, thereby encouraging deeper reasoning and mitigating shortcut learning. PA-FAS significantly improves multimodal reasoning accuracy and cross-domain generalization, and better unifies multimodal fusion, generalization, and interpretability for trustworthy FAS.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17923v1" target="_blank"><h2>Towards Efficient LLM-aware Heterogeneous Graph Learning</h2></a><strong><u>Authors:</u></strong> Wenda Li, Tongya Zheng, Shunyu Liu, Yu Wang, Kaixuan Chen, Hanyang Yuan, Bingde Hu, Zujie Ren, Mingli Song, Gang Chen<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Heterogeneous graphs are widely present in real-world complex networks, where the diversity of node and relation types leads to complex and rich semantics. Efforts for modeling complex relation semantics in heterogeneous graphs are restricted by the limitations of predefined semantic dependencies and the scarcity of supervised signals. The advanced pre-training and fine-tuning paradigm leverages graph structure to provide rich self-supervised signals, but introduces semantic gaps between tasks. Large Language Models (LLMs) offer significant potential to address the semantic issues of relations and tasks in heterogeneous graphs through their strong reasoning capabilities in textual modality, but their incorporation into heterogeneous graphs is largely limited by computational complexity. Therefore, in this paper, we propose an Efficient LLM-Aware (ELLA) framework for heterogeneous graphs, addressing the above issues. To capture complex relation semantics, we propose an LLM-aware Relation Tokenizer that leverages LLM to encode multi-hop, multi-type relations. To reduce computational complexity, we further employ a Hop-level Relation Graph Transformer, which help reduces the complexity of LLM-aware relation reasoning from exponential to linear. To bridge semantic gaps between pre-training and fine-tuning tasks, we introduce the fine-grained task-aware textual Chain-of-Thought (CoT) prompts. Extensive experiments on four heterogeneous graphs show that our proposed ELLA outperforms state-of-the-art methods in the performance and efficiency. In particular, ELLA scales up to 13b-parameter LLMs and achieves up to a 4x speedup compared with existing LLM-based methods. Our code is publicly available at https://github.com/l-wd/ELLA.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17909v1" target="_blank"><h2>ChemVTS-Bench: Evaluating Visual-Textual-Symbolic Reasoning of Multimodal Large Language Models in Chemistry</h2></a><strong><u>Authors:</u></strong> Zhiyuan Huang, Baichuan Yang, Zikun He, Yanhong Wu, Fang Hongyu, Zhenhe Liu, Lin Dongsheng, Bing Su<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Chemical reasoning inherently integrates visual, textual, and symbolic modalities, yet existing benchmarks rarely capture this complexity, often relying on simple image-text pairs with limited chemical semantics. As a result, the actual ability of Multimodal Large Language Models (MLLMs) to process and integrate chemically meaningful information across modalities remains unclear. We introduce \textbf{ChemVTS-Bench}, a domain-authentic benchmark designed to systematically evaluate the Visual-Textual-Symbolic (VTS) reasoning abilities of MLLMs. ChemVTS-Bench contains diverse and challenging chemical problems spanning organic molecules, inorganic materials, and 3D crystal structures, with each task presented in three complementary input modes: (1) visual-only, (2) visual-text hybrid, and (3) SMILES-based symbolic input. This design enables fine-grained analysis of modality-dependent reasoning behaviors and cross-modal integration. To ensure rigorous and reproducible evaluation, we further develop an automated agent-based workflow that standardizes inference, verifies answers, and diagnoses failure modes. Extensive experiments on state-of-the-art MLLMs reveal that visual-only inputs remain challenging, structural chemistry is the hardest domain, and multimodal fusion mitigates but does not eliminate visual, knowledge-based, or logical errors, highlighting ChemVTS-Bench as a rigorous, domain-faithful testbed for advancing multimodal chemical reasoning. All data and code will be released to support future research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17908v1" target="_blank"><h2>Principled Context Engineering for RAG: Statistical Guarantees via Conformal Prediction</h2></a><strong><u>Authors:</u></strong> Debashish Chakraborty, Eugene Yang, Daniel Khashabi, Dawn Lawrie, Kevin Duh<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.IR<br><strong><u>Comments:</u></strong> Preprint<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Retrieval-Augmented Generation (RAG) enhances factual grounding in large language models (LLMs) by incorporating retrieved evidence, but LLM accuracy declines when long or noisy contexts exceed the model's effective attention span. Existing pre-generation filters rely on heuristics or uncalibrated LLM confidence scores, offering no statistical control over retained evidence. We evaluate and demonstrate context engineering through conformal prediction, a coverage-controlled filtering framework that removes irrelevant content while preserving recall of supporting evidence. Using both embedding- and LLM-based scoring functions, we test this approach on the NeuCLIR and RAGTIME collections. Conformal filtering consistently meets its target coverage, ensuring that a specified fraction of relevant snippets are retained, and reduces retained context by 2-3x relative to unfiltered retrieval. On NeuCLIR, downstream factual accuracy measured by ARGUE F1 improves under strict filtering and remains stable at moderate coverage, indicating that most discarded material is redundant or irrelevant. These results demonstrate that conformal prediction enables reliable, coverage-controlled context reduction in RAG, offering a model-agnostic and principled approach to context engineering.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17902v1" target="_blank"><h2>Statistically-Guided Dual-Domain Meta-Learning with Adaptive Multi-Prototype Aggregation for Distributed Fiber Optic Sensing</h2></a><strong><u>Authors:</u></strong> Yifan He, Haodong Zhang, Qiuheng Song, Lin Lei, Zhenxuan Zeng, Haoyang He, Hongyan Wu<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Distributed Fiber Optic Sensing (DFOS) has shown strong potential in perimeter security due to its capability of monitoring vibration events across long distances with fine spatial resolution. However, practical DFOS systems face three critical challenges: (1) signal patterns of the same activity vary drastically under different fiber deployment types (e.g., underground, wall-mounted), causing domain shift; (2) labeled data in new deployment scenarios is often scarce or entirely unavailable, limiting model adaptability; and (3) even within source domains, data scarcity makes it difficult to capture intra-class diversity for robust learning.
  To address these challenges, we propose a novel meta-learning framework, DUPLE, for cross-deployment DFOS activity identification. First, a dual-domain multi-prototype learner fuses temporal and frequency domain features, enhancing the model's generalization ability under signal distribution shifts. Second, a Statistical Guided Network (SGN) infers domain importance and prototype sensitivity from raw statistical features, providing data-driven prior information for learning in unlabeled or unseen domains. Third, a query-aware prototype aggregation module adaptively selects and combines relevant prototypes, thereby improving classification performance even with limited data.
  Extensive experiments on cross-deployment DFOS datasets demonstrate that our method significantly outperforms baseline approaches in domain generalization settings, enabling robust event recognition across diverse fiber configurations with minimal labeled data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17892v1" target="_blank"><h2>Arbitrage-Free Bond and Yield Curve Forecasting with Neural Filters under HJM Constraints</h2></a><strong><u>Authors:</u></strong> Xiang Gao, Cody Hyndman<br><strong><u>Categories:</u></strong> q-fin.MF, cs.LG, q-fin.CP, stat.ML<br><strong><u>Comments:</u></strong> 31 pages, 17 figures<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> We develop an arbitrage-free deep learning framework for yield curve and bond price forecasting based on the Heath-Jarrow-Morton (HJM) term-structure model and a dynamic Nelson-Siegel parameterization of forward rates. Our approach embeds a no-arbitrage drift restriction into a neural state-space architecture by combining Kalman, extended Kalman, and particle filters with recurrent neural networks (LSTM/CLSTM), and introduces an explicit arbitrage error regularization (AER) term during training. The model is applied to U.S. Treasury and corporate bond data, and its performance is evaluated for both yield-space and price-space predictions at 1-day and 5-day horizons. Empirically, arbitrage regularization leads to its strongest improvements at short maturities, particularly in 5-day-ahead forecasts, increasing market-consistency as measured by bid-ask hit rates and reducing dollar-denominated prediction errors.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17885v1" target="_blank"><h2>FastMMoE: Accelerating Multimodal Large Language Models through Dynamic Expert Activation and Routing-Aware Token Pruning</h2></a><strong><u>Authors:</u></strong> Guoyang Xia, Yifeng Ding, Fengfa Li, Lei Ren, Wei Chen, Fangxiang Feng, Xiaojie Wang<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal large language models (MLLMs) have achieved impressive performance, but high-resolution visual inputs result in long sequences of visual tokens and substantial inference latency. Reducing redundant visual tokens is critical to ease computational/memory burdens while preserving performance, enabling MLLM deployment in resource-constrained or latency-sensitive scenarios. Current visual token pruning methods mainly rely on attention-based redundancy analysis and are tailored to dense architectures. We propose Fast Multimodal Mixture-of-Experts (FastMMoE), a training-free acceleration framework for mixture-of-experts (MoE) based MLLMs, developed from a routing analysis perspective. FastMMoE combines two complementary strategies: (i) expert activation reduction for visual tokens to minimize unnecessary expert computation; and (ii) routing-aware token pruning that leverages similarity in routing probability distributions to identify and remove highly redundant visual tokens. Experiments on large-scale MoE-MLLMs such as DeepSeek-VL2 and InternVL3.5 demonstrate that FastMMoE can reduce FLOPs by up to 55.0% while retaining approximately 95.5% of the original performance, consistently outperforming dense-model pruning baselines including FastV and SparseVLM across multiple retention rates.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17881v1" target="_blank"><h2>MGA-VQA: Secure and Interpretable Graph-Augmented Visual Question Answering with Memory-Guided Protection Against Unauthorized Knowledge Use</h2></a><strong><u>Authors:</u></strong> Ahmad Mohammadshirazi, Pinaki Prasad Guha Neogi, Dheeraj Kulshrestha, Rajiv Ramnath<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Document Visual Question Answering (DocVQA) requires models to jointly understand textual semantics, spatial layout, and visual features. Current methods struggle with explicit spatial relationship modeling, inefficiency with high-resolution documents, multi-hop reasoning, and limited interpretability. We propose MGA-VQA, a multi-modal framework that integrates token-level encoding, spatial graph reasoning, memory-augmented inference, and question-guided compression. Unlike prior black-box models, MGA-VQA introduces interpretable graph-based decision pathways and structured memory access for enhanced reasoning transparency. Evaluation across six benchmarks (FUNSD, CORD, SROIE, DocVQA, STE-VQA, and RICO) demonstrates superior accuracy and efficiency, with consistent improvements in both answer prediction and spatial localization.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17869v1" target="_blank"><h2>The Horcrux: Mechanistically Interpretable Task Decomposition for Detecting and Mitigating Reward Hacking in Embodied AI Systems</h2></a><strong><u>Authors:</u></strong> Subramanyam Sahoo, Jared Junkin<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Accepted to the NeurIPS (Mexico City) 2025 Workshop on Embodied and Safe-Assured Robotic Systems (E-SARS). Thanks to Aman Chadha<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Embodied AI agents exploit reward signal flaws through reward hacking, achieving high proxy scores while failing true objectives. We introduce Mechanistically Interpretable Task Decomposition (MITD), a hierarchical transformer architecture with Planner, Coordinator, and Executor modules that detects and mitigates reward hacking. MITD decomposes tasks into interpretable subtasks while generating diagnostic visualizations including Attention Waterfall Diagrams and Neural Pathway Flow Charts. Experiments on 1,000 HH-RLHF samples reveal that decomposition depths of 12 to 25 steps reduce reward hacking frequency by 34 percent across four failure modes. We present new paradigms showing that mechanistically grounded decomposition offers a more effective way to detect reward hacking than post-hoc behavioral monitoring.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17864v1" target="_blank"><h2>Equivalence of Context and Parameter Updates in Modern Transformer Blocks</h2></a><strong><u>Authors:</u></strong> Adrian Goldwaser, Michael Munn, Javier Gonzalvo, Benoit Dherin<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Recent research has established that the impact of context in a vanilla transformer can be represented implicitly by forming a token-dependent, rank-1 patch to its MLP weights. This work extends that foundational theory to the diverse architectures of modern Large Language Models. We first demonstrate a precise, analytical solution for a Gemma-style transformer block, proving that the entire effect of a context can be perfectly mapped to rank-1 patches on its MLP weight matrices and a patch to the RMSNorm scale. We then generalize this result, providing a constructive proof and algorithm for multi-layer models. To unify these findings, we introduce a general framework centered on two core properties: input controllability and output controllability. We prove that a perfect implicit weight patch is possible for any MLP block where the inner function is input-controllable and the outer function is output-controllable. This provides a simpler and more powerful lens for understanding how transformer models transmute prompts into effective weights. This setup generalizes to a wide range of modern LLM architectures including gating, pre-/post-norm, mixture of experts and sequential/parallel transformer blocks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17855v1" target="_blank"><h2>QuickLAP: Quick Language-Action Preference Learning for Autonomous Driving Agents</h2></a><strong><u>Authors:</u></strong> Jordan Abi Nader, David Lee, Nathaniel Dennler, Andreea Bobu<br><strong><u>Categories:</u></strong> cs.AI, cs.RO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Robots must learn from both what people do and what they say, but either modality alone is often incomplete: physical corrections are grounded but ambiguous in intent, while language expresses high-level goals but lacks physical grounding. We introduce QuickLAP: Quick Language-Action Preference learning, a Bayesian framework that fuses physical and language feedback to infer reward functions in real time. Our key insight is to treat language as a probabilistic observation over the user's latent preferences, clarifying which reward features matter and how physical corrections should be interpreted. QuickLAP uses Large Language Models (LLMs) to extract reward feature attention masks and preference shifts from free-form utterances, which it integrates with physical feedback in a closed-form update rule. This enables fast, real-time, and robust reward learning that handles ambiguous feedback. In a semi-autonomous driving simulator, QuickLAP reduces reward learning error by over 70% compared to physical-only and heuristic multimodal baselines. A 15-participant user study further validates our approach: participants found QuickLAP significantly more understandable and collaborative, and preferred its learned behavior over baselines. Code is available at https://github.com/MIT-CLEAR-Lab/QuickLAP.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17852v1" target="_blank"><h2>Transformers with RL or SFT Provably Learn Sparse Boolean Functions, But Differently</h2></a><strong><u>Authors:</u></strong> Bochen Lyu, Yiyang Jia, Xiaohao Cai, Zhanxing Zhu<br><strong><u>Categories:</u></strong> cs.LG, stat.ML<br><strong><u>Comments:</u></strong> 43 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Transformers can acquire Chain-of-Thought (CoT) capabilities to solve complex reasoning tasks through fine-tuning. Reinforcement learning (RL) and supervised fine-tuning (SFT) are two primary approaches to this end, yet their underlying mechanisms and differences remain theoretically unclear. In this work, we examine these aspects specifically for learning $k$-sparse Boolean functions with a one-layer transformer and intermediate supervision that is akin to CoT. In particular, we consider $k$-sparse Boolean functions that can be recursively decomposed into fixed 2-sparse Boolean functions. We analyze the learning dynamics of fine-tuning the transformer via either RL or SFT with CoT to identify sufficient conditions for it to provably learn these functions. We verify that these conditions hold for three basic examples, including $k$-PARITY, $k$-AND, and $k$-OR, thus demonstrating the learnability of both approaches. Notably, we reveal that RL and SFT exhibit distinct learning behaviors: RL learns the whole CoT chain simultaneously, whereas SFT learns the CoT chain step-by-step. Overall, our findings provide theoretical insights into the underlying mechanisms of RL and SFT as well as how they differ in triggering the CoT capabilities of transformers.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17848v1" target="_blank"><h2>Scaling Kinetic Monte-Carlo Simulations of Grain Growth with Combined Convolutional and Graph Neural Networks</h2></a><strong><u>Authors:</u></strong> Zhihui Tian, Ethan Suwandi, Tomas Oppelstrup, Vasily V. Bulatov, Joel B. Harley, Fei Zhou<br><strong><u>Categories:</u></strong> cs.LG, cond-mat.mtrl-sci<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-22<br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), latent space (abstract), neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Graph neural networks (GNN) have emerged as a promising machine learning method for microstructure simulations such as grain growth. However, accurate modeling of realistic grain boundary networks requires large simulation cells, which GNN has difficulty scaling up to. To alleviate the computational costs and memory footprint of GNN, we propose a hybrid architecture combining a convolutional neural network (CNN) based bijective autoencoder to compress the spatial dimensions, and a GNN that evolves the microstructure in the latent space of reduced spatial sizes. Our results demonstrate that the new design significantly reduces computational costs with using fewer message passing layer (from 12 down to 3) compared with GNN alone. The reduction in computational cost becomes more pronounced as the spatial size increases, indicating strong computational scalability. For the largest mesh evaluated (160^3), our method reduces memory usage and runtime in inference by 117x and 115x, respectively, compared with GNN-only baseline. More importantly, it shows higher accuracy and stronger spatiotemporal capability than the GNN-only baseline, especially in long-term testing. Such combination of scalability and accuracy is essential for simulating realistic material microstructures over extended time scales. The improvements can be attributed to the bijective autoencoder's ability to compress information losslessly from spatial domain into a high dimensional feature space, thereby producing more expressive latent features for the GNN to learn from, while also contributing its own spatiotemporal modeling capability. The training was optimized to learn from the stochastic Potts Monte Carlo method. Our findings provide a highly scalable approach for simulating grain growth.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17840v1" target="_blank"><h2>Internalizing Tools as Morphisms in Graded Transformers</h2></a><strong><u>Authors:</u></strong> Tony Shaska<br><strong><u>Categories:</u></strong> cs.LG, math.CT<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> We introduce a graded formulation of internal symbolic computation for transformers. The hidden space is endowed with a grading $V=\bigoplus_{g\in G}V_g$, and symbolic operations are realized as typed block maps (morphisms) $φ_{h\leftarrow g}:V_g\to V_h$ that are activated selectively by a differentiable routing policy. A self-supervised \emph{graded utility functional}, defined as the loss reduction induced by a candidate morphism, governs activation and yields sparse, interpretable behavior. We develop the algebraic and geometric foundations: an internal model category whose objects are homogeneous components and whose morphisms are admissible grade transitions; adjoint pairs encoding typed round trips; and information-geometric interpretations in terms of KL gain, mirror descent with Bregman divergences, and Fisher natural gradients. Methodologically, we specify a utility--aware routing mechanism and objective that remain fully end-to-end differentiable. Analytic case studies and lightweight sanity checks illustrate selective morphic activation on hybrid symbolic-linguistic tasks. The framework unifies symbolic computation, geometry, and self--supervised learning within the \emph{graded transformer} formalism \cite{sh-89,sh-95}, while subsuming prior external-tool paradigms (e.g., Toolformer \cite{toolformer2023}) as a special case via functorial internalization.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17828v1" target="_blank"><h2>Toward explainable AI approaches for breast imaging: adapting foundation models to diverse populations</h2></a><strong><u>Authors:</u></strong> Guilherme J. Cavalcante, José Gabriel A. Moreira, Gabriel A. B. do Nascimento, Vincent Dong, Alex Nguyen, Thaís G. do Rêgo, Yuri Malheiros, Telmo M. Silva Filho, Carla R. Zeballos Torrez, James C. Gee, Anne Marie McCarthy, Andrew D. A. Maidment, Bruno Barufaldi<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 5 pages, 3 figures<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> explainable (title), multi-modal (abstract), multi-modality (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Foundation models hold promise for specialized medical imaging tasks, though their effectiveness in breast imaging remains underexplored. This study leverages BiomedCLIP as a foundation model to address challenges in model generalization. BiomedCLIP was adapted for automated BI-RADS breast density classification using multi-modality mammographic data (synthesized 2D images, digital mammography, and digital breast tomosynthesis). Using 96,995 images, we compared single-modality (s2D only) and multi-modality training approaches, addressing class imbalance through weighted contrastive learning. Both approaches achieved similar accuracy (multi-modality: 0.74, single-modality: 0.73), with the multi-modality model offering broader applicability across different imaging modalities and higher AUC values consistently above 0.84 across BI-RADS categories. External validation on the RSNA and EMBED datasets showed strong generalization capabilities (AUC range: 0.80-0.93). GradCAM visualizations confirmed consistent and clinically relevant attention patterns, highlighting the models interpretability and robustness. This research underscores the potential of foundation models for breast imaging applications, paving the way for future extensions for diagnostic tasks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17806v1" target="_blank"><h2>REXO: Indoor Multi-View Radar Object Detection via 3D Bounding Box Diffusion</h2></a><strong><u>Authors:</u></strong> Ryoma Yataka, Pu Perry Wang, Petros Boufounos, Ryuhei Takahashi<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG, eess.SP<br><strong><u>Comments:</u></strong> 26 pages, Accepted to AAAI 2026; Code to be released<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Multi-view indoor radar perception has drawn attention due to its cost-effectiveness and low privacy risks. Existing methods often rely on {implicit} cross-view radar feature association, such as proposal pairing in RFMask or query-to-feature cross-attention in RETR, which can lead to ambiguous feature matches and degraded detection in complex indoor scenes. To address these limitations, we propose \textbf{REXO} (multi-view Radar object dEtection with 3D bounding boX diffusiOn), which lifts the 2D bounding box (BBox) diffusion process of DiffusionDet into the 3D radar space. REXO utilizes these noisy 3D BBoxes to guide an {explicit} cross-view radar feature association, enhancing the cross-view radar-conditioned denoising process. By accounting for prior knowledge that the person is in contact with the ground, REXO reduces the number of diffusion parameters by determining them from this prior. Evaluated on two open indoor radar datasets, our approach surpasses state-of-the-art methods by a margin of +4.22 AP on the HIBER dataset and +11.02 AP on the MMVR dataset.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17793v1" target="_blank"><h2>Attention Guided Alignment in Efficient Vision-Language Models</h2></a><strong><u>Authors:</u></strong> Shweta Mahajan, Hoang Le, Hyojin Park, Farzad Farhadzadeh, Munawar Hayat, Fatih Porikli<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on Efficient Reasoning<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Large Vision-Language Models (VLMs) rely on effective multimodal alignment between pre-trained vision encoders and Large Language Models (LLMs) to integrate visual and textual information. This paper presents a comprehensive analysis of attention patterns in efficient VLMs, revealing that concatenation-based architectures frequently fail to distinguish between semantically matching and non-matching image-text pairs. This is a key factor for object hallucination in these models. To address this, we introduce Attention-Guided Efficient Vision-Language Models (AGE-VLM), a novel framework that enhances visual grounding through interleaved cross-attention layers to instill vision capabilities in pretrained small language models. This enforces in VLM the ability "look" at the correct image regions by leveraging spatial knowledge distilled from the Segment Anything Model (SAM), significantly reducing hallucination. We validate our approach across different vision-centric benchmarks where our method is better or comparable to prior work on efficient VLMs. Our findings provide valuable insights for future research aimed at achieving enhanced visual and linguistic understanding in VLMs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17787v1" target="_blank"><h2>Data-Driven Predictive Modeling of Microfluidic Cancer Cell Separation Using a Deterministic Lateral Displacement Device</h2></a><strong><u>Authors:</u></strong> Elizabeth Chen, Andrew Lee, Tanbir Sarowar, Xiaolin Chen<br><strong><u>Categories:</u></strong> cs.LG, physics.med-ph, q-bio.QM<br><strong><u>Comments:</u></strong> Accepted to IEEE International Conference on Data Mining (ICDM) 2025 REU Symposium<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract)<br><p><strong><u>Abstract:</u></strong> Deterministic Lateral Displacement (DLD) devices are widely used in microfluidics for label-free, size-based separation of particles and cells, with particular promise in isolating circulating tumor cells (CTCs) for early cancer diagnostics. This study focuses on the optimization of DLD design parameters, such as row shift fraction, post size, and gap distance, to enhance the selective isolation of lung cancer cells based on their physical properties. To overcome the challenges of rare CTC detection and reduce reliance on computationally intensive simulations, machine learning models including gradient boosting, k-nearest neighbors, random forest, and multilayer perceptron (MLP) regressors are employed. Trained on a large, numerically validated dataset, these models predict particle trajectories and identify optimal device configurations, enabling high-throughput and cost-effective DLD design. Beyond trajectory prediction, the models aid in isolating critical design variables, offering a systematic, data-driven framework for automated DLD optimization. This integrative approach advances the development of scalable and precise microfluidic systems for cancer diagnostics, contributing to the broader goals of early detection and personalized medicine.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17776v1" target="_blank"><h2>PrismSSL: One Interface, Many Modalities; A Single-Interface Library for Multimodal Self-Supervised Learning</h2></a><strong><u>Authors:</u></strong> Melika Shirian, Kianoosh Vadaei, Kian Majlessi, Audrina Ebrahimi, Arshia Hemmat, Peyman Adibi, Hossein Karshenas<br><strong><u>Categories:</u></strong> cs.LG, cs.MM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> multimodal (title), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> We present PrismSSL, a Python library that unifies state-of-the-art self-supervised learning (SSL) methods across audio, vision, graphs, and cross-modal settings in a single, modular codebase. The goal of the demo is to show how researchers and practitioners can: (i) install, configure, and run pretext training with a few lines of code; (ii) reproduce compact benchmarks; and (iii) extend the framework with new modalities or methods through clean trainer and dataset abstractions. PrismSSL is packaged on PyPI, released under the MIT license, integrates tightly with HuggingFace Transformers, and provides quality-of-life features such as distributed training in PyTorch, Optuna-based hyperparameter search, LoRA fine-tuning for Transformer backbones, animated embedding visualizations for sanity checks, Weights & Biases logging, and colorful, structured terminal logs for improved usability and clarity. In addition, PrismSSL offers a graphical dashboard - built with Flask and standard web technologies - that enables users to configure and launch training pipelines with minimal coding. The artifact (code and data recipes) will be publicly available and reproducible.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17772v1" target="_blank"><h2>Weighted Birkhoff Averages Accelerate Data-Driven Methods</h2></a><strong><u>Authors:</u></strong> Maria Bou-Sakr-El-Tayar, Jason J. Bramburger, Matthew J. Colbrook<br><strong><u>Categories:</u></strong> math.DS, cs.LG, nlin.CD<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract)<br><p><strong><u>Abstract:</u></strong> Many data-driven algorithms in dynamical systems rely on ergodic averages that converge painfully slowly. One simple idea changes this: taper the ends. Weighted Birkhoff averages can converge much faster (sometimes superpolynomially, even exponentially) and can be incorporated seamlessly into existing methods. We demonstrate this with five weighted algorithms: weighted Dynamic Mode Decomposition (wtDMD), weighted Extended DMD (wtEDMD), weighted Sparse Identification of Nonlinear Dynamics (wtSINDy), weighted spectral measure estimation, and weighted diffusion forecasting. Across examples ranging from fluid flows to El Niño data, the message is clear: weighting costs nothing, is easy to implement, and often delivers markedly better results from the same data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17765v1" target="_blank"><h2>LEARN: Learning End-to-End Aerial Resource-Constrained Multi-Robot Navigation</h2></a><strong><u>Authors:</u></strong> Darren Chiu, Zhehui Huang, Ruohai Ge, Gaurav S. Sukhatme<br><strong><u>Categories:</u></strong> cs.RO, cs.LG, cs.MA<br><strong><u>Comments:</u></strong> 20 pages, 15 figures<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Nano-UAV teams offer great agility yet face severe navigation challenges due to constrained onboard sensing, communication, and computation. Existing approaches rely on high-resolution vision or compute-intensive planners, rendering them infeasible for these platforms. We introduce LEARN, a lightweight, two-stage safety-guided reinforcement learning (RL) framework for multi-UAV navigation in cluttered spaces. Our system combines low-resolution Time-of-Flight (ToF) sensors and a simple motion planner with a compact, attention-based RL policy. In simulation, LEARN outperforms two state-of-the-art planners by $10\%$ while using substantially fewer resources. We demonstrate LEARN's viability on six Crazyflie quadrotors, achieving fully onboard flight in diverse indoor and outdoor environments at speeds up to $2.0 m/s$ and traversing $0.2 m$ gaps.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17760v1" target="_blank"><h2>When Active Learning Fails, Uncalibrated Out of Distribution Uncertainty Quantification Might Be the Problem</h2></a><strong><u>Authors:</u></strong> Ashley S. Dale, Kangming Li, Brian DeCost, Hao Wan, Yuchen Han, Yao Fehlis, Jason Hattrick-Simpers<br><strong><u>Categories:</u></strong> cond-mat.mtrl-sci, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Efficiently and meaningfully estimating prediction uncertainty is important for exploration in active learning campaigns in materials discovery, where samples with high uncertainty are interpreted as containing information missing from the model. In this work, the effect of different uncertainty estimation and calibration methods are evaluated for active learning when using ensembles of ALIGNN, eXtreme Gradient Boost, Random Forest, and Neural Network model architectures. We compare uncertainty estimates from ALIGNN deep ensembles to loss landscape uncertainty estimates obtained for solubility, bandgap, and formation energy prediction tasks. We then evaluate how the quality of the uncertainty estimate impacts an active learning campaign that seeks model generalization to out-of-distribution data. Uncertainty calibration methods were found to variably generalize from in-domain data to out-of-domain data. Furthermore, calibrated uncertainties were generally unsuccessful in reducing the amount of data required by a model to improve during an active learning campaign on out-of-distribution data when compared to random sampling and uncalibrated uncertainties. The impact of poor-quality uncertainty persists for random forest and eXtreme Gradient Boosting models trained on the same data for the same tasks, indicating that this is at least partially intrinsic to the data and not due to model capacity alone. Analysis of the target, in-distribution uncertainty, out-of-distribution uncertainty, and training residual distributions suggest that future work focus on understanding empirical uncertainties in the feature input space for cases where ensemble prediction variances do not accurately capture the missing information required for the model to generalize.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17754v1" target="_blank"><h2>Periodicity-Enforced Neural Network for Designing Deterministic Lateral Displacement Devices</h2></a><strong><u>Authors:</u></strong> Andrew Lee, Mahir Mobarrat, Xiaolin Chen<br><strong><u>Categories:</u></strong> cs.LG, physics.flu-dyn<br><strong><u>Comments:</u></strong> Accepted to IEEE International Conference on Data Mining (ICDM) 2025 REU Symposium<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Deterministic Lateral Displacement (DLD) devices enable liquid biopsy for cancer detection by separating circulating tumor cells (CTCs) from blood samples based on size, but designing these microfluidic devices requires computationally expensive Navier-Stokes simulations and particle-tracing analyses. While recent surrogate modeling approaches using deep learning have accelerated this process, they often inadequately handle the critical periodic boundary conditions of DLD unit cells, leading to cumulative errors in multi-unit device predictions. This paper introduces a periodicity-enforced surrogate modeling approach that incorporates periodic layers, neural network components that guarantee exact periodicity without penalty terms or output modifications, into deep learning architectures for DLD device design. The proposed method employs three sub-networks to predict steady-state, non-dimensional velocity and pressure fields (u, v, p) rather than directly predicting critical diameters or particle trajectories, enabling complete flow field characterization and enhanced design flexibility. Periodic layers ensure exact matching of flow variables across unit cell boundaries through architectural enforcement rather than soft penalty-based approaches. Validation on 120 CFD-generated geometries demonstrates that the periodic layer implementation achieves 0.478% critical diameter error while maintaining perfect periodicity consistency, representing an 85.4% improvement over baseline methods. The approach enables efficient and accurate DLD device design with guaranteed boundary condition satisfaction for multi-unit device applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17753v1" target="_blank"><h2>$Δ$-ML Ensembles for Selecting Quantum Chemistry Methods to Compute Intermolecular Interactions</h2></a><strong><u>Authors:</u></strong> Austin M. Wallace, C. David Sherrill, Giri P. Krishnan<br><strong><u>Categories:</u></strong> physics.chem-ph, cs.AI<br><strong><u>Comments:</u></strong> NeurIPS ML4PS 2025<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Ab initio quantum chemical methods for accurately computing interactions between molecules have a wide range of applications but are often computationally expensive. Hence, selecting an appropriate method based on accuracy and computational cost remains a significant challenge due to varying performance of methods. In this work, we propose a framework based on an ensemble of $Δ$-ML models trained on features extracted from a pre-trained atom-pairwise neural network to predict the error of each method relative to all other methods including the ``gold standard'' coupled cluster with single, double, and perturbative triple excitations at the estimated complete basis set limit [CCSD(T)/CBS]. Our proposed approach provides error estimates across various levels of theories and identifies the computationally efficient approach for a given error range utilizing only a subset of the dataset. Further, this approach allows comparison between various theories. We demonstrate the effectiveness of our approach using an extended BioFragment dataset, which includes the interaction energies for common biomolecular fragments and small organic dimers. Our results show that the proposed framework achieves very small mean-absolute-errors below 0.1 kcal/mol regardless of the given method. Furthermore, by analyzing all-to-all $Δ$-ML models for present levels of theory, we identify method groupings that align with theoretical hypotheses, providing evidence that $Δ$-ML models can easily learn corrections from any level of theory to any other level of theory.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.17743v1" target="_blank"><h2>AI- and Ontology-Based Enhancements to FMEA for Advanced Systems Engineering: Current Developments and Future Directions</h2></a><strong><u>Authors:</u></strong> Haytham Younus, Sohag Kabir, Felician Campean, Pascal Bonnaud, David Delaux<br><strong><u>Categories:</u></strong> cs.AI, eess.SY<br><strong><u>Comments:</u></strong> This manuscript is based on research undertaken by our doctoral student at the University of Bradford. The associated PhD thesis has been formally submitted to the University and is currently awaiting final examination. The review article is being shared on arXiv to make the review accessible to the research community while the thesis examination process is ongoing<br><strong><u>Published:</u></strong> 2025-11-21<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), explainability (abstract)<br><p><strong><u>Abstract:</u></strong> This article presents a state-of-the-art review of recent advances aimed at transforming traditional Failure Mode and Effects Analysis (FMEA) into a more intelligent, data-driven, and semantically enriched process. As engineered systems grow in complexity, conventional FMEA methods, largely manual, document-centric, and expert-dependent, have become increasingly inadequate for addressing the demands of modern systems engineering. We examine how techniques from Artificial Intelligence (AI), including machine learning and natural language processing, can transform FMEA into a more dynamic, data-driven, intelligent, and model-integrated process by automating failure prediction, prioritisation, and knowledge extraction from operational data. In parallel, we explore the role of ontologies in formalising system knowledge, supporting semantic reasoning, improving traceability, and enabling cross-domain interoperability. The review also synthesises emerging hybrid approaches, such as ontology-informed learning and large language model integration, which further enhance explainability and automation. These developments are discussed within the broader context of Model-Based Systems Engineering (MBSE) and function modelling, showing how AI and ontologies can support more adaptive and resilient FMEA workflows. We critically analyse a range of tools, case studies, and integration strategies, while identifying key challenges related to data quality, explainability, standardisation, and interdisciplinary adoption. By leveraging AI, systems engineering, and knowledge representation using ontologies, this review offers a structured roadmap for embedding FMEA within intelligent, knowledge-rich engineering environments.</p><br><hr><br><hr><p><em>Summary: Showing 207 papers (199 new, 8 seen before)</em></p></body></html>