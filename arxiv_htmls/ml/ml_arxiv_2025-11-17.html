<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 10 Nov 2025 to 17 Nov 2025</em></font><a href="https://arxiv.org/pdf/2305.08977v2" target="_blank"><h2>Autoencoder-based Anomaly Detection in Streaming Data with Incremental Learning and Concept Drift Adaptation</h2></a><strong><u>Authors:</u></strong>  Jin Li, Kleanthis Malialis, Marios M. Polycarpou</br><strong><u>Categories:</u></strong> cs.LG, eess.SY</br><strong><u>Comments:</u></strong> anomaly detection, concept drift, incremental anomaly detection, concept drift, incremental learning, autoencoders, data streams, class imbalance, nonstationary environments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title)</br><p><strong><u>Abstract:</u></strong> In our digital universe nowadays, enormous amount of data are produced in a streaming manner in a variety of application areas. These data are often unlabelled. In this case, identifying infrequent events, such as anomalies, poses a great challenge. This problem becomes even more difficult in non-stationary environments, which can cause deterioration of the predictive performance of a model. To address the above challenges, the paper proposes an autoencoder-based incremental learning method with drift detection (strAEm++DD). Our proposed method strAEm++DD leverages on the advantages of both incremental learning and drift detection. We conduct an experimental study using real-world and synthetic datasets with severe or extreme class imbalance, and provide an empirical analysis of strAEm++DD. We further conduct a comparative study, showing that the proposed method significantly outperforms existing baseline and advanced methods.</p></br><a href="https://arxiv.org/pdf/2502.01654v1" target="_blank"><h2>Predicting concentration levels of air pollutants by transfer learning and recurrent neural network</h2></a><strong><u>Authors:</u></strong>  Iat Hang Fong, Tengyue Li, Simon Fong, Raymond K. Wong, Antonio J. Tallón-Ballesteros</br><strong><u>Categories:</u></strong> cs.LG, cs.NE, physics.ao-ph</br><strong><u>Comments:</u></strong> Forecasting, environment monitoring, transfer learning, recurrent neural network, airborne particle matter</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transfer learning (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Air pollution (AP) poses a great threat to human health, and people are paying more attention than ever to its prediction. Accurate prediction of AP helps people to plan for their outdoor activities and aids protecting human health. In this paper, long-short term memory (LSTM) recurrent neural networks (RNNs) have been used to predict the future concentration of air pollutants (APS) in Macau. Additionally, meteorological data and data on the concentration of APS have been utilized. Moreover, in Macau, some air quality monitoring stations (AQMSs) have less observed data in quantity, and, at the same time, some AQMSs recorded less observed data of certain types of APS. Therefore, the transfer learning and pre-trained neural networks have been employed to assist AQMSs with less observed data to build a neural network with high prediction accuracy. The experimental sample covers a period longer than 12-year and includes daily measurements from several APS as well as other more classical meteorological values. Records from five stations, four out of them are AQMSs and the remaining one is an automatic weather station, have been prepared from the aforesaid period and eventually underwent to computational intelligence techniques to build and extract a prediction knowledge-based system. As shown by experimentation, LSTM RNNs initialized with transfer learning methods have higher prediction accuracy; it incurred shorter training time than randomly initialized recurrent neural networks.</p></br><a href="https://arxiv.org/pdf/2212.00966v1" target="_blank"><h2>A Hybrid Deep Learning Anomaly Detection Framework for Intrusion Detection</h2></a><strong><u>Authors:</u></strong>  Rahul Kale, Zhi Lu, Kar Wai Fok, Vrizlynn L. L. Thing</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Keywords: Cybersecurity, Anomaly Detection, Intrusion Detection, Deep Learning, Unsupervised Learning, Neural Networks;this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Cyber intrusion attacks that compromise the users' critical and sensitive data are escalating in volume and intensity, especially with the growing connections between our daily life and the Internet. The large volume and high complexity of such intrusion attacks have impeded the effectiveness of most traditional defence techniques. While at the same time, the remarkable performance of the machine learning methods, especially deep learning, in computer vision, had garnered research interests from the cyber security community to further enhance and automate intrusion detections. However, the expensive data labeling and limitation of anomalous data make it challenging to train an intrusion detector in a fully supervised manner. Therefore, intrusion detection based on unsupervised anomaly detection is an important feature too. In this paper, we propose a three-stage deep learning anomaly detection based network intrusion attack detection framework. The framework comprises an integration of unsupervised (K-means clustering), semi-supervised (GANomaly) and supervised learning (CNN) algorithms. We then evaluated and showed the performance of our implemented framework on three benchmark datasets: NSL-KDD, CIC-IDS2018, and TON_IoT.</p></br><a href="https://arxiv.org/pdf/2305.02496v1" target="_blank"><h2>Revisiting Graph Contrastive Learning for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Zhiyuan Liu, Chunjie Cao, Fangjian Tao, Jingzhang Sun</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 7 pages, 4 figures, graph anomaly detection on attribute network</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Combining Graph neural networks (GNNs) with contrastive learning for anomaly detection has drawn rising attention recently. Existing graph contrastive anomaly detection (GCAD) methods have primarily focused on improving detection capability through graph augmentation and multi-scale contrast modules. However, the underlying mechanisms of how these modules work have not been fully explored. We dive into the multi-scale and graph augmentation mechanism and observed that multi-scale contrast modules do not enhance the expression, while the multi-GNN modules are the hidden contributors. Previous studies have tended to attribute the benefits brought by multi-GNN to the multi-scale modules. In the paper, we delve into the misconception and propose Multi-GNN and Augmented Graph contrastive framework MAG, which unified the existing GCAD methods in the contrastive self-supervised perspective. We extracted two variants from the MAG framework, L-MAG and M-MAG. The L-MAG is the lightweight instance of the MAG, which outperform the state-of-the-art on Cora and Pubmed with the low computational cost. The variant M-MAG equipped with multi-GNN modules further improve the detection performance. Our study sheds light on the drawback of the existing GCAD methods and demonstrates the potential of multi-GNN and graph augmentation modules. Our code is available at https://github.com/liuyishoua/MAG-Framework.</p></br><a href="https://arxiv.org/pdf/1908.00734v1" target="_blank"><h2>Detection of Accounting Anomalies in the Latent Space using Adversarial Autoencoder Neural Networks</h2></a><strong><u>Authors:</u></strong>  Marco Schreyer, Timur Sattarov, Christian Schulze, Bernd Reimer, Damian Borth</br><strong><u>Categories:</u></strong> cs.LG, q-fin.ST, stat.ML</br><strong><u>Comments:</u></strong> 11 pages, 9 figures, 2nd KDD Workshop on Anomaly Detection in Finance, August 05, 2019, Anchorage, Alaska</br><strong><u>Matching Keywords:</u></strong> latent space (title), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> The detection of fraud in accounting data is a long-standing challenge in financial statement audits. Nowadays, the majority of applied techniques refer to handcrafted rules derived from known fraud scenarios. While fairly successful, these rules exhibit the drawback that they often fail to generalize beyond known fraud scenarios and fraudsters gradually find ways to circumvent them. In contrast, more advanced approaches inspired by the recent success of deep learning often lack seamless interpretability of the detected results. To overcome this challenge, we propose the application of adversarial autoencoder networks. We demonstrate that such artificial neural networks are capable of learning a semantic meaningful representation of real-world journal entries. The learned representation provides a holistic view on a given set of journal entries and significantly improves the interpretability of detected accounting anomalies. We show that such a representation combined with the networks reconstruction error can be utilized as an unsupervised and highly adaptive anomaly assessment. Experiments on two datasets and initial feedback received by forensic accountants underpinned the effectiveness of the approach.</p></br><a href="https://arxiv.org/pdf/2212.05478v1" target="_blank"><h2>Mul-GAD: a semi-supervised graph anomaly detection framework via aggregating multi-view information</h2></a><strong><u>Authors:</u></strong>  Zhiyuan Liu, Chunjie Cao, Jingzhang Sun</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> Graph anomaly detection on attribute network</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is defined as discovering patterns that do not conform to the expected behavior. Previously, anomaly detection was mostly conducted using traditional shallow learning techniques, but with little improvement. As the emergence of graph neural networks (GNN), graph anomaly detection has been greatly developed. However, recent studies have shown that GNN-based methods encounter challenge, in that no graph anomaly detection algorithm can perform generalization on most datasets. To bridge the tap, we propose a multi-view fusion approach for graph anomaly detection (Mul-GAD). The view-level fusion captures the extent of significance between different views, while the feature-level fusion makes full use of complementary information. We theoretically and experimentally elaborate the effectiveness of the fusion strategies. For a more comprehensive conclusion, we further investigate the effect of the objective function and the number of fused views on detection performance. Exploiting these findings, our Mul-GAD is proposed equipped with fusion strategies and the well-performed objective function. Compared with other state-of-the-art detection methods, we achieve a better detection performance and generalization in most scenarios via a series of experiments conducted on Pubmed, Amazon Computer, Amazon Photo, Weibo and Books. Our code is available at https://github.com/liuyishoua/Mul-Graph-Fusion.</p></br><a href="https://arxiv.org/pdf/2205.15508v1" target="_blank"><h2>Rethinking Graph Neural Networks for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Jianheng Tang, Jiajin Li, Ziqi Gao, Jia Li</br><strong><u>Categories:</u></strong> cs.LG, eess.SP</br><strong><u>Comments:</u></strong> Accepted by ICML 2022. Our code and data are released atthis https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) are widely applied for graph anomaly detection. As one of the key components for GNN design is to select a tailored spectral filter, we take the first step towards analyzing anomalies via the lens of the graph spectrum. Our crucial observation is the existence of anomalies will lead to the `right-shift' phenomenon, that is, the spectral energy distribution concentrates less on low frequencies and more on high frequencies. This fact motivates us to propose the Beta Wavelet Graph Neural Network (BWGNN). Indeed, BWGNN has spectral and spatial localized band-pass filters to better handle the `right-shift' phenomenon in anomalies. We demonstrate the effectiveness of BWGNN on four large-scale anomaly detection datasets. Our code and data are released at https://github.com/squareRoot3/Rethinking-Anomaly-Detection</p></br><a href="https://arxiv.org/pdf/2103.00113v2" target="_blank"><h2>Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning</h2></a><strong><u>Authors:</u></strong>  Yixin Liu, Zhao Li, Shirui Pan, Chen Gong, Chuan Zhou, George Karypis</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 15 pages, 5 figures, 6 tables. Published in IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection on attributed networks attracts considerable research interests due to wide applications of attributed networks in modeling a wide range of complex systems. Recently, the deep learning-based anomaly detection methods have shown promising results over shallow approaches, especially on networks with high-dimensional attributes and complex structures. However, existing approaches, which employ graph autoencoder as their backbone, do not fully exploit the rich information of the network, resulting in suboptimal performance. Furthermore, these methods do not directly target anomaly detection in their learning objective and fail to scale to large networks due to the full graph training mechanism. To overcome these limitations, in this paper, we present a novel contrastive self-supervised learning framework for anomaly detection on attributed networks. Our framework fully exploits the local information from network data by sampling a novel type of contrastive instance pair, which can capture the relationship between each node and its neighboring substructure in an unsupervised way. Meanwhile, a well-designed graph neural network-based contrastive learning model is proposed to learn informative embedding from high-dimensional attributes and local structure and measure the agreement of each instance pairs with its outputted scores. The multi-round predicted scores by the contrastive learning model are further used to evaluate the abnormality of each node with statistical estimation. In this way, the learning model is trained by a specific anomaly detection-aware target. Furthermore, since the input of the graph neural network module is batches of instance pairs instead of the full network, our framework can adapt to large networks flexibly. Experimental results show that our proposed framework outperforms the state-of-the-art baseline methods on all seven benchmark datasets.</p></br><a href="https://arxiv.org/pdf/2406.16308v1" target="_blank"><h2>Anomaly Detection of Tabular Data Using LLMs</h2></a><strong><u>Authors:</u></strong>  Aodong Li, Yunhan Zhao, Chen Qiu, Marius Kloft, Padhraic Smyth, Maja Rudolph, Stephan Mandt</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL</br><strong><u>Comments:</u></strong> accepted at the Anomaly Detection with Foundation Models workshop</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zero-shot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data, demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned with anomaly detection and frequently output factual errors, we apply simple yet effective data-generating processes to simulate synthetic batch-level anomaly detection datasets and propose an end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par performance with the state-of-the-art transductive learning-based anomaly detection methods and ii) the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.</p></br><a href="https://arxiv.org/pdf/2303.05000v1" target="_blank"><h2>Learning Representation for Anomaly Detection of Vehicle Trajectories</h2></a><strong><u>Authors:</u></strong>  Ruochen Jiao, Juyang Bai, Xiangguo Liu, Takami Sato, Xiaowei Yuan, Qi Alfred Chen, Qi Zhu</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 8 pages paper, in anomaly detection of vehicle trajectory</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Predicting the future trajectories of surrounding vehicles based on their history trajectories is a critical task in autonomous driving. However, when small crafted perturbations are introduced to those history trajectories, the resulting anomalous (or adversarial) trajectories can significantly mislead the future trajectory prediction module of the ego vehicle, which may result in unsafe planning and even fatal accidents. Therefore, it is of great importance to detect such anomalous trajectories of the surrounding vehicles for system safety, but few works have addressed this issue. In this work, we propose two novel methods for learning effective and efficient representations for online anomaly detection of vehicle trajectories. Different from general time-series anomaly detection, anomalous vehicle trajectory detection deals with much richer contexts on the road and fewer observable patterns on the anomalous trajectories themselves. To address these challenges, our methods exploit contrastive learning techniques and trajectory semantics to capture the patterns underlying the driving scenarios for effective anomaly detection under supervised and unsupervised settings, respectively. We conduct extensive experiments to demonstrate that our supervised method based on contrastive learning and unsupervised method based on reconstruction with semantic latent space can significantly improve the performance of anomalous trajectory detection in their corresponding settings over various baseline methods. We also demonstrate our methods' generalization ability to detect unseen patterns of anomalies.</p></br><a href="https://arxiv.org/pdf/2508.07773v1" target="_blank"><h2>PCA-Guided Autoencoding for Structured Dimensionality Reduction in Active Infrared Thermography</h2></a><strong><u>Authors:</u></strong>  Mohammed Salah, Numan Saeed, Davor Svetinovic, Stefano Sfarra, Mohammed Omar, Yusra Abdulrahman</br><strong><u>Categories:</u></strong> eess.IV, cs.AI, cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Infrared thermography, Non-Destructive Testing, Principal Component Analysis, PCA-Guided Autoencoder, PCA Distillation Loss, Dimensionality Reduction</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract), latent space (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Active Infrared thermography (AIRT) is a widely adopted non-destructive testing (NDT) technique for detecting subsurface anomalies in industrial components. Due to the high dimensionality of AIRT data, current approaches employ non-linear autoencoders (AEs) for dimensionality reduction. However, the latent space learned by AIRT AEs lacks structure, limiting their effectiveness in downstream defect characterization tasks. To address this limitation, this paper proposes a principal component analysis guided (PCA-guided) autoencoding framework for structured dimensionality reduction to capture intricate, non-linear features in thermographic signals while enforcing a structured latent space. A novel loss function, PCA distillation loss, is introduced to guide AIRT AEs to align the latent representation with structured PCA components while capturing the intricate, non-linear patterns in thermographic signals. To evaluate the utility of the learned, structured latent space, we propose a neural network-based evaluation metric that assesses its suitability for defect characterization. Experimental results show that the proposed PCA-guided AE outperforms state-of-the-art dimensionality reduction methods on PVC, CFRP, and PLA samples in terms of contrast, signal-to-noise ratio (SNR), and neural network-based metrics.</p></br><a href="https://arxiv.org/pdf/2203.10596v1" target="_blank"><h2>Towards Clinical Practice: Design and Implementation of Convolutional Neural Network-Based Assistive Diagnosis System for COVID-19 Case Detection from Chest X-Ray Images</h2></a><strong><u>Authors:</u></strong>  Daniel Kvak, Marian Bendik, Anna Chromcova</br><strong><u>Categories:</u></strong> eess.IV, cs.CV, cs.LG</br><strong><u>Comments:</u></strong> computer-aided detection, convolutional neural network, COVID-19, deep learning, image classification</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> One of the critical tools for early detection and subsequent evaluation of the incidence of lung diseases is chest radiography. This study presents a real-world implementation of a convolutional neural network (CNN) based Carebot Covid app to detect COVID-19 from chest X-ray (CXR) images. Our proposed model takes the form of a simple and intuitive application. Used CNN can be deployed as a STOW-RS prediction endpoint for direct implementation into DICOM viewers. The results of this study show that the deep learning model based on DenseNet and ResNet architecture can detect SARS-CoV-2 from CXR images with precision of 0.981, recall of 0.962 and AP of 0.993.</p></br><a href="https://arxiv.org/pdf/2506.16815v1" target="_blank"><h2>Robust Group Anomaly Detection for Quasi-Periodic Network Time Series</h2></a><strong><u>Authors:</u></strong>  Kai Yang, Shaoyu Dou, Pan Luo, Xin Wang, H. Vincent Poor</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Published in IEEE Transactions on Network Science and Engineering</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Many real-world multivariate time series are collected from a network of physical objects embedded with software, electronics, and sensors. The quasi-periodic signals generated by these objects often follow a similar repetitive and periodic pattern, but have variations in the period, and come in different lengths caused by timing (synchronization) errors. Given a multitude of such quasi-periodic time series, can we build machine learning models to identify those time series that behave differently from the majority of the observations? In addition, can the models help human experts to understand how the decision was made? We propose a sequence to Gaussian Mixture Model (seq2GMM) framework. The overarching goal of this framework is to identify unusual and interesting time series within a network time series database. We further develop a surrogate-based optimization algorithm that can efficiently train the seq2GMM model. Seq2GMM exhibits strong empirical performance on a plurality of public benchmark datasets, outperforming state-of-the-art anomaly detection techniques by a significant margin. We also theoretically analyze the convergence property of the proposed training algorithm and provide numerical results to substantiate our theoretical claims.</p></br><a href="https://arxiv.org/pdf/1911.06009v1" target="_blank"><h2>A Recurrent Probabilistic Neural Network with Dimensionality Reduction Based on Time-series Discriminant Component Analysis</h2></a><strong><u>Authors:</u></strong>  Hideaki Hayashi, Taro Shibanoki, Keisuke Shima, Yuichi Kurita, Toshio Tsuji</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Published in IEEE Transactions on Neural Networks and Learning Systems</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper proposes a probabilistic neural network developed on the basis of time-series discriminant component analysis (TSDCA) that can be used to classify high-dimensional time-series patterns. TSDCA involves the compression of high-dimensional time series into a lower-dimensional space using a set of orthogonal transformations and the calculation of posterior probabilities based on a continuous-density hidden Markov model with a Gaussian mixture model expressed in the reduced-dimensional space. The analysis can be incorporated into a neural network, which is named a time-series discriminant component network (TSDCN), so that parameters of dimensionality reduction and classification can be obtained simultaneously as network coefficients according to a backpropagation through time-based learning algorithm with the Lagrange multiplier method. The TSDCN is considered to enable high-accuracy classification of high-dimensional time-series patterns and to reduce the computation time taken for network training. The validity of the TSDCN is demonstrated for high-dimensional artificial data and EEG signals in the experiments conducted during the study.</p></br><a href="https://arxiv.org/pdf/1608.05493v1" target="_blank"><h2>Network Volume Anomaly Detection and Identification in Large-scale Networks based on Online Time-structured Traffic Tensor Tracking</h2></a><strong><u>Authors:</u></strong>  Hiroyuki Kasai, Wolfgang Kellerer, Martin Kleinsteuber</br><strong><u>Categories:</u></strong> cs.NI, stat.ML</br><strong><u>Comments:</u></strong> IEEE Transactions on Network and Service Management</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper addresses network anomography, that is, the problem of inferring network-level anomalies from indirect link measurements. This problem is cast as a low-rank subspace tracking problem for normal flows under incomplete observations, and an outlier detection problem for abnormal flows. Since traffic data is large-scale time-structured data accompanied with noise and outliers under partial observations, an efficient modeling method is essential. To this end, this paper proposes an online subspace tracking of a Hankelized time-structured traffic tensor for normal flows based on the Candecomp/PARAFAC decomposition exploiting the recursive least squares (RLS) algorithm. We estimate abnormal flows as outlier sparse flows via sparsity maximization in the underlying under-constrained linear-inverse problem. A major advantage is that our algorithm estimates normal flows by low-dimensional matrices with time-directional features as well as the spatial correlation of multiple links without using the past observed measurements and the past model parameters. Extensive numerical evaluations show that the proposed algorithm achieves faster convergence per iteration of model approximation, and better volume anomaly detection performance compared to state-of-the-art algorithms.</p></br><a href="https://arxiv.org/pdf/1903.06661v1" target="_blank"><h2>GEE: A Gradient-based Explainable Variational Autoencoder for Network Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Quoc Phong Nguyen, Kar Wai Lim, Dinil Mon Divakaran, Kian Hsiang Low, Mun Choon Chan</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> to appear in 2019 IEEE Conference on Communications and Network Security (CNS)</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), VAE (abstract), anomaly detection (title, abstract), explainable (title)</br><p><strong><u>Abstract:</u></strong> This paper looks into the problem of detecting network anomalies by analyzing NetFlow records. While many previous works have used statistical models and machine learning techniques in a supervised way, such solutions have the limitations that they require large amount of labeled data for training and are unlikely to detect zero-day attacks. Existing anomaly detection solutions also do not provide an easy way to explain or identify attacks in the anomalous traffic. To address these limitations, we develop and present GEE, a framework for detecting and explaining anomalies in network traffic. GEE comprises of two components: (i) Variational Autoencoder (VAE) - an unsupervised deep-learning technique for detecting anomalies, and (ii) a gradient-based fingerprinting technique for explaining anomalies. Evaluation of GEE on the recent UGR dataset demonstrates that our approach is effective in detecting different anomalies as well as identifying fingerprints that are good representations of these various attacks.</p></br><a href="https://arxiv.org/pdf/2105.10500v3" target="_blank"><h2>Feature Encoding with AutoEncoders for Weakly-supervised Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Yingjie Zhou, Xucheng Song, Yanru Zhang, Fanxing Liu, Ce Zhu, Lingqiao Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.NI</br><strong><u>Comments:</u></strong> 12pages,4 figures, published by IEEE Transactions on Neural Networks and Learning Systems,2021</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Weakly-supervised anomaly detection aims at learning an anomaly detector from a limited amount of labeled data and abundant unlabeled data. Recent works build deep neural networks for anomaly detection by discriminatively mapping the normal samples and abnormal samples to different regions in the feature space or fitting different distributions. However, due to the limited number of annotated anomaly samples, directly training networks with the discriminative loss may not be sufficient. To overcome this issue, this paper proposes a novel strategy to transform the input data into a more meaningful representation that could be used for anomaly detection. Specifically, we leverage an autoencoder to encode the input data and utilize three factors, hidden representation, reconstruction residual vector, and reconstruction error, as the new representation for the input data. This representation amounts to encode a test sample with its projection on the training data manifold, its direction to its projection and its distance to its projection. In addition to this encoding, we also propose a novel network architecture to seamlessly incorporate those three factors. From our extensive experiments, the benefits of the proposed strategy are clearly demonstrated by its superior performance over the competitive methods.</p></br><a href="https://arxiv.org/pdf/2408.16612v3" target="_blank"><h2>Data Quality Monitoring for the Hadron Calorimeters Using Transfer Learning for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Mulugeta Weldezgina Asres, Christian Walter Omlin, Long Wang, Pavel Parygin, David Yu, Jay Dittmann, The CMS-HCAL Collaboration</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 25 pages, 14 figures, 7 tables, and published version of "aXriv:2408.16612v1: Data Quality Monitoring through Transfer Learning on Anomaly Detection for the Hadron Calorimeters"</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (title, abstract), neural network (abstract), transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> The proliferation of sensors brings an immense volume of spatio-temporal (ST) data in many domains, including monitoring, diagnostics, and prognostics applications. Data curation is a time-consuming process for a large volume of data, making it challenging and expensive to deploy data analytics platforms in new environments. Transfer learning (TL) mechanisms promise to mitigate data sparsity and model complexity by utilizing pre-trained models for a new task. Despite the triumph of TL in fields like computer vision and natural language processing, efforts on complex ST models for anomaly detection (AD) applications are limited. In this study, we present the potential of TL within the context of high-dimensional ST AD with a hybrid autoencoder architecture, incorporating convolutional, graph, and recurrent neural networks. Motivated by the need for improved model accuracy and robustness, particularly in scenarios with limited training data on systems with thousands of sensors, this research investigates the transferability of models trained on different sections of the Hadron Calorimeter of the Compact Muon Solenoid experiment at CERN. The key contributions of the study include exploring TL's potential and limitations within the context of encoder and decoder networks, revealing insights into model initialization and training configurations that enhance performance while substantially reducing trainable parameters and mitigating data contamination effects. Code: https://github.com/muleina/CMS\_HCAL\_ML\_OnlineDQM .</p></br><a href="https://arxiv.org/pdf/2509.09030v1" target="_blank"><h2>Deep Context-Conditioned Anomaly Detection for Tabular Data</h2></a><strong><u>Authors:</u></strong>  Spencer King, Zhilu Zhang, Ruofan Yu, Baris Coskun, Wei Ding, Qian Cui</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Submitted to WSDM 2026. 11 pages, 4 figures, 5 tables, 1 algorithm, 8 datasets, contextual anomaly detection framework for tabular data</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is critical in domains such as cybersecurity and finance, especially when working with large-scale tabular data. Yet, unsupervised anomaly detection -- where no labeled anomalies are available -- remains a significant challenge. Although various deep learning methods have been proposed to model a dataset's joint distribution, real-world tabular data often contain heterogeneous contexts (e.g., different users), making globally rare events normal under certain contexts. Consequently, relying on a single global distribution can overlook these contextual nuances, degrading detection performance. In this paper, we present a context-conditional anomaly detection framework tailored for tabular datasets. Our approach automatically identifies context features and models the conditional data distribution using a simple deep autoencoder. Extensive experiments on multiple tabular benchmark datasets demonstrate that our method outperforms state-of-the-art approaches, underscoring the importance of context in accurately distinguishing anomalous from normal instances.</p></br><a href="https://arxiv.org/pdf/2409.18427v3" target="_blank"><h2>Neural Collaborative Filtering to Detect Anomalies in Human Semantic Trajectories</h2></a><strong><u>Authors:</u></strong>  Yueyang Liu, Lance Kennedy, Hossein Amiri, Andreas Züfle</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.IR, cs.SI</br><strong><u>Comments:</u></strong> Accepted for publication in the 1st ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection (GeoAnomalies'24)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), explainable (abstract)</br><p><strong><u>Abstract:</u></strong> Human trajectory anomaly detection has become increasingly important across a wide range of applications, including security surveillance and public health. However, existing trajectory anomaly detection methods are primarily focused on vehicle-level traffic, while human-level trajectory anomaly detection remains under-explored. Since human trajectory data is often very sparse, machine learning methods have become the preferred approach for identifying complex patterns. However, concerns regarding potential biases and the robustness of these models have intensified the demand for more transparent and explainable alternatives. In response to these challenges, our research focuses on developing a lightweight anomaly detection model specifically designed to detect anomalies in human trajectories. We propose a Neural Collaborative Filtering approach to model and predict normal mobility. Our method is designed to model users' daily patterns of life without requiring prior knowledge, thereby enhancing performance in scenarios where data is sparse or incomplete, such as in cold start situations. Our algorithm consists of two main modules. The first is the collaborative filtering module, which applies collaborative filtering to model normal mobility of individual humans to places of interest. The second is the neural module, responsible for interpreting the complex spatio-temporal relationships inherent in human trajectory data. To validate our approach, we conducted extensive experiments using simulated and real-world datasets comparing to numerous state-of-the-art trajectory anomaly detection approaches.</p></br><a href="https://arxiv.org/pdf/2202.07787v1" target="_blank"><h2>Trustworthy Anomaly Detection: A Survey</h2></a><strong><u>Authors:</u></strong>  Shuhan Yuan, Xintao Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Paper list, seethis https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection has a wide range of real-world applications, such as bank fraud detection and cyber intrusion detection. In the past decade, a variety of anomaly detection models have been developed, which lead to big progress towards accurately detecting various anomalies. Despite the successes, anomaly detection models still face many limitations. The most significant one is whether we can trust the detection results from the models. In recent years, the research community has spent a great effort to design trustworthy machine learning models, such as developing trustworthy classification models. However, the attention to anomaly detection tasks is far from sufficient. Considering that many anomaly detection tasks are life-changing tasks involving human beings, labeling someone as anomalies or fraudsters should be extremely cautious. Hence, ensuring the anomaly detection models conducted in a trustworthy fashion is an essential requirement to deploy the models to conduct automatic decisions in the real world. In this brief survey, we summarize the existing efforts and discuss open problems towards trustworthy anomaly detection from the perspectives of interpretability, fairness, robustness, and privacy-preservation.</p></br><a href="https://arxiv.org/pdf/2012.12111v4" target="_blank"><h2>MOCCA: Multi-Layer One-Class ClassificAtion for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Fabio Valerio Massoli, Fabrizio Falchi, Alperen Kantarci, Şeymanur Akti, Hazim Kemal Ekenel, Giuseppe Amato</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> The paper has been accepted for publication in the IEEE Transactions on Neural Networks and Learning Systems, Special Issue on Deep Learning for Anomaly Detection</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Anomalies are ubiquitous in all scientific fields and can express an unexpected event due to incomplete knowledge about the data distribution or an unknown process that suddenly comes into play and distorts observations. Due to such events' rarity, to train deep learning models on the Anomaly Detection (AD) task, scientists only rely on "normal" data, i.e., non-anomalous samples. Thus, letting the neural network infer the distribution beneath the input data. In such a context, we propose a novel framework, named Multi-layer One-Class ClassificAtion (MOCCA),to train and test deep learning models on the AD task. Specifically, we applied it to autoencoders. A key novelty in our work stems from the explicit optimization of intermediate representations for the AD task. Indeed, differently from commonly used approaches that consider a neural network as a single computational block, i.e., using the output of the last layer only, MOCCA explicitly leverages the multi-layer structure of deep architectures. Each layer's feature space is optimized for AD during training, while in the test phase, the deep representations extracted from the trained layers are combined to detect anomalies. With MOCCA, we split the training process into two steps. First, the autoencoder is trained on the reconstruction task only. Then, we only retain the encoder tasked with minimizing the L_2 distance between the output representation and a reference point, the anomaly-free training data centroid, at each considered layer. Subsequently, we combine the deep features extracted at the various trained layers of the encoder model to detect anomalies at inference time. To assess the performance of the models trained with MOCCA, we conduct extensive experiments on publicly available datasets. We show that our proposed method reaches comparable or superior performance to state-of-the-art approaches available in the literature.</p></br><a href="https://arxiv.org/pdf/1610.06761v1" target="_blank"><h2>Maximally Divergent Intervals for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Erik Rodner, Björn Barz, Yanira Guanche, Milan Flach, Miguel Mahecha, Paul Bodesheim, Markus Reichstein, Joachim Denzler</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> ICML Workshop on Anomaly Detection</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> We present new methods for batch anomaly detection in multivariate time series. Our methods are based on maximizing the Kullback-Leibler divergence between the data distribution within and outside an interval of the time series. An empirical analysis shows the benefits of our algorithms compared to methods that treat each time step independently from each other without optimizing with respect to all possible intervals.</p></br><a href="https://arxiv.org/pdf/2004.03722v1" target="_blank"><h2>Challenges in Vessel Behavior and Anomaly Detection: From Classical Machine Learning to Deep Learning</h2></a><strong><u>Authors:</u></strong>  Lucas May Petry, Amilcar Soares, Vania Bogorny, Bruno Brandoli, Stan Matwin</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> This is an extended version of the article Challenges in Vessel Behavior and Anomaly Detection: From Classical Machine Learning to Deep Learning, to be published by Springer in the proceedings of the 33rd Canadian Conference on Artificial Intelligence</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> The global expansion of maritime activities and the development of the Automatic Identification System (AIS) have driven the advances in maritime monitoring systems in the last decade. Monitoring vessel behavior is fundamental to safeguard maritime operations, protecting other vessels sailing the ocean and the marine fauna and flora. Given the enormous volume of vessel data continually being generated, real-time analysis of vessel behaviors is only possible because of decision support systems provided with event and anomaly detection methods. However, current works on vessel event detection are ad-hoc methods able to handle only a single or a few predefined types of vessel behavior. Most of the existing approaches do not learn from the data and require the definition of queries and rules for describing each behavior. In this paper, we discuss challenges and opportunities in classical machine learning and deep learning for vessel event and anomaly detection. We hope to motivate the research of novel methods and tools, since addressing these challenges is an essential step towards actual intelligent maritime monitoring systems.</p></br><a href="https://arxiv.org/pdf/2404.06832v1" target="_blank"><h2>SplatPose & Detect: Pose-Agnostic 3D Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Mathis Kruse, Marco Rudolph, Dominik Woiwode, Bodo Rosenhahn</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Visual Anomaly and Novelty Detection 2.0 Workshop at CVPR 2024</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Detecting anomalies in images has become a well-explored problem in both academia and industry. State-of-the-art algorithms are able to detect defects in increasingly difficult settings and data modalities. However, most current methods are not suited to address 3D objects captured from differing poses. While solutions using Neural Radiance Fields (NeRFs) have been proposed, they suffer from excessive computation requirements, which hinder real-world usability. For this reason, we propose the novel 3D Gaussian splatting-based framework SplatPose which, given multi-view images of a 3D object, accurately estimates the pose of unseen views in a differentiable manner, and detects anomalies in them. We achieve state-of-the-art results in both training and inference speed, and detection performance, even when using less training data than competing methods. We thoroughly evaluate our framework using the recently proposed Pose-agnostic Anomaly Detection benchmark and its multi-pose anomaly detection (MAD) data set.</p></br><a href="https://arxiv.org/pdf/2307.11085v1" target="_blank"><h2>Representation Learning in Anomaly Detection: Successes, Limits and a Grand Challenge</h2></a><strong><u>Authors:</u></strong>  Yedid Hoshen</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> Keynote talk at the Visual Anomaly and Novelty Detection Workshop, CVPR'23</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> In this perspective paper, we argue that the dominant paradigm in anomaly detection cannot scale indefinitely and will eventually hit fundamental limits. This is due to the a no free lunch principle for anomaly detection. These limitations can be overcome when there are strong tasks priors, as is the case for many industrial tasks. When such priors do not exists, the task is much harder for anomaly detection. We pose two such tasks as grand challenges for anomaly detection: i) scientific discovery by anomaly detection ii) a "mini-grand" challenge of detecting the most anomalous image in the ImageNet dataset. We believe new anomaly detection tools and ideas would need to be developed to overcome these challenges.</p></br><a href="https://arxiv.org/pdf/2507.20019v1" target="_blank"><h2>Anomaly Detection in Human Language via Meta-Learning: A Few-Shot Approach</h2></a><strong><u>Authors:</u></strong>  Saurav Singla, Aarav Singla, Advik Gupta, Parnika Gupta</br><strong><u>Categories:</u></strong> cs.CL, cs.AI</br><strong><u>Comments:</u></strong> 15 pages. PyTorch code for few-shot anomaly detection using meta-learning is available upon request or can be shared via GitHub</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> We propose a meta learning framework for detecting anomalies in human language across diverse domains with limited labeled data. Anomalies in language ranging from spam and fake news to hate speech pose a major challenge due to their sparsity and variability. We treat anomaly detection as a few shot binary classification problem and leverage meta-learning to train models that generalize across tasks. Using datasets from domains such as SMS spam, COVID-19 fake news, and hate speech, we evaluate model generalization on unseen tasks with minimal labeled anomalies. Our method combines episodic training with prototypical networks and domain resampling to adapt quickly to new anomaly detection tasks. Empirical results show that our method outperforms strong baselines in F1 and AUC scores. We also release the code and benchmarks to facilitate further research in few-shot text anomaly detection.</p></br><a href="https://arxiv.org/pdf/2212.06370v4" target="_blank"><h2>Dual Accuracy-Quality-Driven Neural Network for Prediction Interval Generation</h2></a><strong><u>Authors:</u></strong>  Giorgio Morales, John W. Sheppard</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted at the IEEE Transactions on Neural Networks and Learning Systems</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Accurate uncertainty quantification is necessary to enhance the reliability of deep learning models in real-world applications. In the case of regression tasks, prediction intervals (PIs) should be provided along with the deterministic predictions of deep learning models. Such PIs are useful or "high-quality" as long as they are sufficiently narrow and capture most of the probability density. In this paper, we present a method to learn prediction intervals for regression-based neural networks automatically in addition to the conventional target predictions. In particular, we train two companion neural networks: one that uses one output, the target estimate, and another that uses two outputs, the upper and lower bounds of the corresponding PI. Our main contribution is the design of a novel loss function for the PI-generation network that takes into account the output of the target-estimation network and has two optimization objectives: minimizing the mean prediction interval width and ensuring the PI integrity using constraints that maximize the prediction interval probability coverage implicitly. Furthermore, we introduce a self-adaptive coefficient that balances both objectives within the loss function, which alleviates the task of fine-tuning. Experiments using a synthetic dataset, eight benchmark datasets, and a real-world crop yield prediction dataset showed that our method was able to maintain a nominal probability coverage and produce significantly narrower PIs without detriment to its target estimation accuracy when compared to those PIs generated by three state-of-the-art neural-network-based methods. In other words, our method was shown to produce higher-quality PIs.</p></br><a href="https://arxiv.org/pdf/2210.01707v1" target="_blank"><h2>Multiple Instance Learning for Detecting Anomalies over Sequential Real-World Datasets</h2></a><strong><u>Authors:</u></strong>  Parastoo Kamranfar, David Lattanzi, Amarda Shehu, Daniel Barbará</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 9 pages,5 figures, Anomaly and Novelty Detection, Explanation and Accommodation (ANDEA 2022)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), sequential data (abstract)</br><p><strong><u>Abstract:</u></strong> Detecting anomalies over real-world datasets remains a challenging task. Data annotation is an intensive human labor problem, particularly in sequential datasets, where the start and end time of anomalies are not known. As a result, data collected from sequential real-world processes can be largely unlabeled or contain inaccurate labels. These characteristics challenge the application of anomaly detection techniques based on supervised learning. In contrast, Multiple Instance Learning (MIL) has been shown effective on problems with incomplete knowledge of labels in the training dataset, mainly due to the notion of bags. While largely under-leveraged for anomaly detection, MIL provides an appealing formulation for anomaly detection over real-world datasets, and it is the primary contribution of this paper. In this paper, we propose an MIL-based formulation and various algorithmic instantiations of this framework based on different design decisions for key components of the framework. We evaluate the resulting algorithms over four datasets that capture different physical processes along different modalities. The experimental evaluation draws out several observations. The MIL-based formulation performs no worse than single instance learning on easy to moderate datasets and outperforms single-instance learning on more challenging datasets. Altogether, the results show that the framework generalizes well over diverse datasets resulting from different real-world application domains.</p></br><a href="https://arxiv.org/pdf/2105.07346v1" target="_blank"><h2>Understanding the Effect of Bias in Deep Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Ziyu Ye, Yuxin Chen, Haitao Zheng</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted at IJCAI '21. Codes available onthis http URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection presents a unique challenge in machine learning, due to the scarcity of labeled anomaly data. Recent work attempts to mitigate such problems by augmenting training of deep anomaly detection models with additional labeled anomaly samples. However, the labeled data often does not align with the target distribution and introduces harmful bias to the trained model. In this paper, we aim to understand the effect of a biased anomaly set on anomaly detection. Concretely, we view anomaly detection as a supervised learning task where the objective is to optimize the recall at a given false positive rate. We formally study the relative scoring bias of an anomaly detector, defined as the difference in performance with respect to a baseline anomaly detector. We establish the first finite sample rates for estimating the relative scoring bias for deep anomaly detection, and empirically validate our theoretical results on both synthetic and real-world datasets. We also provide an extensive empirical study on how a biased training anomaly set affects the anomaly score function and therefore the detection performance on different anomaly classes. Our study demonstrates scenarios in which the biased anomaly set can be useful or problematic, and provides a solid benchmark for future research.</p></br><a href="https://arxiv.org/pdf/2510.12076v1" target="_blank"><h2>BeSTAD: Behavior-Aware Spatio-Temporal Anomaly Detection for Human Mobility Data</h2></a><strong><u>Authors:</u></strong>  Junyi Xie, Jina Kim, Yao-Yi Chiang, Lingyi Zhao, Khurram Shafique</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> accepted by The 2nd ACM SIGSPATIAL International Workshop on Geospatial Anomaly Detection</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Traditional anomaly detection in human mobility has primarily focused on trajectory-level analysis, identifying statistical outliers or spatiotemporal inconsistencies across aggregated movement traces. However, detecting individual-level anomalies, i.e., unusual deviations in a person's mobility behavior relative to their own historical patterns, within datasets encompassing large populations remains a significant challenge. In this paper, we present BeSTAD (Behavior-aware Spatio-Temporal Anomaly Detection for Human Mobility Data), an unsupervised framework that captures individualized behavioral signatures across large populations and uncovers fine-grained anomalies by jointly modeling spatial context and temporal dynamics. BeSTAD learns semantically enriched mobility representations that integrate location meaning and temporal patterns, enabling the detection of subtle deviations in individual movement behavior. BeSTAD further employs a behavior-cluster-aware modeling mechanism that builds personalized behavioral profiles from normal activity and identifies anomalies through cross-period behavioral comparison with consistent semantic alignment. Building on prior work in mobility behavior clustering, this approach enables not only the detection of behavioral shifts and deviations from established routines but also the identification of individuals exhibiting such changes within large-scale mobility datasets. By learning individual behaviors directly from unlabeled data, BeSTAD advances anomaly detection toward personalized and interpretable mobility analysis.</p></br><a href="https://arxiv.org/pdf/2410.21006v2" target="_blank"><h2>A Review of Graph-Powered Data Quality Applications for IoT Monitoring Sensor Networks</h2></a><strong><u>Authors:</u></strong>  Pau Ferrer-Cid, Jose M. Barcelo-Ordinas, Jorge Garcia-Vidal</br><strong><u>Categories:</u></strong> cs.LG, eess.SY</br><strong><u>Comments:</u></strong> Paper accepted to Journal of Network and Computer Applications</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The development of Internet of Things (IoT) technologies has led to the widespread adoption of monitoring networks for a wide variety of applications, such as smart cities, environmental monitoring, and precision agriculture. A major research focus in recent years has been the development of graph-based techniques to improve the quality of data from sensor networks, a key aspect for the use of sensed data in decision-making processes, digital twins, and other applications. Emphasis has been placed on the development of machine learning and signal processing techniques over graphs, taking advantage of the benefits provided by the use of structured data through a graph topology. Many technologies such as the graph signal processing (GSP) or the successful graph neural networks (GNNs) have been used for data quality enhancement tasks. In this survey, we focus on graph-based models for data quality control in monitoring sensor networks. Furthermore, we delve into the technical details that are commonly leveraged for providing powerful graph-based solutions for data quality tasks in sensor networks, including missing value imputation, outlier detection, or virtual sensing. To conclude, we have identified future trends and challenges such as graph-based models for digital twins or model transferability and generalization.</p></br><a href="https://arxiv.org/pdf/2001.05137v3" target="_blank"><h2>Driver Safety Development Real Time Driver Drowsiness Detection System Based on Convolutional Neural Network</h2></a><strong><u>Authors:</u></strong>  Maryam Hashemi, Alireza Mirrashid, Aliasghar Beheshti Shirazi</br><strong><u>Categories:</u></strong> eess.IV, cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Hashemi, M., Mirrashid, A. & Beheshti Shirazi, A. Driver Safety Development: Real-Time Driver Drowsiness Detection System Based on Convolutional Neural Network. SN COMPUT. SCI. 1, 289 (2020).this https URL</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract), transfer learning (abstract)</br><p><strong><u>Abstract:</u></strong> This paper focuses on the challenge of driver safety on the road and presents a novel system for driver drowsiness detection. In this system, to detect the falling sleep state of the driver as the sign of drowsiness, Convolutional Neural Networks (CNN) are used with regarding the two goals of real-time application, including high accuracy and fastness. Three networks introduced as a potential network for eye status classifcation in which one of them is a Fully Designed Neural Network (FD-NN) and others use Transfer Learning in VGG16 and VGG19 with extra designed layers (TL-VGG). Lack of an available and accurate eye dataset strongly feels in the area of eye closure detection. Therefore, a new comprehensive dataset proposed. The experimental results show the high accuracy and low computational complexity of the eye closure estimation and the ability of the proposed framework on drowsiness detection.</p></br><a href="https://arxiv.org/pdf/2003.10713v3" target="_blank"><h2>Unsupervised Anomaly Detection with Adversarial Mirrored AutoEncoders</h2></a><strong><u>Authors:</u></strong>  Gowthami Somepalli, Yexin Wu, Yogesh Balaji, Bhanukiran Vinzamuri, Soheil Feizi</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Updated the paper with more OOD detection baselines. Performed ablation analysis on various components of AMA</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Detecting out of distribution (OOD) samples is of paramount importance in all Machine Learning applications. Deep generative modeling has emerged as a dominant paradigm to model complex data distributions without labels. However, prior work has shown that generative models tend to assign higher likelihoods to OOD samples compared to the data distribution on which they were trained. First, we propose Adversarial Mirrored Autoencoder (AMA), a variant of Adversarial Autoencoder, which uses a mirrored Wasserstein loss in the discriminator to enforce better semantic-level reconstruction. We also propose a latent space regularization to learn a compact manifold for in-distribution samples. The use of AMA produces better feature representations that improve anomaly detection performance. Second, we put forward an alternative measure of anomaly score to replace the reconstruction-based metric which has been traditionally used in generative model-based anomaly detection methods. Our method outperforms the current state-of-the-art methods for anomaly detection on several OOD detection benchmarks.</p></br><a href="https://arxiv.org/pdf/1912.08785v2" target="_blank"><h2>Unsupervised Anomaly Detection in Stream Data with Online Evolving Spiking Neural Networks</h2></a><strong><u>Authors:</u></strong>  Piotr S. Maciąg, Marzena Kryszkiewicz, Robert Bembenik, Jesus L. Lobo, Javier Del Ser</br><strong><u>Categories:</u></strong> cs.NE, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> 52 pages</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Unsupervised anomaly discovery in stream data is a research topic with many practical applications. However, in many cases, it is not easy to collect enough training data with labeled anomalies for supervised learning of an anomaly detector in order to deploy it later for identification of real anomalies in streaming data. It is thus important to design anomalies detectors that can correctly detect anomalies without access to labeled training data. Our idea is to adapt the Online evolving Spiking Neural Network (OeSNN) classifier to the anomaly detection task. As a result, we offer an Online evolving Spiking Neural Network for Unsupervised Anomaly Detection algorithm (OeSNN-UAD), which, unlike OeSNN, works in an unsupervised way and does not separate output neurons into disjoint decision classes. OeSNN-UAD uses our proposed new two-step anomaly detection method. Also, we derive new theoretical properties of neuronal model and input layer encoding of OeSNN, which enable more effective and efficient detection of anomalies in our OeSNN-UAD approach. The proposed OeSNN-UAD detector was experimentally compared with state-of-the-art unsupervised and semi-supervised detectors of anomalies in stream data from the Numenta Anomaly Benchmark and Yahoo Anomaly Datasets repositories. Our approach outperforms the other solutions provided in the literature in the case of data streams from the Numenta Anomaly Benchmark repository. Also, in the case of real data files of the Yahoo Anomaly Benchmark repository, OeSNN-UAD outperforms other selected algorithms, whereas in the case of Yahoo Anomaly Benchmark synthetic data files, it provides competitive results to the results recently reported in the literature.</p></br><a href="https://arxiv.org/pdf/1802.09089v2" target="_blank"><h2>Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection</h2></a><strong><u>Authors:</u></strong>  Yisroel Mirsky, Tomer Doitshman, Yuval Elovici, Asaf Shabtai</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Appears in Network and Distributed Systems Security Symposium (NDSS) 2018</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Neural networks have become an increasingly popular solution for network intrusion detection systems (NIDS). Their capability of learning complex patterns and behaviors make them a suitable solution for differentiating between normal traffic and network attacks. However, a drawback of neural networks is the amount of resources needed to train them. Many network gateways and routers devices, which could potentially host an NIDS, simply do not have the memory or processing power to train and sometimes even execute such models. More importantly, the existing neural network solutions are trained in a supervised manner. Meaning that an expert must label the network traffic and update the model manually from time to time.
  In this paper, we present Kitsune: a plug and play NIDS which can learn to detect attacks on the local network, without supervision, and in an efficient online manner. Kitsune's core algorithm (KitNET) uses an ensemble of neural networks called autoencoders to collectively differentiate between normal and abnormal traffic patterns. KitNET is supported by a feature extraction framework which efficiently tracks the patterns of every network channel. Our evaluations show that Kitsune can detect various attacks with a performance comparable to offline anomaly detectors, even on a Raspberry PI. This demonstrates that Kitsune can be a practical and economic NIDS.</p></br><a href="https://arxiv.org/pdf/2107.02821v1" target="_blank"><h2>New Methods and Datasets for Group Anomaly Detection From Fundamental Physics</h2></a><strong><u>Authors:</u></strong>  Gregor Kasieczka, Benjamin Nachman, David Shih</br><strong><u>Categories:</u></strong> stat.ML, cs.LG, hep-ex, hep-ph</br><strong><u>Comments:</u></strong> Accepted for ANDEA (Anomaly and Novelty Detection, Explanation and Accommodation) Workshop at KDD 2021</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> The identification of anomalous overdensities in data - group or collective anomaly detection - is a rich problem with a large number of real world applications. However, it has received relatively little attention in the broader ML community, as compared to point anomalies or other types of single instance outliers. One reason for this is the lack of powerful benchmark datasets. In this paper, we first explain how, after the Nobel-prize winning discovery of the Higgs boson, unsupervised group anomaly detection has become a new frontier of fundamental physics (where the motivation is to find new particles and forces). Then we propose a realistic synthetic benchmark dataset (LHCO2020) for the development of group anomaly detection algorithms. Finally, we compare several existing statistically-sound techniques for unsupervised group anomaly detection, and demonstrate their performance on the LHCO2020 dataset.</p></br><a href="https://arxiv.org/pdf/1607.05974v1" target="_blank"><h2>Anomaly Detection and Localisation using Mixed Graphical Models</h2></a><strong><u>Authors:</u></strong>  Romain Laby, François Roueff, Alexandre Gramfort</br><strong><u>Categories:</u></strong> stat.ML</br><strong><u>Comments:</u></strong> in ICML 2016 Anomaly Detection Workshop, Jun 2016, New York, United States</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> We propose a method that performs anomaly detection and localisation within heterogeneous data using a pairwise undirected mixed graphical model. The data are a mixture of categorical and quantitative variables, and the model is learned over a dataset that is supposed not to contain any anomaly. We then use the model over temporal data, potentially a data stream, using a version of the two-sided CUSUM algorithm. The proposed decision statistic is based on a conditional likelihood ratio computed for each variable given the others. Our results show that this function allows to detect anomalies variable by variable, and thus to localise the variables involved in the anomalies more precisely than univariate methods based on simple marginals.</p></br><a href="https://arxiv.org/pdf/2505.21563v1" target="_blank"><h2>Fog Intelligence for Network Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Kai Yang, Hui Ma, Shaoyu Dou</br><strong><u>Categories:</u></strong> cs.NI, cs.AI</br><strong><u>Comments:</u></strong> published in IEEE Network</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title)</br><p><strong><u>Abstract:</u></strong> Anomalies are common in network system monitoring. When manifested as network threats to be mitigated, service outages to be prevented, and security risks to be ameliorated, detecting such anomalous network behaviors becomes of great importance. However, the growing scale and complexity of the mobile communication networks, as well as the ever-increasing amount and dimensionality of the network surveillance data, make it extremely difficult to monitor a mobile network and discover abnormal network behaviors. Recent advances in machine learning allow for obtaining near-optimal solutions to complicated decision-making problems with many sources of uncertainty that cannot be accurately characterized by traditional mathematical models. However, most machine learning algorithms are centralized, which renders them inapplicable to a large-scale distributed wireless networks with tens of millions of mobile devices. In this article, we present fog intelligence, a distributed machine learning architecture that enables intelligent wireless network management. It preserves the advantage of both edge processing and centralized cloud computing. In addition, the proposed architecture is scalable, privacy-preserving, and well suited for intelligent management of a distributed wireless network.</p></br><a href="https://arxiv.org/pdf/2003.06344v1" target="_blank"><h2>Automating Botnet Detection with Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Jiawei Zhou, Zhiying Xu, Alexander M. Rush, Minlan Yu</br><strong><u>Categories:</u></strong> cs.CR, cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Data and code availablethis https URL. Accepted as a workshop paper in MLSys 2020 Conference</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Botnets are now a major source for many network attacks, such as DDoS attacks and spam. However, most traditional detection methods heavily rely on heuristically designed multi-stage detection criteria. In this paper, we consider the neural network design challenges of using modern deep learning techniques to learn policies for botnet detection automatically. To generate training data, we synthesize botnet connections with different underlying communication patterns overlaid on large-scale real networks as datasets. To capture the important hierarchical structure of centralized botnets and the fast-mixing structure for decentralized botnets, we tailor graph neural networks (GNN) to detect the properties of these structures. Experimental results show that GNNs are better able to capture botnet structure than previous non-learning methods when trained with appropriate data, and that deeper GNNs are crucial for learning difficult botnet topologies. We believe our data and studies can be useful for both the network security and graph learning communities.</p></br><a href="https://arxiv.org/pdf/2002.09594v2" target="_blank"><h2>One-Class Graph Neural Networks for Anomaly Detection in Attributed Networks</h2></a><strong><u>Authors:</u></strong>  Xuhong Wang, Baihong Jin, Ying Du, Ping Cui, Yupu Yang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> 16 pages, 4 figures. Neural Comput & Applic (2021)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Nowadays, graph-structured data are increasingly used to model complex systems. Meanwhile, detecting anomalies from graph has become a vital research problem of pressing societal concerns. Anomaly detection is an unsupervised learning task of identifying rare data that differ from the majority. As one of the dominant anomaly detection algorithms, One Class Support Vector Machine has been widely used to detect outliers. However, those traditional anomaly detection methods lost their effectiveness in graph data. Since traditional anomaly detection methods are stable, robust and easy to use, it is vitally important to generalize them to graph data. In this work, we propose One Class Graph Neural Network (OCGNN), a one-class classification framework for graph anomaly detection. OCGNN is designed to combine the powerful representation ability of Graph Neural Networks along with the classical one-class objective. Compared with other baselines, OCGNN achieves significant improvements in extensive experiments.</p></br><a href="https://arxiv.org/pdf/1710.01467v3" target="_blank"><h2>Mechanisms of dimensionality reduction and decorrelation in deep neural networks</h2></a><strong><u>Authors:</u></strong>  Haiping Huang</br><strong><u>Categories:</u></strong> cs.LG, cond-mat.stat-mech, stat.ML</br><strong><u>Comments:</u></strong> 11 pages, 5 figures, a physics explanation of decorrelation and dimensionality reduction is added; to be published by Phys Rev E (2018)</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Deep neural networks are widely used in various domains. However, the nature of computations at each layer of the deep networks is far from being well understood. Increasing the interpretability of deep neural networks is thus important. Here, we construct a mean-field framework to understand how compact representations are developed across layers, not only in deterministic deep networks with random weights but also in generative deep networks where an unsupervised learning is carried out. Our theory shows that the deep computation implements a dimensionality reduction while maintaining a finite level of weak correlations between neurons for possible feature extraction. Mechanisms of dimensionality reduction and decorrelation are unified in the same framework. This work may pave the way for understanding how a sensory hierarchy works.</p></br><a href="https://arxiv.org/pdf/2510.02155v1" target="_blank"><h2>Unlocking Vision-Language Models for Video Anomaly Detection via Fine-Grained Prompting</h2></a><strong><u>Authors:</u></strong>  Shu Zou, Xinyu Tian, Lukas Wesemann, Fabian Waschkowski, Zhaoyuan Yang, Jing Zhang</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> 14 pages, video anomaly detection</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), explainable (abstract)</br><p><strong><u>Abstract:</u></strong> Prompting has emerged as a practical way to adapt frozen vision-language models (VLMs) for video anomaly detection (VAD). Yet, existing prompts are often overly abstract, overlooking the fine-grained human-object interactions or action semantics that define complex anomalies in surveillance videos. We propose ASK-Hint, a structured prompting framework that leverages action-centric knowledge to elicit more accurate and interpretable reasoning from frozen VLMs. Our approach organizes prompts into semantically coherent groups (e.g. violence, property crimes, public safety) and formulates fine-grained guiding questions that align model predictions with discriminative visual cues. Extensive experiments on UCF-Crime and XD-Violence show that ASK-Hint consistently improves AUC over prior baselines, achieving state-of-the-art performance compared to both fine-tuned and training-free methods. Beyond accuracy, our framework provides interpretable reasoning traces towards anomaly and demonstrates strong generalization across datasets and VLM backbones. These results highlight the critical role of prompt granularity and establish ASK-Hint as a new training-free and generalizable solution for explainable video anomaly detection.</p></br><a href="https://arxiv.org/pdf/1902.02401v1" target="_blank"><h2>Adversarial Domain Adaptation for Stance Detection</h2></a><strong><u>Authors:</u></strong>  Brian Xu, Mitra Mohtarami, James Glass</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted at NIPS-CL-2018, Stance Detection, Fact Checking, Adversarial Domain Adaptation</br><strong><u>Matching Keywords:</u></strong> domain adaptation (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper studies the problem of stance detection which aims to predict the perspective (or stance) of a given document with respect to a given claim. Stance detection is a major component of automated fact checking. As annotating stances in different domains is a tedious and costly task, automatic methods based on machine learning are viable alternatives. In this paper, we focus on adversarial domain adaptation for stance detection where we assume there exists sufficient labeled data in the source domain and limited labeled data in the target domain. Extensive experiments on publicly available datasets show the effectiveness of our domain adaption model in transferring knowledge for accurate stance detection across domains.</p></br><a href="https://arxiv.org/pdf/1803.02421v2" target="_blank"><h2>Masked Conditional Neural Networks for Audio Classification</h2></a><strong><u>Authors:</u></strong>  Fady Medhat, David Chesmore, John Robinson</br><strong><u>Categories:</u></strong> stat.ML, cs.LG, cs.SD, eess.AS</br><strong><u>Comments:</u></strong> Restricted BoltzmannMachine, RBM, Conditional Restricted Boltzmann Machine, CRBM, Music Information Retrieval, MIR, Conditional Neural Network, CLNN, Masked Conditional Neural Network, MCLNN, Deep Neural Network</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> We present the ConditionaL Neural Network (CLNN) and the Masked ConditionaL Neural Network (MCLNN) designed for temporal signal recognition. The CLNN takes into consideration the temporal nature of the sound signal and the MCLNN extends upon the CLNN through a binary mask to preserve the spatial locality of the features and allows an automated exploration of the features combination analogous to hand-crafting the most relevant features for the recognition task. MCLNN has achieved competitive recognition accuracies on the GTZAN and the ISMIR2004 music datasets that surpass several state-of-the-art neural network based architectures and hand-crafted methods applied on both datasets.</p></br><a href="https://arxiv.org/pdf/1909.10086v3" target="_blank"><h2>Learning Universal Graph Neural Network Embeddings With Aid Of Transfer Learning</h2></a><strong><u>Authors:</u></strong>  Saurabh Verma, Zhi-Li Zhang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Previous Paper Title: Deep Universal Graph Embedding Neural Network</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> Learning powerful data embeddings has become a center piece in machine learning, especially in natural language processing and computer vision domains. The crux of these embeddings is that they are pretrained on huge corpus of data in a unsupervised fashion, sometimes aided with transfer learning. However currently in the graph learning domain, embeddings learned through existing graph neural networks (GNNs) are task dependent and thus cannot be shared across different datasets. In this paper, we present a first powerful and theoretically guaranteed graph neural network that is designed to learn task-independent graph embeddings, thereafter referred to as deep universal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph neural network (as a universal graph encoder) and leverages rich Graph Kernels (as a multi-task graph decoder) for both unsupervised learning and (task-specific) adaptive supervised learning. By learning task-independent graph embeddings across diverse datasets, DUGNN also reaps the benefits of transfer learning. Through extensive experiments and ablation studies, we show that the proposed DUGNN model consistently outperforms both the existing state-of-art GNN models and Graph Kernels by an increased accuracy of 3% - 8% on graph classification benchmark datasets.</p></br><a href="https://arxiv.org/pdf/1602.07109v5" target="_blank"><h2>Variational Inference for On-line Anomaly Detection in High-Dimensional Time Series</h2></a><strong><u>Authors:</u></strong>  Maximilian Soelch, Justin Bayer, Marvin Ludersdorfer, Patrick van der Smagt</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> Accepted as workshop paper at ICLR 2016; accepted as workshop paper for anomaly detection workshop at ICML 2016</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title)</br><p><strong><u>Abstract:</u></strong> Approximate variational inference has shown to be a powerful tool for modeling unknown complex probability distributions. Recent advances in the field allow us to learn probabilistic models of sequences that actively exploit spatial and temporal structure. We apply a Stochastic Recurrent Network (STORN) to learn robot time series data. Our evaluation demonstrates that we can robustly detect anomalies both off- and on-line.</p></br><a href="https://arxiv.org/pdf/2010.14957v1" target="_blank"><h2>Dimensionality Reduction and Anomaly Detection for CPPS Data using Autoencoder</h2></a><strong><u>Authors:</u></strong>  Benedikt Eiteneuer, Nemanja Hranisavljevic, Oliver Niggemann</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Copyright IEEE 2019</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), dimensionality reduction (title, abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Unsupervised anomaly detection (AD) is a major topic in the field of Cyber-Physical Production Systems (CPPSs). A closely related concern is dimensionality reduction (DR) which is: 1) often used as a preprocessing step in an AD solution, 2) a sort of AD, if a measure of observation conformity to the learned data manifold is provided.
  We argue that the two aspects can be complementary in a CPPS anomaly detection solution. In this work, we focus on the nonlinear autoencoder (AE) as a DR/AD approach. The contribution of this work is: 1) we examine the suitability of AE reconstruction error as an AD decision criterion in CPPS data. 2) we analyze its relation to a potential second-phase AD approach in the AE latent space 3) we evaluate the performance of the approach on three real-world datasets. Moreover, the approach outperforms state-of-the-art techniques, alongside a relatively simple and straightforward application.</p></br><a href="https://arxiv.org/pdf/2002.03665v2" target="_blank"><h2>AnomalyDAE: Dual autoencoder for anomaly detection on attributed networks</h2></a><strong><u>Authors:</u></strong>  Haoyi Fan, Fengbin Zhang, Zuoyong Li</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted by ICASSP2020. Copyright (c) 2020 IEEE. The source codes are publicly available:this https URL. Only personal use of these materials is permitted</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), latent space (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection on attributed networks aims at finding nodes whose patterns deviate significantly from the majority of reference nodes, which is pervasive in many applications such as network intrusion detection and social spammer detection. However, most existing methods neglect the complex cross-modality interactions between network structure and node attribute. In this paper, we propose a deep joint representation learning framework for anomaly detection through a dual autoencoder (AnomalyDAE), which captures the complex interactions between network structure and node attribute for high-quality embeddings. Specifically, AnomalyDAE consists of a structure autoencoder and an attribute autoencoder to learn both node embedding and attribute embedding jointly in latent space. Moreover, attention mechanism is employed in structure encoder to learn the importance between a node and its neighbors for an effective capturing of structure pattern, which is important to anomaly detection. Besides, by taking both the node embedding and attribute embedding as inputs of attribute decoder, the cross-modality interactions between network structure and node attribute are learned during the reconstruction of node attribute. Finally, anomalies can be detected by measuring the reconstruction errors of nodes from both the structure and attribute perspectives. Extensive experiments on real-world datasets demonstrate the effectiveness of the proposed method.</p></br><a href="https://arxiv.org/pdf/2504.03306v1" target="_blank"><h2>Multi-Flow: Multi-View-Enriched Normalizing Flows for Industrial Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Mathis Kruse, Bodo Rosenhahn</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Visual Anomaly and Novelty Detection 3.0 Workshop at CVPR 2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> With more well-performing anomaly detection methods proposed, many of the single-view tasks have been solved to a relatively good degree. However, real-world production scenarios often involve complex industrial products, whose properties may not be fully captured by one single image. While normalizing flow based approaches already work well in single-camera scenarios, they currently do not make use of the priors in multi-view data. We aim to bridge this gap by using these flow-based models as a strong foundation and propose Multi-Flow, a novel multi-view anomaly detection method. Multi-Flow makes use of a novel multi-view architecture, whose exact likelihood estimation is enhanced by fusing information across different views. For this, we propose a new cross-view message-passing scheme, letting information flow between neighboring views. We empirically validate it on the real-world multi-view data set Real-IAD and reach a new state-of-the-art, surpassing current baselines in both image-wise and sample-wise anomaly detection tasks.</p></br><a href="https://arxiv.org/pdf/2004.02396v1" target="_blank"><h2>A Learning Framework for n-bit Quantized Neural Networks toward FPGAs</h2></a><strong><u>Authors:</u></strong>  Jun Chen, Liang Liu, Yong Liu, Xianfang Zeng</br><strong><u>Categories:</u></strong> cs.LG, eess.SP, stat.ML</br><strong><u>Comments:</u></strong> This paper has been accepted for publication in the IEEE Transactions on Neural Networks and Learning Systems</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> The quantized neural network (QNN) is an efficient approach for network compression and can be widely used in the implementation of FPGAs. This paper proposes a novel learning framework for n-bit QNNs, whose weights are constrained to the power of two. To solve the gradient vanishing problem, we propose a reconstructed gradient function for QNNs in back-propagation algorithm that can directly get the real gradient rather than estimating an approximate gradient of the expected loss. We also propose a novel QNN structure named n-BQ-NN, which uses shift operation to replace the multiply operation and is more suitable for the inference on FPGAs. Furthermore, we also design a shift vector processing element (SVPE) array to replace all 16-bit multiplications with SHIFT operations in convolution operation on FPGAs. We also carry out comparable experiments to evaluate our framework. The experimental results show that the quantized models of ResNet, DenseNet and AlexNet through our learning framework can achieve almost the same accuracies with the original full-precision models. Moreover, when using our learning framework to train our n-BQ-NN from scratch, it can achieve state-of-the-art results compared with typical low-precision QNNs. Experiments on Xilinx ZCU102 platform show that our n-BQ-NN with our SVPE can execute 2.9 times faster than with the vector processing element (VPE) in inference. As the SHIFT operation in our SVPE array will not consume Digital Signal Processings (DSPs) resources on FPGAs, the experiments have shown that the use of SVPE array also reduces average energy consumption to 68.7% of the VPE array with 16-bit.</p></br><a href="https://arxiv.org/pdf/1905.06549v2" target="_blank"><h2>TapNet: Neural Network Augmented with Task-Adaptive Projection for Few-Shot Learning</h2></a><strong><u>Authors:</u></strong>  Sung Whan Yoon, Jun Seo, Jaekyun Moon</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> in proceedings of the 36th International Conference on Machine Learning (ICML), Long Beach, PMLR 97:7115-7123, 2019</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Handling previously unseen tasks after given only a few training examples continues to be a tough challenge in machine learning. We propose TapNets, neural networks augmented with task-adaptive projection for improved few-shot learning. Here, employing a meta-learning strategy with episode-based training, a network and a set of per-class reference vectors are learned across widely varying tasks. At the same time, for every episode, features in the embedding space are linearly projected into a new space as a form of quick task-specific conditioning. The training loss is obtained based on a distance metric between the query and the reference vectors in the projection space. Excellent generalization results in this way. When tested on the Omniglot, miniImageNet and tieredImageNet datasets, we obtain state of the art classification accuracies under various few-shot scenarios.</p></br><a href="https://arxiv.org/pdf/2505.17357v1" target="_blank"><h2>Graph Attention Neural Network for Botnet Detection: Evaluating Autoencoder, VAE and PCA-Based Dimension Reduction</h2></a><strong><u>Authors:</u></strong>  Hassan Wasswa, Hussein Abbass, Timothy Lynar</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), dimension reduction (title, abstract), neural network (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> With the rise of IoT-based botnet attacks, researchers have explored various learning models for detection, including traditional machine learning, deep learning, and hybrid approaches. A key advancement involves deploying attention mechanisms to capture long-term dependencies among features, significantly improving detection accuracy. However, most models treat attack instances independently, overlooking inter-instance relationships. Graph Neural Networks (GNNs) address this limitation by learning an embedding space via iterative message passing where similar instances are placed closer based on node features and relationships, enhancing classification performance. To further improve detection, attention mechanisms have been embedded within GNNs, leveraging both long-range dependencies and inter-instance connections. However, transforming the high dimensional IoT attack datasets into a graph structured dataset poses challenges, such as large graph structures leading computational overhead. To mitigate this, this paper proposes a framework that first reduces dimensionality of the NetFlow-based IoT attack dataset before transforming it into a graph dataset. We evaluate three dimension reduction techniques--Variational Autoencoder (VAE-encoder), classical autoencoder (AE-encoder), and Principal Component Analysis (PCA)--and compare their effects on a Graph Attention neural network (GAT) model for botnet attack detection</p></br><a href="https://arxiv.org/pdf/2412.19286v1" target="_blank"><h2>Time Series Foundational Models: Their Role in Anomaly Detection and Prediction</h2></a><strong><u>Authors:</u></strong>  Chathurangi Shyalika, Harleen Kaur Bagga, Ahan Bhatt, Renjith Prasad, Alaa Al Ghazo, Amit Sheth</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 12 pages, 6 figures, 5 tables. Accepted at AAAI2025 Anomaly Detection in Scientific Domains Workshop</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Time series foundational models (TSFM) have gained prominence in time series forecasting, promising state-of-the-art performance across various applications. However, their application in anomaly detection and prediction remains underexplored, with growing concerns regarding their black-box nature, lack of interpretability and applicability. This paper critically evaluates the efficacy of TSFM in anomaly detection and prediction tasks. We systematically analyze TSFM across multiple datasets, including those characterized by the absence of discernible patterns, trends and seasonality. Our analysis shows that while TSFMs can be extended for anomaly detection and prediction, traditional statistical and deep learning models often match or outperform TSFM in these tasks. Additionally, TSFMs require high computational resources but fail to capture sequential dependencies effectively or improve performance in few-shot or zero-shot scenarios. \noindent The preprocessed datasets, codes to reproduce the results and supplementary materials are available at https://github.com/smtmnfg/TSFM.</p></br><a href="https://arxiv.org/pdf/2503.19371v2" target="_blank"><h2>Flow to Learn: Flow Matching on Neural Network Parameters</h2></a><strong><u>Authors:</u></strong>  Daniel Saragih, Deyu Cao, Tejas Balaji, Ashwin Santhosh</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted at the ICLR Workshop on Neural Network Weights as a New Data Modality 2025</br><strong><u>Matching Keywords:</u></strong> latent space (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Foundational language models show a remarkable ability to learn new concepts during inference via context data. However, similar work for images lag behind. To address this challenge, we introduce FLoWN, a flow matching model that learns to generate neural network parameters for different tasks. Our approach models the flow on latent space, while conditioning the process on context data. Experiments verify that FLoWN attains various desiderata for a meta-learning model. In addition, it matches or exceeds baselines on in-distribution tasks, provides better initializations for classifier training, and is performant on out-of-distribution few-shot tasks while having a fine-tuning mechanism to improve performance.</p></br><a href="https://arxiv.org/pdf/2212.13904v1" target="_blank"><h2>A Novel Self-Supervised Learning-Based Anomaly Node Detection Method Based on an Autoencoder in Wireless Sensor Networks</h2></a><strong><u>Authors:</u></strong>  Miao Ye, Qinghao Zhang, Xingsi Xue, Yong Wang, Qiuxiang Jiang, Hongbing Qiu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Due to the issue that existing wireless sensor network (WSN)-based anomaly detection methods only consider and analyze temporal features, in this paper, a self-supervised learning-based anomaly node detection method based on an autoencoder is designed. This method integrates temporal WSN data flow feature extraction, spatial position feature extraction and intermodal WSN correlation feature extraction into the design of the autoencoder to make full use of the spatial and temporal information of the WSN for anomaly detection. First, a fully connected network is used to extract the temporal features of nodes by considering a single mode from a local spatial perspective. Second, a graph neural network (GNN) is used to introduce the WSN topology from a global spatial perspective for anomaly detection and extract the spatial and temporal features of the data flows of nodes and their neighbors by considering a single mode. Then, the adaptive fusion method involving weighted summation is used to extract the relevant features between different models. In addition, this paper introduces a gated recurrent unit (GRU) to solve the long-term dependence problem of the time dimension. Eventually, the reconstructed output of the decoder and the hidden layer representation of the autoencoder are fed into a fully connected network to calculate the anomaly probability of the current system. Since the spatial feature extraction operation is advanced, the designed method can be applied to the task of large-scale network anomaly detection by adding a clustering operation. Experiments show that the designed method outperforms the baselines, and the F1 score reaches 90.6%, which is 5.2% higher than those of the existing anomaly detection methods based on unsupervised reconstruction and prediction. Code and model are available at https://github.com/GuetYe/anomaly_detection/GLSL</p></br><a href="https://arxiv.org/pdf/2406.15038v1" target="_blank"><h2>Online detection and infographic explanation of spam reviews with data drift adaptation</h2></a><strong><u>Authors:</u></strong>  Francisco de Arriba-Pérez, Silvia García-Méndez, Fátima Leal, Benedita Malheiro, J. C. Burguillo</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL, cs.SI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (abstract)</br><p><strong><u>Abstract:</u></strong> Spam reviews are a pervasive problem on online platforms due to its significant impact on reputation. However, research into spam detection in data streams is scarce. Another concern lies in their need for transparency. Consequently, this paper addresses those problems by proposing an online solution for identifying and explaining spam reviews, incorporating data drift adaptation. It integrates (i) incremental profiling, (ii) data drift detection & adaptation, and (iii) identification of spam reviews employing Machine Learning. The explainable mechanism displays a visual and textual prediction explanation in a dashboard. The best results obtained reached up to 87 % spam F-measure.</p></br><a href="https://arxiv.org/pdf/1607.00148v2" target="_blank"><h2>LSTM-based Encoder-Decoder for Multi-sensor Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet Agarwal, Gautam Shroff</br><strong><u>Categories:</u></strong> cs.AI, cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted at ICML 2016 Anomaly Detection Workshop, New York, NY, USA, 2016. Reference update in this version (v2)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Mechanical devices such as engines, vehicles, aircrafts, etc., are typically instrumented with numerous sensors to capture the behavior and health of the machine. However, there are often external factors or variables which are not captured by sensors leading to time-series which are inherently unpredictable. For instance, manual controls and/or unmonitored environmental conditions or load may lead to inherently unpredictable time-series. Detecting anomalies in such scenarios becomes challenging using standard approaches based on mathematical models that rely on stationarity, or prediction models that utilize prediction errors to detect anomalies. We propose a Long Short Term Memory Networks based Encoder-Decoder scheme for Anomaly Detection (EncDec-AD) that learns to reconstruct 'normal' time-series behavior, and thereafter uses reconstruction error to detect anomalies. We experiment with three publicly available quasi predictable time-series datasets: power demand, space shuttle, and ECG, and two real-world engine datasets with both predictive and unpredictable behavior. We show that EncDec-AD is robust and can detect anomalies from predictable, unpredictable, periodic, aperiodic, and quasi-periodic time-series. Further, we show that EncDec-AD is able to detect anomalies from short time-series (length as small as 30) as well as long time-series (length as large as 500).</p></br><a href="https://arxiv.org/pdf/1908.09156v1" target="_blank"><h2>A framework for anomaly detection using language modeling, and its applications to finance</h2></a><strong><u>Authors:</u></strong>  Armineh Nourbakhsh, Grace Bang</br><strong><u>Categories:</u></strong> cs.CL, cs.AI</br><strong><u>Comments:</u></strong> 5 pages, 2 figures, presented at the 2nd KDD Workshop on Anomaly Detection in Finance, 2019</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> In the finance sector, studies focused on anomaly detection are often associated with time-series and transactional data analytics. In this paper, we lay out the opportunities for applying anomaly and deviation detection methods to text corpora and challenges associated with them. We argue that language models that use distributional semantics can play a significant role in advancing these studies in novel directions, with new applications in risk identification, predictive modeling, and trend analysis.</p></br><a href="https://arxiv.org/pdf/1802.05792v2" target="_blank"><h2>Masked Conditional Neural Networks for Automatic Sound Events Recognition</h2></a><strong><u>Authors:</u></strong>  Fady Medhat, David Chesmore, John Robinson</br><strong><u>Categories:</u></strong> cs.LG, cs.SD, eess.AS, stat.ML</br><strong><u>Comments:</u></strong> Restricted Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Belief Net, DBN, Conditional Neural Network, CLNN, Masked Conditional Neural Network, MCLNN, Environmental Sound Recognition, ESR</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Deep neural network architectures designed for application domains other than sound, especially image recognition, may not optimally harness the time-frequency representation when adapted to the sound recognition problem. In this work, we explore the ConditionaL Neural Network (CLNN) and the Masked ConditionaL Neural Network (MCLNN) for multi-dimensional temporal signal recognition. The CLNN considers the inter-frame relationship, and the MCLNN enforces a systematic sparseness over the network's links to enable learning in frequency bands rather than bins allowing the network to be frequency shift invariant mimicking a filterbank. The mask also allows considering several combinations of features concurrently, which is usually handcrafted through exhaustive manual search. We applied the MCLNN to the environmental sound recognition problem using the ESC-10 and ESC-50 datasets. MCLNN achieved competitive performance, using 12% of the parameters and without augmentation, compared to state-of-the-art Convolutional Neural Networks.</p></br><a href="https://arxiv.org/pdf/2312.06342v1" target="_blank"><h2>Detecting Contextual Network Anomalies with Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Hamid Latif-Martínez, José Suárez-Varela, Albert Cabellos-Aparicio, Pere Barlet-Ros</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NI</br><strong><u>Comments:</u></strong> 7 pages, 3 figures, 2nd International Workshop on Graph Neural Networking (GNNet '23)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), contextual anomaly detection (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Detecting anomalies on network traffic is a complex task due to the massive amount of traffic flows in today's networks, as well as the highly-dynamic nature of traffic over time. In this paper, we propose the use of Graph Neural Networks (GNN) for network traffic anomaly detection. We formulate the problem as contextual anomaly detection on network traffic measurements, and propose a custom GNN-based solution that detects traffic anomalies on origin-destination flows. In our evaluation, we use real-world data from Abilene (6 months), and make a comparison with other widely used methods for the same task (PCA, EWMA, RNN). The results show that the anomalies detected by our solution are quite complementary to those captured by the baselines (with a max. of 36.33% overlapping anomalies for PCA). Moreover, we manually inspect the anomalies detected by our method, and find that a large portion of them can be visually validated by a network expert (64% with high confidence, 18% with mid confidence, 18% normal traffic). Lastly, we analyze the characteristics of the anomalies through two paradigmatic cases that are quite representative of the bulk of anomalies.</p></br><a href="https://arxiv.org/pdf/2406.07927v1" target="_blank"><h2>ExoSpikeNet: A Light Curve Analysis Based Spiking Neural Network for Exoplanet Detection</h2></a><strong><u>Authors:</u></strong>  Maneet Chatterjee, Anuvab Sen, Subhabrata Roy</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.EP</br><strong><u>Comments:</u></strong> 6 Pages, 10 Figures, 2 Tables, Accepted by the 13th IEEE International Conference on Communication Systems and Network Technologies(CSNT 2024), April 06-07,2024,India</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Exoplanets are celestial bodies orbiting stars beyond our Solar System. Although historically they posed detection challenges, Kepler's data has revolutionized our understanding. By analyzing flux values from the Kepler Mission, we investigate the intricate patterns in starlight that may indicate the presence of exoplanets. This study investigates a novel approach for exoplanet classification using Spiking Neural Networks (SNNs) applied to data obtained from the NASA Kepler mission. SNNs offer a unique advantage by mimicking the spiking behavior of neurons in the brain, allowing for more nuanced and biologically inspired processing of temporal data. Experimental results demonstrate the efficacy of the proposed SNN architecture, excelling in various performance metrics such as accuracy, F1 score, precision, and recall.</p></br><a href="https://arxiv.org/pdf/2210.08363v3" target="_blank"><h2>Data-Efficient Augmentation for Training Neural Networks</h2></a><strong><u>Authors:</u></strong>  Tian Yu Liu, Baharan Mirzasoleiman</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Code available at:this https URL</br><strong><u>Matching Keywords:</u></strong> neural network (title), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Data augmentation is essential to achieve state-of-the-art performance in many deep learning applications. However, the most effective augmentation techniques become computationally prohibitive for even medium-sized datasets. To address this, we propose a rigorous technique to select subsets of data points that when augmented, closely capture the training dynamics of full data augmentation. We first show that data augmentation, modeled as additive perturbations, improves learning and generalization by relatively enlarging and perturbing the smaller singular values of the network Jacobian, while preserving its prominent directions. This prevents overfitting and enhances learning the harder to learn information. Then, we propose a framework to iteratively extract small subsets of training data that when augmented, closely capture the alignment of the fully augmented Jacobian with labels/residuals. We prove that stochastic gradient descent applied to the augmented subsets found by our approach has similar training dynamics to that of fully augmented data. Our experiments demonstrate that our method achieves 6.3x speedup on CIFAR10 and 2.2x speedup on SVHN, and outperforms the baselines by up to 10% across various subset sizes. Similarly, on TinyImageNet and ImageNet, our method beats the baselines by up to 8%, while achieving up to 3.3x speedup across various subset sizes. Finally, training on and augmenting 50% subsets using our method on a version of CIFAR10 corrupted with label noise even outperforms using the full dataset. Our code is available at: https://github.com/tianyu139/data-efficient-augmentation</p></br><a href="https://arxiv.org/pdf/2504.08115v1" target="_blank"><h2>Benchmarking Suite for Synthetic Aperture Radar Imagery Anomaly Detection (SARIAD) Algorithms</h2></a><strong><u>Authors:</u></strong>  Lucian Chauvin, Somil Gupta, Angelina Ibarra, Joshua Peeples</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Accepted to SPIE at:this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is a key research challenge in computer vision and machine learning with applications in many fields from quality control to radar imaging. In radar imaging, specifically synthetic aperture radar (SAR), anomaly detection can be used for the classification, detection, and segmentation of objects of interest. However, there is no method for developing and benchmarking these methods on SAR imagery. To address this issue, we introduce SAR imagery anomaly detection (SARIAD). In conjunction with Anomalib, a deep-learning library for anomaly detection, SARIAD provides a comprehensive suite of algorithms and datasets for assessing and developing anomaly detection approaches on SAR imagery. SARIAD specifically integrates multiple SAR datasets along with tools to effectively apply various anomaly detection algorithms to SAR imagery. Several anomaly detection metrics and visualizations are available. Overall, SARIAD acts as a central package for benchmarking SAR models and datasets to allow for reproducible research in the field of anomaly detection in SAR imagery. This package is publicly available: https://github.com/Advanced-Vision-and-Learning-Lab/SARIAD.</p></br><a href="https://arxiv.org/pdf/1906.11052v1" target="_blank"><h2>Further advantages of data augmentation on convolutional neural networks</h2></a><strong><u>Authors:</u></strong>  Alex Hernández-García, Peter König</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Preprint of the manuscript accepted for presentation at the International Conference on Artificial Neural Networks (ICANN) 2018. Best Paper Award</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract), data augmentation (title, abstract)</br><p><strong><u>Abstract:</u></strong> Data augmentation is a popular technique largely used to enhance the training of convolutional neural networks. Although many of its benefits are well known by deep learning researchers and practitioners, its implicit regularization effects, as compared to popular explicit regularization techniques, such as weight decay and dropout, remain largely unstudied. As a matter of fact, convolutional neural networks for image object classification are typically trained with both data augmentation and explicit regularization, assuming the benefits of all techniques are complementary. In this paper, we systematically analyze these techniques through ablation studies of different network architectures trained with different amounts of training data. Our results unveil a largely ignored advantage of data augmentation: networks trained with just data augmentation more easily adapt to different architectures and amount of training data, as opposed to weight decay and dropout, which require specific fine-tuning of their hyperparameters.</p></br><a href="https://arxiv.org/pdf/2311.18598v2" target="_blank"><h2>Generalisable Agents for Neural Network Optimisation</h2></a><strong><u>Authors:</u></strong>  Kale-ab Tessera, Callum Rhys Tilbury, Sasha Abramowitz, Ruan de Kock, Omayma Mahjoub, Benjamin Rosman, Sara Hooker, Arnu Pretorius</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.MA</br><strong><u>Comments:</u></strong> Accepted at the Workshop on Advanced Neural Network Training (WANT) and Optimization for Machine Learning (OPT) at NeurIPS 2023</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Optimising deep neural networks is a challenging task due to complex training dynamics, high computational requirements, and long training times. To address this difficulty, we propose the framework of Generalisable Agents for Neural Network Optimisation (GANNO) -- a multi-agent reinforcement learning (MARL) approach that learns to improve neural network optimisation by dynamically and responsively scheduling hyperparameters during training. GANNO utilises an agent per layer that observes localised network dynamics and accordingly takes actions to adjust these dynamics at a layerwise level to collectively improve global performance. In this paper, we use GANNO to control the layerwise learning rate and show that the framework can yield useful and responsive schedules that are competitive with handcrafted heuristics. Furthermore, GANNO is shown to perform robustly across a wide variety of unseen initial conditions, and can successfully generalise to harder problems than it was trained on. Our work presents an overview of the opportunities that this paradigm offers for training neural networks, along with key challenges that remain to be overcome.</p></br><a href="https://arxiv.org/pdf/2510.05235v1" target="_blank"><h2>Interpreting anomaly detection of SDSS spectra</h2></a><strong><u>Authors:</u></strong>  Edgar Ortiz Manrique, Médéric Boquien</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA</br><strong><u>Comments:</u></strong> 15 pages, 14 figures, accepted for publication in Astronomy & Astrophysics. The software is publicly available atthis https URL</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> The increasing use of ML in astronomy introduces important questions about interpretability. Due to their complexity and non-linear nature, it can be challenging to understand their decision-making process. While these models can effectively identify unusual spectra, interpreting the physical nature of the flagged outliers remains a major challenge. We aim to bridge the gap between anomaly detection and physical understanding by combining deep learning with interpretable ML (iML) techniques to identify and explain anomalous galaxy spectra from SDSS data. We present a flexible framework that uses a variational autoencoder to compute multiple anomaly scores, including physically-motivated variants of the mean squared error. We adapt the iML LIME algorithm to spectroscopic data, systematically explore segmentation and perturbation strategies, and compute explanation weights that identify the features most responsible for each detection. To uncover population-level trends, we normalize the LIME weights and apply clustering to the top 1\% most anomalous spectra. Our approach successfully separates instrumental artifacts from physically meaningful outliers and groups anomalous spectra into astrophysically coherent categories. These include dusty, metal-rich starbursts; chemically-enriched H\,II regions with moderate excitation; and extreme emission-line galaxies with low metallicity and hard ionizing spectra. The explanation weights align with established emission-line diagnostics, enabling a physically-grounded taxonomy of spectroscopic anomalies. Our work shows that interpretable anomaly detection provides a scalable, transparent, and physically meaningful approach to exploring large spectroscopic datasets. Our framework opens the door for incorporating interpretability tools into quality control, follow-up targeting, and discovery pipelines in current and future surveys.</p></br><a href="https://arxiv.org/pdf/1812.04872v1" target="_blank"><h2>Distributed Anomaly Detection using Autoencoder Neural Networks in WSN for IoT</h2></a><strong><u>Authors:</u></strong>  Tie Luo, Sai G. Nagarajan</br><strong><u>Categories:</u></strong> cs.NI, cs.LG</br><strong><u>Comments:</u></strong> 6 pages, 7 figures, IEEE ICC 2018</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Wireless sensor networks (WSN) are fundamental to the Internet of Things (IoT) by bridging the gap between the physical and the cyber worlds. Anomaly detection is a critical task in this context as it is responsible for identifying various events of interests such as equipment faults and undiscovered phenomena. However, this task is challenging because of the elusive nature of anomalies and the volatility of the ambient environments. In a resource-scarce setting like WSN, this challenge is further elevated and weakens the suitability of many existing solutions. In this paper, for the first time, we introduce autoencoder neural networks into WSN to solve the anomaly detection problem. We design a two-part algorithm that resides on sensors and the IoT cloud respectively, such that (i) anomalies can be detected at sensors in a fully distributed manner without the need for communicating with any other sensors or the cloud, and (ii) the relatively more computation-intensive learning task can be handled by the cloud with a much lower (and configurable) frequency. In addition to the minimal communication overhead, the computational load on sensors is also very low (of polynomial complexity) and readily affordable by most COTS sensors. Using a real WSN indoor testbed and sensor data collected over 4 consecutive months, we demonstrate via experiments that our proposed autoencoder-based anomaly detection mechanism achieves high detection accuracy and low false alarm rate. It is also able to adapt to unforeseeable and new changes in a non-stationary environment, thanks to the unsupervised learning feature of our chosen autoencoder neural networks.</p></br><a href="https://arxiv.org/pdf/2106.15379v2" target="_blank"><h2>Unified Framework for Spectral Dimensionality Reduction, Maximum Variance Unfolding, and Kernel Learning By Semidefinite Programming: Tutorial and Survey</h2></a><strong><u>Authors:</u></strong>  Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley</br><strong><u>Categories:</u></strong> stat.ML, cs.CV, cs.LG</br><strong><u>Comments:</u></strong> To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning. v2: corrected some typos</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract)</br><p><strong><u>Abstract:</u></strong> This is a tutorial and survey paper on unification of spectral dimensionality reduction methods, kernel learning by Semidefinite Programming (SDP), Maximum Variance Unfolding (MVU) or Semidefinite Embedding (SDE), and its variants. We first explain how the spectral dimensionality reduction methods can be unified as kernel Principal Component Analysis (PCA) with different kernels. This unification can be interpreted as eigenfunction learning or representation of kernel in terms of distance matrix. Then, since the spectral methods are unified as kernel PCA, we say let us learn the best kernel for unfolding the manifold of data to its maximum variance. We first briefly introduce kernel learning by SDP for the transduction task. Then, we explain MVU in detail. Various versions of supervised MVU using nearest neighbors graph, by class-wise unfolding, by Fisher criterion, and by colored MVU are explained. We also explain out-of-sample extension of MVU using eigenfunctions and kernel mapping. Finally, we introduce other variants of MVU including action respecting embedding, relaxed MVU, and landmark MVU for big data.</p></br><a href="https://arxiv.org/pdf/2006.04005v3" target="_blank"><h2>Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples</h2></a><strong><u>Authors:</u></strong>  David Macêdo, Tsang Ing Ren, Cleber Zanchettin, Adriano L. I. Oliveira, Teresa Ludermir</br><strong><u>Categories:</u></strong> cs.LG, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> Accepted for publication in the IEEE Transactions on Neural Networks and Learning Systems: Special Issue on Deep Learning for Anomaly Detection</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> In this paper, we argue that the unsatisfactory out-of-distribution (OOD) detection performance of neural networks is mainly due to the SoftMax loss anisotropy and propensity to produce low entropy probability distributions in disagreement with the principle of maximum entropy. Current out-of-distribution (OOD) detection approaches usually do not directly fix the SoftMax loss drawbacks, but rather build techniques to circumvent it. Unfortunately, those methods usually produce undesired side effects (e.g., classification accuracy drop, additional hyperparameters, slower inferences, and collecting extra data). In the opposite direction, we propose replacing SoftMax loss with a novel loss function that does not suffer from the mentioned weaknesses. The proposed IsoMax loss is isotropic (exclusively distance-based) and provides high entropy posterior probability distributions. Replacing the SoftMax loss by IsoMax loss requires no model or training changes. Additionally, the models trained with IsoMax loss produce as fast and energy-efficient inferences as those trained using SoftMax loss. Moreover, no classification accuracy drop is observed. The proposed method does not rely on outlier/background data, hyperparameter tuning, temperature calibration, feature extraction, metric learning, adversarial training, ensemble procedures, or generative models. Our experiments showed that IsoMax loss works as a seamless SoftMax loss drop-in replacement that significantly improves neural networks' OOD detection performance. Hence, it may be used as a baseline OOD detection approach to be combined with current or future OOD detection techniques to achieve even higher results.</p></br><a href="https://arxiv.org/pdf/1812.01662v1" target="_blank"><h2>Feed-Forward Neural Networks Need Inductive Bias to Learn Equality Relations</h2></a><strong><u>Authors:</u></strong>  Tillman Weyde, Radha Manisha Kopparti</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Relational Representation Learning Workshop, NeurIPS 2018</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Basic binary relations such as equality and inequality are fundamental to relational data structures. Neural networks should learn such relations and generalise to new unseen data. We show in this study, however, that this generalisation fails with standard feed-forward networks on binary vectors. Even when trained with maximal training data, standard networks do not reliably detect equality.We introduce differential rectifier (DR) units that we add to the network in different configurations. The DR units create an inductive bias in the networks, so that they do learn to generalise, even from small numbers of examples and we have not found any negative effect of their inclusion in the network. Given the fundamental nature of these relations, we hypothesize that feed-forward neural network learning benefits from inductive bias in other relations as well. Consequently, the further development of suitable inductive biases will be beneficial to many tasks in relational learning with neural networks.</p></br><a href="https://arxiv.org/pdf/1801.09390v2" target="_blank"><h2>Nonlinear Dimensionality Reduction on Graphs</h2></a><strong><u>Authors:</u></strong>  Yanning Shen, Panagiotis A. Traganitis, Georgios B. Giannakis</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Dimensionality reduction, nonlinear modeling, signal processing over graphs</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract)</br><p><strong><u>Abstract:</u></strong> In this era of data deluge, many signal processing and machine learning tasks are faced with high-dimensional datasets, including images, videos, as well as time series generated from social, commercial and brain network interactions. Their efficient processing calls for dimensionality reduction techniques capable of properly compressing the data while preserving task-related characteristics, going beyond pairwise data correlations. The present paper puts forth a nonlinear dimensionality reduction framework that accounts for data lying on known graphs. The novel framework encompasses most of the existing dimensionality reduction methods, but it is also capable of capturing and preserving possibly nonlinear correlations that are ignored by linear methods. Furthermore, it can take into account information from multiple graphs. The proposed algorithms were tested on synthetic as well as real datasets to corroborate their effectiveness.</p></br><a href="https://arxiv.org/pdf/2502.14197v1" target="_blank"><h2>Adaptive Sparsified Graph Learning Framework for Vessel Behavior Anomalies</h2></a><strong><u>Authors:</u></strong>  Jeehong Kim, Minchan Kim, Jaeseong Ju, Youngseok Hwang, Wonhee Lee, Hyunwoo Park</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Anomaly Detection in Scientific Domains AAAI Workshop</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Graph neural networks have emerged as a powerful tool for learning spatiotemporal interactions. However, conventional approaches often rely on predefined graphs, which may obscure the precise relationships being modeled. Additionally, existing methods typically define nodes based on fixed spatial locations, a strategy that is ill-suited for dynamic environments like maritime environments. Our method introduces an innovative graph representation where timestamps are modeled as distinct nodes, allowing temporal dependencies to be explicitly captured through graph edges. This setup is extended to construct a multi-ship graph that effectively captures spatial interactions while preserving graph sparsity. The graph is processed using Graph Convolutional Network layers to capture spatiotemporal patterns, with a forecasting layer for feature prediction and a Variational Graph Autoencoder for reconstruction, enabling robust anomaly detection.</p></br><a href="https://arxiv.org/pdf/1810.01403v4" target="_blank"><h2>GLAD: GLocalized Anomaly Detection via Human-in-the-Loop Learning</h2></a><strong><u>Authors:</u></strong>  Md Rakibul Islam, Shubhomoy Das, Janardhan Rao Doppa, Sriraam Natarajan</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Presented at the ICML-2020 Workshop on Human in the Loop Learning; 8 pages, 8 figures</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), explainable (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Human analysts that use anomaly detection systems in practice want to retain the use of simple and explainable global anomaly detectors. In this paper, we propose a novel human-in-the-loop learning algorithm called GLAD (GLocalized Anomaly Detection) that supports global anomaly detectors. GLAD automatically learns their local relevance to specific data instances using label feedback from human analysts. The key idea is to place a uniform prior on the relevance of each member of the anomaly detection ensemble over the input feature space via a neural network trained on unlabeled instances. Subsequently, weights of the neural network are tuned to adjust the local relevance of each ensemble member using all labeled instances. GLAD also provides explanations which can improve the understanding of end-users about anomalies. Our experiments on synthetic and real-world data show the effectiveness of GLAD in learning the local relevance of ensemble members and discovering anomalies via label feedback.</p></br><a href="https://arxiv.org/pdf/2504.02999v1" target="_blank"><h2>Anomaly Detection in Time Series Data Using Reinforcement Learning, Variational Autoencoder, and Active Learning</h2></a><strong><u>Authors:</u></strong>  Bahareh Golchin, Banafsheh Rekabdar</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), VAE (abstract), anomaly detection (title, abstract), sequential data (abstract)</br><p><strong><u>Abstract:</u></strong> A novel approach to detecting anomalies in time series data is presented in this paper. This approach is pivotal in domains such as data centers, sensor networks, and finance. Traditional methods often struggle with manual parameter tuning and cannot adapt to new anomaly types. Our method overcomes these limitations by integrating Deep Reinforcement Learning (DRL) with a Variational Autoencoder (VAE) and Active Learning. By incorporating a Long Short-Term Memory (LSTM) network, our approach models sequential data and its dependencies effectively, allowing for the detection of new anomaly classes with minimal labeled data. Our innovative DRL- VAE and Active Learning combination significantly improves existing methods, as shown by our evaluations on real-world datasets, enhancing anomaly detection techniques and advancing time series analysis.</p></br><a href="https://arxiv.org/pdf/1802.06360v2" target="_blank"><h2>Anomaly Detection using One-Class Neural Networks</h2></a><strong><u>Authors:</u></strong>  Raghavendra Chalapathy, Aditya Krishna Menon, Sanjay Chawla</br><strong><u>Categories:</u></strong> cs.LG, cs.NE, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> We propose a one-class neural network (OC-NN) model to detect anomalies in complex data sets. OC-NN combines the ability of deep networks to extract a progressively rich representation of data with the one-class objective of creating a tight envelope around normal data. The OC-NN approach breaks new ground for the following crucial reason: data representation in the hidden layer is driven by the OC-NN objective and is thus customized for anomaly detection. This is a departure from other approaches which use a hybrid approach of learning deep features using an autoencoder and then feeding the features into a separate anomaly detection method like one-class SVM (OC-SVM). The hybrid OC-SVM approach is sub-optimal because it is unable to influence representational learning in the hidden layers. A comprehensive set of experiments demonstrate that on complex data sets (like CIFAR and GTSRB), OC-NN performs on par with state-of-the-art methods and outperformed conventional shallow methods in some scenarios.</p></br><a href="https://arxiv.org/pdf/1905.12665v3" target="_blank"><h2>Graph Learning Network: A Structure Learning Algorithm</h2></a><strong><u>Authors:</u></strong>  Darwin Saire Pilco, Adín Ramírez Rivera</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted for publication at ICML 2019 Workshop on Learning and Reasoning with Graph-Structured Data. Code available atthis https URL</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Recently, graph neural networks (GNNs) have proved to be suitable in tasks on unstructured data. Particularly in tasks as community detection, node classification, and link prediction. However, most GNN models still operate with static relationships. We propose the Graph Learning Network (GLN), a simple yet effective process to learn node embeddings and structure prediction functions. Our model uses graph convolutions to propose expected node features, and predict the best structure based on them. We repeat these steps recursively to enhance the prediction and the embeddings.</p></br><a href="https://arxiv.org/pdf/1907.06129v1" target="_blank"><h2>Towards Robust Voice Pathology Detection</h2></a><strong><u>Authors:</u></strong>  Pavol Harar, Zoltan Galaz, Jesus B. Alonso-Hernandez, Jiri Mekyska, Radim Burget, Zdenek Smekal</br><strong><u>Categories:</u></strong> cs.SD, cs.LG, eess.AS</br><strong><u>Comments:</u></strong> 11 pages, 1 figure, 10 tables. Keywords: Voice pathology detection, deep learning, gradient boosting, anomaly detection</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> Automatic objective non-invasive detection of pathological voice based on computerized analysis of acoustic signals can play an important role in early diagnosis, progression tracking and even effective treatment of pathological voices. In search towards such a robust voice pathology detection system we investigated 3 distinct classifiers within supervised learning and anomaly detection paradigms. We conducted a set of experiments using a variety of input data such as raw waveforms, spectrograms, mel-frequency cepstral coefficients (MFCC) and conventional acoustic (dysphonic) features (AF). In comparison with previously published works, this article is the first to utilize combination of 4 different databases comprising normophonic and pathological recordings of sustained phonation of the vowel /a/ unrestricted to a subset of vocal pathologies. Furthermore, to our best knowledge, this article is the first to explore gradient boosted trees and deep learning for this application. The following best classification performances measured by F1 score on dedicated test set were achieved: XGBoost (0.733) using AF and MFCC, DenseNet (0.621) using MFCC, and Isolation Forest (0.610) using AF. Even though these results are of exploratory character, conducted experiments do show promising potential of gradient boosting and deep learning methods to robustly detect voice pathologies.</p></br><a href="https://arxiv.org/pdf/2309.15762v1" target="_blank"><h2>Rapid Network Adaptation: Learning to Adapt Neural Networks Using Test-Time Feedback</h2></a><strong><u>Authors:</u></strong>  Teresa Yeo, Oğuzhan Fatih Kar, Zahra Sodagar, Amir Zamir</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Project website atthis https URL</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> We propose a method for adapting neural networks to distribution shifts at test-time. In contrast to training-time robustness mechanisms that attempt to anticipate and counter the shift, we create a closed-loop system and make use of a test-time feedback signal to adapt a network on the fly. We show that this loop can be effectively implemented using a learning-based function, which realizes an amortized optimizer for the network. This leads to an adaptation method, named Rapid Network Adaptation (RNA), that is notably more flexible and orders of magnitude faster than the baselines. Through a broad set of experiments using various adaptation signals and target tasks, we study the efficiency and flexibility of this method. We perform the evaluations using various datasets (Taskonomy, Replica, ScanNet, Hypersim, COCO, ImageNet), tasks (depth, optical flow, semantic segmentation, classification), and distribution shifts (Cross-datasets, 2D and 3D Common Corruptions) with promising results. We end with a discussion on general formulations for handling distribution shifts and our observations from comparing with similar approaches from other domains.</p></br><a href="https://arxiv.org/pdf/2106.05410v4" target="_blank"><h2>DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Hadi Hojjati, Narges Armanfard</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Semi-supervised anomaly detection aims to detect anomalies from normal samples using a model that is trained on normal data. With recent advancements in deep learning, researchers have designed efficient deep anomaly detection methods. Existing works commonly use neural networks to map the data into a more informative representation and then apply an anomaly detection algorithm. In this paper, we propose a method, DASVDD, that jointly learns the parameters of an autoencoder while minimizing the volume of an enclosing hyper-sphere on its latent representation. We propose an anomaly score which is a combination of autoencoder's reconstruction error and the distance from the center of the enclosing hypersphere in the latent representation. Minimizing this anomaly score aids us in learning the underlying distribution of the normal class during training. Including the reconstruction error in the anomaly score ensures that DASVDD does not suffer from the common hypersphere collapse issue since the DASVDD model does not converge to the trivial solution of mapping all inputs to a constant point in the latent representation. Experimental evaluations on several benchmark datasets show that the proposed method outperforms the commonly used state-of-the-art anomaly detection algorithms while maintaining robust performance across different anomaly classes.</p></br><a href="https://arxiv.org/pdf/1905.13628v1" target="_blank"><h2>Time Series Anomaly Detection Using Convolutional Neural Networks and Transfer Learning</h2></a><strong><u>Authors:</u></strong>  Tailai Wen, Roy Keyes</br><strong><u>Categories:</u></strong> cs.LG, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> 8 pages, 8 figures, AI for Internet of Things Workshop in IJCAI 2019</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), anomaly detection (title, abstract), neural network (title, abstract), transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> Time series anomaly detection plays a critical role in automated monitoring systems. Most previous deep learning efforts related to time series anomaly detection were based on recurrent neural networks (RNN). In this paper, we propose a time series segmentation approach based on convolutional neural networks (CNN) for anomaly detection. Moreover, we propose a transfer learning framework that pretrains a model on a large-scale synthetic univariate time series data set and then fine-tunes its weights on small-scale, univariate or multivariate data sets with previously unseen classes of anomalies. For the multivariate case, we introduce a novel network architecture. The approach was tested on multiple synthetic and real data sets successfully.</p></br><a href="https://arxiv.org/pdf/2003.09671v3" target="_blank"><h2>On Information Plane Analyses of Neural Network Classifiers -- A Review</h2></a><strong><u>Authors:</u></strong>  Bernhard C. Geiger</br><strong><u>Categories:</u></strong> cs.LG, cs.CV, cs.IT, stat.ML</br><strong><u>Comments:</u></strong> 12 pages, 3 figures; accepted for publication in IEEE Transactions on Neural Networks and Learning Systems. (c) 2021 IEEE</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> We review the current literature concerned with information plane analyses of neural network classifiers. While the underlying information bottleneck theory and the claim that information-theoretic compression is causally linked to generalization are plausible, empirical evidence was found to be both supporting and conflicting. We review this evidence together with a detailed analysis of how the respective information quantities were estimated. Our survey suggests that compression visualized in information planes is not necessarily information-theoretic, but is rather often compatible with geometric compression of the latent representations. This insight gives the information plane a renewed justification.
  Aside from this, we shed light on the problem of estimating mutual information in deterministic neural networks and its consequences. Specifically, we argue that even in feed-forward neural networks the data processing inequality need not hold for estimates of mutual information. Similarly, while a fitting phase, in which the mutual information between the latent representation and the target increases, is necessary (but not sufficient) for good classification performance, depending on the specifics of mutual information estimation such a fitting phase need not be visible in the information plane.</p></br><a href="https://arxiv.org/pdf/2307.05639v2" target="_blank"><h2>Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks</h2></a><strong><u>Authors:</u></strong>  Danny D'Agostino, Ilija Ilievski, Christine Annette Shoemaker</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NE, stat.ML</br><strong><u>Comments:</u></strong> Accepted in Neural Networks, Elsevier</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract), neural network (title, abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Providing a model that achieves a strong predictive performance and is simultaneously interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the radial basis function neural network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the prediction task enhancing the model interpretability. We conducted numerical experiments for regression, classification, and feature selection tasks, comparing our model against popular machine learning models, the state-of-the-art deep learning-based embedding feature selection techniques, and a transformer model for tabular data. Our results demonstrate that the proposed model does not only yield an attractive prediction performance compared to the competitors but also provides meaningful and interpretable results that potentially could assist the decision-making process in real-world applications. A PyTorch implementation of the model is available on GitHub at the following link. https://github.com/dannyzx/Gaussian-RBFNN</p></br><a href="https://arxiv.org/pdf/2006.12456v1" target="_blank"><h2>Effective Version Space Reduction for Convolutional Neural Networks</h2></a><strong><u>Authors:</u></strong>  Jiayu Liu, Ioannis Chiotellis, Rudolph Triebel, Daniel Cremers</br><strong><u>Categories:</u></strong> cs.LG, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> 22 pages, 8 figures, to be published in the Proceedings of the European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD) 2020</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> In active learning, sampling bias could pose a serious inconsistency problem and hinder the algorithm from finding the optimal hypothesis. However, many methods for neural networks are hypothesis space agnostic and do not address this problem. We examine active learning with convolutional neural networks through the principled lens of version space reduction. We identify the connection between two approaches---prior mass reduction and diameter reduction---and propose a new diameter-based querying method---the minimum Gibbs-vote disagreement. By estimating version space diameter and bias, we illustrate how version space of neural networks evolves and examine the realizability assumption. With experiments on MNIST, Fashion-MNIST, SVHN and STL-10 datasets, we demonstrate that diameter reduction methods reduce the version space more effectively and perform better than prior mass reduction and other baselines, and that the Gibbs vote disagreement is on par with the best query method.</p></br><a href="https://arxiv.org/pdf/2205.01432v3" target="_blank"><h2>ARCADE: Adversarially Regularized Convolutional Autoencoder for Network Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Willian T. Lunardi, Martin Andreoni Lopez, Jean-Pierre Giacalone</br><strong><u>Categories:</u></strong> cs.LG, cs.CR, cs.NI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> As the number of heterogenous IP-connected devices and traffic volume increase, so does the potential for security breaches. The undetected exploitation of these breaches can bring severe cybersecurity and privacy risks. Anomaly-based \acp{IDS} play an essential role in network security. In this paper, we present a practical unsupervised anomaly-based deep learning detection system called ARCADE (Adversarially Regularized Convolutional Autoencoder for unsupervised network anomaly DEtection). With a convolutional \ac{AE}, ARCADE automatically builds a profile of the normal traffic using a subset of raw bytes of a few initial packets of network flows so that potential network anomalies and intrusions can be efficiently detected before they cause more damage to the network. ARCADE is trained exclusively on normal traffic. An adversarial training strategy is proposed to regularize and decrease the \ac{AE}'s capabilities to reconstruct network flows that are out-of-the-normal distribution, thereby improving its anomaly detection capabilities. The proposed approach is more effective than state-of-the-art deep learning approaches for network anomaly detection. Even when examining only two initial packets of a network flow, ARCADE can effectively detect malware infection and network attacks. ARCADE presents 20 times fewer parameters than baselines, achieving significantly faster detection speed and reaction time.</p></br><a href="https://arxiv.org/pdf/2508.19294v2" target="_blank"><h2>Object Detection with Multimodal Large Vision-Language Models: An In-depth Review</h2></a><strong><u>Authors:</u></strong>  Ranjan Sapkota, Manoj Karkee</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL</br><strong><u>Comments:</u></strong> First Peer Reviewed Review Paper for Object Detection with Vision-Language Models (VLMs)</br><strong><u>Matching Keywords:</u></strong> multimodal (title)</br><p><strong><u>Abstract:</u></strong> The fusion of language and vision in large vision-language models (LVLMs) has revolutionized deep learning-based object detection by enhancing adaptability, contextual reasoning, and generalization beyond traditional architectures. This in-depth review presents a structured exploration of the state-of-the-art in LVLMs, systematically organized through a three-step research review process. First, we discuss the functioning of vision language models (VLMs) for object detection, describing how these models harness natural language processing (NLP) and computer vision (CV) techniques to revolutionize object detection and localization. We then explain the architectural innovations, training paradigms, and output flexibility of recent LVLMs for object detection, highlighting how they achieve advanced contextual understanding for object detection. The review thoroughly examines the approaches used in integration of visual and textual information, demonstrating the progress made in object detection using VLMs that facilitate more sophisticated object detection and localization strategies. This review presents comprehensive visualizations demonstrating LVLMs' effectiveness in diverse scenarios including localization and segmentation, and then compares their real-time performance, adaptability, and complexity to traditional deep learning systems. Based on the review, its is expected that LVLMs will soon meet or surpass the performance of conventional methods in object detection. The review also identifies a few major limitations of the current LVLM modes, proposes solutions to address those challenges, and presents a clear roadmap for the future advancement in this field. We conclude, based on this study, that the recent advancement in LVLMs have made and will continue to make a transformative impact on object detection and robotic applications in the future.</p></br><a href="https://arxiv.org/pdf/2510.18998v1" target="_blank"><h2>An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data--Extended Version</h2></a><strong><u>Authors:</u></strong>  Buang Zhang, Tung Kieu, Xiangfei Qiu, Chenjuan Guo, Jilin Hu, Aoying Zhou, Christian S. Jensen, Bin Yang</br><strong><u>Categories:</u></strong> cs.LG, cs.DB</br><strong><u>Comments:</u></strong> 15 pages. An extended version of "An Encode-then-Decompose Approach to Unsupervised Time Series Anomaly Detection on Contaminated Training Data" accepted at ICDE 2026</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Time series anomaly detection is important in modern large-scale systems and is applied in a variety of domains to analyze and monitor the operation of diverse systems. Unsupervised approaches have received widespread interest, as they do not require anomaly labels during training, thus avoiding potentially high costs and having wider applications. Among these, autoencoders have received extensive attention. They use reconstruction errors from compressed representations to define anomaly scores. However, representations learned by autoencoders are sensitive to anomalies in training time series, causing reduced accuracy. We propose a novel encode-then-decompose paradigm, where we decompose the encoded representation into stable and auxiliary representations, thereby enhancing the robustness when training with contaminated time series. In addition, we propose a novel mutual information based metric to replace the reconstruction errors for identifying anomalies. Our proposal demonstrates competitive or state-of-the-art performance on eight commonly used multi- and univariate time series benchmarks and exhibits robustness to time series with different contamination ratios.</p></br><a href="https://arxiv.org/pdf/2105.14568v1" target="_blank"><h2>How effective are Graph Neural Networks in Fraud Detection for Network Data?</h2></a><strong><u>Authors:</u></strong>  Ronald D. R. Pereira, Fabrício Murai</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 12 pages, in Portuguese</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph-based Neural Networks (GNNs) are recent models created for learning representations of nodes (and graphs), which have achieved promising results when detecting patterns that occur in large-scale data relating different entities. Among these patterns, financial fraud stands out for its socioeconomic relevance and for presenting particular challenges, such as the extreme imbalance between the positive (fraud) and negative (legitimate transactions) classes, and the concept drift (i.e., statistical properties of the data change over time). Since GNNs are based on message propagation, the representation of a node is strongly impacted by its neighbors and by the network's hubs, amplifying the imbalance effects. Recent works attempt to adapt undersampling and oversampling strategies for GNNs in order to mitigate this effect without, however, accounting for concept drift. In this work, we conduct experiments to evaluate existing techniques for detecting network fraud, considering the two previous challenges. For this, we use real data sets, complemented by synthetic data created from a new methodology introduced here. Based on this analysis, we propose a series of improvement points that should be investigated in future research.</p></br><a href="https://arxiv.org/pdf/2205.06716v1" target="_blank"><h2>A Vision Inspired Neural Network for Unsupervised Anomaly Detection in Unordered Data</h2></a><strong><u>Authors:</u></strong>  Nassir Mohammad</br><strong><u>Categories:</u></strong> cs.LG, cs.CR, cs.NE</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> A fundamental problem in the field of unsupervised machine learning is the detection of anomalies corresponding to rare and unusual observations of interest; reasons include for their rejection, accommodation or further investigation. Anomalies are intuitively understood to be something unusual or inconsistent, whose occurrence sparks immediate attention. More formally anomalies are those observations-under appropriate random variable modelling-whose expectation of occurrence with respect to a grouping of prior interest is less than one; such a definition and understanding has been used to develop the parameter-free perception anomaly detection algorithm. The present work seeks to establish important and practical connections between the approach used by the perception algorithm and prior decades of research in neurophysiology and computational neuroscience; particularly that of information processing in the retina and visual cortex. The algorithm is conceptualised as a neuron model which forms the kernel of an unsupervised neural network that learns to signal unexpected observations as anomalies. Both the network and neuron display properties observed in biological processes including: immediate intelligence; parallel processing; redundancy; global degradation; contrast invariance; parameter-free computation, dynamic thresholds and non-linear processing. A robust and accurate model for anomaly detection in univariate and multivariate data is built using this network as a concrete application.</p></br><a href="https://arxiv.org/pdf/2104.10529v1" target="_blank"><h2>A Lightweight Concept Drift Detection and Adaptation Framework for IoT Data Streams</h2></a><strong><u>Authors:</u></strong>  Li Yang, Abdallah Shami</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted and to appear in IEEE Internet of Things Magazine; Code is available at Github link:this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> In recent years, with the increasing popularity of "Smart Technology", the number of Internet of Things (IoT) devices and systems have surged significantly. Various IoT services and functionalities are based on the analytics of IoT streaming data. However, IoT data analytics faces concept drift challenges due to the dynamic nature of IoT systems and the ever-changing patterns of IoT data streams. In this article, we propose an adaptive IoT streaming data analytics framework for anomaly detection use cases based on optimized LightGBM and concept drift adaptation. A novel drift adaptation method named Optimized Adaptive and Sliding Windowing (OASW) is proposed to adapt to the pattern changes of online IoT data streams. Experiments on two public datasets show the high accuracy and efficiency of our proposed adaptive LightGBM model compared against other state-of-the-art approaches. The proposed adaptive LightGBM model can perform continuous learning and drift adaptation on IoT data streams without human intervention.</p></br><a href="https://arxiv.org/pdf/1901.07538v1" target="_blank"><h2>Unsupervised Learning of Neural Networks to Explain Neural Networks (extended abstract)</h2></a><strong><u>Authors:</u></strong>  Quanshi Zhang, Yu Yang, Ying Nian Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> In AAAI-19 Workshop on Network Interpretability for Deep Learning. arXiv admin note: substantial text overlap witharXiv:1805.07468</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper presents an unsupervised method to learn a neural network, namely an explainer, to interpret a pre-trained convolutional neural network (CNN), i.e., the explainer uses interpretable visual concepts to explain features in middle conv-layers of a CNN. Given feature maps of a conv-layer of the CNN, the explainer performs like an auto-encoder, which decomposes the feature maps into object-part features. The object-part features are learned to reconstruct CNN features without much loss of information. We can consider the disentangled representations of object parts a paraphrase of CNN features, which help people understand the knowledge encoded by the CNN. More crucially, we learn the explainer via knowledge distillation without using any annotations of object parts or textures for supervision. In experiments, our method was widely used to interpret features of different benchmark CNNs, and explainers significantly boosted the feature interpretability without hurting the discrimination power of the CNNs.</p></br><a href="https://arxiv.org/pdf/2309.06449v1" target="_blank"><h2>Quantized Non-Volatile Nanomagnetic Synapse based Autoencoder for Efficient Unsupervised Network Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Muhammad Sabbir Alam, Walid Al Misba, Jayasimha Atulasimha</br><strong><u>Categories:</u></strong> cond-mat.mes-hall, cs.LG, cs.NE</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> In the autoencoder based anomaly detection paradigm, implementing the autoencoder in edge devices capable of learning in real-time is exceedingly challenging due to limited hardware, energy, and computational resources. We show that these limitations can be addressed by designing an autoencoder with low-resolution non-volatile memory-based synapses and employing an effective quantized neural network learning algorithm. We propose a ferromagnetic racetrack with engineered notches hosting a magnetic domain wall (DW) as the autoencoder synapses, where limited state (5-state) synaptic weights are manipulated by spin orbit torque (SOT) current pulses. The performance of anomaly detection of the proposed autoencoder model is evaluated on the NSL-KDD dataset. Limited resolution and DW device stochasticity aware training of the autoencoder is performed, which yields comparable anomaly detection performance to the autoencoder having floating-point precision weights. While the limited number of quantized states and the inherent stochastic nature of DW synaptic weights in nanoscale devices are known to negatively impact the performance, our hardware-aware training algorithm is shown to leverage these imperfect device characteristics to generate an improvement in anomaly detection accuracy (90.98%) compared to accuracy obtained with floating-point trained weights. Furthermore, our DW-based approach demonstrates a remarkable reduction of at least three orders of magnitude in weight updates during training compared to the floating-point approach, implying substantial energy savings for our method. This work could stimulate the development of extremely energy efficient non-volatile multi-state synapse-based processors that can perform real-time training and inference on the edge with unsupervised data.</p></br><a href="https://arxiv.org/pdf/2304.10550v2" target="_blank"><h2>Deep transfer learning for intrusion detection in industrial control networks: A comprehensive review</h2></a><strong><u>Authors:</u></strong>  Hamza Kheddar, Yassine Himeur, Ali Ismail Awad</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG, cs.NI, eess.SY</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> Globally, the external internet is increasingly being connected to industrial control systems. As a result, there is an immediate need to protect these networks from a variety of threats. The key infrastructure of industrial activity can be protected from harm using an intrusion detection system (IDS), a preventive mechanism that seeks to recognize new kinds of dangerous threats and hostile activities. This review examines the most recent artificial-intelligence techniques that are used to create IDSs in many kinds of industrial control networks, with a particular emphasis on IDS-based deep transfer learning (DTL). DTL can be seen as a type of information-fusion approach that merges and/or adapts knowledge from multiple domains to enhance the performance of a target task, particularly when labeled data in the target domain is scarce. Publications issued after 2015 were considered. These selected publications were divided into three categories: DTL-only and IDS-only works are examined in the introduction and background section, and DTL-based IDS papers are considered in the core section of this review. By reading this review paper, researchers will be able to gain a better grasp of the current state of DTL approaches used in IDSs in many different types of network. Other useful information, such as the datasets used, the type of DTL employed, the pre-trained network, IDS techniques, the evaluation metrics including accuracy/F-score and false-alarm rate, and the improvements gained, are also covered. The algorithms and methods used in several studies are presented, and the principles of DTL-based IDS subcategories are presented to the reader and illustrated deeply and clearly</p></br><a href="https://arxiv.org/pdf/1804.02665v2" target="_blank"><h2>Environmental Sound Recognition using Masked Conditional Neural Networks</h2></a><strong><u>Authors:</u></strong>  Fady Medhat, David Chesmore, John Robinson</br><strong><u>Categories:</u></strong> cs.LG, cs.SD, eess.AS, stat.ML</br><strong><u>Comments:</u></strong> Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Neural Network, DNN, Conditional Neural Network, CLNN, Masked Conditional Neural Net-work, MCLNN, Environmental Sound Recognition, ESR, Advanced Data Mining and Applications (ADMA) Year: 2017</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Neural network based architectures used for sound recognition are usually adapted from other application domains, which may not harness sound related properties. The ConditionaL Neural Network (CLNN) is designed to consider the relational properties across frames in a temporal signal, and its extension the Masked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within the network, which enforces the network to learn in frequency bands rather than bins. Additionally, it automates the exploration of different feature combinations analogous to handcrafting the optimum combination of features for a recognition task. We applied the MCLNN to the environmental sounds of the ESC-10 dataset. The MCLNN achieved competitive accuracies compared to state-of-the-art convolutional neural networks and hand-crafted attempts.</p></br><a href="https://arxiv.org/pdf/2207.03820v2" target="_blank"><h2>Deep Learning for Anomaly Detection in Log Data: A Survey</h2></a><strong><u>Authors:</u></strong>  Max Landauer, Sebastian Onder, Florian Skopik, Markus Wurzenberger</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), literature review (abstract)</br><p><strong><u>Abstract:</u></strong> Automatic log file analysis enables early detection of relevant incidents such as system failures. In particular, self-learning anomaly detection techniques capture patterns in log data and subsequently report unexpected log event occurrences to system operators without the need to provide or manually model anomalous scenarios in advance. Recently, an increasing number of approaches leveraging deep learning neural networks for this purpose have been presented. These approaches have demonstrated superior detection performance in comparison to conventional machine learning techniques and simultaneously resolve issues with unstable data formats. However, there exist many different architectures for deep learning and it is non-trivial to encode raw and unstructured log data to be analyzed by neural networks. We therefore carry out a systematic literature review that provides an overview of deployed models, data pre-processing mechanisms, anomaly detection techniques, and evaluations. The survey does not quantitatively compare existing approaches but instead aims to help readers understand relevant aspects of different model architectures and emphasizes open issues for future work.</p></br><a href="https://arxiv.org/pdf/2102.01331v1" target="_blank"><h2>Anomaly Detection of Time Series with Smoothness-Inducing Sequential Variational Auto-Encoder</h2></a><strong><u>Authors:</u></strong>  Longyuan Li, Junchi Yan, Haiyang Wang, Yaohui Jin</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted by IEEE Transactions on Neural Network and Learning System (TNNLS), 2020</br><strong><u>Matching Keywords:</u></strong> VAE (abstract), anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Deep generative models have demonstrated their effectiveness in learning latent representation and modeling complex dependencies of time series. In this paper, we present a Smoothness-Inducing Sequential Variational Auto-Encoder (SISVAE) model for robust estimation and anomaly detection of multi-dimensional time series. Our model is based on Variational Auto-Encoder (VAE), and its backbone is fulfilled by a Recurrent Neural Network to capture latent temporal structures of time series for both generative model and inference model. Specifically, our model parameterizes mean and variance for each time-stamp with flexible neural networks, resulting in a non-stationary model that can work without the assumption of constant noise as commonly made by existing Markov models. However, such a flexibility may cause the model fragile to anomalies. To achieve robust density estimation which can also benefit detection tasks, we propose a smoothness-inducing prior over possible estimations. The proposed prior works as a regularizer that places penalty at non-smooth reconstructions. Our model is learned efficiently with a novel stochastic gradient variational Bayes estimator. In particular, we study two decision criteria for anomaly detection: reconstruction probability and reconstruction error. We show the effectiveness of our model on both synthetic datasets and public real-world benchmarks.</p></br><a href="https://arxiv.org/pdf/2205.08953v1" target="_blank"><h2>Representation Learning for Content-Sensitive Anomaly Detection in Industrial Networks</h2></a><strong><u>Authors:</u></strong>  Fabian Kopp</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Master Thesis, 114 pages</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Using a convGRU-based autoencoder, this thesis proposes a framework to learn spatial-temporal aspects of raw network traffic in an unsupervised and protocol-agnostic manner. The learned representations are used to measure the effect on the results of a subsequent anomaly detection and are compared to the application without the extracted features. The evaluation showed, that the anomaly detection could not effectively be enhanced when applied on compressed traffic fragments for the context of network intrusion detection. Yet, the trained autoencoder successfully generates a compressed representation (code) of the network traffic, which hold spatial and temporal information. Based on the models residual loss, the autoencoder is also capable of detecting anomalies by itself. Lastly, an approach for a kind of model interpretability (LRP) was investigated in order to identify relevant areas within the raw input data, which is used to enrich alerts generated by an anomaly detection method.</p></br><a href="https://arxiv.org/pdf/2303.07452v1" target="_blank"><h2>Network Anomaly Detection Using Federated Learning</h2></a><strong><u>Authors:</u></strong>  William Marfo, Deepak K. Tosh, Shirley V. Moore</br><strong><u>Categories:</u></strong> cs.LG, cs.DC</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Due to the veracity and heterogeneity in network traffic, detecting anomalous events is challenging. The computational load on global servers is a significant challenge in terms of efficiency, accuracy, and scalability. Our primary motivation is to introduce a robust and scalable framework that enables efficient network anomaly detection. We address the issue of scalability and efficiency for network anomaly detection by leveraging federated learning, in which multiple participants train a global model jointly. Unlike centralized training architectures, federated learning does not require participants to upload their training data to the server, preventing attackers from exploiting the training data. Moreover, most prior works have focused on traditional centralized machine learning, making federated machine learning under-explored in network anomaly detection. Therefore, we propose a deep neural network framework that could work on low to mid-end devices detecting network anomalies while checking if a request from a specific IP address is malicious or not. Compared to multiple traditional centralized machine learning models, the deep neural federated model reduces training time overhead. The proposed method performs better than baseline machine learning techniques on the UNSW-NB15 data set as measured by experiments conducted with an accuracy of 97.21% and a faster computation time.</p></br><a href="https://arxiv.org/pdf/2103.16329v8" target="_blank"><h2>E-GraphSAGE: A Graph Neural Network based Intrusion Detection System for IoT</h2></a><strong><u>Authors:</u></strong>  Wai Weng Lo, Siamak Layeghy, Mohanad Sarhan, Marcus Gallagher, Marius Portmann</br><strong><u>Categories:</u></strong> cs.NI, cs.AI, cs.CR, cs.LG</br><strong><u>Comments:</u></strong> will appear in IEEE/IFIP Network Operations and Management Symposium 2022</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper presents a new Network Intrusion Detection System (NIDS) based on Graph Neural Networks (GNNs). GNNs are a relatively new sub-field of deep neural networks, which can leverage the inherent structure of graph-based data. Training and evaluation data for NIDSs are typically represented as flow records, which can naturally be represented in a graph format. In this paper, we propose E-GraphSAGE, a GNN approach that allows capturing both the edge features of a graph as well as the topological information for network intrusion detection in IoT networks. To the best of our knowledge, our proposal is the first successful, practical, and extensively evaluated approach of applying GNNs on the problem of network intrusion detection for IoT using flow-based data. Our extensive experimental evaluation on four recent NIDS benchmark datasets shows that our approach outperforms the state-of-the-art in terms of key classification metrics, which demonstrates the potential of GNNs in network intrusion detection, and provides motivation for further research.</p></br><a href="https://arxiv.org/pdf/2012.09407v2" target="_blank"><h2>Joint Search of Data Augmentation Policies and Network Architectures</h2></a><strong><u>Authors:</u></strong>  Taiga Kashima, Yoshihiro Yamada, Shunta Saito</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> AAAI 2021 Workshop: Learning Network Architecture during Training</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), data augmentation (title, abstract)</br><p><strong><u>Abstract:</u></strong> The common pipeline of training deep neural networks consists of several building blocks such as data augmentation and network architecture selection. AutoML is a research field that aims at automatically designing those parts, but most methods explore each part independently because it is more challenging to simultaneously search all the parts. In this paper, we propose a joint optimization method for data augmentation policies and network architectures to bring more automation to the design of training pipeline. The core idea of our approach is to make the whole part differentiable. The proposed method combines differentiable methods for augmentation policy search and network architecture search to jointly optimize them in the end-to-end manner. The experimental results show our method achieves competitive or superior performance to the independently searched results.</p></br><a href="https://arxiv.org/pdf/2010.06746v2" target="_blank"><h2>Analogical and Relational Reasoning with Spiking Neural Networks</h2></a><strong><u>Authors:</u></strong>  Rollin Omari, R. I. McKay, Tom Gedeon</br><strong><u>Categories:</u></strong> cs.NE, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Problems were discovered with the details of the experiments involving the LSM neural network, the results reported were not correct. A new version of the paper is in progress with corrected results</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Raven's Progressive Matrices have been widely used for measuring abstract reasoning and intelligence in humans. However for artificial learning systems, abstract reasoning remains a challenging problem. In this paper we investigate how neural networks augmented with biologically inspired spiking modules gain a significant advantage in solving this problem. To illustrate this, we first investigate the performance of our networks with supervised learning, then with unsupervised learning. Experiments on the RAVEN dataset show that the overall accuracy of our supervised networks surpass human-level performance, while our unsupervised networks significantly outperform existing unsupervised methods. Finally, our results from both supervised and unsupervised learning illustrate that, unlike their non-augmented counterparts, networks with spiking modules are able to extract and encode temporal features without any explicit instruction, do not heavily rely on training data, and generalise more readily to new problems. In summary, the results reported here indicate that artificial neural networks with spiking modules are well suited to solving abstract reasoning.</p></br><a href="https://arxiv.org/pdf/1803.04967v1" target="_blank"><h2>Recurrent Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Andy Brown, Aaron Tuor, Brian Hutchinson, Nicole Nichols</br><strong><u>Categories:</u></strong> cs.LG, cs.NE, stat.ML</br><strong><u>Comments:</u></strong> Submitted to the First Workshop On Machine Learning for Computer Systems, ACM HPDC 2018</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Deep learning has recently demonstrated state-of-the art performance on key tasks related to the maintenance of computer systems, such as intrusion detection, denial of service attack detection, hardware and software system failures, and malware detection. In these contexts, model interpretability is vital for administrator and analyst to trust and act on the automated analysis of machine learning models. Deep learning methods have been criticized as black box oracles which allow limited insight into decision factors. In this work we seek to "bridge the gap" between the impressive performance of deep learning models and the need for interpretable model introspection. To this end we present recurrent neural network (RNN) language models augmented with attention for anomaly detection in system logs. Our methods are generally applicable to any computer system and logging source.
  By incorporating attention variants into our RNN language models we create opportunities for model introspection and analysis without sacrificing state-of-the art performance.
  We demonstrate model performance and illustrate model interpretability on an intrusion detection task using the Los Alamos National Laboratory (LANL) cyber security dataset, reporting upward of 0.99 area under the receiver operator characteristic curve despite being trained only on a single day's worth of data.</p></br><a href="https://arxiv.org/pdf/2504.09480v1" target="_blank"><h2>Vision-Language Model for Object Detection and Segmentation: A Review and Evaluation</h2></a><strong><u>Authors:</u></strong>  Yongchao Feng, Yajie Liu, Shuai Yang, Wenrui Cai, Jinqing Zhang, Qiqi Zhan, Ziyue Huang, Hongxi Yan, Qiao Wan, Chenguang Liu, Junzhe Wang, Jiahui Lv, Ziqi Liu, Tengyuan Shi, Qingjie Liu, Yunhong Wang</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> A Review and Evaluation about Vision-Language Model for Object Detection and Segmentation</br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), domain adaptation (abstract)</br><p><strong><u>Abstract:</u></strong> Vision-Language Model (VLM) have gained widespread adoption in Open-Vocabulary (OV) object detection and segmentation tasks. Despite they have shown promise on OV-related tasks, their effectiveness in conventional vision tasks has thus far been unevaluated. In this work, we present the systematic review of VLM-based detection and segmentation, view VLM as the foundational model and conduct comprehensive evaluations across multiple downstream tasks for the first time: 1) The evaluation spans eight detection scenarios (closed-set detection, domain adaptation, crowded objects, etc.) and eight segmentation scenarios (few-shot, open-world, small object, etc.), revealing distinct performance advantages and limitations of various VLM architectures across tasks. 2) As for detection tasks, we evaluate VLMs under three finetuning granularities: \textit{zero prediction}, \textit{visual fine-tuning}, and \textit{text prompt}, and further analyze how different finetuning strategies impact performance under varied task. 3) Based on empirical findings, we provide in-depth analysis of the correlations between task characteristics, model architectures, and training methodologies, offering insights for future VLM design. 4) We believe that this work shall be valuable to the pattern recognition experts working in the fields of computer vision, multimodal learning, and vision foundation models by introducing them to the problem, and familiarizing them with the current status of the progress while providing promising directions for future research. A project associated with this review and evaluation has been created at https://github.com/better-chao/perceptual_abilities_evaluation.</p></br><a href="https://arxiv.org/pdf/2001.09209v1" target="_blank"><h2>Detection of Thin Boundaries between Different Types of Anomalies in Outlier Detection using Enhanced Neural Networks</h2></a><strong><u>Authors:</u></strong>  Rasoul Kiani, Amin Keshavarzi, Mahdi Bohlouli</br><strong><u>Categories:</u></strong> cs.LG, cs.NE, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), neural network (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Outlier detection has received special attention in various fields, mainly for those dealing with machine learning and artificial intelligence. As strong outliers, anomalies are divided into the point, contextual and collective outliers. The most important challenges in outlier detection include the thin boundary between the remote points and natural area, the tendency of new data and noise to mimic the real data, unlabelled datasets and different definitions for outliers in different applications. Considering the stated challenges, we defined new types of anomalies called Collective Normal Anomaly and Collective Point Anomaly in order to improve a much better detection of the thin boundary between different types of anomalies. Basic domain-independent methods are introduced to detect these defined anomalies in both unsupervised and supervised datasets. The Multi-Layer Perceptron Neural Network is enhanced using the Genetic Algorithm to detect newly defined anomalies with higher precision so as to ensure a test error less than that calculated for the conventional Multi-Layer Perceptron Neural Network. Experimental results on benchmark datasets indicated reduced error of anomaly detection process in comparison to baselines.</p></br><a href="https://arxiv.org/pdf/2407.08758v1" target="_blank"><h2>Credit Card Fraud Detection in the Nigerian Financial Sector: A Comparison of Unsupervised TensorFlow-Based Anomaly Detection Techniques, Autoencoders and PCA Algorithm</h2></a><strong><u>Authors:</u></strong>  Jennifer Onyeama</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Pre-STATA compression, pre-analysis, full-scale raw data-set:this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), dimensionality reduction (abstract)</br><p><strong><u>Abstract:</u></strong> Credit card fraud is a major cause of national concern in the Nigerian financial sector, affecting hundreds of transactions per second and impacting international ecommerce negatively. Despite the rapid spread and adoption of online marketing, millions of Nigerians are prevented from transacting in several countries with local credit cards due to bans and policies directed at restricting credit card fraud. Presently, a myriad of technologies exist to detect fraudulent transactions, a few of which are adopted by Nigerian financial institutions to proactively manage the situation. Fraud detection allows institutions to restrict offenders from networks and with a centralized banking identity management system, such as the Bank Verification Number used by the Central Bank of Nigeria, offenders who may have stolen other identities can be backtraced and their bank accounts frozen. This paper aims to compare the effectiveness of two fraud detection technologies that are projected to work fully independent of human intervention to possibly predict and detect fraudulent credit card transactions. Autoencoders as an unsupervised tensorflow based anomaly detection technique generally offers greater performance in dimensionality reduction than the Principal Component Analysis, and this theory was tested out on Nigerian credit card transaction data. Results demonstrate that autoencoders are better suited to analyzing complex and extensive datasets and offer more reliable results with minimal mislabeling than the PCA algorithm.</p></br><a href="https://arxiv.org/pdf/1912.13387v2" target="_blank"><h2>AEGR: A simple approach to gradient reversal in autoencoders for network anomaly detection</h2></a><strong><u>Authors:</u></strong>  Kasra Babaei, Zhi Yuan Chen, Tomas Maul</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is referred to as a process in which the aim is to detect data points that follow a different pattern from the majority of data points. Anomaly detection methods suffer from several well-known challenges that hinder their performance such as high dimensionality. Autoencoders are unsupervised neural networks that have been used for the purpose of reducing dimensionality and also detecting network anomalies in large datasets. The performance of autoencoders debilitates when the training set contains noise and anomalies. In this paper, a new gradient-reversal method is proposed to overcome the influence of anomalies on the training phase for the purpose of detecting network anomalies. The method is different from other approaches as it does not require an anomaly-free training set and is based on reconstruction error. Once latent variables are extracted from the network, Local Outlier Factor is used to separate normal data points from anomalies. A simple pruning approach and data augmentation is also added to further improve performance. The experimental results show that the proposed model can outperform other well-know approaches.</p></br><a href="https://arxiv.org/pdf/2201.00464v1" target="_blank"><h2>Adaptive Memory Networks with Self-supervised Learning for Unsupervised Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Yuxin Zhang, Jindong Wang, Yiqiang Chen, Han Yu, Tao Qin</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted by IEEE Transactions on Knowledge and Data Engineering (TKDE) 2022; 13 pages</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Unsupervised anomaly detection aims to build models to effectively detect unseen anomalies by only training on the normal data. Although previous reconstruction-based methods have made fruitful progress, their generalization ability is limited due to two critical challenges. First, the training dataset only contains normal patterns, which limits the model generalization ability. Second, the feature representations learned by existing models often lack representativeness which hampers the ability to preserve the diversity of normal patterns. In this paper, we propose a novel approach called Adaptive Memory Network with Self-supervised Learning (AMSL) to address these challenges and enhance the generalization ability in unsupervised anomaly detection. Based on the convolutional autoencoder structure, AMSL incorporates a self-supervised learning module to learn general normal patterns and an adaptive memory fusion module to learn rich feature representations. Experiments on four public multivariate time series datasets demonstrate that AMSL significantly improves the performance compared to other state-of-the-art methods. Specifically, on the largest CAP sleep stage detection dataset with 900 million samples, AMSL outperforms the second-best baseline by \textbf{4}\%+ in both accuracy and F1 score. Apart from the enhanced generalization ability, AMSL is also more robust against input noise.</p></br><a href="https://arxiv.org/pdf/2508.18025v1" target="_blank"><h2>AQ-PCDSys: An Adaptive Quantized Planetary Crater Detection System for Autonomous Space Exploration</h2></a><strong><u>Authors:</u></strong>  Aditri Paul, Archan Paul</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, cs.ET, eess.SY</br><strong><u>Comments:</u></strong> 17 pages, 6 figures. A research paper on a novel deep learning framework for planetary crater detection</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Autonomous planetary exploration missions are critically dependent on real-time, accurate environmental perception for navigation and hazard avoidance. However, deploying deep learning models on the resource-constrained computational hardware of planetary exploration platforms remains a significant challenge. This paper introduces the Adaptive Quantized Planetary Crater Detection System (AQ-PCDSys), a novel framework specifically engineered for real-time, onboard deployment in the computationally constrained environments of space exploration missions. AQ-PCDSys synergistically integrates a Quantized Neural Network (QNN) architecture, trained using Quantization-Aware Training (QAT), with an Adaptive Multi-Sensor Fusion (AMF) module. The QNN architecture significantly optimizes model size and inference latency suitable for real-time onboard deployment in space exploration missions, while preserving high accuracy. The AMF module intelligently fuses data from Optical Imagery (OI) and Digital Elevation Models (DEMs) at the feature level, utilizing an Adaptive Weighting Mechanism (AWM) to dynamically prioritize the most relevant and reliable sensor modality based on planetary ambient conditions. This approach enhances detection robustness across diverse planetary landscapes. Paired with Multi-Scale Detection Heads specifically designed for robust and efficient detection of craters across a wide range of sizes, AQ-PCDSys provides a computationally efficient, reliable and accurate solution for planetary crater detection, a critical capability for enabling the next generation of autonomous planetary landing, navigation, and scientific exploration.</p></br><a href="https://arxiv.org/pdf/1907.06582v1" target="_blank"><h2>AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and Time-Evolving Categorical Data</h2></a><strong><u>Authors:</u></strong>  Zheng Gao, Lin Guo, Chi Ma, Xiao Ma, Kai Sun, Hang Xiang, Xiaoqiang Zhu, Hongsong Li, Xiaozhong Liu</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Accepted by 2019 KDD Workshop on Deep Learning Practice for High-Dimensional Sparse Data</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is facing with emerging challenges in many important industry domains, such as cyber security and online recommendation and advertising. The recent trend in these areas calls for anomaly detection on time-evolving data with high-dimensional categorical features without labeled samples. Also, there is an increasing demand for identifying and monitoring irregular patterns at multiple resolutions. In this work, we propose a unified end-to-end approach to solve these challenges by combining the advantages of Adversarial Autoencoder and Recurrent Neural Network. The model learns data representations cross different scales with attention mechanisms, on which an enhanced two-resolution anomaly detector is developed for both instances and data blocks. Extensive experiments are performed over three types of datasets to demonstrate the efficacy of our method and its superiority over the state-of-art approaches.</p></br><a href="https://arxiv.org/pdf/2502.14293v2" target="_blank"><h2>Cross-Domain Graph Anomaly Detection via Test-Time Training with Homophily-Guided Self-Supervision</h2></a><strong><u>Authors:</u></strong>  Delaram Pirhayati, Arlei Silva</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.SI</br><strong><u>Comments:</u></strong> Accepted at Transactions on Machine Learning Research (TMLR), 2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Graph Anomaly Detection (GAD) has demonstrated great effectiveness in identifying unusual patterns within graph-structured data. However, while labeled anomalies are often scarce in emerging applications, existing supervised GAD approaches are either ineffective or not applicable when moved across graph domains due to distribution shifts and heterogeneous feature spaces. To address these challenges, we present GADT3, a novel test-time training framework for cross-domain GAD. GADT3 combines supervised and self-supervised learning during training while adapting to a new domain during test time using only self-supervised learning by leveraging a homophily-based affinity score that captures domain-invariant properties of anomalies. Our framework introduces four key innovations to cross-domain GAD: an effective self-supervision scheme, an attention-based mechanism that dynamically learns edge importance weights during message passing, domain-specific encoders for handling heterogeneous features, and class-aware regularization to address imbalance. Experiments across multiple cross-domain settings demonstrate that GADT3 significantly outperforms existing approaches, achieving average improvements of over 8.2\% in AUROC and AUPRC compared to the best competing model.</p></br><a href="https://arxiv.org/pdf/2410.21696v4" target="_blank"><h2>The Effects of Multi-Task Learning on ReLU Neural Network Functions</h2></a><strong><u>Authors:</u></strong>  Julia Nakhleh, Joseph Shenouda, Robert D. Nowak</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> Expanded version of the NeurIPS 2024 paper "A New Neural Kernel Regime: The Inductive Bias of Multi-Task Learning."</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper studies the properties of solutions to multi-task shallow ReLU neural network learning problems, wherein the network is trained to fit a dataset with minimal sum of squared weights. Remarkably, the solutions learned for each individual task resemble those obtained by solving a kernel regression problem, revealing a novel connection between neural networks and kernel methods. It is known that single-task neural network learning problems are equivalent to a minimum norm interpolation problem in a non-Hilbertian Banach space, and that the solutions of such problems are generally non-unique. In contrast, we prove that the solutions to univariate-input, multi-task neural network interpolation problems are almost always unique, and coincide with the solution to a minimum-norm interpolation problem in a Sobolev (Reproducing Kernel) Hilbert Space. We also demonstrate a similar phenomenon in the multivariate-input case; specifically, we show that neural network learning problems with large numbers of tasks are approximately equivalent to an $\ell^2$ (Hilbert space) minimization problem over a fixed kernel determined by the optimal neurons.</p></br><a href="https://arxiv.org/pdf/2508.15100v1" target="_blank"><h2>Adaptive Anomaly Detection in Evolving Network Environments</h2></a><strong><u>Authors:</u></strong>  Ehssan Mousavipour, Andrey Dimanchev, Majid Ghaderi</br><strong><u>Categories:</u></strong> cs.CR, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Distribution shift, a change in the statistical properties of data over time, poses a critical challenge for deep learning anomaly detection systems. Existing anomaly detection systems often struggle to adapt to these shifts. Specifically, systems based on supervised learning require costly manual labeling, while those based on unsupervised learning rely on clean data, which is difficult to obtain, for shift adaptation. Both of these requirements are challenging to meet in practice. 
In this paper, we introduce NetSight, a framework for supervised anomaly detection in network data that continually detects and adapts to distribution shifts in an online manner. NetSight eliminates manual intervention through a novel pseudo-labeling technique and uses a knowledge distillation-based adaptation strategy to prevent catastrophic forgetting. Evaluated on three long-term network datasets, NetSight demonstrates superior adaptation performance compared to state-of-the-art methods that rely on manual labeling, achieving F1-score improvements of up to 11.72%. This proves its robustness and effectiveness in dynamic networks that experience distribution shifts over time.</p></br><a href="https://arxiv.org/pdf/1710.07110v1" target="_blank"><h2>Meta-Learning via Feature-Label Memory Network</h2></a><strong><u>Authors:</u></strong>  Dawit Mureja, Hyunsin Park, Chang D. Yoo</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> this https URL</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Deep learning typically requires training a very capable architecture using large datasets. However, many important learning problems demand an ability to draw valid inferences from small size datasets, and such problems pose a particular challenge for deep learning. In this regard, various researches on "meta-learning" are being actively conducted. Recent work has suggested a Memory Augmented Neural Network (MANN) for meta-learning. MANN is an implementation of a Neural Turing Machine (NTM) with the ability to rapidly assimilate new data in its memory, and use this data to make accurate predictions. In models such as MANN, the input data samples and their appropriate labels from previous step are bound together in the same memory locations. This often leads to memory interference when performing a task as these models have to retrieve a feature of an input from a certain memory location and read only the label information bound to that location. In this paper, we tried to address this issue by presenting a more robust MANN. We revisited the idea of meta-learning and proposed a new memory augmented neural network by explicitly splitting the external memory into feature and label memories. The feature memory is used to store the features of input data samples and the label memory stores their labels. Hence, when predicting the label of a given input, our model uses its feature memory unit as a reference to extract the stored feature of the input, and based on that feature, it retrieves the label information of the input from the label memory unit. In order for the network to function in this framework, a new memory-writingmodule to encode label information into the label memory in accordance with the meta-learning task structure is designed. Here, we demonstrate that our model outperforms MANN by a large margin in supervised one-shot classification tasks using Omniglot and MNIST datasets.</p></br><a href="https://arxiv.org/pdf/1802.02617v2" target="_blank"><h2>Recognition of Acoustic Events Using Masked Conditional Neural Networks</h2></a><strong><u>Authors:</u></strong>  Fady Medhat, David Chesmore, John Robinson</br><strong><u>Categories:</u></strong> cs.LG, cs.SD, eess.AS, stat.ML</br><strong><u>Comments:</u></strong> Restricted Boltzmann Machine, RBM, Conditional Restricted Boltzmann Machine, CRBM, Conditional Neural Networks, CLNN, Masked Conditional Neural Networks, MCLNN, Deep Neural Network, Environmental Sound Recognition, ESR</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Automatic feature extraction using neural networks has accomplished remarkable success for images, but for sound recognition, these models are usually modified to fit the nature of the multi-dimensional temporal representation of the audio signal in spectrograms. This may not efficiently harness the time-frequency representation of the signal. The ConditionaL Neural Network (CLNN) takes into consideration the interrelation between the temporal frames, and the Masked ConditionaL Neural Network (MCLNN) extends upon the CLNN by forcing a systematic sparseness over the network's weights using a binary mask. The masking allows the network to learn about frequency bands rather than bins, mimicking a filterbank used in signal transformations such as MFCC. Additionally, the Mask is designed to consider various combinations of features, which automates the feature hand-crafting process. We applied the MCLNN for the Environmental Sound Recognition problem using the Urbansound8k, YorNoise, ESC-10 and ESC-50 datasets. The MCLNN have achieved competitive performance compared to state-of-the-art Convolutional Neural Networks and hand-crafted attempts.</p></br><a href="https://arxiv.org/pdf/2009.09011v1" target="_blank"><h2>Experimental Review of Neural-based approaches for Network Intrusion Management</h2></a><strong><u>Authors:</u></strong>  Mario Di Mauro, Giovanni Galatro, Antonio Liotta</br><strong><u>Categories:</u></strong> cs.NI, cs.LG</br><strong><u>Comments:</u></strong> Early Access on IEEE Transactions on Network and Service Management</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The use of Machine Learning (ML) techniques in Intrusion Detection Systems (IDS) has taken a prominent role in the network security management field, due to the substantial number of sophisticated attacks that often pass undetected through classic IDSs. These are typically aimed at recognising attacks based on a specific signature, or at detecting anomalous events. However, deterministic, rule-based methods often fail to differentiate particular (rarer) network conditions (as in peak traffic during specific network situations) from actual cyber attacks. In this paper we provide an experimental-based review of neural-based methods applied to intrusion detection issues. Specifically, we i) offer a complete view of the most prominent neural-based techniques relevant to intrusion detection, including deep-based approaches or weightless neural networks, which feature surprising outcomes; ii) evaluate novel datasets (updated w.r.t. the obsolete KDD99 set) through a designed-from-scratch Python-based routine; iii) perform experimental analyses including time complexity and performance (accuracy and F-measure), considering both single-class and multi-class problems, and identifying trade-offs between resource consumption and performance. Our evaluation quantifies the value of neural networks, particularly when state-of-the-art datasets are used to train the models. This leads to interesting guidelines for security managers and computer network practitioners who are looking at the incorporation of neural-based ML into IDS.</p></br><a href="https://arxiv.org/pdf/2403.04429v1" target="_blank"><h2>Exploring the Influence of Dimensionality Reduction on Anomaly Detection Performance in Multivariate Time Series</h2></a><strong><u>Authors:</u></strong>  Mahsun Altin, Altan Cakir</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Submitted to Machine Learning</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), dimensionality reduction (title, abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> This paper presents an extensive empirical study on the integration of dimensionality reduction techniques with advanced unsupervised time series anomaly detection models, focusing on the MUTANT and Anomaly-Transformer models. The study involves a comprehensive evaluation across three different datasets: MSL, SMAP, and SWaT. Each dataset poses unique challenges, allowing for a robust assessment of the models' capabilities in varied contexts. The dimensionality reduction techniques examined include PCA, UMAP, Random Projection, and t-SNE, each offering distinct advantages in simplifying high-dimensional data. Our findings reveal that dimensionality reduction not only aids in reducing computational complexity but also significantly enhances anomaly detection performance in certain scenarios. Moreover, a remarkable reduction in training times was observed, with reductions by approximately 300\% and 650\% when dimensionality was halved and minimized to the lowest dimensions, respectively. This efficiency gain underscores the dual benefit of dimensionality reduction in both performance enhancement and operational efficiency. The MUTANT model exhibits notable adaptability, especially with UMAP reduction, while the Anomaly-Transformer demonstrates versatility across various reduction techniques. These insights provide a deeper understanding of the synergistic effects of dimensionality reduction and anomaly detection, contributing valuable perspectives to the field of time series analysis. The study underscores the importance of selecting appropriate dimensionality reduction strategies based on specific model requirements and dataset characteristics, paving the way for more efficient, accurate, and scalable solutions in anomaly detection.</p></br><a href="https://arxiv.org/pdf/2012.08100v1" target="_blank"><h2>Anomaly Detection and Localization based on Double Kernelized Scoring and Matrix Kernels</h2></a><strong><u>Authors:</u></strong>  Shunsuke Hirose, Tomotake Kozu, Yingzi Jin</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 15 pages and 3 figures. A translation of "Anomaly Detection based on Doubly-Kernelized Scoring and Matrix Kernels" by Shunsuke Hirose and Tomotake Kozu (This article is written in Japanese). DOI:this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection is necessary for proper and safe operation of large-scale systems consisting of multiple devices, networks, and/or plants. Those systems are often characterized by a pair of multivariate datasets. To detect anomaly in such a system and localize element(s) associated with anomaly, one would need to estimate scores that quantify anomalousness of the entire system as well as its elements. However, it is not trivial to estimate such scores by considering changes of relationships between the elements, which strongly correlate with each other. Moreover, it is necessary to estimate the scores for the entire system and its elements from a single framework, in order to identify relationships among the scores for localizing elements associated with anomaly. Here, we developed a new method to quantify anomalousness of an entire system and its elements simultaneously.
  The purpose of this paper is threefold. The first one is to propose a new anomaly detection method: Double Kernelized Scoring (DKS). DKS is a unified framework for entire-system anomaly scoring and element-wise anomaly scoring. Therefore, DKS allows for conducting simultaneously 1) anomaly detection for the entire system and 2) localization for identifying faulty elements responsible for the system anomaly. The second purpose is to propose a new kernel function: Matrix Kernel. The Matrix Kernel is defined between general matrices, which might have different dimensions, allowing for conducting anomaly detection on systems where the number of elements change over time. The third purpose is to demonstrate the effectiveness of the proposed method experimentally. We evaluated the proposed method with synthetic and real time series data. The results demonstrate that DKS is able to detect anomaly and localize the elements associated with it successfully.</p></br><a href="https://arxiv.org/pdf/2008.13361v1" target="_blank"><h2>Multi-Scale One-Class Recurrent Neural Networks for Discrete Event Sequence Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Zhiwei Wang, Zhengzhang Chen, Jingchao Ni, Hui Liu, Haifeng Chen, Jiliang Tang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), latent space (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Discrete event sequences are ubiquitous, such as an ordered event series of process interactions in Information and Communication Technology systems. Recent years have witnessed increasing efforts in detecting anomalies with discrete-event sequences. However, it still remains an extremely difficult task due to several intrinsic challenges including data imbalance issues, the discrete property of the events, and sequential nature of the data. To address these challenges, in this paper, we propose OC4Seq, a multi-scale one-class recurrent neural network for detecting anomalies in discrete event sequences. Specifically, OC4Seq integrates the anomaly detection objective with recurrent neural networks (RNNs) to embed the discrete event sequences into latent spaces, where anomalies can be easily detected. In addition, given that an anomalous sequence could be caused by either individual events, subsequences of events, or the whole sequence, we design a multi-scale RNN framework to capture different levels of sequential patterns simultaneously. Experimental results on three benchmark datasets show that OC4Seq consistently outperforms various representative baselines by a large margin. Moreover, through both quantitative and qualitative analysis, the importance of capturing multi-scale sequential patterns for event anomaly detection is verified.</p></br><a href="https://arxiv.org/pdf/2002.09545v2" target="_blank"><h2>RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks</h2></a><strong><u>Authors:</u></strong>  Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun, Huan Xu</br><strong><u>Categories:</u></strong> cs.LG, eess.SP, stat.AP, stat.ML</br><strong><u>Comments:</u></strong> Extended version of the paper at ACM SIGKDD Workshop on Mining and Learning from Time Series (KDD-MiLeTS 2020); 9 pages, 5 figures, and 2 tables</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), anomaly detection (title, abstract), neural network (title, abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> The monitoring and management of numerous and diverse time series data at Alibaba Group calls for an effective and scalable time series anomaly detection service. In this paper, we propose RobustTAD, a Robust Time series Anomaly Detection framework by integrating robust seasonal-trend decomposition and convolutional neural network for time series data. The seasonal-trend decomposition can effectively handle complicated patterns in time series, and meanwhile significantly simplifies the architecture of the neural network, which is an encoder-decoder architecture with skip connections. This architecture can effectively capture the multi-scale information from time series, which is very useful in anomaly detection. Due to the limited labeled data in time series anomaly detection, we systematically investigate data augmentation methods in both time and frequency domains. We also introduce label-based weight and value-based weight in the loss function by utilizing the unbalanced nature of the time series anomaly detection problem. Compared with the widely used forecasting-based anomaly detection algorithms, decomposition-based algorithms, traditional statistical algorithms, as well as recent neural network based algorithms, RobustTAD performs significantly better on public benchmark datasets. It is deployed as a public online service and widely adopted in different business scenarios at Alibaba Group.</p></br><a href="https://arxiv.org/pdf/2103.16440v4" target="_blank"><h2>Neural Transformation Learning for Deep Anomaly Detection Beyond Images</h2></a><strong><u>Authors:</u></strong>  Chen Qiu, Timo Pfrommer, Marius Kloft, Stephan Mandt, Maja Rudolph</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Data transformations (e.g. rotations, reflections, and cropping) play an important role in self-supervised learning. Typically, images are transformed into different views, and neural networks trained on tasks involving these views produce useful feature representations for downstream tasks, including anomaly detection. However, for anomaly detection beyond image data, it is often unclear which transformations to use. Here we present a simple end-to-end procedure for anomaly detection with learnable transformations. The key idea is to embed the transformed data into a semantic space such that the transformed data still resemble their untransformed form, while different transformations are easily distinguishable. Extensive experiments on time series demonstrate that our proposed method outperforms existing approaches in the one-vs.-rest setting and is competitive in the more challenging n-vs.-rest anomaly detection task. On tabular datasets from the medical and cyber-security domains, our method learns domain-specific transformations and detects anomalies more accurately than previous work.</p></br><a href="https://arxiv.org/pdf/2311.14469v1" target="_blank"><h2>Fault Detection in Telecom Networks using Bi-level Federated Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  R. Bourgerie, T. Zanouda</br><strong><u>Categories:</u></strong> cs.LG, cs.NI</br><strong><u>Comments:</u></strong> This paper has been accepted as part of the The 2nd International Workshop on Federated Learning with Graph Data, colocated at EEE ICDM 2023</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> 5G and Beyond Networks become increasingly complex and heterogeneous, with diversified and high requirements from a wide variety of emerging applications. The complexity and diversity of Telecom networks place an increasing strain on maintenance and operation efforts. Moreover, the strict security and privacy requirements present a challenge for mobile operators to leverage network data. To detect network faults, and mitigate future failures, prior work focused on leveraging traditional ML/DL methods to locate anomalies in networks. The current approaches, although powerful, do not consider the intertwined nature of embedded and software-intensive Radio Access Network systems. In this paper, we propose a Bi-level Federated Graph Neural Network anomaly detection and diagnosis model that is able to detect anomalies in Telecom networks in a privacy-preserving manner, while minimizing communication costs. Our method revolves around conceptualizing Telecom data as a bi-level temporal Graph Neural Networks. The first graph captures the interactions between different RAN nodes that are exposed to different deployment scenarios in the network, while each individual Radio Access Network node is further elaborated into its software (SW) execution graph. Additionally, we use Federated Learning to address privacy and security limitations. Furthermore, we study the performance of anomaly detection model under three settings: (1) Centralized (2) Federated Learning and (3) Personalized Federated Learning using real-world data from an operational network. Our comprehensive experiments showed that Personalized Federated Temporal Graph Neural Networks method outperforms the most commonly used techniques for Anomaly Detection.</p></br><a href="https://arxiv.org/pdf/2104.00035v1" target="_blank"><h2>Strengthening the Training of Convolutional Neural Networks By Using Walsh Matrix</h2></a><strong><u>Authors:</u></strong>  Tamer Ölmez, Zümray Dokur</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> Keyword: Deep neural networks, Convolutional neural network, Pattern recognition, Training deep neural network, Classification. arXiv admin note: substantial text overlap witharXiv:2103.10977</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> DNN structures are continuously developing and achieving high performances in classification problems. Also, it is observed that success rates obtained with DNNs are higher than those obtained with traditional neural networks. In addition, one of the advantages of DNNs is that there is no need to spend an extra effort to determine the features; the CNN automatically extracts the features from the dataset during the training. Besides their benefits, the DNNs have the following three major drawbacks among the others: (i) Researchers have struggled with over-fitting and under-fitting issues in the training of DNNs, (ii) determination of even a coarse structure for the DNN may take days, and (iii) most of the time, the proposed network structure is too large to be too bulky to be used in real time applications. We have modified the training and structure of DNN to increase the classification performance, to decrease the number of nodes in the structure, and to be used with less number of hyper parameters. A minimum distance network (MDN) following the last layer of the convolutional neural network (CNN) is used as the classifier instead of a fully connected neural network (FCNN). In order to strengthen the training of the CNN, we suggest employing Walsh function. We tested the performances of the proposed DNN (named as DivFE) on the classification of ECG, EEG, heart sound, detection pneumonia in X-ray chest images, detection of BGA solder defects, and patterns of benchmark datasets (MNIST, IRIS, CIFAR10 and CIFAR20). In different areas, it has been observed that a higher classification performance was obtained by using the DivFE with less number of nodes.</p></br><a href="https://arxiv.org/pdf/1808.07632v2" target="_blank"><h2>DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN</h2></a><strong><u>Authors:</u></strong>  Swee Kiat Lim, Yi Loo, Ngoc-Trung Tran, Ngai-Man Cheung, Gemma Roig, Yuval Elovici</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> Published as a conference paper at ICDM 2018 (IEEE International Conference on Data Mining)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), multimodal (abstract), data augmentation (title, abstract)</br><p><strong><u>Abstract:</u></strong> Recently, the introduction of the generative adversarial network (GAN) and its variants has enabled the generation of realistic synthetic samples, which has been used for enlarging training sets. Previous work primarily focused on data augmentation for semi-supervised and supervised tasks. In this paper, we instead focus on unsupervised anomaly detection and propose a novel generative data augmentation framework optimized for this task. In particular, we propose to oversample infrequent normal samples - normal samples that occur with small probability, e.g., rare normal events. We show that these samples are responsible for false positives in anomaly detection. However, oversampling of infrequent normal samples is challenging for real-world high-dimensional data with multimodal distributions. To address this challenge, we propose to use a GAN variant known as the adversarial autoencoder (AAE) to transform the high-dimensional multimodal data distributions into low-dimensional unimodal latent distributions with well-defined tail probability. Then, we systematically oversample at the `edge' of the latent distributions to increase the density of infrequent normal samples. We show that our oversampling pipeline is a unified one: it is generally applicable to datasets with different complex data distributions. To the best of our knowledge, our method is the first data augmentation technique focused on improving performance in unsupervised anomaly detection. We validate our method by demonstrating consistent improvements across several real-world datasets.</p></br><a href="https://arxiv.org/pdf/2306.15938v1" target="_blank"><h2>Interpretable Anomaly Detection in Cellular Networks by Learning Concepts in Variational Autoencoders</h2></a><strong><u>Authors:</u></strong>  Amandeep Singh, Michael Weber, Markus Lange-Hegermann</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NI, stat.AP</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), VAE (abstract), anomaly detection (title), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> This paper addresses the challenges of detecting anomalies in cellular networks in an interpretable way and proposes a new approach using variational autoencoders (VAEs) that learn interpretable representations of the latent space for each Key Performance Indicator (KPI) in the dataset. This enables the detection of anomalies based on reconstruction loss and Z-scores. We ensure the interpretability of the anomalies via additional information centroids (c) using the K-means algorithm to enhance representation learning. We evaluate the performance of the model by analyzing patterns in the latent dimension for specific KPIs and thereby demonstrate the interpretability and anomalies. The proposed framework offers a faster and autonomous solution for detecting anomalies in cellular networks and showcases the potential of deep learning-based algorithms in handling big data.</p></br><a href="https://arxiv.org/pdf/1905.08318v1" target="_blank"><h2>DeepCABAC: Context-adaptive binary arithmetic coding for deep neural network compression</h2></a><strong><u>Authors:</u></strong>  Simon Wiedemann, Heiner Kirchhoffer, Stefan Matlage, Paul Haase, Arturo Marban, Talmaj Marinc, David Neumann, Ahmed Osman, Detlev Marpe, Heiko Schwarz, Thomas Wiegand, Wojciech Samek</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.IT</br><strong><u>Comments:</u></strong> ICML 2019, Joint Workshop on On-Device Machine Learning and Compact Deep Neural Network Representations (ODML-CDNNR)</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> We present DeepCABAC, a novel context-adaptive binary arithmetic coder for compressing deep neural networks. It quantizes each weight parameter by minimizing a weighted rate-distortion function, which implicitly takes the impact of quantization on to the accuracy of the network into account. Subsequently, it compresses the quantized values into a bitstream representation with minimal redundancies. We show that DeepCABAC is able to reach very high compression ratios across a wide set of different network architectures and datasets. For instance, we are able to compress by x63.6 the VGG16 ImageNet model with no loss of accuracy, thus being able to represent the entire network with merely 8.7MB.</p></br><a href="https://arxiv.org/pdf/1811.04576v2" target="_blank"><h2>Estimation of Dimensions Contributing to Detected Anomalies with Variational Autoencoders</h2></a><strong><u>Authors:</u></strong>  Yasuhiro Ikeda, Kengo Tajiri, Yuusuke Nakano, Keishiro Watanabe, Keisuke Ishibashi</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), VAE (abstract), anomaly detection (abstract), dimensionality reduction (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection using dimensionality reduction has been an essential technique for monitoring multidimensional data. Although deep learning-based methods have been well studied for their remarkable detection performance, their interpretability is still a problem. In this paper, we propose a novel algorithm for estimating the dimensions contributing to the detected anomalies by using variational autoencoders (VAEs). Our algorithm is based on an approximative probabilistic model that considers the existence of anomalies in the data, and by maximizing the log-likelihood, we estimate which dimensions contribute to determining data as an anomaly. The experiments results with benchmark datasets show that our algorithm extracts the contributing dimensions more accurately than baseline methods.</p></br><a href="https://arxiv.org/pdf/1906.10015v2" target="_blank"><h2>A Review on Neural Network Models of Schizophrenia and Autism Spectrum Disorder</h2></a><strong><u>Authors:</u></strong>  Pablo Lanillos, Daniel Oliva, Anja Philippsen, Yuichi Yamashita, Yukie Nagai, Gordon Cheng</br><strong><u>Categories:</u></strong> q-bio.NC, cs.AI, cs.NE</br><strong><u>Comments:</u></strong> Preprint submitted to Neural Networks. Research not referenced in the manuscript within the field of NN models of SZ and ASD are encouraged to contact the corresponding authors</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> This survey presents the most relevant neural network models of autism spectrum disorder and schizophrenia, from the first connectionist models to recent deep network architectures. We analyzed and compared the most representative symptoms with its neural model counterpart, detailing the alteration introduced in the network that generates each of the symptoms, and identifying their strengths and weaknesses. We additionally cross-compared Bayesian and free-energy approaches, as they are widely applied to modeling psychiatric disorders and share basic mechanisms with neural networks. Models of schizophrenia mainly focused on hallucinations and delusional thoughts using neural dysconnections or inhibitory imbalance as the predominating alteration. Models of autism rather focused on perceptual difficulties, mainly excessive attention to environment details, implemented as excessive inhibitory connections or increased sensory precision. We found an excessive tight view of the psychopathologies around one specific and simplified effect, usually constrained to the technical idiosyncrasy of the used network architecture. Recent theories and evidence on sensorimotor integration and body perception combined with modern neural network architectures could offer a broader and novel spectrum to approach these psychopathologies. This review emphasizes the power of artificial neural networks for modeling some symptoms of neurological disorders but also calls for further developing these techniques in the field of computational psychiatry.</p></br><a href="https://arxiv.org/pdf/2302.13317v1" target="_blank"><h2>TransferD2: Automated Defect Detection Approach in Smart Manufacturing using Transfer Learning Techniques</h2></a><strong><u>Authors:</u></strong>  Atah Nuh Mih, Hung Cao, Joshua Pickard, Monica Wachowicz, Rickey Dubay</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Keywords: Transfer Learning, Smart Manufacturing, Defect Detection, Deflectometry Data, Data Enhancement, Product Quality Assurance</br><strong><u>Matching Keywords:</u></strong> transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> Quality assurance is crucial in the smart manufacturing industry as it identifies the presence of defects in finished products before they are shipped out. Modern machine learning techniques can be leveraged to provide rapid and accurate detection of these imperfections. We, therefore, propose a transfer learning approach, namely TransferD2, to correctly identify defects on a dataset of source objects and extend its application to new unseen target objects. We present a data enhancement technique to generate a large dataset from the small source dataset for building a classifier. We then integrate three different pre-trained models (Xception, ResNet101V2, and InceptionResNetV2) into the classifier network and compare their performance on source and target data. We use the classifier to detect the presence of imperfections on the unseen target data using pseudo-bounding boxes. Our results show that ResNet101V2 performs best on the source data with an accuracy of 95.72%. Xception performs best on the target data with an accuracy of 91.00% and also provides a more accurate prediction of the defects on the target images. Throughout the experiment, the results also indicate that the choice of a pre-trained model is not dependent on the depth of the network. Our proposed approach can be applied in defect detection applications where insufficient data is available for training a model and can be extended to identify imperfections in new unseen data.</p></br><a href="https://arxiv.org/pdf/2505.09129v1" target="_blank"><h2>WSCIF: A Weakly-Supervised Color Intelligence Framework for Tactical Anomaly Detection in Surveillance Keyframes</h2></a><strong><u>Authors:</u></strong>  Wei Meng</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> 17 pages, 3 figures, 3 tables. The paper proposes a lightweight weakly-supervised color intelligence model for tactical video anomaly detection, tested on anonymized African surveillance data</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The deployment of traditional deep learning models in high-risk security tasks in an unlabeled, data-non-exploitable video intelligence environment faces significant challenges. In this paper, we propose a lightweight anomaly detection framework based on color features for surveillance video clips in a high sensitivity tactical mission, aiming to quickly identify and interpret potential threat events under resource-constrained and data-sensitive conditions. The method fuses unsupervised KMeans clustering with RGB channel histogram modeling to achieve composite detection of structural anomalies and color mutation signals in key frames. The experiment takes an operation surveillance video occurring in an African country as a research sample, and successfully identifies multiple highly anomalous frames related to high-energy light sources, target presence, and reflective interference under the condition of no access to the original data. The results show that this method can be effectively used for tactical assassination warning, suspicious object screening and environmental drastic change monitoring with strong deployability and tactical interpretation value. The study emphasizes the importance of color features as low semantic battlefield signal carriers, and its battlefield intelligent perception capability will be further extended by combining graph neural networks and temporal modeling in the future.</p></br><a href="https://arxiv.org/pdf/2306.09269v1" target="_blank"><h2>Zero-Shot Anomaly Detection with Pre-trained Segmentation Models</h2></a><strong><u>Authors:</u></strong>  Matthew Baugh, James Batten, Johanna P. Müller, Bernhard Kainz</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Ranked 3rd in zero-shot track of the Visual Anomaly and Novelty Detection (VAND) 2023 Challenge</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title)</br><p><strong><u>Abstract:</u></strong> This technical report outlines our submission to the zero-shot track of the Visual Anomaly and Novelty Detection (VAND) 2023 Challenge. Building on the performance of the WINCLIP framework, we aim to enhance the system's localization capabilities by integrating zero-shot segmentation models. In addition, we perform foreground instance segmentation which enables the model to focus on the relevant parts of the image, thus allowing the models to better identify small or subtle deviations. Our pipeline requires no external data or information, allowing for it to be directly applied to new datasets. Our team (Variance Vigilance Vanguard) ranked third in the zero-shot track of the VAND challenge, and achieve an average F1-max score of 81.5/24.2 at a sample/pixel level on the VisA dataset.</p></br><a href="https://arxiv.org/pdf/2107.11514v1" target="_blank"><h2>Multi-Perspective Content Delivery Networks Security Framework Using Optimized Unsupervised Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Li Yang, Abdallah Moubayed, Abdallah Shami, Parisa Heidari, Amine Boukhtouta, Adel Larabi, Richard Brunner, Stere Preda, Daniel Migault</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG, cs.NI</br><strong><u>Comments:</u></strong> Accepted and to Appear in IEEE Transactions on Network and Service Management</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Content delivery networks (CDNs) provide efficient content distribution over the Internet. CDNs improve the connectivity and efficiency of global communications, but their caching mechanisms may be breached by cyber-attackers. Among the security mechanisms, effective anomaly detection forms an important part of CDN security enhancement. In this work, we propose a multi-perspective unsupervised learning framework for anomaly detection in CDNs. In the proposed framework, a multi-perspective feature engineering approach, an optimized unsupervised anomaly detection model that utilizes an isolation forest and a Gaussian mixture model, and a multi-perspective validation method, are developed to detect abnormal behaviors in CDNs mainly from the client Internet Protocol (IP) and node perspectives, therefore to identify the denial of service (DoS) and cache pollution attack (CPA) patterns. Experimental results are presented based on the analytics of eight days of real-world CDN log data provided by a major CDN operator. Through experiments, the abnormal contents, compromised nodes, malicious IPs, as well as their corresponding attack types, are identified effectively by the proposed framework and validated by multiple cybersecurity experts. This shows the effectiveness of the proposed method when applied to real-world CDN data.</p></br><a href="https://arxiv.org/pdf/2210.09766v1" target="_blank"><h2>DAGAD: Data Augmentation for Graph Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Fanzhen Liu, Xiaoxiao Ma, Jia Wu, Jian Yang, Shan Xue, Amin Beheshti, Chuan Zhou, Hao Peng, Quan Z. Sheng, Charu C. Aggarwal</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Regular paper accepted by the 22nd IEEE International Conference on Data Mining (ICDM 2022)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), attention (abstract), data augmentation (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph anomaly detection in this paper aims to distinguish abnormal nodes that behave differently from the benign ones accounting for the majority of graph-structured instances. Receiving increasing attention from both academia and industry, yet existing research on this task still suffers from two critical issues when learning informative anomalous behavior from graph data. For one thing, anomalies are usually hard to capture because of their subtle abnormal behavior and the shortage of background knowledge about them, which causes severe anomalous sample scarcity. Meanwhile, the overwhelming majority of objects in real-world graphs are normal, bringing the class imbalance problem as well. To bridge the gaps, this paper devises a novel Data Augmentation-based Graph Anomaly Detection (DAGAD) framework for attributed graphs, equipped with three specially designed modules: 1) an information fusion module employing graph neural network encoders to learn representations, 2) a graph data augmentation module that fertilizes the training set with generated samples, and 3) an imbalance-tailored learning module to discriminate the distributions of the minority (anomalous) and majority (normal) classes. A series of experiments on three datasets prove that DAGAD outperforms ten state-of-the-art baseline detectors concerning various mostly-used metrics, together with an extensive ablation study validating the strength of our proposed modules.</p></br><a href="https://arxiv.org/pdf/2110.09620v1" target="_blank"><h2>Sufficient Dimension Reduction for High-Dimensional Regression and Low-Dimensional Embedding: Tutorial and Survey</h2></a><strong><u>Authors:</u></strong>  Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley</br><strong><u>Categories:</u></strong> stat.ME, cs.LG, math.ST, stat.ML</br><strong><u>Comments:</u></strong> To appear as a part of an upcoming textbook on dimensionality reduction and manifold learning</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract), dimension reduction (title, abstract)</br><p><strong><u>Abstract:</u></strong> This is a tutorial and survey paper on various methods for Sufficient Dimension Reduction (SDR). We cover these methods with both statistical high-dimensional regression perspective and machine learning approach for dimensionality reduction. We start with introducing inverse regression methods including Sliced Inverse Regression (SIR), Sliced Average Variance Estimation (SAVE), contour regression, directional regression, Principal Fitted Components (PFC), Likelihood Acquired Direction (LAD), and graphical regression. Then, we introduce forward regression methods including Principal Hessian Directions (pHd), Minimum Average Variance Estimation (MAVE), Conditional Variance Estimation (CVE), and deep SDR methods. Finally, we explain Kernel Dimension Reduction (KDR) both for supervised and unsupervised learning. We also show that supervised KDR and supervised PCA are equivalent.</p></br><a href="https://arxiv.org/pdf/2306.14753v1" target="_blank"><h2>The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory</h2></a><strong><u>Authors:</u></strong>  Sergey Oladyshkin, Timothy Praditia, Ilja Kröker, Farid Mohammadi, Wolfgang Nowak, Sebastian Otte</br><strong><u>Categories:</u></strong> cs.NE, stat.ML</br><strong><u>Comments:</u></strong> Submitted to Neural Networks</br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen as a $1^{st}$ degree multi-variate polynomial of single neurons from the previous layer, i.e. linear weighted sum of monomials. From this point of view, the conventional DANN structure relies implicitly (but erroneously) on a Gaussian distribution of neural signals. Additionally, this view revels that by design DANNs do not necessarily fulfill any orthogonality or orthonormality condition for a majority of data-driven applications. Therefore, the prevailing handling of neural signals in DANNs could lead to redundant representation as any neural signal could contain some partial information from other neural signals. To tackle that challenge, we suggest to employ the data-driven generalization of PCE theory known as arbitrary polynomial chaos (aPC) to construct a corresponding multi-variate orthonormal representations on each node of a DANN to obtain Deep arbitrary polynomial chaos neural networks.</p></br></body>