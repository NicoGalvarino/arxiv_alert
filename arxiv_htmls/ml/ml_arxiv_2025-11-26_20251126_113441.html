<!DOCTYPE html><html><head><meta charset='utf-8'><link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>
    body {font-family: 'Montserrat', sans-serif; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}
    h1 {font-size: 70px}
    a {color: #45ABC2}
    em {font-size: 120%}
    </style>
    </head><body><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 25 Nov 2025 to 25 Nov 2025</em></font><br><br><a href="https://arxiv.org/pdf/2511.20641v1" target="_blank"><h2>Unleashing the Power of Vision-Language Models for Long-Tailed Multi-Label Visual Recognition</h2></a><strong><u>Authors:</u></strong> Wei Tang, Zuo-Zheng Wang, Kun Zhang, Tong Wei, Min-Ling Zhang<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> Long-tailed multi-label visual recognition poses a significant challenge, as images typically contain multiple labels with highly imbalanced class distributions, leading to biased models that favor head classes while underperforming on tail classes. Recent efforts have leveraged pre-trained vision-language models, such as CLIP, alongside long-tailed learning techniques to exploit rich visual-textual priors for improved performance. However, existing methods often derive semantic inter-class relationships directly from imbalanced datasets, resulting in unreliable correlations for tail classes due to data scarcity. Moreover, CLIP's zero-shot paradigm is optimized for single-label image-text matching, making it suboptimal for multi-label tasks. To address these issues, we propose the correlation adaptation prompt network (CAPNET), a novel end-to-end framework that explicitly models label correlations from CLIP's textual encoder. The framework incorporates a graph convolutional network for label-aware propagation and learnable soft prompts for refined embeddings. It utilizes a distribution-balanced Focal loss with class-aware re-weighting for optimized training under imbalance. Moreover, it improves generalization through test-time ensembling and realigns visual-textual modalities using parameter-efficient fine-tuning to avert overfitting on tail classes without compromising head class performance. Extensive experiments and ablation studies on benchmarks including VOC-LT, COCO-LT, and NUS-WIDE demonstrate that CAPNET achieves substantial improvements over state-of-the-art methods, validating its effectiveness for real-world long-tailed multi-label visual recognition.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20639v1" target="_blank"><h2>Latent Collaboration in Multi-Agent Systems</h2></a><strong><u>Authors:</u></strong> Jiaru Zou, Xiyuan Yang, Ruizhong Qiu, Gaotang Li, Katherine Tieu, Pan Lu, Ke Shen, Hanghang Tong, Yejin Choi, Jingrui He, James Zou, Mengdi Wang, Ling Yang<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Project:this https URL<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Multi-agent systems (MAS) extend large language models (LLMs) from independent single-model reasoning to coordinative system-level intelligence. While existing LLM agents depend on text-based mediation for reasoning and communication, we take a step forward by enabling models to collaborate directly within the continuous latent space. We introduce LatentMAS, an end-to-end training-free framework that enables pure latent collaboration among LLM agents. In LatentMAS, each agent first performs auto-regressive latent thoughts generation through last-layer hidden embeddings. A shared latent working memory then preserves and transfers each agent's internal representations, ensuring lossless information exchange. We provide theoretical analyses establishing that LatentMAS attains higher expressiveness and lossless information preservation with substantially lower complexity than vanilla text-based MAS. In addition, empirical evaluations across 9 comprehensive benchmarks spanning math and science reasoning, commonsense understanding, and code generation show that LatentMAS consistently outperforms strong single-model and text-based MAS baselines, achieving up to 14.6% higher accuracy, reducing output token usage by 70.8%-83.7%, and providing 4x-4.3x faster end-to-end inference. These results demonstrate that our new latent collaboration framework enhances system-level reasoning quality while offering substantial efficiency gains without any additional training. Code and data are fully open-sourced at https://github.com/Gen-Verse/LatentMAS.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20636v1" target="_blank"><h2>Image2Gcode: Image-to-G-code Generation for Additive Manufacturing Using Diffusion-Transformer Model</h2></a><strong><u>Authors:</u></strong> Ziyue Wang, Yayati Jadhav, Peter Pak, Amir Barati Farimani<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), transformer (title)<br><p><strong><u>Abstract:</u></strong> Mechanical design and manufacturing workflows conventionally begin with conceptual design, followed by the creation of a computer-aided design (CAD) model and fabrication through material-extrusion (MEX) printing. This process requires converting CAD geometry into machine-readable G-code through slicing and path planning. While each step is well established, dependence on CAD modeling remains a major bottleneck: constructing object-specific 3D geometry is slow and poorly suited to rapid prototyping. Even minor design variations typically necessitate manual updates in CAD software, making iteration time-consuming and difficult to scale. To address this limitation, we introduce Image2Gcode, an end-to-end data-driven framework that bypasses the CAD stage and generates printer-ready G-code directly from images and part drawings. Instead of relying on an explicit 3D model, a hand-drawn or captured 2D image serves as the sole input. The framework first extracts slice-wise structural cues from the image and then employs a denoising diffusion probabilistic model (DDPM) over G-code sequences. Through iterative denoising, the model transforms Gaussian noise into executable print-move trajectories with corresponding extrusion parameters, establishing a direct mapping from visual input to native toolpaths. By producing structured G-code directly from 2D imagery, Image2Gcode eliminates the need for CAD or STL intermediates, lowering the entry barrier for additive manufacturing and accelerating the design-to-fabrication cycle. This approach supports on-demand prototyping from simple sketches or visual references and integrates with upstream 2D-to-3D reconstruction modules to enable an automated pipeline from concept to physical artifact. The result is a flexible, computationally efficient framework that advances accessibility in design iteration, repair workflows, and distributed manufacturing.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20627v1" target="_blank"><h2>Fighting AI with AI: Leveraging Foundation Models for Assuring AI-Enabled Safety-Critical Systems</h2></a><strong><u>Authors:</u></strong> Anastasia Mavridou, Divya Gopinath, Corina S. Păsăreanu<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> The integration of AI components, particularly Deep Neural Networks (DNNs), into safety-critical systems such as aerospace and autonomous vehicles presents fundamental challenges for assurance. The opacity of AI systems, combined with the semantic gap between high-level requirements and low-level network representations, creates barriers to traditional verification approaches. These AI-specific challenges are amplified by longstanding issues in Requirements Engineering, including ambiguity in natural language specifications and scalability bottlenecks in formalization. We propose an approach that leverages AI itself to address these challenges through two complementary components. REACT (Requirements Engineering with AI for Consistency and Testing) employs Large Language Models (LLMs) to bridge the gap between informal natural language requirements and formal specifications, enabling early verification and validation. SemaLens (Semantic Analysis of Visual Perception using large Multi-modal models) utilizes Vision Language Models (VLMs) to reason about, test, and monitor DNN-based perception systems using human-understandable concepts. Together, these components provide a comprehensive pipeline from informal requirements to validated implementations.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20626v1" target="_blank"><h2>ROOT: Robust Orthogonalized Optimizer for Neural Network Training</h2></a><strong><u>Authors:</u></strong> Wei He, Kai Han, Hang Zhou, Hanting Chen, Zhicheng Liu, Xinghao Chen, Yunhe Wang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title)<br><p><strong><u>Abstract:</u></strong> The optimization of large language models (LLMs) remains a critical challenge, particularly as model scaling exacerbates sensitivity to algorithmic imprecision and training instability. Recent advances in optimizers have improved convergence efficiency through momentum orthogonalization, but suffer from two key robustness limitations: dimensional fragility in orthogonalization precision and vulnerability to outlier-induced noise. To address these robustness challenges, we introduce ROOT, a Robust Orthogonalized Optimizer that enhances training stability through dual robustness mechanisms. First, we develop a dimension-robust orthogonalization scheme using adaptive Newton iterations with fine-grained coefficients tailored to specific matrix sizes, ensuring consistent precision across diverse architectural configurations. Second, we introduce an optimization-robust framework via proximal optimization that suppresses outlier noise while preserving meaningful gradient directions. Extensive experiments demonstrate that ROOT achieves significantly improved robustness, with faster convergence and superior final performance compared to both Muon and Adam-based optimizers, particularly in noisy and non-convex scenarios. Our work establishes a new paradigm for developing robust and precise optimizers capable of handling the complexities of modern large-scale model training. The code will be available at https://github.com/huawei-noah/noah-research/tree/master/ROOT.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20615v1" target="_blank"><h2>Evaluating the Performance of Deep Learning Models in Whole-body Dynamic 3D Posture Prediction During Load-reaching Activities</h2></a><strong><u>Authors:</u></strong> Seyede Niloofar Hosseini, Ali Mojibi, Mahdi Mohseni, Navid Arjmand, Alireza Taheri<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 6 figures, 7 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> This study aimed to explore the application of deep neural networks for whole-body human posture prediction during dynamic load-reaching activities. Two time-series models were trained using bidirectional long short-term memory (BLSTM) and transformer architectures. The dataset consisted of 3D full-body plug-in gait dynamic coordinates from 20 normal-weight healthy male individuals each performing 204 load-reaching tasks from different load positions while adapting various lifting and handling techniques. The model inputs consisted of the 3D position of the hand-load position, lifting (stoop, full-squat and semi-squat) and handling (one- and two-handed) techniques, body weight and height, and the 3D coordinate data of the body posture from the first 25% of the task duration. These inputs were used by the models to predict body coordinates during the remaining 75% of the task period. Moreover, a novel method was proposed to improve the accuracy of the previous and present posture prediction networks by enforcing constant body segment lengths through the optimization of a new cost function. The results indicated that the new cost function decreased the prediction error of the models by approximately 8% and 21% for the arm and leg models, respectively. We indicated that utilizing the transformer architecture, with a root-mean-square-error of 47.0 mm, exhibited ~58% more accurate long-term performance than the BLSTM-based model. This study merits the use of neural networks that capture time series dependencies in 3D motion frames, providing a unique approach for understanding and predict motion dynamics during manual material handling activities.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20612v1" target="_blank"><h2>Sparse-to-Field Reconstruction via Stochastic Neural Dynamic Mode Decomposition</h2></a><strong><u>Authors:</u></strong> Yujin Kim, Sarah Dean<br><strong><u>Categories:</u></strong> cs.LG, eess.SY<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Many consequential real-world systems, like wind fields and ocean currents, are dynamic and hard to model. Learning their governing dynamics remains a central challenge in scientific machine learning. Dynamic Mode Decomposition (DMD) provides a simple, data-driven approximation, but practical use is limited by sparse/noisy observations from continuous fields, reliance on linear approximations, and the lack of principled uncertainty quantification. To address these issues, we introduce Stochastic NODE-DMD, a probabilistic extension of DMD that models continuous-time, nonlinear dynamics while remaining interpretable. Our approach enables continuous spatiotemporal reconstruction at arbitrary coordinates and quantifies predictive uncertainty. Across four benchmarks, a synthetic setting and three physics-based flows, it surpasses a baseline in reconstruction accuracy when trained from only 10% observation density. It further recovers the dynamical structure by aligning learned modes and continuous-time eigenvalues with ground truth. Finally, on datasets with multiple realizations, our method learns a calibrated distribution over latent dynamics that preserves ensemble variability rather than averaging across regimes. Our code is available at: https://github.com/sedan-group/Stochastic-NODE-DMD</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20595v1" target="_blank"><h2>Inferring the Impacts of Baryonic Feedback from Kinetic Sunyaev-Zeldovich Cross-Correlations <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Alex Laguë, Mathew S. Madhavacheril, Josh Borrow, Kendrick M. Smith, Xinyi Chen, Matthieu Schaller, Joop Schaye<br><strong><u>Categories:</u></strong> astro-ph.CO<br><strong><u>Comments:</u></strong> Comments welcome<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The complex processes of baryonic feedback associated with galaxy evolution are still poorly understood, and their impact on the clustering of matter on small scales remains difficult to quantify. While many fitting functions and emulators exist to model the matter power spectrum, their input parameters are not directly observable. However, recent studies using hydrodynamical simulations have identified a promising correlation between the gas content of halos and changes to the matter power spectrum from feedback. Building on these findings, we create the first fully data-driven power spectrum emulator. We utilize the kinematic Sunyaev-Zeldovich (kSZ) effect, a secondary anisotropy in the cosmic microwave background, as a tracer of free electrons in and around halos. We train a neural network to learn the mapping between the suppression of the matter power spectrum and the shape of the kSZ power spectrum extracted with a radial velocity template. We train and validate our algorithm using the FLAMINGO suite of hydrodynamical simulations, which encompasses a wide range of feedback models. Our emulator can reconstruct the matter power spectrum at the sub-percent level for scales $k\leq 5\;h/$Mpc and $0.2\leq z \leq 1.25$ directly from the data. Our model is robust and retains percent-level accuracy even for feedback models and cosmological parameter values not seen during training (except in a few extreme cases drastically different from the fiducial model). Due to its robustness, our algorithm offers a new way to identify the sources of suppression in the matter power spectrum, breaking the degeneracies between baryonic feedback and new physics. Finally, we present a forecast for reconstruction of the matter power spectrum combining maps of the microwave background anisotropies from a Simons Observatory-like experiment and galaxy catalogs from the Dark Energy Spectroscopic Instrument.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20594v1" target="_blank"><h2>Variational bagging: a robust approach for Bayesian uncertainty quantification</h2></a><strong><u>Authors:</u></strong> Shitao Fan, Ilsang Ohn, David Dunson, Lizhen Lin<br><strong><u>Categories:</u></strong> math.ST, stat.ML<br><strong><u>Comments:</u></strong> 44 pages, 14 figures<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Variational Bayes methods are popular due to their computational efficiency and adaptability to diverse applications. In specifying the variational family, mean-field classes are commonly used, which enables efficient algorithms such as coordinate ascent variational inference (CAVI) but fails to capture parameter dependence and typically underestimates uncertainty. In this work, we introduce a variational bagging approach that integrates a bagging procedure with variational Bayes, resulting in a bagged variational posterior for improved inference. We establish strong theoretical guarantees, including posterior contraction rates for general models and a Bernstein-von Mises (BVM) type theorem that ensures valid uncertainty quantification. Notably, our results show that even when using a mean-field variational family, our approach can recover off-diagonal elements of the limiting covariance structure and provide proper uncertainty quantification. In addition, variational bagging is robust to model misspecification, with covariance structures matching those of the target covariance. We illustrate our variational bagging method in numerical studies through applications to parametric models, finite mixture models, deep neural networks, and variational autoencoders (VAEs).</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20592v1" target="_blank"><h2>Latent Diffusion Inversion Requires Understanding the Latent Space</h2></a><strong><u>Authors:</u></strong> Mingxing Rao, Bowen Qu, Daniel Moyer<br><strong><u>Categories:</u></strong> cs.LG, cs.CV<br><strong><u>Comments:</u></strong> 14 pages, 4 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> latent space (title, abstract)<br><p><strong><u>Abstract:</u></strong> The recovery of training data from generative models (``model inversion'') has been extensively studied for diffusion models in the data domain. The encoder/decoder pair and corresponding latent codes have largely been ignored by inversion techniques applied to latent space generative models, e.g., Latent Diffusion models (LDMs). In this work we describe two key findings: (1) The diffusion model exhibits non-uniform memorization across latent codes, tending to overfit samples located in high-distortion regions of the decoder pullback metric. (2) Even within a single latent code, different dimensions contribute unequally to memorization. We introduce a principled method to rank latent dimensions by their per-dimensional contribution to the decoder pullback metric, identifying those most responsible for memorization. Empirically, removing less-memorizing dimensions when computing attack statistics for score-based membership inference attacker significantly improves performance, with average AUROC gains of 2.7\% and substantial increases in TPR@1\%FPR (6.42\%) across diverse datasets including CIFAR-10, CelebA, ImageNet-1K, Pokémon, MS-COCO, and Flickr. This indicates stronger confidence in identifying members under extremely low false-positive tolerance. Our results highlight the overlooked influence of the auto-encoder geometry on LDM memorization and provide a new perspective for analyzing privacy risks in diffusion-based generative models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20591v1" target="_blank"><h2>Attention Trajectories as a Diagnostic Axis for Deep Reinforcement Learning</h2></a><strong><u>Authors:</u></strong> Charlotte Beylier, Hannah Selder, Arthur Fleig, Simon M. Hofmann, Nico Scherf<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> The learning process of a reinforcement learning (RL) agent remains poorly understood beyond the mathematical formulation of its learning algorithm. To address this gap, we introduce attention-oriented metrics (ATOMs) to investigate the development of an RL agent's attention during training. In a controlled experiment, we tested ATOMs on three variations of a Pong game, each designed to teach the agent distinct behaviours, complemented by a behavioural assessment. ATOMs successfully delineate the attention patterns of an agent trained on each game variation, and that these differences in attention patterns translate into differences in the agent's behaviour. Through continuous monitoring of ATOMs during training, we observed that the agent's attention developed in phases, and that these phases were consistent across game variations. Overall, we believe that ATOM could help improve our understanding of the learning processes of RL agents and better understand the relationship between attention and learning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20586v1" target="_blank"><h2>PaTAS: A Parallel System for Trust Propagation in Neural Networks Using Subjective Logic</h2></a><strong><u>Authors:</u></strong> Koffi Ismael Ouattara, Ioannis Krontiris, Theo Dimitrakos, Dennis Eisermann, Frank Kargl<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Trustworthiness has become a key requirement for the deployment of artificial intelligence systems in safety-critical applications. Conventional evaluation metrics such as accuracy and precision fail to capture uncertainty or the reliability of model predictions, particularly under adversarial or degraded conditions. This paper introduces the \emph{Parallel Trust Assessment System (PaTAS)}, a framework for modeling and propagating trust in neural networks using Subjective Logic (SL). PaTAS operates in parallel with standard neural computation through \emph{Trust Nodes} and \emph{Trust Functions} that propagate input, parameter, and activation trust across the network. The framework defines a \emph{Parameter Trust Update} mechanism to refine parameter reliability during training and an \emph{Inference-Path Trust Assessment (IPTA)} method to compute instance-specific trust at inference. Experiments on real-world and adversarial datasets demonstrate that PaTAS produces interpretable, symmetric, and convergent trust estimates that complement accuracy and expose reliability gaps in poisoned, biased, or uncertain data scenarios. The results show that PaTAS effectively distinguishes between benign and adversarial inputs and identifies cases where model confidence diverges from actual reliability. By enabling transparent and quantifiable trust reasoning within neural architectures, PaTAS provides a principled foundation for evaluating model reliability across the AI lifecycle.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20577v1" target="_blank"><h2>MSTN: Fast and Efficient Multivariate Time Series Model</h2></a><strong><u>Authors:</u></strong> Sumit S Shevtekar, Chandresh K Maurya, Gourab Sil<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 21 pages, 1 figure, 5 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Real-world time-series data is highly non stationary and complex in dynamics that operate across multiple timescales, ranging from fast, short-term changes to slow, long-term trends. Most existing models rely on fixed-scale structural priors, such as patch-based tokenization, fixed frequency transformations, or frozen backbone architectures. This often leads to over-regularization of temporal dynamics, which limits their ability to adaptively model the full spectrum of temporal variations and impairs their performance on unpredictable, Sudden, high-magnitude events. To address this, we introduce the Multi-scale Temporal Network (MSTN), a novel deep learning architecture founded on a hierarchical multi-scale and sequence modeling principle. The MSTN framework integrates: (i) a multi-scale convolutional encoder that constructs a hierarchical feature pyramid for local patterns (ii) a sequence modeling component for long-range temporal dependencies. We empirically validate this with BiLSTM and Transformer variants, establishing a flexible foundation for future architectural advancements. and (iii) a gated fusion mechanism augmented with squeeze-and-excitation (SE) and multi-head temporal attention (MHTA) for dynamic, context-aware feature integration. This design enables MSTN to adaptively model temporal patterns from milliseconds to long-range dependencies within a unified framework. Extensive evaluations across time-series long-horizon forecasting, imputation, classification and generalizability study demonstrate that MSTN achieves competitive state-of-the-art (SOTA) performance, showing improvements over contemporary approaches including EMTSF, LLM4TS, HiMTM, TIME-LLM, MTST, SOFTS, iTransformer, TimesNet, and PatchTST. In total, MSTN establishes new SOTA performance on 24 of 32 benchmark datasets, demonstrating its consistent performance across diverse temporal tasks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20564v1" target="_blank"><h2>E2E-GRec: An End-to-End Joint Training Framework for Graph Neural Networks and Recommender Systems</h2></a><strong><u>Authors:</u></strong> Rui Xue, Shichao Zhu, Liang Qin, Guangmou Pan, Yang Song, Tianfu Wu<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) have emerged as powerful tools for modeling graph-structured data and have been widely used in recommender systems, such as for capturing complex user-item and item-item relations. However, most industrial deployments adopt a two-stage pipeline: GNNs are first pre-trained offline to generate node embeddings, which are then used as static features for downstream recommender systems. This decoupled paradigm leads to two key limitations: (1) high computational overhead, since large-scale GNN inference must be repeatedly executed to refresh embeddings; and (2) lack of joint optimization, as the gradient from the recommender system cannot directly influence the GNN learning process, causing the GNN to be suboptimally informative for the recommendation task. In this paper, we propose E2E-GRec, a novel end-to-end training framework that unifies GNN training with the recommender system. Our framework is characterized by three key components: (i) efficient subgraph sampling from a large-scale cross-domain heterogeneous graph to ensure training scalability and efficiency; (ii) a Graph Feature Auto-Encoder (GFAE) serving as an auxiliary self-supervised task to guide the GNN to learn structurally meaningful embeddings; and (iii) a two-level feature fusion mechanism combined with Gradnorm-based dynamic loss balancing, which stabilizes graph-aware multi-task end-to-end training. Extensive offline evaluations, online A/B tests (e.g., a +0.133% relative improvement in stay duration, a 0.3171% reduction in the average number of videos a user skips) on large-scale production data, together with theoretical analysis, demonstrate that E2E-GRec consistently surpasses traditional approaches, yielding significant gains across multiple recommendation metrics.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20551v1" target="_blank"><h2>Time-Domain Linear Model-based Framework for Passive Acoustic Mapping of Cavitation Activity</h2></a><strong><u>Authors:</u></strong> Tatiana Gelvez-Barrera, Barbara Nicolas, Denis Kouamé, Bruno Gilles, Adrian Basarab<br><strong><u>Categories:</u></strong> eess.SP, cs.AI, eess.IV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> time-domain (title, abstract)<br><p><strong><u>Abstract:</u></strong> Passive acoustic mapping enables the spatial mapping and temporal monitoring of cavitation activity, playing a crucial role in therapeutic ultrasound applications. Most conventional beamforming methods, whether implemented in the time or frequency domains, suffer from limited axial resolution due to the absence of a reference emission onset time. While frequency-domain methods, the most efficient of which are based on the cross-spectral matrix, require long signals for accurate estimation, time-domain methods typically achieve lower spatial resolution. To address these limitations, we propose a linear model-based beamforming framework fully formulated in the time domain. The linear forward model relates a discretized spatiotemporal distribution of cavitation activity to the temporal signals recorded by a probe, explicitly accounting for time-of-flight delays dictated by the acquisition geometry. This model is then inverted using regularization techniques that exploit prior knowledge of cavitation activity in both spatial and temporal domains. Experimental results show that the proposed framework achieves enhanced or competitive cavitation map quality while using only 20\% of the data typically required by frequency-domain methods. This highlights the substantial gain in data efficiency and the flexibility of our spatiotemporal regularization to adapt to diverse passive cavitation scenarios, outperforming state-of-the-art techniques.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20544v1" target="_blank"><h2>New York Smells: A Large Multimodal Dataset for Olfaction</h2></a><strong><u>Authors:</u></strong> Ege Ozguroglu, Junbang Liang, Ruoshi Liu, Mia Chiquier, Michael DeTienne, Wesley Wei Qian, Alexandra Horowitz, Andrew Owens, Carl Vondrick<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Project website atthis https URL<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> While olfaction is central to how animals perceive the world, this rich chemical sensory modality remains largely inaccessible to machines. One key bottleneck is the lack of diverse, multimodal olfactory training data collected in natural settings. We present New York Smells, a large dataset of paired image and olfactory signals captured ``in the wild.'' Our dataset contains 7,000 smell-image pairs from 3,500 distinct objects across indoor and outdoor environments, with approximately 70$\times$ more objects than existing olfactory datasets. Our benchmark has three tasks: cross-modal smell-to-image retrieval, recognizing scenes, objects, and materials from smell alone, and fine-grained discrimination between grass species. Through experiments on our dataset, we find that visual data enables cross-modal olfactory representation learning, and that our learned olfactory representations outperform widely-used hand-crafted features.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20542v1" target="_blank"><h2>H II regions and supernova remnants associated with molecular clouds: A pilot study with the SARAO MeerKAT Galactic Plane Survey <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Moses O. Langa, Mark A. Thompson, Andrew J. Rigby, Gwenllian M. Williams, Mubela Mutale, Paul O. Baki, James O. Chibueze, Willice O. Obonyo<br><strong><u>Categories:</u></strong> astro-ph.GA<br><strong><u>Comments:</u></strong> This paper has been accepted for publication in Monthly Notices of the Royal Astronomical Society (MNRAS)<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> Massive stars (mass beyond 8 solMass) release vast amounts of energy into the interstellar medium through their stellar winds, photoionising radiation and supernova explosions. These processes may compress nearby regions, triggering further star formation, but the significance of triggered star formation across the Galactic disc is not well understood. This pilot study combines 1.3 GHz continuum data from the South African Radio Astronomy Observatory (SARAO) MeerKAT Galactic Plane Survey (SMGPS) with 13CO (2-1) data from the Structure, Excitation, and Dynamics of the Inner Galactic Interstellar Medium (SEDIGISM) survey to identify and examine molecular clouds associated with H II regions and supernovae remnants (SNRs). We focus on their physical properties and massive star formation potential. We identify 268 molecular clouds from the SEDIGISM tile covering the Galactic plane region between 341 and 343 longitude deg and latitude deg equal to or less 0.5, of which 90 clouds (34 per cent) are associated with SMGPS extended sources. Compared to unassociated clouds, we find that associated clouds exhibit significantly higher mean mass (9600 solMass vs. 2500 solMass ) and average gas surface density (104 solMass / pc^2 vs. 67 solMass / pc^2 ), and slightly elevated but comparable virial parameters. We also find that the size-linewidth scaling relation is steeper for associated clouds compared to unassociated clouds. In addition, radio luminosity shows a positive correlation with total complex mass, and the ratio L_radio/L_complex increases with source size, consistent with an evolutionary sequence where expanding H II regions progressively disrupt their natal molecular environment. These findings suggest an enhanced dynamical activity for the associated clouds and support the hypothesis that feedback from massive stars influences molecular cloud properties and may trigger star formation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20541v1" target="_blank"><h2>Automated Monitoring of Cultural Heritage Artifacts Using Semantic Segmentation</h2></a><strong><u>Authors:</u></strong> Andrea Ranieri, Giorgio Palmieri, Silvia Biasotti<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Keywords: Cultural Heritage, Monitoring, Deep Learning, U-Nets, Semantic Segmentation<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> This paper addresses the critical need for automated crack detection in the preservation of cultural heritage through semantic segmentation. We present a comparative study of U-Net architectures, using various convolutional neural network (CNN) encoders, for pixel-level crack identification on statues and monuments. A comparative quantitative evaluation is performed on the test set of the OmniCrack30k dataset [1] using popular segmentation metrics including Mean Intersection over Union (mIoU), Dice coefficient, and Jaccard index. This is complemented by an out-of-distribution qualitative evaluation on an unlabeled test set of real-world cracked statues and monuments. Our findings provide valuable insights into the capabilities of different CNN- based encoders for fine-grained crack segmentation. We show that the models exhibit promising generalization capabilities to unseen cultural heritage contexts, despite never having been explicitly trained on images of statues or monuments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20531v1" target="_blank"><h2>Beyond Generation: Multi-Hop Reasoning for Factual Accuracy in Vision-Language Models</h2></a><strong><u>Authors:</u></strong> Shamima Hossain<br><strong><u>Categories:</u></strong> cs.AI, cs.CV, cs.LG<br><strong><u>Comments:</u></strong> Accepted as poster at NewInML Workshop ICML, 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Visual Language Models (VLMs) are powerful generative tools but often produce factually inaccurate outputs due to a lack of robust reasoning capabilities. While extensive research has been conducted on integrating external knowledge for reasoning in large language models (LLMs), such efforts remain underexplored in VLMs, where the challenge is compounded by the need to bridge multiple modalities seamlessly. This work introduces a framework for knowledge-guided reasoning in VLMs, leveraging structured knowledge graphs for multi-hop verification using image-captioning task to illustrate our framework. Our approach enables systematic reasoning across multiple steps, including visual entity recognition, knowledge graph traversal, and fact-based caption refinement. We evaluate the framework using hierarchical, triple-based and bullet-point based knowledge representations, analyzing their effectiveness in factual accuracy and logical inference. Empirical results show that our approach improves factual accuracy by approximately 31% on preliminary experiments on a curated dataset of mixtures from Google Landmarks v2, Conceptual captions and Coco captions revealing key insights into reasoning patterns and failure modes. This work demonstrates the potential of integrating external knowledge for advancing reasoning in VLMs, paving the way for more reliable and knowledgable multimodal systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20509v1" target="_blank"><h2>DP-MicroAdam: Private and Frugal Algorithm for Training and Fine-tuning</h2></a><strong><u>Authors:</u></strong> Mihaela Hudişteanu, Edwige Cyffers, Nikita P. Kalinin<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Adaptive optimizers are the de facto standard in non-private training as they often enable faster convergence and improved performance. In contrast, differentially private (DP) training is still predominantly performed with DP-SGD, typically requiring extensive compute and hyperparameter tuning. We propose DP-MicroAdam, a memory-efficient and sparsity-aware adaptive DP optimizer. We prove that DP-MicroAdam converges in stochastic non-convex optimization at the optimal $\mathcal{O}(1/\sqrt{T})$ rate, up to privacy-dependent constants. Empirically, DP-MicroAdam outperforms existing adaptive DP optimizers and achieves competitive or superior accuracy compared to DP-SGD across a range of benchmarks, including CIFAR-10, large-scale ImageNet training, and private fine-tuning of pretrained transformers. These results demonstrate that adaptive optimization can improve both performance and stability under differential privacy.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20501v1" target="_blank"><h2>A Physics-Informed Loss Function for Boundary-Consistent and Robust Artery Segmentation in DSA Sequences</h2></a><strong><u>Authors:</u></strong> Muhammad Irfan, Nasir Rahim, Khalid Mahmood Malik<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate extraction and segmentation of the cerebral arteries from digital subtraction angiography (DSA) sequences is essential for developing reliable clinical management models of complex cerebrovascular diseases. Conventional loss functions often rely solely on pixel-wise overlap, overlooking the geometric and physical consistency of vascular boundaries, which can lead to fragmented or unstable vessel predictions. To overcome this limitation, we propose a novel \textit{Physics-Informed Loss} (PIL) that models the interaction between the predicted and ground-truth boundaries as an elastic process inspired by dislocation theory in materials physics. This formulation introduces a physics-based regularization term that enforces smooth contour evolution and structural consistency, allowing the network to better capture fine vascular geometry. The proposed loss is integrated into several segmentation architectures, including U-Net, U-Net++, SegFormer, and MedFormer, and evaluated on two public benchmarks: DIAS and DSCA. Experimental results demonstrate that PIL consistently outperforms conventional loss functions such as Cross-Entropy, Dice, Active Contour, and Surface losses, achieving superior sensitivity, F1 score, and boundary coherence. These findings confirm that the incorporation of physics-based boundary interactions into deep neural networks improves both the precision and robustness of vascular segmentation in dynamic angiographic imaging. The implementation of the proposed method is publicly available at https://github.com/irfantahir301/Physicsis_loss.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20500v1" target="_blank"><h2>From One Attack Domain to Another: Contrastive Transfer Learning with Siamese Networks for APT Detection</h2></a><strong><u>Authors:</u></strong> Sidahmed Benabderrahmane, Talal Rahwan<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CR, cs.NE<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> explainable (abstract), transfer learning (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Advanced Persistent Threats (APT) pose a major cybersecurity challenge due to their stealth, persistence, and adaptability. Traditional machine learning detectors struggle with class imbalance, high dimensional features, and scarce real world traces. They often lack transferability-performing well in the training domain but degrading in novel attack scenarios. We propose a hybrid transfer framework that integrates Transfer Learning, Explainable AI (XAI), contrastive learning, and Siamese networks to improve cross-domain generalization. An attention-based autoencoder supports knowledge transfer across domains, while Shapley Additive exPlanations (SHAP) select stable, informative features to reduce dimensionality and computational cost. A Siamese encoder trained with a contrastive objective aligns source and target representations, increasing anomaly separability and mitigating feature drift. We evaluate on real-world traces from the DARPA Transparent Computing (TC) program and augment with synthetic attack scenarios to test robustness. Across source to target transfers, the approach delivers improved detection scores with classical and deep baselines, demonstrating a scalable, explainable, and transferable solution for APT detection.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20490v1" target="_blank"><h2>MTBBench: A Multimodal Sequential Clinical Decision-Making Benchmark in Oncology</h2></a><strong><u>Authors:</u></strong> Kiril Vasilev, Alexandre Misrahi, Eeshaan Jain, Phil F Cheng, Petros Liakopoulos, Olivier Michielin, Michael Moor, Charlotte Bunne<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted to NeurIPS 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Large Language Models (LLMs) hold promise for biomedical reasoning, but current benchmarks fail to capture the complexity of real-world clinical workflows. Existing evaluations primarily assess unimodal, decontextualized question-answering, overlooking multi-agent decision-making environments such as Molecular Tumor Boards (MTBs). MTBs bring together diverse experts in oncology, where diagnostic and prognostic tasks require integrating heterogeneous data and evolving insights over time. Current benchmarks lack this longitudinal and multimodal complexity. We introduce MTBBench, an agentic benchmark simulating MTB-style decision-making through clinically challenging, multimodal, and longitudinal oncology questions. Ground truth annotations are validated by clinicians via a co-developed app, ensuring clinical relevance. We benchmark multiple open and closed-source LLMs and show that, even at scale, they lack reliability -- frequently hallucinating, struggling with reasoning from time-resolved data, and failing to reconcile conflicting evidence or different modalities. To address these limitations, MTBBench goes beyond benchmarking by providing an agentic framework with foundation model-based tools that enhance multi-modal and longitudinal reasoning, leading to task-level performance gains of up to 9.0% and 11.2%, respectively. Overall, MTBBench offers a challenging and realistic testbed for advancing multimodal LLM reasoning, reliability, and tool-use with a focus on MTB environments in precision oncology.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20480v1" target="_blank"><h2>Ranking-Enhanced Anomaly Detection Using Active Learning-Assisted Attention Adversarial Dual AutoEncoders</h2></a><strong><u>Authors:</u></strong> Sidahmed Benabderrahmane, James Cheney, Talal Rahwan<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CR, cs.NE<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Advanced Persistent Threats (APTs) pose a significant challenge in cybersecurity due to their stealthy and long-term nature. Modern supervised learning methods require extensive labeled data, which is often scarce in real-world cybersecurity environments. In this paper, we propose an innovative approach that leverages AutoEncoders for unsupervised anomaly detection, augmented by active learning to iteratively improve the detection of APT anomalies. By selectively querying an oracle for labels on uncertain or ambiguous samples, we minimize labeling costs while improving detection rates, enabling the model to improve its detection accuracy with minimal data while reducing the need for extensive manual labeling. We provide a detailed formulation of the proposed Attention Adversarial Dual AutoEncoder-based anomaly detection framework and show how the active learning loop iteratively enhances the model. The framework is evaluated on real-world imbalanced provenance trace databases produced by the DARPA Transparent Computing program, where APT-like attacks constitute as little as 0.004\% of the data. The datasets span multiple operating systems, including Android, Linux, BSD, and Windows, and cover two attack scenarios. The results have shown significant improvements in detection rates during active learning and better performance compared to other existing approaches.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20474v1" target="_blank"><h2>Modular Deep Learning Framework for Assistive Perception: Gaze, Affect, and Speaker Identification</h2></a><strong><u>Authors:</u></strong> Akshit Pramod Anchan, Jewelith Thomas, Sritama Roy<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 10 pages, 9 figures, and 3 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multimodal (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Developing comprehensive assistive technologies requires the seamless integration of visual and auditory perception. This research evaluates the feasibility of a modular architecture inspired by core functionalities of perceptive systems like 'Smart Eye.' We propose and benchmark three independent sensing modules: a Convolutional Neural Network (CNN) for eye state detection (drowsiness/attention), a deep CNN for facial expression recognition, and a Long Short-Term Memory (LSTM) network for voice-based speaker identification. Utilizing the Eyes Image, FER2013, and customized audio datasets, our models achieved accuracies of 93.0%, 97.8%, and 96.89%, respectively. This study demonstrates that lightweight, domain-specific models can achieve high fidelity on discrete tasks, establishing a validated foundation for future real-time, multimodal integration in resource-constrained assistive devices.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20471v1" target="_blank"><h2>Universe of Thoughts: Enabling Creative Reasoning with Large Language Models</h2></a><strong><u>Authors:</u></strong> Yuto Suzuki, Farnoush Banaei-Kashani<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Reasoning based on Large Language Models (LLMs) has garnered increasing attention due to outstanding performance of these models in mathematical and complex logical tasks. Beginning with the Chain-of-Thought (CoT) prompting technique, numerous reasoning methods have emerged that decompose problems into smaller, sequential steps (or thoughts). However, existing reasoning models focus on conventional problem-solving and do not necessarily generate creative solutions by ``creative reasoning''. In domains where the solution space is expansive and conventional solutions are suboptimal, such as drug discovery or business strategization, creative reasoning to discover innovative solutions is crucial. To address this gap, first we introduce a computational framework for creative reasoning inspired by established cognitive science principles. With this framework, we propose three core creative reasoning paradigms, namely, \textit{combinational}, \textit{exploratory}, and \textit{transformative} reasoning, where each offers specific directions for systematic exploration of the universe of thoughts to generate creative solutions. Next, to materialize this framework using LLMs, we introduce the \textit{Universe of Thoughts} (or \textit{UoT}, for short), a novel set of methods to implement the aforementioned three creative processes. Finally, we introduce three novel tasks that necessitate creative problem-solving, along with an evaluation benchmark to assess creativity from three orthogonal perspectives: feasibility as constraint, and utility and novelty as metrics. With a comparative analysis against the state-of-the-art (SOTA) reasoning techniques as well as representative commercial models with reasoning capability, we show that UoT demonstrates superior performance in creative reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20470v1" target="_blank"><h2>Efficient and Fast Generative-Based Singing Voice Separation using a Latent Diffusion Model</h2></a><strong><u>Authors:</u></strong> Genís Plaja-Roglans, Yun-Ning Hung, Xavier Serra, Igor Pereira<br><strong><u>Categories:</u></strong> cs.SD, cs.AI<br><strong><u>Comments:</u></strong> Accepted for oral presentation at IJCNN 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Extracting individual elements from music mixtures is a valuable tool for music production and practice. While neural networks optimized to mask or transform mixture spectrograms into the individual source(s) have been the leading approach, the source overlap and correlation in music signals poses an inherent challenge. Also, accessing all sources in the mixture is crucial to train these systems, while complicated. Attempts to address these challenges in a generative fashion exist, however, the separation performance and inference efficiency remain limited. In this work, we study the potential of diffusion models to advance toward bridging this gap, focusing on generative singing voice separation relying only on corresponding pairs of isolated vocals and mixtures for training. To align with creative workflows, we leverage latent diffusion: the system generates samples encoded in a compact latent space, and subsequently decodes these into audio. This enables efficient optimization and faster inference. Our system is trained using only open data. We outperform existing generative separation systems, and level the compared non-generative systems on a list of signal quality measures and on interference removal. We provide a noise robustness study on the latent encoder, providing insights on its potential for the task. We release a modular toolkit for further research on the topic.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20462v1" target="_blank"><h2>STARFlow-V: End-to-End Video Generative Modeling with Normalizing Flow</h2></a><strong><u>Authors:</u></strong> Jiatao Gu, Ying Shen, Tianrong Chen, Laurent Dinh, Yuyang Wang, Miguel Angel Bautista, David Berthelot, Josh Susskind, Shuangfei Zhai<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 21 pages<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), attention (abstract), causality (abstract)<br><p><strong><u>Abstract:</u></strong> Normalizing flows (NFs) are end-to-end likelihood-based generative models for continuous data, and have recently regained attention with encouraging progress on image generation. Yet in the video generation domain, where spatiotemporal complexity and computational cost are substantially higher, state-of-the-art systems almost exclusively rely on diffusion-based models. In this work, we revisit this design space by presenting STARFlow-V, a normalizing flow-based video generator with substantial benefits such as end-to-end learning, robust causal prediction, and native likelihood estimation. Building upon the recently proposed STARFlow, STARFlow-V operates in the spatiotemporal latent space with a global-local architecture which restricts causal dependencies to a global latent space while preserving rich local within-frame interactions. This eases error accumulation over time, a common pitfall of standard autoregressive diffusion model generation. Additionally, we propose flow-score matching, which equips the model with a light-weight causal denoiser to improve the video generation consistency in an autoregressive fashion. To improve the sampling efficiency, STARFlow-V employs a video-aware Jacobi iteration scheme that recasts inner updates as parallelizable iterations without breaking causality. Thanks to the invertible structure, the same model can natively support text-to-video, image-to-video as well as video-to-video generation tasks. Empirically, STARFlow-V achieves strong visual fidelity and temporal consistency with practical sampling throughput relative to diffusion-based baselines. These results present the first evidence, to our knowledge, that NFs are capable of high-quality autoregressive video generation, establishing them as a promising research direction for building world models. Code and generated samples are available at https://github.com/apple/ml-starflow.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20459v1" target="_blank"><h2>Generation, Evaluation, and Explanation of Novelists' Styles with Single-Token Prompts</h2></a><strong><u>Authors:</u></strong> Mosab Rezaei, Mina Rajaei Moghadam, Abdul Rahman Shaikh, Hamed Alhoori, Reva Freedman<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> explainable (abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in large language models have created new opportunities for stylometry, the study of writing styles and authorship. Two challenges, however, remain central: training generative models when no paired data exist, and evaluating stylistic text without relying only on human judgment. In this work, we present a framework for both generating and evaluating sentences in the style of 19th-century novelists. Large language models are fine-tuned with minimal, single-token prompts to produce text in the voices of authors such as Dickens, Austen, Twain, Alcott, and Melville. To assess these generative models, we employ a transformer-based detector trained on authentic sentences, using it both as a classifier and as a tool for stylistic explanation. We complement this with syntactic comparisons and explainable AI methods, including attention-based and gradient-based analyses, to identify the linguistic cues that drive stylistic imitation. Our findings show that the generated text reflects the authors' distinctive patterns and that AI-based evaluation offers a reliable alternative to human assessment. All artifacts of this work are published online.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20452v1" target="_blank"><h2>A Self-Consistent Model of the Ultra High-Energy Gamma-Ray Emission of Pulsar Wind Nebulae: Insights from LHAASO and ATNF Catalogs</h2></a><strong><u>Authors:</u></strong> Samy Kaci, Gwenael Giacinti, Dmitri Semikoz<br><strong><u>Categories:</u></strong> astro-ph.HE<br><strong><u>Comments:</u></strong> 15 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Pulsar wind nebulae (PWNe) are the dominant Ultra-high-energy (UHE) gamma-ray sources in the LHAASO catalog suggesting that they are the dominant leptonic PeVatrons in our Galaxy. Despite this, still very little is known about their UHE gamma-ray emission, their number in the Galaxy, or their contribution to the gamma-ray emission of our Galaxy. In this work, we propose a self-consistent data-driven model of the UHE gamma-ray emission of PWNe based on the ATNF and LHAASO catalogs. More specifically, we build a model of the UHE gamma-ray emission of PWNe that preserves the statistical relationships in the ATNF catalog and reproduces the number of PWNe detected in the LHAASO catalog. To cope with the limited data available in the LHAASO catalog when performing fits on gamma-ray data, we introduce the concept of censored regression that allows to also use the information provided by unresolved sources. Using our model, we find that reproducing the number of PWNe detected by LHAASO requires either fractions of misaligned pulsars smaller ($\lesssim60\%$) than usually found in the literature, or that some of the associations of PWNe to ATNF pulsars made by LHAASO may not be true. In both cases, we find that in order to reach self-consistency between radio and gamma-ray data, it is necessary that the majority of the unidentified sources in the LHAASO catalog are PWNe associated to an unseen pulsar. Moreover, using our model we also find that the contribution of unresolved PWNe to the total (diffuse) gamma-ray background measured by LHAASO in the $1-1000\,\rm{TeV}$ range is always smaller than $\lesssim10\%$ ($\lesssim30\%$). We conclude that PWNe mostly contribute to the source component of the UHE gamma-ray sky, while having almost no imprint on its diffuse component.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20429v1" target="_blank"><h2>Estimating the triaxiality of massive clusters from 2D observables in MillenniumTNG with machine learning</h2></a><strong><u>Authors:</u></strong> Ana Maria Delgado, Michelle Ntampaka, Sownak Bose, Fulvio Ferlito, Boryana Hadzhiyska, Lars Hernquist, John Soltis, John F. Wu, Mikaeel Yunus, John ZuHone<br><strong><u>Categories:</u></strong> astro-ph.CO, astro-ph.GA<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Properties of massive galaxy clusters, such as mass abundance and concentration, are sensitive to cosmology, making cluster statistics a powerful tool for cosmological studies. However, favoring a more simplified, spherically symmetric model for galaxy clusters can lead to biases in the estimates of cluster properties. In this work, we present a deep-learning approach for estimating the triaxiality and orientations of massive galaxy clusters (those with masses $\gtrsim 10^{14}\,M_\odot h^{-1}$) from 2D observables. We utilize the flagship hydrodynamical volume of the suite of cosmological-hydrodynamical MillenniumTNG (MTNG) simulations as our ground truth. Our model combines the feature extracting power of a convolutional neural network (CNN) and the message passing power of a graph neural network (GNN) in a multi-modal, fusion network. Our model is able to extract 3D geometry information from 2D idealized cluster multi-wavelength images (soft X-ray, medium X-ray, hard X-ray and tSZ effect) and mathematical graph representations of 2D cluster member observables (line-of-sight radial velocities, 2D projected positions and V-band luminosities). Our network improves cluster geometry estimation in MTNG by $30\%$ compared to assuming spherical symmetry. We report an $R^2 = 0.85$ regression score for estimating the major axis length of triaxial clusters and correctly classifying $71\%$ of prolate clusters with elongated orientations along our line-of-sight.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20422v1" target="_blank"><h2>VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning</h2></a><strong><u>Authors:</u></strong> Bo Pang, Chenxi Xu, Jierui Ren, Guoping Wang, Sheng Li<br><strong><u>Categories:</u></strong> cs.AI, cs.CV, cs.GR, cs.RO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20406v1" target="_blank"><h2>Short-Range Oversquashing</h2></a><strong><u>Authors:</u></strong> Yaaqov Mishayev, Yonatan Sverdlov, Tal Amir, Nadav Dym<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted to Learning on Graphs (LoG) 2025. Version identical to the camera-ready paper<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Message Passing Neural Networks (MPNNs) are widely used for learning on graphs, but their ability to process long-range information is limited by the phenomenon of oversquashing. This limitation has led some researchers to advocate Graph Transformers as a better alternative, whereas others suggest that it can be mitigated within the MPNN framework, using virtual nodes or other rewiring techniques.
  In this work, we demonstrate that oversquashing is not limited to long-range tasks, but can also arise in short-range problems. This observation allows us to disentangle two distinct mechanisms underlying oversquashing: (1) the bottleneck phenomenon, which can arise even in low-range settings, and (2) the vanishing gradient phenomenon, which is closely associated with long-range tasks.
  We further show that the short-range bottleneck effect is not captured by existing explanations for oversquashing, and that adding virtual nodes does not resolve it. In contrast, transformers do succeed in such tasks, positioning them as the more compelling solution to oversquashing, compared to specialized MPNNs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20397v1" target="_blank"><h2>Model-Based Learning of Whittle indices</h2></a><strong><u>Authors:</u></strong> Joël Charles-Rebuffé, Nicolas Gast, Bruno Gaujal<br><strong><u>Categories:</u></strong> cs.LG, cs.DS, math.NA<br><strong><u>Comments:</u></strong> 31 pages, 8 figures, submitted to TOMPECS<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> We present BLINQ, a new model-based algorithm that learns the Whittle indices of an indexable, communicating and unichain Markov Decision Process (MDP). Our approach relies on building an empirical estimate of the MDP and then computing its Whittle indices using an extended version of a state-of-the-art existing algorithm. We provide a proof of convergence to the Whittle indices we want to learn as well as a bound on the time needed to learn them with arbitrary precision. Moreover, we investigate its computational complexity. Our numerical experiments suggest that BLINQ significantly outperforms existing Q-learning approaches in terms of the number of samples needed to get an accurate approximation. In addition, it has a total computational cost even lower than Q-learning for any reasonably high number of samples. These observations persist even when the Q-learning algorithms are speeded up using pre-trained neural networks to predict Q-values.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20395v1" target="_blank"><h2>Identifying environmental factors associated with tetrodotoxin contamination in bivalve mollusks using eXplainable AI</h2></a><strong><u>Authors:</u></strong> M. C. Schoppema, B. H. M. van der Velden, A. Hürriyetoğlu, M. D. Klijnstra, E. J. Faassen, A. Gerssen, H. J. van der Fels-Klerx<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 18 pages, 6 figures, submitted to Nature Food<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)<br><p><strong><u>Abstract:</u></strong> Since 2012, tetrodotoxin (TTX) has been found in seafoods such as bivalve mollusks in temperate European waters. TTX contamination leads to food safety risks and economic losses, making early prediction of TTX contamination vital to the food industry and competent authorities. Recent studies have pointed to shallow habitats and water temperature as main drivers to TTX contamination in bivalve mollusks. However, the temporal relationships between abiotic factors, biotic factors, and TTX contamination remain unexplored.
  We have developed an explainable, deep learning-based model to predict TTX contamination in the Dutch Zeeland estuary. Inputs for the model were meteorological and hydrological features; output was the presence or absence of TTX contamination.
  Results showed that the time of sunrise, time of sunset, global radiation, water temperature, and chloride concentration contributed most to TTX contamination. Thus, the effective number of sun hours, represented by day length and global radiation, was an important driver for tetrodotoxin contamination in bivalve mollusks.
  To conclude, our explainable deep learning model identified the aforementioned environmental factors (number of sun hours, global radiation, water temperature, and water chloride concentration) to be associated with tetrodotoxin contamination in bivalve mollusks; making our approach a valuable tool to mitigate marine toxin risks for food industry and competent authorities.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20382v1" target="_blank"><h2>MoRE: Batch-Robust Multi-Omics Representations from Frozen Pre-trained Transformers</h2></a><strong><u>Authors:</u></strong> Audrey Pei-Hsuan Chen<br><strong><u>Categories:</u></strong> cs.LG, q-bio.GN<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Representation learning on multi-omics data is challenging due to extreme dimensionality, modality heterogeneity, and cohort-specific batch effects. While pre-trained transformer backbones have shown broad generalization capabilities in biological sequence modeling, their application to multi-omics integration remains underexplored. We present MoRE (Multi-Omics Representation Embedding), a framework that repurposes frozen pre-trained transformers to align heterogeneous assays into a shared latent space. Unlike purely generative approaches, MoRE employs a parameter-efficient fine-tuning (PEFT) strategy, prioritizing cross-sample and cross-modality alignment over simple sequence reconstruction. Specifically, MoRE attaches lightweight, modality-specific adapters and a task-adaptive fusion layer to the frozen backbone. It optimizes a masked modeling objective jointly with supervised contrastive and batch-invariant alignment losses, yielding structure-preserving embeddings that generalize across unseen cell types and platforms. We benchmark MoRE against established baselines, including scGPT, scVI, and Harmony with scArches, evaluating integration fidelity, rare population detection, and modality transfer. Our results demonstrate that MoRE achieves competitive batch robustness and biological conservation while significantly reducing trainable parameters compared to fully fine-tuned models. This work positions MoRE as a practical step toward general-purpose omics foundation models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20362v1" target="_blank"><h2>PRISM: Periodic Representation with multIscale and Similarity graph Modelling for enhanced crystal structure property prediction</h2></a><strong><u>Authors:</u></strong> Àlex Solé, Albert Mosella-Montoro, Joan Cardona, Daniel Aravena, Silvia Gómez-Coca, Eliseo Ruiz, Javier Ruiz-Hidalgo<br><strong><u>Categories:</u></strong> cs.LG, cond-mat.mtrl-sci<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Crystal structures are characterised by repeating atomic patterns within unit cells across three-dimensional space, posing unique challenges for graph-based representation learning. Current methods often overlook essential periodic boundary conditions and multiscale interactions inherent to crystalline structures. In this paper, we introduce PRISM, a graph neural network framework that explicitly integrates multiscale representations and periodic feature encoding by employing a set of expert modules, each specialised in encoding distinct structural and chemical aspects of periodic systems. Extensive experiments across crystal structure-based benchmarks demonstrate that PRISM improves state-of-the-art predictive accuracy, significantly enhancing crystal property prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20333v1" target="_blank"><h2>NNGPT: Rethinking AutoML with Large Language Models</h2></a><strong><u>Authors:</u></strong> Roman Kochnev, Waleed Khalid, Tolgay Atinc Uzun, Xi Zhang, Yashkumar Sanjaybhai Dhameliya, Furui Qin, Chandini Vysyaraju, Raghuvir Duvvuri, Avi Goyal, Dmitry Ignatov, Radu Timofte<br><strong><u>Categories:</u></strong> cs.AI, cs.LG, cs.NE<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Building self-improving AI systems remains a fundamental challenge in the AI domain. We present NNGPT, an open-source framework that turns a large language model (LLM) into a self-improving AutoML engine for neural network development, primarily for computer vision. Unlike previous frameworks, NNGPT extends the dataset of neural networks by generating new models, enabling continuous fine-tuning of LLMs based on closed-loop system of generation, assessment, and self-improvement. It integrates within one unified workflow five synergistic LLM-based pipelines: zero-shot architecture synthesis, hyperparameter optimization (HPO), code-aware accuracy/early-stop prediction, retrieval-augmented synthesis of scope-closed PyTorch blocks (NN-RAG), and reinforcement learning. Built on the LEMUR dataset as an audited corpus with reproducible metrics, NNGPT emits from a single prompt and validates network architecture, preprocessing code, and hyperparameters, executes them end-to-end, and learns from result. The PyTorch adapter makes NNGPT framework-agnostic, enabling strong performance: NN-RAG achieves 73% executability on 1,289 targets, 3-shot prompting boosts accuracy on common datasets, and hash-based deduplication saves hundreds of runs. One-shot prediction matches search-based AutoML, reducing the need for numerous trials. HPO on LEMUR achieves RMSE 0.60, outperforming Optuna (0.64), while the code-aware predictor reaches RMSE 0.14 with Pearson r=0.78. The system has already generated over 5K validated models, proving NNGPT as an autonomous AutoML engine. Upon acceptance, the code, prompts, and checkpoints will be released for public access to enable reproducibility and facilitate community usage.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20332v1" target="_blank"><h2>3D Motion Perception of Binocular Vision Target with PID-CNN</h2></a><strong><u>Authors:</u></strong> Shi Jiazhao, Pan Pan, Shi Haotian<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 7 pages, 9 figures, 2 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> This article trained a network for perceiving three-dimensional motion information of binocular vision target, which can provide real-time three-dimensional coordinate, velocity, and acceleration, and has a basic spatiotemporal perception capability. Understood the ability of neural networks to fit nonlinear problems from the perspective of PID. Considered a single-layer neural network as using a second-order difference equation and a nonlinearity to describe a local problem. Multilayer networks gradually transform the raw representation to the desired representation through multiple such combinations. Analysed some reference principles for designing neural networks. Designed a relatively small PID convolutional neural network, with a total of 17 layers and 413 thousand parameters. Implemented a simple but practical feature reuse method by concatenation and pooling. The network was trained and tested using the simulated randomly moving ball datasets, and the experimental results showed that the prediction accuracy was close to the upper limit that the input image resolution can represent. Analysed the experimental results and errors, as well as the existing shortcomings and possible directions for improvement. Finally, discussed the advantages of high-dimensional convolution in improving computational efficiency and feature space utilization. As well as the potential advantages of using PID information to implement memory and attention mechanisms.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20327v1" target="_blank"><h2>MXtalTools: A Toolkit for Machine Learning on Molecular Crystals</h2></a><strong><u>Authors:</u></strong> Michael Kilgour, Mark E. Tuckerman, Jutta Rogal<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 16 pages, 11 figures<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> We present MXtalTools, a flexible Python package for the data-driven modelling of molecular crystals, facilitating machine learning studies of the molecular solid state. MXtalTools comprises several classes of utilities: (1) synthesis, collation, and curation of molecule and crystal datasets, (2) integrated workflows for model training and inference, (3) crystal parameterization and representation, (4) crystal structure sampling and optimization, (5) end-to-end differentiable crystal sampling, construction and analysis. Our modular functions can be integrated into existing workflows or combined and used to build novel modelling pipelines. MXtalTools leverages CUDA acceleration to enable high-throughput crystal modelling. The Python code is available open-source on our GitHub page, with detailed documentation on ReadTheDocs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20315v1" target="_blank"><h2>Geometry of Decision Making in Language Models</h2></a><strong><u>Authors:</u></strong> Abhinav Joshi, Divyanshu Bhatt, Ashutosh Modi<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> Accepted at NeurIPS 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) show strong generalization across diverse tasks, yet the internal decision-making processes behind their predictions remain opaque. In this work, we study the geometry of hidden representations in LLMs through the lens of \textit{intrinsic dimension} (ID), focusing specifically on decision-making dynamics in a multiple-choice question answering (MCQA) setting. We perform a large-scale study, with 28 open-weight transformer models and estimate ID across layers using multiple estimators, while also quantifying per-layer performance on MCQA tasks. Our findings reveal a consistent ID pattern across models: early layers operate on low-dimensional manifolds, middle layers expand this space, and later layers compress it again, converging to decision-relevant representations. Together, these results suggest LLMs implicitly learn to project linguistic inputs onto structured, low-dimensional manifolds aligned with task-specific decisions, providing new geometric insights into how generalization and reasoning emerge in language models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20312v1" target="_blank"><h2>Data Augmentation Techniques to Reverse-Engineer Neural Network Weights from Input-Output Queries</h2></a><strong><u>Authors:</u></strong> Alexander Beiser, Flavio Martinelli, Wulfram Gerstner, Johanni Brea<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> Proceedings of the III edition of the Workshop on Unifying Representations in Neural Models (UniReps 2025)<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title), data augmentation (title, abstract)<br><p><strong><u>Abstract:</u></strong> Network weights can be reverse-engineered given enough informative samples of a network's input-output function. In a teacher-student setup, this translates into collecting a dataset of the teacher mapping -- querying the teacher -- and fitting a student to imitate such mapping. A sensible choice of queries is the dataset the teacher is trained on. But current methods fail when the teacher parameters are more numerous than the training data, because the student overfits to the queries instead of aligning its parameters to the teacher. In this work, we explore augmentation techniques to best sample the input-output mapping of a teacher network, with the goal of eliciting a rich set of representations from the teacher hidden layers. We discover that standard augmentations such as rotation, flipping, and adding noise, bring little to no improvement to the identification problem. We design new data augmentation techniques tailored to better sample the representational space of the network's hidden layers. With our augmentations we extend the state-of-the-art range of recoverable network sizes. To test their scalability, we show that we can recover networks of up to 100 times more parameters than training data-points.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20305v1" target="_blank"><h2>RIS-Assisted Downlink Pinching-Antenna Systems: GNN-Enabled Optimization Approaches</h2></a><strong><u>Authors:</u></strong> Changpeng He, Yang Lu, Yanqing Xu, Chong-Yung Chi, Bo Ai, Arumugam Nallanathan<br><strong><u>Categories:</u></strong> cs.NI, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> This paper investigates a reconfigurable intelligent surface (RIS)-assisted multi-waveguide pinching-antenna (PA) system (PASS) for multi-user downlink information transmission, motivated by the unknown impact of the integration of emerging PASS and RIS on wireless communications. First, we formulate sum rate (SR) and energy efficiency (EE) maximization problems in a unified framework, subject to constraints on the movable region of PAs, total power budget, and tunable phase of RIS elements. Then, by leveraging a graph-structured topology of the RIS-assisted PASS, a novel three-stage graph neural network (GNN) is proposed, which learns PA positions based on user locations, and RIS phase shifts according to composite channel conditions at the first two stages, respectively, and finally determines beamforming vectors. Specifically, the proposed GNN is achieved through unsupervised training, together with three implementation strategies for its integration with convex optimization, thus offering trade-offs between inference time and solution optimality. Extensive numerical results are provided to validate the effectiveness of the proposed GNN, and to support its unique attributes of viable generalization capability, good performance reliability, and real-time applicability. Moreover, the impact of key parameters on RIS-assisted PASS is illustrated and analyzed.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20285v1" target="_blank"><h2>SMoG: Schema Matching on Graph</h2></a><strong><u>Authors:</u></strong> Mingyu Jeon, Jaeyoung Suh, Suwan Cho<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> explainability (abstract)<br><p><strong><u>Abstract:</u></strong> Schema matching is a critical task in data integration, particularly in the medical domain where disparate Electronic Health Record (EHR) systems must be aligned to standard models like OMOP CDM. While Large Language Models (LLMs) have shown promise in schema matching, they suffer from hallucination and lack of up-to-date domain knowledge. Knowledge Graphs (KGs) offer a solution by providing structured, verifiable knowledge. However, existing KG-augmented LLM approaches often rely on inefficient complex multi-hop queries or storage-intensive vector-based retrieval methods. This paper introduces SMoG (Schema Matching on Graph), a novel framework that leverages iterative execution of simple 1-hop SPARQL queries, inspired by successful strategies in Knowledge Graph Question Answering (KGQA). SMoG enhances explainability and reliability by generating human-verifiable query paths while significantly reducing storage requirements by directly querying SPARQL endpoints. Experimental results on real-world medical datasets demonstrate that SMoG achieves performance comparable to state-of-the-art baselines, validating its effectiveness and efficiency in KG-augmented schema matching.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20283v1" target="_blank"><h2>Solving Heterogeneous Agent Models with Physics-informed Neural Networks</h2></a><strong><u>Authors:</u></strong> Marta Grzeskiewicz<br><strong><u>Categories:</u></strong> econ.GN, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Understanding household behaviour is essential for modelling macroeconomic dynamics and designing effective policy. While heterogeneous agent models offer a more realistic alternative to representative agent frameworks, their implementation poses significant computational challenges, particularly in continuous time. The Aiyagari-Bewley-Huggett (ABH) framework, recast as a system of partial differential equations, typically relies on grid-based solvers that suffer from the curse of dimensionality, high computational cost, and numerical inaccuracies. This paper introduces the ABH-PINN solver, an approach based on Physics-Informed Neural Networks (PINNs), which embeds the Hamilton-Jacobi-Bellman and Kolmogorov Forward equations directly into the neural network training objective. By replacing grid-based approximation with mesh-free, differentiable function learning, the ABH-PINN solver benefits from the advantages of PINNs of improved scalability, smoother solutions, and computational efficiency. Preliminary results show that the PINN-based approach is able to obtain economically valid results matching the established finite-difference solvers.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20273v1" target="_blank"><h2>Beyond Components: Singular Vector-Based Interpretability of Transformer Circuits</h2></a><strong><u>Authors:</u></strong> Areeb Ahmad, Abhinav Joshi, Ashutosh Modi<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> Accepted at NeurIPS 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Transformer-based language models exhibit complex and distributed behavior, yet their internal computations remain poorly understood. Existing mechanistic interpretability methods typically treat attention heads and multilayer perceptron layers (MLPs) (the building blocks of a transformer architecture) as indivisible units, overlooking possibilities of functional substructure learned within them. In this work, we introduce a more fine-grained perspective that decomposes these components into orthogonal singular directions, revealing superposed and independent computations within a single head or MLP. We validate our perspective on widely used standard tasks like Indirect Object Identification (IOI), Gender Pronoun (GP), and Greater Than (GT), showing that previously identified canonical functional heads, such as the name mover, encode multiple overlapping subfunctions aligned with distinct singular directions. Nodes in a computational graph, that are previously identified as circuit elements show strong activation along specific low-rank directions, suggesting that meaningful computations reside in compact subspaces. While some directions remain challenging to interpret fully, our results highlight that transformer computations are more distributed, structured, and compositional than previously assumed. This perspective opens new avenues for fine-grained mechanistic interpretability and a deeper understanding of model internals.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20267v1" target="_blank"><h2>Projection Effects in Barred Galaxies Causing Wrong Interpretation of Radial Flows <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> E. Salibur, A. Hallé, F. Combes<br><strong><u>Categories:</u></strong> astro-ph.GA<br><strong><u>Comments:</u></strong> 12 pages, 10 figures, 1 table. Submitted to A&A<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> Galaxy disks in rotation are sometimes the site of radial flows, especially in their gas component. It is important to estimate the outflows, due to AGN or supernovae feedback, or inflows due to bar gravity torques. However, these radial flows may be confused with non-circular motions, which are quite frequent in the center of galaxy disks. We use a simulated giant, barred spiral galaxy from the GalMer database to study the non-circular motions induced by the bar. Our goal is to identify the spurious radial flows that kinematics modeling algorithms can detect, assuming circular orbits for the gas. Using mock data of a strongly barred galaxy, we quantify the radial velocities computed by the 3D-Barolo algorithm for different disk inclinations and several bar orientations in the plane of the sky: along the major and minor kinematic axes and at 45° from them. Our results show that projection effects cause kinematics modeling algorithms to confuse the radial component of velocity due to elliptical orbits with significant radial flows with mean values up to 84 km.s$^{-1}$, within the bar region. The computed rotation curve is also wrongly estimated inside the bar region, by as much as 150 km.s$^{-1}$ for the highest inclination.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20258v1" target="_blank"><h2>Modality-Balanced Collaborative Distillation for Multi-Modal Domain Generalization</h2></a><strong><u>Authors:</u></strong> Xiaohan Wang, Zhangtao Cheng, Ting Zhong, Leiting Chen, Fan Zhou<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multi-modal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Weight Averaging (WA) has emerged as a powerful technique for enhancing generalization by promoting convergence to a flat loss landscape, which correlates with stronger out-of-distribution performance. However, applying WA directly to multi-modal domain generalization (MMDG) is challenging: differences in optimization speed across modalities lead WA to overfit to faster-converging ones in early stages, suppressing the contribution of slower yet complementary modalities, thereby hindering effective modality fusion and skewing the loss surface toward sharper, less generalizable minima. To address this issue, we propose MBCD, a unified collaborative distillation framework that retains WA's flatness-inducing advantages while overcoming its shortcomings in multi-modal contexts. MBCD begins with adaptive modality dropout in the student model to curb early-stage bias toward dominant modalities. A gradient consistency constraint then aligns learning signals between uni-modal branches and the fused representation, encouraging coordinated and smoother optimization. Finally, a WA-based teacher conducts cross-modal distillation by transferring fused knowledge to each uni-modal branch, which strengthens cross-modal interactions and steer convergence toward flatter solutions. Extensive experiments on MMDG benchmarks show that MBCD consistently outperforms existing methods, achieving superior accuracy and robustness across diverse unseen domains.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20257v1" target="_blank"><h2>Interpretable Air Pollution Forecasting by Physics-Guided Spatiotemporal Decoupling</h2></a><strong><u>Authors:</u></strong> Zhiguo Zhang, Xiaoliang Ma, Daniel Schlesinger<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted to 2025 IEEE International Conference on Big Data<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> explainable (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate and interpretable air pollution forecasting is crucial for public health, but most models face a trade-off between performance and interpretability. This study proposes a physics-guided, interpretable-by-design spatiotemporal learning framework. The model decomposes the spatiotemporal behavior of air pollutant concentrations into two transparent, additive modules. The first is a physics-guided transport kernel with directed weights conditioned on wind and geography (advection). The second is an explainable attention mechanism that learns local responses and attributes future concentrations to specific historical lags and exogenous drivers. Evaluated on a comprehensive dataset from the Stockholm region, our model consistently outperforms state-of-the-art baselines across multiple forecasting horizons. Our model's integration of high predictive performance and spatiotemporal interpretability provides a more reliable foundation for operational air-quality management in real-world applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20254v1" target="_blank"><h2>XiCAD: Camera Activation Detection in the Da Vinci Xi User Interface</h2></a><strong><u>Authors:</u></strong> Alexander C. Jenke, Gregor Just, Claas de Boer, Martin Wagner, Sebastian Bodenstedt, Stefanie Speidel<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Purpose: Robot-assisted minimally invasive surgery relies on endoscopic video as the sole intraoperative visual feedback. The DaVinci Xi system overlays a graphical user interface (UI) that indicates the state of each robotic arm, including the activation of the endoscope arm. Detecting this activation provides valuable metadata such as camera movement information, which can support downstream surgical data science tasks including tool tracking, skill assessment, or camera control automation.
  Methods: We developed a lightweight pipeline based on a ResNet18 convolutional neural network to automatically identify the position of the camera tile and its activation state within the DaVinci Xi UI. The model was fine-tuned on manually annotated data from the SurgToolLoc dataset and evaluated across three public datasets comprising over 70,000 frames.
  Results: The model achieved F1-scores between 0.993 and 1.000 for the binary detection of active cameras and correctly localized the camera tile in all cases without false multiple-camera detections.
  Conclusion: The proposed pipeline enables reliable, real-time extraction of camera activation metadata from surgical videos, facilitating automated preprocessing and analysis for diverse downstream applications. All code, trained models, and annotations are publicly available.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20234v1" target="_blank"><h2>Leveraging weights signals -- Predicting and improving generalizability in reinforcement learning</h2></a><strong><u>Authors:</u></strong> Olivier Moulin, Vincent Francois-lavet, Paul Elbers, Mark Hoogendoorn<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Generalizability of Reinforcement Learning (RL) agents (ability to perform on environments different from the ones they have been trained on) is a key problem as agents have the tendency to overfit to their training environments. In order to address this problem and offer a solution to increase the generalizability of RL agents, we introduce a new methodology to predict the generalizability score of RL agents based on the internal weights of the agent's neural networks. Using this prediction capability, we propose some changes in the Proximal Policy Optimization (PPO) loss function to boost the generalization score of the agents trained with this upgraded version. Experimental results demonstrate that our improved PPO algorithm yields agents with stronger generalizability compared to the original version.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20222v1" target="_blank"><h2>Decoupling and Damping: Structurally-Regularized Gradient Matching for Multimodal Graph Condensation</h2></a><strong><u>Authors:</u></strong> Lian Shen, Zhendan Chen, Yinhui jiang, Meijia Song, Ziming Su, Juan Liu, Xiangrong Liu<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 11pages,5 figures,6 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> In critical web applications such as e-commerce and recommendation systems, multimodal graphs integrating rich visual and textual attributes are increasingly central, yet their large scale introduces substantial computational burdens for training Graph Neural Networks (GNNs). While Graph Condensation (GC) offers a promising solution by synthesizing smaller datasets, existing methods falter in the multimodal setting. We identify a dual challenge causing this failure: (1) conflicting gradients arising from semantic misalignments between modalities, and (2) the GNN's message-passing architecture pathologically amplifying this gradient noise across the graph structure. To address this, we propose Structurally-Regularized Gradient Matching (SR-GM), a novel condensation framework tailored for multimodal graphs. SR-GM introduces two synergistic components: first, a gradient decoupling mechanism that resolves inter-modality conflicts at their source via orthogonal projection; and second, a structural damping regularizer that acts directly on the gradient field. By leveraging the graph's Dirichlet energy, this regularizer transforms the topology from a noise amplifier into a stabilizing force during optimization. Extensive experiments demonstrate that SR-GM significantly improves accuracy and accelerates convergence compared to baseline methods. Ablation studies confirm that addressing both gradient conflict and structural amplification in tandem is essential for achieving superior performance. Moreover, the condensed multimodal graphs exhibit strong cross-architecture generalization and promise to accelerate applications like Neural Architecture Search. This research provides a scalable methodology for multimodal graph-based learning in resource-constrained environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20216v1" target="_blank"><h2>CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents</h2></a><strong><u>Authors:</u></strong> Haebin Seong, Sungmin Kim, Minchan Kim, Yongjun Cho, Myunchul Joe, Suhwan Choi, Jaeyoon Jung, Jiyong Youn, Yoonshik Kim, Samwoo Seong, Yubeen Park, Youngjae Yu, Yunsung Lee<br><strong><u>Categories:</u></strong> cs.AI, cs.CE, cs.CV, cs.LG, cs.RO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20211v1" target="_blank"><h2>OmniAlpha: A Sequence-to-Sequence Framework for Unified Multi-Task RGBA Generation</h2></a><strong><u>Authors:</u></strong> Hao Yu, Jiabo Zhan, Zile Wang, Jinglin Wang, Huaisong Zhang, Hongyu Li, Xinrui Chen, Yongxian Wei, Chun Yuan<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Generative models have excelled in RGB synthesis, but real-world applications require RGBA manipulation. This has led to a fragmented landscape: specialized, single-task models handle alpha but lack versatility, while unified multi-task frameworks are confined to the RGB domain. To bridge this critical gap, we propose OmniAlpha, the first unified, multi-task generative framework for sequence-to-sequence RGBA image generation and editing. Its architecture features MSRoPE-BiL, a novel RoPE method with a bi-directionally extendable layer axis for its Diffusion Transformer (DiT) backbone, enabling the concurrent processing of multiple input and target RGBA layers. To power this framework, we introduce AlphaLayers, a new dataset of 1,000 high-quality, multi-layer triplets, built via a novel automated synthesis and filter pipeline. Jointly training OmniAlpha on this dataset across a comprehensive suite of 21 diverse tasks, extensive experiments demonstrate that our unified approach consistently outperforms strong, specialized baselines. Most notably, OmniAlpha achieves a dramatic 84.8% relative reduction in SAD for mask-free matting on AIM-500 and wins over 90% of human preferences in layer-conditioned completion. Our work proves that a unified, multi-task model can learn a superior shared representation for RGBA, paving the way for more powerful, layer-aware generative systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20196v1" target="_blank"><h2>Towards Benign Memory Forgetting for Selective Multimodal Large Language Model Unlearning</h2></a><strong><u>Authors:</u></strong> Zhen Zeng, Leijiang Gu, Zhangling Duan, Feng Li, Zenglin Shi, Cees G. M. Snoek, Meng Wang<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Large Language Models (MLLMs) achieve remarkable capabilities but can inadvertently memorize privacy-sensitive information. Although existing unlearning methods can remove such knowledge, they fail to achieve benign forgetting because they often degrade the model's general image understanding performance. To address this, we propose the Sculpted Memory Forgetting Adapter (SMFA), which confines forgetting to targeted memory regions while preserving overall capabilities. SMFA first fine-tunes the model to replace sensitive responses with refusals, yielding a memory forgetting adapter, and then applies a retaining anchor-guided masking mechanism to prevent interference with unrelated knowledge and understanding ability. To systematically evaluate selective MLLM unlearning, we introduce S-MLLMUn Bench, the first benchmark designed to jointly assess the removal of sensitive knowledge and retention of general visual understanding. Extensive experiments show that, unlike prior methods, SMFA achieves precise and controllable unlearning while maintaining the model's foundational image understanding.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20194v1" target="_blank"><h2>In-Context Compositional Learning via Sparse Coding Transformer</h2></a><strong><u>Authors:</u></strong> Wei Chen, Jingxi Yu, Zichen Miao, Qiang Qiu<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> NeurIPS 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Transformer architectures have achieved remarkable success across language, vision, and multimodal tasks, and there is growing demand for them to address in-context compositional learning tasks. In these tasks, models solve the target problems by inferring compositional rules from context examples, which are composed of basic components structured by underlying rules. However, some of these tasks remain challenging for Transformers, which are not inherently designed to handle compositional tasks and offer limited structural inductive bias. In this work, inspired by the principle of sparse coding, we propose a reformulation of the attention to enhance its capability for compositional tasks. In sparse coding, data are represented as sparse combinations of dictionary atoms with coefficients that capture their compositional rules. Specifically, we reinterpret the attention block as a mapping of inputs into outputs through projections onto two sets of learned dictionary atoms: an encoding dictionary and a decoding dictionary. The encoding dictionary decomposes the input into a set of coefficients, which represent the compositional structure of the input. To enhance structured representations, we impose sparsity on these coefficients. The sparse coefficients are then used to linearly combine the decoding dictionary atoms to generate the output. Furthermore, to assist compositional generalization tasks, we propose estimating the coefficients of the target problem as a linear combination of the coefficients obtained from the context examples. We demonstrate the effectiveness of our approach on the S-RAVEN and RAVEN datasets. For certain compositional generalization tasks, our method maintains performance even when standard Transformers fail, owing to its ability to learn and apply compositional rules.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20170v1" target="_blank"><h2>AdaCap: An Adaptive Contrastive Approach for Small-Data Neural Networks</h2></a><strong><u>Authors:</u></strong> Bruno Belucci, Karim Lounici, Katia Meziani<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Submitted to ESANN 2026<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Neural networks struggle on small tabular datasets, where tree-based models remain dominant. We introduce Adaptive Contrastive Approach (AdaCap), a training scheme that combines a permutation-based contrastive loss with a Tikhonov-based closed-form output mapping. Across 85 real-world regression datasets and multiple architectures, AdaCap yields consistent and statistically significant improvements in the small-sample regime, particularly for residual models. A meta-predictor trained on dataset characteristics (size, skewness, noise) accurately anticipates when AdaCap is beneficial. These results show that AdaCap acts as a targeted regularization mechanism, strengthening neural networks precisely where they are most fragile. All results and code are publicly available at https://github.com/BrunoBelucci/adacap.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20162v1" target="_blank"><h2>While recognizing actions, LMMs struggle to detect core interaction events</h2></a><strong><u>Authors:</u></strong> Daniel Harari, Michael Sidorov, Liel David, Chen Shterental, Abrham Kahsay Gebreselasie, Muhammad Haris Khan<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, q-bio.NC<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20143v1" target="_blank"><h2>SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models</h2></a><strong><u>Authors:</u></strong> Wen-Fang Su, Hsiao-Wei Chou, Wen-Yang Lin<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.IR<br><strong><u>Comments:</u></strong> 9 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data augmentation (title, abstract)<br><p><strong><u>Abstract:</u></strong> Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20141v1" target="_blank"><h2>IDAP++: Advancing Divergence-Based Pruning via Filter-Level and Layer-Level Optimization</h2></a><strong><u>Authors:</u></strong> Aleksei Samarin, Artem Nazarenko, Egor Kotenko, Valentin Malykh, Alexander Savelev, Aleksei Toropov<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 65 pages, 4 figures, 38 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> This paper presents a novel approach to neural network compression that addresses redundancy at both the filter and architectural levels through a unified framework grounded in information flow analysis. Building on the concept of tensor flow divergence, which quantifies how information is transformed across network layers, we develop a two-stage optimization process. The first stage employs iterative divergence-aware pruning to identify and remove redundant filters while preserving critical information pathways. The second stage extends this principle to higher-level architecture optimization by analyzing layer-wise contributions to information propagation and selectively eliminating entire layers that demonstrate minimal impact on network performance. The proposed method naturally adapts to diverse architectures, including convolutional networks, transformers, and hybrid designs, providing a consistent metric for comparing the structural importance across different layer types. Experimental validation across multiple modern architectures and datasets reveals that this combined approach achieves substantial model compression while maintaining competitive accuracy. The presented approach achieves parameter reduction results that are globally comparable to those of state-of-the-art solutions and outperforms them across a wide range of modern neural network architectures, from convolutional models to transformers. The results demonstrate how flow divergence serves as an effective guiding principle for both filter-level and layer-level optimization, offering practical benefits for deployment in resource-constrained environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20138v1" target="_blank"><h2>From data to concepts via wiring diagrams</h2></a><strong><u>Authors:</u></strong> Jason Lo, Mohammadnima Jafari<br><strong><u>Categories:</u></strong> cs.AI, cs.DM, cs.LG, math.CO<br><strong><u>Comments:</u></strong> 19 pages<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> sequential data (abstract)<br><p><strong><u>Abstract:</u></strong> A wiring diagram is a labeled directed graph that represents an abstract concept such as a temporal process. In this article, we introduce the notion of a quasi-skeleton wiring diagram graph, and prove that quasi-skeleton wiring diagram graphs correspond to Hasse diagrams. Using this result, we designed algorithms that extract wiring diagrams from sequential data. We used our algorithms in analyzing the behavior of an autonomous agent playing a computer game, and the algorithms correctly identified the winning strategies. We compared the performance of our main algorithm with two other algorithms based on standard clustering techniques (DBSCAN and agglomerative hierarchical), including when some of the data was perturbed. Overall, this article brings together techniques in category theory, graph theory, clustering, reinforcement learning, and data engineering.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20120v1" target="_blank"><h2>"When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings</h2></a><strong><u>Authors:</u></strong> Somsubhra De, Harsh Kumar, Arun Prakash A<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 5 figures, 5 tables; Accept-demonstration at BHASHA Workshop, IJCNLP-AACL 2025<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20116v1" target="_blank"><h2>LungEvaty: A Scalable, Open-Source Transformer-based Deep Learning Model for Lung Cancer Risk Prediction in LDCT Screening</h2></a><strong><u>Authors:</u></strong> Johannes Brandt, Maulik Chevli, Rickmer Braren, Georgios Kaissis, Philip Müller, Daniel Rueckert<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Lung cancer risk estimation is gaining increasing importance as more countries introduce population-wide screening programs using low-dose CT (LDCT). As imaging volumes grow, scalable methods that can process entire lung volumes efficiently are essential to tap into the full potential of these large screening datasets. Existing approaches either over-rely on pixel-level annotations, limiting scalability, or analyze the lung in fragments, weakening performance. We present LungEvaty, a fully transformer-based framework for predicting 1-6 year lung cancer risk from a single LDCT scan. The model operates on whole-lung inputs, learning directly from large-scale screening data to capture comprehensive anatomical and pathological cues relevant for malignancy risk. Using only imaging data and no region supervision, LungEvaty matches state-of-the-art performance, refinable by an optional Anatomically Informed Attention Guidance (AIAG) loss that encourages anatomically focused attention. In total, LungEvaty was trained on more than 90,000 CT scans, including over 28,000 for fine-tuning and 6,000 for evaluation. The framework offers a simple, data-efficient, and fully open-source solution that provides an extensible foundation for future research in longitudinal and multimodal lung cancer risk prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20109v1" target="_blank"><h2>CLIMATEAGENT: Multi-Agent Orchestration for Complex Climate Data Science Workflows</h2></a><strong><u>Authors:</u></strong> Hyeonjae Kim, Chenyue Li, Wen Deng, Mengxi Jin, Wen Huang, Mengqian Lu, Binhang Yuan<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 30 pages, 6 figures, 3 tables<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Climate science demands automated workflows to transform comprehensive questions into data-driven statements across massive, heterogeneous datasets. However, generic LLM agents and static scripting pipelines lack climate-specific context and flexibility, thus, perform poorly in practice. We present ClimateAgent, an autonomous multi-agent framework that orchestrates end-to-end climate data analytic workflows. ClimateAgent decomposes user questions into executable sub-tasks coordinated by an Orchestrate-Agent and a Plan-Agent; acquires data via specialized Data-Agents that dynamically introspect APIs to synthesize robust download scripts; and completes analysis and reporting with a Coding-Agent that generates Python code, visualizations, and a final report with a built-in self-correction loop. To enable systematic evaluation, we introduce Climate-Agent-Bench-85, a benchmark of 85 real-world tasks spanning atmospheric rivers, drought, extreme precipitation, heat waves, sea surface temperature, and tropical cyclones. On Climate-Agent-Bench-85, ClimateAgent achieves 100% task completion and a report quality score of 8.32, outperforming GitHub-Copilot (6.27) and a GPT-5 baseline (3.26). These results demonstrate that our multi-agent orchestration with dynamic API awareness and self-correcting execution substantially advances reliable, end-to-end automation for climate science analytic tasks.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20105v1" target="_blank"><h2>Multivariate Forecasting of Bitcoin Volatility with Gradient Boosting: Deterministic, Probabilistic, and Feature Importance Perspectives</h2></a><strong><u>Authors:</u></strong> Grzegorz Dudek, Mateusz Kasprzyk, Paweł Pełka<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> This study investigates the application of the Light Gradient Boosting Machine (LGBM) model for both deterministic and probabilistic forecasting of Bitcoin realized volatility. Utilizing a comprehensive set of 69 predictors -- encompassing market, behavioral, and macroeconomic indicators -- we evaluate the performance of LGBM-based models and compare them with both econometric and machine learning baselines. For probabilistic forecasting, we explore two quantile-based approaches: direct quantile regression using the pinball loss function, and a residual simulation method that transforms point forecasts into predictive distributions. To identify the main drivers of volatility, we employ gain-based and permutation feature importance techniques, consistently highlighting the significance of trading volume, lagged volatility measures, investor attention, and market capitalization. The results demonstrate that LGBM models effectively capture the nonlinear and high-variance characteristics of cryptocurrency markets while providing interpretable insights into the underlying volatility dynamics.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20088v1" target="_blank"><h2>Explainable Visual Anomaly Detection via Concept Bottleneck Models</h2></a><strong><u>Authors:</u></strong> Arianna Stropeni, Valentina Zaccaria, Francesco Borsatti, Davide Dalle Pezze, Manuel Barusco, Gian Antonio Susto<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), explainable (title), attention (abstract)<br><p><strong><u>Abstract:</u></strong> In recent years, Visual Anomaly Detection (VAD) has gained significant attention due to its ability to identify anomalous images using only normal images during training. Many VAD models work without supervision but are still able to provide visual explanations by highlighting the anomalous regions within an image. However, although these visual explanations can be helpful, they lack a direct and semantically meaningful interpretation for users. To address this limitation, we propose extending Concept Bottleneck Models (CBMs) to the VAD setting. By learning meaningful concepts, the network can provide human-interpretable descriptions of anomalies, offering a novel and more insightful way to explain them. Our contributions are threefold: (i) we develop a Concept Dataset to support research on CBMs for VAD; (ii) we improve the CBM architecture to generate both concept-based and visual explanations, bridging semantic and localization interpretability; and (iii) we introduce a pipeline for synthesizing artificial anomalies, preserving the VAD paradigm of minimizing dependence on rare anomalous samples. Our approach, Concept-Aware Visual Anomaly Detection (CONVAD), achieves performance comparable to classic VAD methods while providing richer, concept-driven explanations that enhance interpretability and trust in VAD systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.20085v1" target="_blank"><h2>VICoT-Agent: A Vision-Interleaved Chain-of-Thought Framework for Interpretable Multimodal Reasoning and Scalable Remote Sensing Analysis</h2></a><strong><u>Authors:</u></strong> Chujie Wang, Zhiyuan Luo, Ruiqi Liu, Can Ran, Shenghua Fan, Xi Chen, Chu He<br><strong><u>Categories:</u></strong> cs.AI, cs.MA<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-25<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> The current remote sensing image analysis task is increasingly evolving from traditional object recognition to complex intelligence reasoning, which places higher requirements on the model's reasoning ability and the flexibility of tool invocation. To this end, we propose a new multimodal agent framework, Vision-Interleaved Chain-of-Thought Framework (VICoT), which implements explicit multi-round reasoning by dynamically incorporating visual tools into the chain of thought. Through a stack-based reasoning structure and a modular MCP-compatible tool suite, VICoT enables LLMs to efficiently perform multi-round, interleaved vision-language reasoning tasks with strong generalization and flexibility.We also propose the Reasoning Stack distillation method to migrate complex Agent behaviors to small, lightweight models, which ensures the reasoning capability while significantly reducing complexity. Experiments on multiple remote sensing benchmarks demonstrate that VICoT significantly outperforms existing SOTA frameworks in reasoning transparency, execution efficiency, and generation quality.</p><br><hr><br><hr><p><em>Summary: Showing 67 papers (64 new, 3 seen before)</em></p></body></html>