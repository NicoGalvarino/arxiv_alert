<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'><style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 09 Jun 2025 to 11 Jun 2025</em></font><a href="http://arxiv.org/pdf/2506.08932v1" target="_blank"><h2>Measurement of the Dispersion$\unicode{x2013}$Galaxy Cross-Power
  Spectrum with the Second CHIME/FRB Catalog</h2></a><strong><u>Authors:</u></strong>  Haochen Wang, Kiyoshi Masui, Shion Andrew, Emmanuel Fonseca, B. M. Gaensler, R. C. Joseph, Victoria M. Kaspi, Bikash Kharel, Adam E. Lanman, Calvin Leung, Lluis Mas-Ribas, Juan Mena-Parra, Kenzie Nimmo, Aaron B. Pearlman, Ue-Li Pen, J. Xavier Prochaska, Ryan Raikman, Kaitlyn Shin, Seth R. Siegel, Kendrick M. Smith, Ingrid H. Stairs</br><strong><u>Categories:</u></strong> astro-ph.CO, astro-ph.GA, astro-ph.HE, astro-ph.IM, gr-qc</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> The dispersion of extragalactic fast radio bursts (FRBs) can serve as a
powerful probe of the diffuse plasma between and surrounding galaxies, which
contains most of the Universe's baryons. By cross-correlating the dispersion of
background FRBs with the locations of foreground galaxies, we can study the
relative spatial distributions of plasma and galaxies on scales of 0.1 to 50
Mpc, which are strongly affected by feedback processes in galaxy formation.
Here we present the measurement of the dispersion$\unicode{x2013}$galaxy
angular cross-power spectrum between 2873 FRBs from the Second CHIME/FRB
Catalog and nearly 6 million galaxies from the Dark Energy Spectroscopic
Instrument (DESI) Legacy Imaging Survey. Over five photometric galaxy redshift
bins spanning $0.05 < z <0.5$ and at 5.1$\sigma$ significance, we make the
first definitive detection of spatial correlations in FRB dispersion measure
due to cosmic structure. While parameter inferences should be interpreted with
caution because of incomplete modelling of both the signal and systematic
errors, our data indicate that the plasma$\unicode{x2013}$galaxy cross-power
spectrum cuts off relative to the matter power spectrum at a scale
$k_\textrm{cut}^{-1}=0.9^{+0.4}_{-0.4}\,\textrm{Mpc}$. This scale is consistent
with those X-ray stacking analyses that suggest dark-matter halos with
group-scale masses are largely evacuated of their baryons by feedback
processes. Our study demonstrates that FRBs are promising tools to discern the
physics of baryonic structure formation and will only become more powerful as
FRB surveys expand.</p></br><a href="http://arxiv.org/pdf/2506.08783v1" target="_blank"><h2>syren-baryon: Analytic emulators for the impact of baryons on the matter
  power spectrum</h2></a><strong><u>Authors:</u></strong>  Lukas Kammerer, Deaglan J. Bartlett, Gabriel Kronberger, Harry Desmond, Pedro G. Ferreira</br><strong><u>Categories:</u></strong> astro-ph.CO, astro-ph.GA, astro-ph.IM, cs.LG, cs.NE</br><strong><u>Comments:</u></strong> 14 pages, 6 figures. Submitted to A&A</br><p><strong><u>Abstract:</u></strong> Baryonic physics has a considerable impact on the distribution of matter in
our Universe on scales probed by current and future cosmological surveys,
acting as a key systematic in such analyses. We seek simple symbolic
parametrisations for the impact of baryonic physics on the matter power
spectrum for a range of physically motivated models, as a function of
wavenumber, redshift, cosmology, and parameters controlling the baryonic
feedback. We use symbolic regression to construct analytic approximations for
the ratio of the matter power spectrum in the presence of baryons to that
without such effects. We obtain separate functions of each of four distinct
sub-grid prescriptions of baryonic physics from the CAMELS suite of
hydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as
well as for a baryonification algorithm. We also provide functions which
describe the uncertainty on these predictions, due to both the stochastic
nature of baryonic physics and the errors on our fits. The error on our
approximations to the hydrodynamical simulations is comparable to the sample
variance estimated through varying initial conditions, and our baryonification
expression has a root mean squared error of better than one percent, although
this increases on small scales. These errors are comparable to those of
previous numerical emulators for these models. Our expressions are enforced to
have the physically correct behaviour on large scales and at high redshift. Due
to their analytic form, we are able to directly interpret the impact of varying
cosmology and feedback parameters, and we can identify parameters which have
little to no effect. Each function is based on a different implementation of
baryonic physics, and can therefore be used to discriminate between these
models when applied to real data. We provide publicly available code for all
symbolic approximations found.</p></br><a href="http://arxiv.org/pdf/2506.08698v1" target="_blank"><h2>Variational Autoencoder-Based Approach to Latent Feature Analysis on
  Efficient Representation of Power Load Monitoring Data</h2></a><strong><u>Authors:</u></strong>  Boyu Xie, Tangtang Xie</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 9 pages, 2 figures</br><p><strong><u>Abstract:</u></strong> With the development of smart grids, High-Dimensional and Incomplete (HDI)
Power Load Monitoring (PLM) data challenges the performance of Power Load
Forecasting (PLF) models. In this paper, we propose a potential
characterization model VAE-LF based on Variational Autoencoder (VAE) for
efficiently representing and complementing PLM missing data. VAE-LF learns a
low-dimensional latent representation of the data using an Encoder-Decoder
structure by splitting the HDI PLM data into vectors and feeding them
sequentially into the VAE-LF model, and generates the complementary data.
Experiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark
models in both 5% and 10% sparsity test cases, with significantly lower RMSE
and MAE, and especially outperforms on low sparsity ratio data. The method
provides an efficient data-completion solution for electric load management in
smart grids.</p></br><a href="http://arxiv.org/pdf/2506.08368v1" target="_blank"><h2>Prospects for Time-Domain and Multi-Messenger Science with eXTP</h2></a><strong><u>Authors:</u></strong>  Shu-Xu Yi, Wen Zhao, Ren-Xin Xu, Xue-Feng Wu, Giulia Stratta, Simone Dall'Osso, Yan-Jun Xu, Andrea Santangelo, Silvia Zane, Shuang-Nan Zhang, Hua Feng, Huan Yang, Junjie Mao, Junqiang Ge, Lijing Shao, Mi-Xiang Lan, He Gao, Lin Lin, Ning Jiang, Qingwen Wu, Tong Liu, Yun-Wei Yu, Xiang-Yu Wang, Jin Zhang, Dafne Guetta, Jin-Jun Geng, Di Xiao, Yong-Feng Huang, Yacheng Kang, Tian-Yong Cao, Zhen Zhang, Zhenwei Lyu, Zhen Pan, Yunfeng Chen, Yong Gao, Ang Li, Yu-Cong Fu, Shuo Xiao, Wei-Yang Wang, Fayin Wang, Zhenyin Zhao, Weihua Lei, Rong-Feng Shen, Lixin Dai, Guang-Lei Wu, Liang-Duan Liu, Jin Zhang, Xilong Fan, Xing-Jiang Zhu, Youjun Lu, Fan Xu, Kangfa Cheng, Da-Bin Lin, Xiao-Hong Zhao, Jun-Jie We, Bin-Bin Zhang, Ji-Rong Mao, Yongquan Xue, Xinwen Shu, Wenjie Zhang, Wei-Li Lin, Achille Fiore, Zhuo Li, Antonio Martin-Carrillo, Joseph Fisher, Fei Xie, Ye Li, Sandro Mereghetti, Shao-Lin Xiong, Yu-Han Yang, Eleonora Troja, Zi-Gao Dai, Da-Ming We, En-Wei Liang</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.CO, astro-ph.GA</br><strong><u>Comments:</u></strong> Submitted to the SCIENCE CHINA Physics, Mechanics & Astronomy</br><p><strong><u>Abstract:</u></strong> In this new era of time-domain and multi-messenger astronomy, various new
transients and new phenomena are constantly being discovered thanks to the
rapid advances in observations, which provide the excellent opportunity to
study the physics in the extreme environments. The enhanced X-ray Timing and
Polarimetry mission (eXTP), planned to be launched in 2030, has several key
advantages, including advanced polarimetry, high sensitivity & large effective
area, and wide energy range coverage, which make it a groundbreaking project in
high-energy astrophysics. In this article, we briefly introduce the potential
time-domain and multi-messenger targets for eXTP, including gravitational-wave
(GW) counterparts, gamma-ray bursts (GRBs), magnetars and fast radio bursts
(FRBs), tidal disruption events (TDEs), supernovae, high energy neutrinos and
TeV active galactic nucleus (AGNs), and so on. We discuss the advantages of
future eXTP observations for detecting these sources, their detection
capabilities, the abilities to distinguish theoretical models, and their
applications in gravity and cosmology.</p></br><a href="http://arxiv.org/pdf/2506.08367v1" target="_blank"><h2>Observatory Science with eXTP</h2></a><strong><u>Authors:</u></strong>  Ping Zhou, Jirong Mao, Liang Zhang, Alessandro Patruno, Enrico Bozzo, Yanjun Xu, Andrea Santangelo, Silvia Zane, Shuang-Nan Zhang, Hua Feng, Yuri Cavecchi, Barbara De Marco, Junhui Fan, Xian Hou, Pengfei Jiang, Patrizia Romano, Gloria Sala, Lian Tao, Alexandra Veledina, Jacco Vink, Song Wang, Junxian Wang, Yidi Wang, Shanshan Weng, Qingwen Wu, Fei Xie, Guobao Zhang, Jin Zhang, Zhanhao Zhao, Shijie Zheng, Samuzal Barua, Yue-Hong Chen, Yupeng Chen, Shi-Jiang Chen, Liang Chen, Yongyun Chen, Xin Cheng, Yi-Heng Chi, Lang Cui, Domitilla de Martino, Wei Deng, Lorenzo Ducci, Ruben Farinelli, Fabo Feng, Mingyu Ge, Minfeng Gu, Hengxiao Guo, Dawei Han, Xinke Hu, Yongfeng Huang, Jean in't Zand, Long Ji, Jialai Kang, Yves Kini, Panping Li, Zhaosheng Li, Kuan Liu, Jiren Liu, Jieying Liu, Ming Lyu, Alessio Marino, Alex Markowitz, Mar Mezcua, Matt Middleton, Guobin Mou, C. -Y. Ng, Alessandro Papitto, Zhiyuan Pei, Jingqiang Peng, Juri Poutanen, Qingcang Shui, Scaringi Simone, Yang Su, Ying Tan, Xilu Wang, Pengju Wang, Di Wang, Fayin Wang, Junfeng Wang, Mengye Wang, Yusong Wang, Jiancheng Wu, Hubing Xiao, Dingrong Xiong, Xiaojie Xu, Rui Xue, Zhen Yan, Ming Yang, Chuyuan Yang, Wenxin Yang, Wentao Ye, Zhuoli Yu, Yuhai Yuan, Xiao Zhang, Lixia Zhang, Shujie Zhao, Qingchang Zhao, Yonggang Zheng, Wei Zheng, Wenwen Zuo</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA, astro-ph.HE, astro-ph.SR</br><strong><u>Comments:</u></strong> Submitted to the SCIENCE CHINA Physics, Mechanics & Astronomy</br><p><strong><u>Abstract:</u></strong> Scheduled for launch in 2030, the enhanced X-ray Timing and Polarization
(eXTP) telescope is a Chinese space-based mission aimed at studying extreme
conditions and phenomena in astrophysics. eXTP will feature three main
payloads: Spectroscopy Focusing Arrays (SFAs), Polarimetry Focusing Arrays
(PFAs), and a Wide-field Camera (W2C). This white paper outlines observatory
science, incorporating key scientific advances and instrumental changes since
the publication of the previous white paper [1]. We will discuss perspectives
of eXTP on the research domains of flare stars, supernova remnants, pulsar wind
nebulae, cataclysmic variables, X-ray binaries, ultraluminous X-ray sources,
AGN, and pulsar-based positioning and timekeeping.</p></br><a href="http://arxiv.org/pdf/2506.07854v1" target="_blank"><h2>Residual Reweighted Conformal Prediction for Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Zheng Zhang, Jie Bao, Zhixin Zhou, Nicolo Colombo, Lixin Cheng, Rui Luo</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) excel at modeling relational data but face
significant challenges in high-stakes domains due to unquantified uncertainty.
Conformal prediction (CP) offers statistical coverage guarantees, but existing
methods often produce overly conservative prediction intervals that fail to
account for graph heteroscedasticity and structural biases. While residual
reweighting CP variants address some of these limitations, they neglect graph
topology, cluster-specific uncertainties, and risk data leakage by reusing
training sets. To address these issues, we propose Residual Reweighted GNN
(RR-GNN), a framework designed to generate minimal prediction sets with
provable marginal coverage guarantees.
  RR-GNN introduces three major innovations to enhance prediction performance.
First, it employs Graph-Structured Mondrian CP to partition nodes or edges into
communities based on topological features, ensuring cluster-conditional
coverage that reflects heterogeneity. Second, it uses Residual-Adaptive
Nonconformity Scores by training a secondary GNN on a held-out calibration set
to estimate task-specific residuals, dynamically adjusting prediction intervals
according to node or edge uncertainty. Third, it adopts a Cross-Training
Protocol, which alternates the optimization of the primary GNN and the residual
predictor to prevent information leakage while maintaining graph dependencies.
We validate RR-GNN on 15 real-world graphs across diverse tasks, including node
classification, regression, and edge weight prediction. Compared to CP
baselines, RR-GNN achieves improved efficiency over state-of-the-art methods,
with no loss of coverage.</p></br><a href="http://arxiv.org/pdf/2506.08475v1" target="_blank"><h2>Thermodynamically Consistent Latent Dynamics Identification for
  Parametric Systems</h2></a><strong><u>Authors:</u></strong>  Xiaolong He, Yeonjong Shin, Anthony Gruber, Sohyeon Jung, Kookjin Lee, Youngsoo Choi</br><strong><u>Categories:</u></strong> cs.LG, cs.CE, cs.NA, math.NA</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> We propose an efficient thermodynamics-informed latent space dynamics
identification (tLaSDI) framework for the reduced-order modeling of parametric
nonlinear dynamical systems. This framework integrates autoencoders for
dimensionality reduction with newly developed parametric GENERIC
formalism-informed neural networks (pGFINNs), which enable efficient learning
of parametric latent dynamics while preserving key thermodynamic principles
such as free energy conservation and entropy generation across the parameter
space. To further enhance model performance, a physics-informed active learning
strategy is incorporated, leveraging a greedy, residual-based error indicator
to adaptively sample informative training data, outperforming uniform sampling
at equivalent computational cost. Numerical experiments on the Burgers'
equation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed
method achieves up to 3,528x speed-up with 1-3% relative errors, and
significant reduction in training (50-90%) and inference (57-61%) cost.
Moreover, the learned latent space dynamics reveal the underlying thermodynamic
behavior of the system, offering valuable insights into the physical-space
dynamics.</p></br><a href="http://arxiv.org/pdf/2506.07864v1" target="_blank"><h2>Lightweight Sequential Transformers for Blood Glucose Level Prediction
  in Type-1 Diabetes</h2></a><strong><u>Authors:</u></strong>  Mirko Paolo Barbato, Giorgia Rigamonti, Davide Marelli, Paolo Napoletano</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Type 1 Diabetes (T1D) affects millions worldwide, requiring continuous
monitoring to prevent severe hypo- and hyperglycemic events. While continuous
glucose monitoring has improved blood glucose management, deploying predictive
models on wearable devices remains challenging due to computational and memory
constraints. To address this, we propose a novel Lightweight Sequential
Transformer model designed for blood glucose prediction in T1D. By integrating
the strengths of Transformers' attention mechanisms and the sequential
processing of recurrent neural networks, our architecture captures long-term
dependencies while maintaining computational efficiency. The model is optimized
for deployment on resource-constrained edge devices and incorporates a balanced
loss function to handle the inherent data imbalance in hypo- and hyperglycemic
events. Experiments on two benchmark datasets, OhioT1DM and DiaTrend,
demonstrate that the proposed model outperforms state-of-the-art methods in
predicting glucose levels and detecting adverse events. This work fills the gap
between high-performance modeling and practical deployment, providing a
reliable and efficient T1D management solution.</p></br><a href="http://arxiv.org/pdf/2506.08066v1" target="_blank"><h2>WWAggr: A Window Wasserstein-based Aggregation for Ensemble Change Point
  Detection</h2></a><strong><u>Authors:</u></strong>  Alexander Stepikin, Evgenia Romanenkova, Alexey Zaytsev</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Change Point Detection (CPD) aims to identify moments of abrupt distribution
shifts in data streams. Real-world high-dimensional CPD remains challenging due
to data pattern complexity and violation of common assumptions. Resorting to
standalone deep neural networks, the current state-of-the-art detectors have
yet to achieve perfect quality. Concurrently, ensembling provides more robust
solutions, boosting the performance. In this paper, we investigate ensembles of
deep change point detectors and realize that standard prediction aggregation
techniques, e.g., averaging, are suboptimal and fail to account for problem
peculiarities. Alternatively, we introduce WWAggr -- a novel task-specific
method of ensemble aggregation based on the Wasserstein distance. Our procedure
is versatile, working effectively with various ensembles of deep CPD models.
Moreover, unlike existing solutions, we practically lift a long-standing
problem of the decision threshold selection for CPD.</p></br><a href="http://arxiv.org/pdf/2506.08244v1" target="_blank"><h2>Parameter-free approximate equivariance for tasks with finite group
  symmetry</h2></a><strong><u>Authors:</u></strong>  Riccardo Ali, Pietro Li√≤, Jamie Vicary</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Equivariant neural networks incorporate symmetries through group actions,
embedding them as an inductive bias to improve performance on a wide variety of
tasks. However, existing equivariant methods can be computationally intensive,
with high parameter counts, and are often tied to a specific architecture. We
propose a simple zero-parameter approach that imposes approximate equivariance
for a finite group in the latent representation, as an additional term in the
loss function. We conduct experiments which allow the network to learn a group
representation on the latent space, and show in every case it prefers to learn
the regular representation. Fixing this action on the latent space, this yields
a simple method to impose approximate equivariance as an additional loss
penalty. We benchmark our approach on three datasets and compare it against
several existing equivariant methods, showing that in many cases it achieves
similar or better performance for a fraction of the parameters.</p></br><a href="http://arxiv.org/pdf/2506.08397v1" target="_blank"><h2>Spatiotemporal deep learning models for detection of rapid
  intensification in cyclones</h2></a><strong><u>Authors:</u></strong>  Vamshika Sutar, Amandeep Singh, Rohitash Chandra</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Cyclone rapid intensification is the rapid increase in cyclone wind
intensity, exceeding a threshold of 30 knots, within 24 hours. Rapid
intensification is considered an extreme event during a cyclone, and its
occurrence is relatively rare, contributing to a class imbalance in the
dataset. A diverse array of factors influences the likelihood of a cyclone
undergoing rapid intensification, further complicating the task for
conventional machine learning models. In this paper, we evaluate deep learning,
ensemble learning and data augmentation frameworks to detect cyclone rapid
intensification based on wind intensity and spatial coordinates. We note that
conventional data augmentation methods cannot be utilised for generating
spatiotemporal patterns replicating cyclones that undergo rapid
intensification. Therefore, our framework employs deep learning models to
generate spatial coordinates and wind intensity that replicate cyclones to
address the class imbalance problem of rapid intensification. We also use a
deep learning model for the classification module within the data augmentation
framework to differentiate between rapid and non-rapid intensification events
during a cyclone. Our results show that data augmentation improves the results
for rapid intensification detection in cyclones, and spatial coordinates play a
critical role as input features to the given models. This paves the way for
research in synthetic data generation for spatiotemporal data with extreme
events.</p></br><a href="http://arxiv.org/pdf/2506.07883v1" target="_blank"><h2>Diffusion Counterfactual Generation with Semantic Abduction</h2></a><strong><u>Authors:</u></strong>  Rajat Rasal, Avinash Kori, Fabio De Sousa Ribeiro, Tian Xia, Ben Glocker</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> Proceedings of the 42nd International Conference on Machine Learning, Vancouver, Canada</br><p><strong><u>Abstract:</u></strong> Counterfactual image generation presents significant challenges, including
preserving identity, maintaining perceptual quality, and ensuring faithfulness
to an underlying causal model. While existing auto-encoding frameworks admit
semantic latent spaces which can be manipulated for causal control, they
struggle with scalability and fidelity. Advancements in diffusion models
present opportunities for improving counterfactual image editing, having
demonstrated state-of-the-art visual quality, human-aligned perception and
representation learning capabilities. Here, we present a suite of
diffusion-based causal mechanisms, introducing the notions of spatial, semantic
and dynamic abduction. We propose a general framework that integrates semantic
representations into diffusion models through the lens of Pearlian causality to
edit images via a counterfactual reasoning process. To our knowledge, this is
the first work to consider high-level semantic identity preservation for
diffusion counterfactuals and to demonstrate how semantic control enables
principled trade-offs between faithful causal control and identity
preservation.</p></br><a href="http://arxiv.org/pdf/2506.07903v1" target="_blank"><h2>Diffuse Everything: Multimodal Diffusion Models on Arbitrary State
  Spaces</h2></a><strong><u>Authors:</u></strong>  Kevin Rojas, Yuchen Zhu, Sichen Zhu, Felix X. -F. Ye, Molei Tao</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV</br><strong><u>Comments:</u></strong> Accepted to ICML 2025. Code available atthis https URL</br><p><strong><u>Abstract:</u></strong> Diffusion models have demonstrated remarkable performance in generating
unimodal data across various tasks, including image, video, and text
generation. On the contrary, the joint generation of multimodal data through
diffusion models is still in the early stages of exploration. Existing
approaches heavily rely on external preprocessing protocols, such as tokenizers
and variational autoencoders, to harmonize varied data representations into a
unified, unimodal format. This process heavily demands the high accuracy of
encoders and decoders, which can be problematic for applications with limited
data. To lift this restriction, we propose a novel framework for building
multimodal diffusion models on arbitrary state spaces, enabling native
generation of coupled data across different modalities. By introducing an
innovative decoupled noise schedule for each modality, we enable both
unconditional and modality-conditioned generation within a single model
simultaneously. We empirically validate our approach for text-image generation
and mixed-type tabular data synthesis, demonstrating that it achieves
competitive performance.</p></br><a href="http://arxiv.org/pdf/2506.08054v1" target="_blank"><h2>STAMImputer: Spatio-Temporal Attention MoE for Traffic Data Imputation</h2></a><strong><u>Authors:</u></strong>  Yiming Wang, Hao Peng, Senzhang Wang, Haohua Du, Chunyang Liu, Jia Wu, Guanlin Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 10 pages, 5 figures, 3 tables. Extended version of paper accepted at IJCAI 2025</br><p><strong><u>Abstract:</u></strong> Traffic data imputation is fundamentally important to support various
applications in intelligent transportation systems such as traffic flow
prediction. However, existing time-to-space sequential methods often fail to
effectively extract features in block-wise missing data scenarios. Meanwhile,
the static graph structure for spatial feature propagation significantly
constrains the models flexibility in handling the distribution shift issue for
the nonstationary traffic data. To address these issues, this paper proposes a
SpatioTemporal Attention Mixture of experts network named STAMImputer for
traffic data imputation. Specifically, we introduce a Mixture of Experts (MoE)
framework to capture latent spatio-temporal features and their influence
weights, effectively imputing block missing. A novel Low-rank guided Sampling
Graph ATtention (LrSGAT) mechanism is designed to dynamically balance the local
and global correlations across road networks. The sampled attention vectors are
utilized to generate dynamic graphs that capture real-time spatial
correlations. Extensive experiments are conducted on four traffic datasets for
evaluation. The result shows STAMImputer achieves significantly performance
improvement compared with existing SOTA approaches. Our codes are available at
https://github.com/RingBDStack/STAMImupter.</p></br><a href="http://arxiv.org/pdf/2506.08306v1" target="_blank"><h2>AstroCompress: A benchmark dataset for multi-purpose compression of
  astronomical data</h2></a><strong><u>Authors:</u></strong>  Tuan Truong, Rithwik Sudharsan, Yibo Yang, Peter Xiangyuan Ma, Ruihan Yang, Stephan Mandt, Joshua S. Bloom</br><strong><u>Categories:</u></strong> cs.AI, astro-ph.IM</br><strong><u>Comments:</u></strong> ICLR 2025 conference paper. See reviews atthis https URL</br><p><strong><u>Abstract:</u></strong> The site conditions that make astronomical observatories in space and on the
ground so desirable -- cold and dark -- demand a physical remoteness that leads
to limited data transmission capabilities. Such transmission limitations
directly bottleneck the amount of data acquired and in an era of costly modern
observatories, any improvements in lossless data compression has the potential
scale to billions of dollars worth of additional science that can be
accomplished on the same instrument. Traditional lossless methods for
compressing astrophysical data are manually designed. Neural data compression,
on the other hand, holds the promise of learning compression algorithms
end-to-end from data and outperforming classical techniques by leveraging the
unique spatial, temporal, and wavelength structures of astronomical images.
This paper introduces AstroCompress: a neural compression challenge for
astrophysics data, featuring four new datasets (and one legacy dataset) with
16-bit unsigned integer imaging data in various modes: space-based,
ground-based, multi-wavelength, and time-series imaging. We provide code to
easily access the data and benchmark seven lossless compression methods (three
neural and four non-neural, including all practical state-of-the-art
algorithms). Our results on lossless compression indicate that lossless neural
compression techniques can enhance data collection at observatories, and
provide guidance on the adoption of neural compression in scientific
applications. Though the scope of this paper is restricted to lossless
compression, we also comment on the potential exploration of lossy compression
methods in future studies.</p></br><a href="http://arxiv.org/pdf/2506.08270v1" target="_blank"><h2>SWAT-NN: Simultaneous Weights and Architecture Training for Neural
  Networks in a Latent Space</h2></a><strong><u>Authors:</u></strong>  Zitong Huang, Mansooreh Montazerin, Ajitesh Srivastava</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Designing neural networks typically relies on manual trial and error or a
neural architecture search (NAS) followed by weight training. The former is
time-consuming and labor-intensive, while the latter often discretizes
architecture search and weight optimization. In this paper, we propose a
fundamentally different approach that simultaneously optimizes both the
architecture and the weights of a neural network. Our framework first trains a
universal multi-scale autoencoder that embeds both architectural and parametric
information into a continuous latent space, where functionally similar neural
networks are mapped closer together. Given a dataset, we then randomly
initialize a point in the embedding space and update it via gradient descent to
obtain the optimal neural network, jointly optimizing its structure and
weights. The optimization process incorporates sparsity and compactness
penalties to promote efficient models. Experiments on synthetic regression
tasks demonstrate that our method effectively discovers sparse and compact
neural networks with strong performance.</p></br><a href="http://arxiv.org/pdf/2506.08572v1" target="_blank"><h2>The Geometries of Truth Are Orthogonal Across Tasks</h2></a><strong><u>Authors:</u></strong>  Waiss Azizian, Michael Kirchhof, Eugene Ndiaye, Louis Bethune, Michal Klein, Pierre Ablin, Marco Cuturi</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) have demonstrated impressive generalization
capabilities across various tasks, but their claim to practical relevance is
still mired by concerns on their reliability. Recent works have proposed
examining the activations produced by an LLM at inference time to assess
whether its answer to a question is correct. Some works claim that a "geometry
of truth" can be learned from examples, in the sense that the activations that
generate correct answers can be distinguished from those leading to mistakes
with a linear classifier. In this work, we underline a limitation of these
approaches: we observe that these "geometries of truth" are intrinsically
task-dependent and fail to transfer across tasks. More precisely, we show that
linear classifiers trained across distinct tasks share little similarity and,
when trained with sparsity-enforcing regularizers, have almost disjoint
supports. We show that more sophisticated approaches (e.g., using mixtures of
probes and tasks) fail to overcome this limitation, likely because activation
vectors commonly used to classify answers form clearly separated clusters when
examined across tasks.</p></br><a href="http://arxiv.org/pdf/2506.07804v1" target="_blank"><h2>Enhancing Adversarial Robustness with Conformal Prediction: A Framework
  for Guaranteed Model Reliability</h2></a><strong><u>Authors:</u></strong>  Jie Bao, Chuangyin Dang, Rui Luo, Hanwei Zhang, Zhixin Zhou</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> As deep learning models are increasingly deployed in high-risk applications,
robust defenses against adversarial attacks and reliable performance guarantees
become paramount. Moreover, accuracy alone does not provide sufficient
assurance or reliable uncertainty estimates for these models. This study
advances adversarial training by leveraging principles from Conformal
Prediction. Specifically, we develop an adversarial attack method, termed OPSA
(OPtimal Size Attack), designed to reduce the efficiency of conformal
prediction at any significance level by maximizing model uncertainty without
requiring coverage guarantees. Correspondingly, we introduce OPSA-AT
(Adversarial Training), a defense strategy that integrates OPSA within a novel
conformal training paradigm. Experimental evaluations demonstrate that our OPSA
attack method induces greater uncertainty compared to baseline approaches for
various defenses. Conversely, our OPSA-AT defensive model significantly
enhances robustness not only against OPSA but also other adversarial attacks,
and maintains reliable prediction. Our findings highlight the effectiveness of
this integrated approach for developing trustworthy and resilient deep learning
models for safety-critical domains. Our code is available at
https://github.com/bjbbbb/Enhancing-Adversarial-Robustness-with-Conformal-Prediction.</p></br><a href="http://arxiv.org/pdf/2506.08505v1" target="_blank"><h2>Explaining, Fast and Slow: Abstraction and Refinement of Provable
  Explanations</h2></a><strong><u>Authors:</u></strong>  Shahaf Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Matthias Althoff, Guy Katz</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.LO</br><strong><u>Comments:</u></strong> To appear in ICML 2025</br><p><strong><u>Abstract:</u></strong> Despite significant advancements in post-hoc explainability techniques for
neural networks, many current methods rely on heuristics and do not provide
formally provable guarantees over the explanations provided. Recent work has
shown that it is possible to obtain explanations with formal guarantees by
identifying subsets of input features that are sufficient to determine that
predictions remain unchanged using neural network verification techniques.
Despite the appeal of these explanations, their computation faces significant
scalability challenges. In this work, we address this gap by proposing a novel
abstraction-refinement technique for efficiently computing provably sufficient
explanations of neural network predictions. Our method abstracts the original
large neural network by constructing a substantially reduced network, where a
sufficient explanation of the reduced network is also provably sufficient for
the original network, hence significantly speeding up the verification process.
If the explanation is in sufficient on the reduced network, we iteratively
refine the network size by gradually increasing it until convergence. Our
experiments demonstrate that our approach enhances the efficiency of obtaining
provably sufficient explanations for neural network predictions while
additionally providing a fine-grained interpretation of the network's
predictions across different abstraction levels.</p></br><a href="http://arxiv.org/pdf/2506.07407v1" target="_blank"><h2>Anomaly Detection and Early Warning Mechanism for Intelligent Monitoring
  Systems in Multi-Cloud Environments Based on LLM</h2></a><strong><u>Authors:</u></strong>  Yihong Jin, Ze Yang, Juntian Liu, Xinhe Xu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Proceedings of 2025 5th International Symposium on Computer Technology and Information Science (ISCTIS 2025)</br><p><strong><u>Abstract:</u></strong> With the rapid development of multi-cloud environments, it is increasingly
important to ensure the security and reliability of intelligent monitoring
systems. In this paper, we propose an anomaly detection and early warning
mechanism for intelligent monitoring system in multi-cloud environment based on
Large-Scale Language Model (LLM). On the basis of the existing monitoring
framework, the proposed model innovatively introduces a multi-level feature
extraction method, which combines the natural language processing ability of
LLM with traditional machine learning methods to enhance the accuracy of
anomaly detection and improve the real-time response efficiency. By introducing
the contextual understanding capabilities of LLMs, the model dynamically adapts
to different cloud service providers and environments, so as to more
effectively detect abnormal patterns and predict potential failures.
Experimental results show that the proposed model is significantly better than
the traditional anomaly detection system in terms of detection accuracy and
latency, and significantly improves the resilience and active management
ability of cloud infrastructure.</p></br></body>