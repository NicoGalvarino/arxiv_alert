<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 27 Aug 2025 to 29 Aug 2025</em></font><a href="http://arxiv.org/pdf/2508.20413v1" target="_blank"><h2>Assessing local deformation and computing scalar curvature with
  nonlinear conformal regularization of decoders</h2></a><strong><u>Authors:</u></strong>  Benjamin Couéraud, Vikram Sunkara, Christof Schütte</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, 68T07</br><strong><u>Comments:</u></strong> 9 pages</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> One aim of dimensionality reduction is to discover the main factors that
explain the data, and as such is paramount to many applications. When working
with high dimensional data, autoencoders offer a simple yet effective approach
to learn low-dimensional representations. The two components of a general
autoencoder consist first of an encoder that maps the observed data onto a
latent space; and second a decoder that maps the latent space back to the
original observation space, which allows to learn a low-dimensional manifold
representation of the original data. In this article, we introduce a new type
of geometric regularization for decoding maps approximated by deep neural
networks, namely nonlinear conformal regularization. This regularization
procedure permits local variations of the decoder map and comes with a new
scalar field called conformal factor which acts as a quantitative indicator of
the amount of local deformation sustained by the latent space when mapped into
the original data space. We also show that this regularization technique allows
the computation of the scalar curvature of the learned manifold. Implementation
and experiments on the Swiss roll and CelebA datasets are performed to
illustrate how to obtain these quantities from the architecture.</p></br><a href="http://arxiv.org/pdf/2508.20829v1" target="_blank"><h2>ATM-GAD: Adaptive Temporal Motif Graph Anomaly Detection for Financial
  Transaction Networks</h2></a><strong><u>Authors:</u></strong>  Zeyue Zhang, Lin Song, Erkang Bao, Xiaoling Lv, Xinyue Wang</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Financial fraud detection is essential to safeguard billions of dollars, yet
the intertwined entities and fast-changing transaction behaviors in modern
financial systems routinely defeat conventional machine learning models. Recent
graph-based detectors make headway by representing transactions as networks,
but they still overlook two fraud hallmarks rooted in time: (1) temporal
motifs--recurring, telltale subgraphs that reveal suspicious money flows as
they unfold--and (2) account-specific intervals of anomalous activity, when
fraud surfaces only in short bursts unique to each entity. To exploit both
signals, we introduce ATM-GAD, an adaptive graph neural network that leverages
temporal motifs for financial anomaly detection. A Temporal Motif Extractor
condenses each account's transaction history into the most informative motifs,
preserving both topology and temporal patterns. These motifs are then analyzed
by dual-attention blocks: IntraA reasons over interactions within a single
motif, while InterA aggregates evidence across motifs to expose multi-step
fraud schemes. In parallel, a differentiable Adaptive Time-Window Learner
tailors the observation window for every node, allowing the model to focus
precisely on the most revealing time slices. Experiments on four real-world
datasets show that ATM-GAD consistently outperforms seven strong
anomaly-detection baselines, uncovering fraud patterns missed by earlier
methods.</p></br><a href="http://arxiv.org/pdf/2508.20294v1" target="_blank"><h2>Dynamics-Aligned Latent Imagination in Contextual World Models for
  Zero-Shot Generalization</h2></a><strong><u>Authors:</u></strong>  Frank Röder, Jan Benad, Manfred Eppe, Pradeep Kr. Banerjee</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 31 pages, 4 figures</br><strong><u>Matching Keywords:</u></strong> latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Real-world reinforcement learning demands adaptation to unseen environmental
conditions without costly retraining. Contextual Markov Decision Processes
(cMDP) model this challenge, but existing methods often require explicit
context variables (e.g., friction, gravity), limiting their use when contexts
are latent or hard to measure. We introduce Dynamics-Aligned Latent Imagination
(DALI), a framework integrated within the Dreamer architecture that infers
latent context representations from agent-environment interactions. By training
a self-supervised encoder to predict forward dynamics, DALI generates
actionable representations conditioning the world model and policy, bridging
perception and control. We theoretically prove this encoder is essential for
efficient context inference and robust generalization. DALI's latent space
enables counterfactual consistency: Perturbing a gravity-encoding dimension
alters imagined rollouts in physically plausible ways. On challenging cMDP
benchmarks, DALI achieves significant gains over context-unaware baselines,
often surpassing context-aware baselines in extrapolation tasks, enabling
zero-shot generalization to unseen contextual variations.</p></br><a href="http://arxiv.org/pdf/2508.20903v1" target="_blank"><h2>Improved photometric redshift estimations through self-organising
  map-based data augmentation</h2></a><strong><u>Authors:</u></strong>  Yun-Hao Zhang, Joe Zuntz, Irene Moskowitz, Eric Gawiser, Konrad Kuijken, Marika Asgari, Henk Hoekstra, Alex I. Malz, Ziang Yan, Tianqing Zhang, The LSST Dark Energy Science Collaboration</br><strong><u>Categories:</u></strong> astro-ph.GA, astro-ph.CO</br><strong><u>Comments:</u></strong> Submitted to MNRAS</br><strong><u>Matching Keywords:</u></strong> data augmentation (title, abstract)</br><p><strong><u>Abstract:</u></strong> We introduce a framework for the enhanced estimation of photometric redshifts
using Self-Organising Maps (SOMs). Our method projects galaxy Spectral Energy
Distributions (SEDs) onto a two-dimensional map, identifying regions that are
sparsely sampled by existing spectroscopic observations. These under-sampled
areas are then augmented with simulated galaxies, yielding a more
representative spectroscopic training dataset. To assess the efficacy of this
SOM-based data augmentation in the context of the forthcoming Legacy Survey of
Space and Time (LSST), we employ mock galaxy catalogues from the
OpenUniverse2024 project and generate synthetic datasets that mimic the
expected photometric selections of LSST after one (Y1) and ten (Y10) years of
observation. We construct 501 degraded realisations by sampling galaxy colours,
magnitudes, redshifts and spectroscopic success rates, in order to emulate the
compilation of a wide array of realistic spectroscopic surveys. Augmenting the
degraded mock datasets with simulated galaxies from the independent CosmoDC2
catalogues has markedly improved the performance of our photometric redshift
estimates compared to models lacking this augmentation, particularly for
high-redshift galaxies ($z_\mathrm{true} \gtrsim 1.5$). This improvement is
manifested in notably reduced systematic biases and a decrease in catastrophic
failures by up to approximately a factor of 2, along with a reduction in
information loss in the conditional density estimations. These results
underscore the effectiveness of SOM-based augmentation in refining photometric
redshift estimation, thereby enabling more robust analyses in cosmology and
astrophysics for the NSF-DOE Vera C. Rubin Observatory.</p></br><a href="http://arxiv.org/pdf/2508.19750v1" target="_blank"><h2>Fractal Flow: Hierarchical and Interpretable Normalizing Flow via Topic
  Modeling and Recursive Strategy</h2></a><strong><u>Authors:</u></strong>  Binhui Zhang, Jianwei Ma</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Normalizing Flows provide a principled framework for high-dimensional density
estimation and generative modeling by constructing invertible transformations
with tractable Jacobian determinants. We propose Fractal Flow, a novel
normalizing flow architecture that enhances both expressiveness and
interpretability through two key innovations. First, we integrate
Kolmogorov-Arnold Networks and incorporate Latent Dirichlet Allocation into
normalizing flows to construct a structured, interpretable latent space and
model hierarchical semantic clusters. Second, inspired by Fractal Generative
Models, we introduce a recursive modular design into normalizing flows to
improve transformation interpretability and estimation accuracy. Experiments on
MNIST, FashionMNIST, CIFAR-10, and geophysical data demonstrate that the
Fractal Flow achieves latent clustering, controllable generation, and superior
estimation accuracy.</p></br><a href="http://arxiv.org/pdf/2508.20398v1" target="_blank"><h2>TF-TransUNet1D: Time-Frequency Guided Transformer U-Net for Robust ECG
  Denoising in Digital Twin</h2></a><strong><u>Authors:</u></strong>  Shijie Wang, Lei Li</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 9 pages, 3 figures International Workshop on Digital Twin for Healthcare (DT4H) in MICCAI 2025 (Daejeon, Republic of Korea)</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (title, abstract)</br><p><strong><u>Abstract:</u></strong> Electrocardiogram (ECG) signals serve as a foundational data source for
cardiac digital twins, yet their diagnostic utility is frequently compromised
by noise and artifacts. To address this issue, we propose TF-TransUNet1D, a
novel one-dimensional deep neural network that integrates a U-Net-based
encoder-decoder architecture with a Transformer encoder, guided by a hybrid
time-frequency domain loss. The model is designed to simultaneously capture
local morphological features and long-range temporal dependencies, which are
critical for preserving the diagnostic integrity of ECG signals. To enhance
denoising robustness, we introduce a dual-domain loss function that jointly
optimizes waveform reconstruction in the time domain and spectral fidelity in
the frequency domain. In particular, the frequency-domain component effectively
suppresses high-frequency noise while maintaining the spectral structure of the
signal, enabling recovery of subtle but clinically significant waveform
components. We evaluate TF-TransUNet1D using synthetically corrupted signals
from the MIT-BIH Arrhythmia Database and the Noise Stress Test Database
(NSTDB). Comparative experiments against state-of-the-art baselines demonstrate
consistent superiority of our model in terms of SNR improvement and error
metrics, achieving a mean absolute error of 0.1285 and Pearson correlation
coefficient of 0.9540. By delivering high-precision denoising, this work
bridges a critical gap in pre-processing pipelines for cardiac digital twins,
enabling more reliable real-time monitoring and personalized modeling.</p></br><a href="http://arxiv.org/pdf/2508.21010v1" target="_blank"><h2>ChainReaction! Structured Approach with Causal Chains as Intermediate
  Representations for Improved and Explainable Causal Video Question Answering</h2></a><strong><u>Authors:</u></strong>  Paritosh Parmar, Eric Peh, Basura Fernando</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL, cs.HC, cs.LG</br><strong><u>Comments:</u></strong> Project page:this https URL</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title), causality (abstract)</br><p><strong><u>Abstract:</u></strong> Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/</p></br></body>