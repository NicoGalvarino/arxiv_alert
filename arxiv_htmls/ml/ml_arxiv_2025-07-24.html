<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 17 Jul 2025 to 24 Jul 2025</em></font><a href="http://arxiv.org/pdf/2507.16088v1" target="_blank"><h2>Applying multimodal learning to Classify transient Detections Early
  (AppleCiDEr) I: Data set, methods, and infrastructure</h2></a><strong><u>Authors:</u></strong>  Alexandra Junell, Argyro Sasli, Felipe Fontinele Nunes, Maojie Xu, Benny Border, Nabeel Rehemtulla, Mariia Rizhko, Yu-Jing Qin, Theophile Jegou Du Laz, Antoine Le Calloch, Sushant Sharma Chaudhary, Shaowei Wu, Jesper Sollerman, Niharika Sravan, Steven L. Groom, David Hale, Avery Wold, Michael W. Coughlin</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE</br><strong><u>Comments:</u></strong> 17 pages, 8 figures</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multimodal (title, abstract), time-domain (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Modern time-domain surveys like the Zwicky Transient Facility (ZTF) and the
Legacy Survey of Space and Time (LSST) generate hundreds of thousands to
millions of alerts, demanding automatic, unified classification of transients
and variable stars for efficient follow-up. We present AppleCiDEr (Applying
Multimodal Learning to Classify Transient Detections Early), a novel framework
that integrates four key data modalities (photometry, image cutouts, metadata,
and spectra) to overcome limitations of single-modality classification
approaches. Our architecture introduces (i) two transformer encoders for
photometry, (ii) a multimodal convolutional neural network (CNN) with
domain-specialized metadata towers and Mixture-of-Experts fusion for combining
metadata and images, and (iii) a CNN for spectra classification. Training on ~
30,000 real ZTF alerts, AppleCiDEr achieves high accuracy, allowing early
identification and suggesting follow-up for rare transient spectra. The system
provides the first unified framework for both transient and variable star
classification using real observational data, with seamless integration into
brokering pipelines, demonstrating readiness for the LSST era.</p></br><a href="http://arxiv.org/pdf/2507.15643v1" target="_blank"><h2>Towards Explainable Anomaly Detection in Shared Mobility Systems</h2></a><strong><u>Authors:</u></strong>  Elnur Isgandarov, Matteo Cederle, Federico Chiariotti, Gian Antonio Susto</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 6 pages, 8 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), explainable (title)</br><p><strong><u>Abstract:</u></strong> Shared mobility systems, such as bike-sharing networks, play a crucial role
in urban transportation. Identifying anomalies in these systems is essential
for optimizing operations, improving service reliability, and enhancing user
experience. This paper presents an interpretable anomaly detection framework
that integrates multi-source data, including bike-sharing trip records, weather
conditions, and public transit availability. The Isolation Forest algorithm is
employed for unsupervised anomaly detection, along with the Depth-based
Isolation Forest Feature Importance (DIFFI) algorithm providing
interpretability. Results show that station-level analysis offers a robust
understanding of anomalies, highlighting the influence of external factors such
as adverse weather and limited transit availability. Our findings contribute to
improving decision-making in shared mobility operations.</p></br><a href="http://arxiv.org/pdf/2507.15718v1" target="_blank"><h2>Explainable Anomaly Detection for Electric Vehicles Charging Stations</h2></a><strong><u>Authors:</u></strong>  Matteo Cederle, Andrea Mazzucco, Andrea Demartini, Eugenio Mazza, Eugenia Suriani, Federico Vitti, Gian Antonio Susto</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 4 pages, 3 figures. Paper accepted to J3C 2025 (Joint Conference on Computers, Cognition and Communication)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> Electric vehicles (EV) charging stations are one of the critical
infrastructures needed to support the transition to renewable-energy-based
mobility, but ensuring their reliability and efficiency requires effective
anomaly detection to identify irregularities in charging behavior. However, in
such a productive scenario, it is also crucial to determine the underlying
cause behind the detected anomalies. To achieve this goal, this study
investigates unsupervised anomaly detection techniques for EV charging
infrastructure, integrating eXplainable Artificial Intelligence techniques to
enhance interpretability and uncover root causes of anomalies.
  Using real-world sensors and charging session data, this work applies
Isolation Forest to detect anomalies and employs the Depth-based Isolation
Forest Feature Importance (DIFFI) method to identify the most important
features contributing to such anomalies. The efficacy of the proposed approach
is evaluated in a real industrial case.</p></br><a href="http://arxiv.org/pdf/2507.14387v1" target="_blank"><h2>Incremental Causal Graph Learning for Online Cyberattack Detection in
  Cyber-Physical Infrastructures</h2></a><strong><u>Authors:</u></strong>  Arun Vignesh Malarkkan, Dongjie Wang, Haoyue Bai, Yanjie Fu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 12 pages, 5 figures, 3 Tables, under review in IEEE Transactions on Big Data</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> The escalating threat of cyberattacks on real-time critical infrastructures
poses serious risks to public safety, demanding detection methods that
effectively capture complex system interdependencies and adapt to evolving
attack patterns. Traditional real-time anomaly detection techniques often
suffer from excessive false positives due to their statistical sensitivity to
high data variance and class imbalance. To address these limitations, recent
research has explored modeling causal relationships among system components.
However, prior work mainly focuses on offline causal graph-based approaches
that require static historical data and fail to generalize to real-time
settings. These methods are fundamentally constrained by: (1) their inability
to adapt to dynamic shifts in data distribution without retraining, and (2) the
risk of catastrophic forgetting when lacking timely supervision in live
systems. To overcome these challenges, we propose INCADET, a novel framework
for incremental causal graph learning tailored to real-time cyberattack
detection. INCADET dynamically captures evolving system behavior by
incrementally updating causal graphs across streaming time windows. The
framework comprises three modules: 1) Early Symptom Detection: Detects
transitions in system status using divergence in edge-weight distributions
across sequential causal graphs. 2) Incremental Causal Graph Learning:
Leverages experience replay and edge reinforcement to continually refine causal
structures while preserving prior knowledge. 3) Causal Graph Classification:
Employs Graph Convolutional Networks (GCNs) to classify system status using the
learned causal graphs. Extensive experiments on real-world critical
infrastructure datasets demonstrate that INCADET achieves superior accuracy,
robustness, and adaptability compared to both static causal and deep temporal
baselines in evolving attack scenarios.</p></br><a href="http://arxiv.org/pdf/2507.15066v1" target="_blank"><h2>Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback</h2></a><strong><u>Authors:</u></strong>  Yiyuan Yang, Zichuan Liu, Lei Song, Kai Ying, Zhiguang Wang, Tom Bamford, Svitlana Vyetrenko, Jiang Bian, Qingsong Wen</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.MM</br><strong><u>Comments:</u></strong> Under review. 19 pages, 8 figures, 12 tables</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Time series anomaly detection is critical across various domains, yet current
approaches often limit analysis to mere binary anomaly classification without
detailed categorization or further explanatory reasoning. To address these
limitations, we propose a novel task, Time-series Reasoning for Anomaly
(Time-RA) that transforms classical time series anomaly detection from a
discriminative into a generative, reasoning-intensive task leveraging Large
Language Models (LLMs). Also, we introduce the first real-world multimodal
benchmark dataset, RATs40K, explicitly annotated for anomaly reasoning,
comprising approximately 40,000 samples across 10 real-world domains. Each
sample includes numeric time series data, contextual text information, and
visual representations, each annotated with fine-grained categories (14 types
for univariate anomalies and 6 for multivariate anomalies) and structured
explanatory reasoning. We develop a sophisticated annotation framework
utilizing ensemble-generated labels refined through GPT-4-driven feedback,
ensuring accuracy and interpretability. Extensive benchmarking of LLMs and
multimodal LLMs demonstrates the capabilities and limitations of current
models, highlighting the critical role of supervised fine-tuning. Our dataset
and task pave the way for significant advancements in interpretable time series
anomaly detection and reasoning.</p></br><a href="http://arxiv.org/pdf/2507.15905v1" target="_blank"><h2>Foundation Models and Transformers for Anomaly Detection: A Survey</h2></a><strong><u>Authors:</u></strong>  Mouïn Ben Ammar, Arturo Mendoza, Nacim Belkhir, Antoine Manzanera, Gianni Franchi</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), transformer (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> In line with the development of deep learning, this survey examines the
transformative role of Transformers and foundation models in advancing visual
anomaly detection (VAD). We explore how these architectures, with their global
receptive fields and adaptability, address challenges such as long-range
dependency modeling, contextual modeling and data scarcity. The survey
categorizes VAD methods into reconstruction-based, feature-based and
zero/few-shot approaches, highlighting the paradigm shift brought about by
foundation models. By integrating attention mechanisms and leveraging
large-scale pre-training, Transformers and foundation models enable more
robust, interpretable, and scalable anomaly detection solutions. This work
provides a comprehensive review of state-of-the-art techniques, their
strengths, limitations, and emerging trends in leveraging these architectures
for VAD.</p></br><a href="http://arxiv.org/pdf/2507.14126v1" target="_blank"><h2>Toward Temporal Causal Representation Learning with Tensor Decomposition</h2></a><strong><u>Authors:</u></strong>  Jianhong Chen, Meng Zhao, Mostafa Reisi Gahrooei, Xubo Yue</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (abstract)</br><p><strong><u>Abstract:</u></strong> Temporal causal representation learning is a powerful tool for uncovering
complex patterns in observational studies, which are often represented as
low-dimensional time series. However, in many real-world applications, data are
high-dimensional with varying input lengths and naturally take the form of
irregular tensors. To analyze such data, irregular tensor decomposition is
critical for extracting meaningful clusters that capture essential information.
In this paper, we focus on modeling causal representation learning based on the
transformed information. First, we present a novel causal formulation for a set
of latent clusters. We then propose CaRTeD, a joint learning framework that
integrates temporal causal representation learning with irregular tensor
decomposition. Notably, our framework provides a blueprint for downstream tasks
using the learned tensor factors, such as modeling latent structures and
extracting causal information, and offers a more flexible regularization design
to enhance tensor decomposition. Theoretically, we show that our algorithm
converges to a stationary point. More importantly, our results fill the gap in
theoretical guarantees for the convergence of state-of-the-art irregular tensor
decomposition. Experimental results on synthetic and real-world electronic
health record (EHR) datasets (MIMIC-III), with extensive benchmarks from both
phenotyping and network recovery perspectives, demonstrate that our proposed
method outperforms state-of-the-art techniques and enhances the explainability
of causal representations.</p></br><a href="http://arxiv.org/pdf/2507.17499v1" target="_blank"><h2>Early Identification of Optical Tidal Disruption Events: A science
  module for the Fink broker</h2></a><strong><u>Authors:</u></strong>  Miguel Llamas Lanza, Sergey Karpov, Etienne Russeil, Erwan Quintin, Emille Ishida, Julien Peloton, Maria Pruzhinskaya, Anais Möller</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA, astro-ph.IM</br><strong><u>Comments:</u></strong> Submitted to A&A. 12 pages + 1 appendix, 6 (+1) Figures</br><strong><u>Matching Keywords:</u></strong> time-domain (abstract)</br><p><strong><u>Abstract:</u></strong> The detection of tidal disruption events (TDEs) is one of the key science
goals of large optical time-domain surveys such as the Zwicky Transient
Facility (ZTF) and the upcoming Vera C. Rubin Observatory Legacy Survey of
Space and Time. However, identifying TDEs in the vast alert streams produced by
these surveys requires automated and reliable classification pipelines that can
select promising candidates in real time. We developed a module within the Fink
alert broker to identify TDEs during their rising phase. It was built to
autonomously operate within the ZTF alert stream, producing a list of
candidates every night and enabling spectral and multi-wavelength follow-up
near peak brightness. All rising alerts are submitted to selection cuts and
feature extraction using the Rainbow multi-band lightcurve fit. Best-fit values
were used as input to train an XGBoost classifier with the goal of identifying
TDEs. The training set was constructed using ZTF observations for objects with
available classification in the Transient Name Server. Finally, candidates with
high enough probability were visually inspected. The classifier achieves 76%
recall, indicating strong performance in early-phase identification, despite
the limited available information before peak. We show that, out of the known
TDEs that pass the selection cuts, half of them are flagged as TDE before
halfway in their rise, proving the feasibility of early classification.
Additionally, new candidates were identified by applying the classifier on
archival data, including a likely repeated TDE and some potential TDEs
occurring in active galaxies. The module is implemented into the Fink alert
processing framework, reporting each night a small number of candidates to
dedicated communication channels through a user-friendly interface, for manual
vetting and potential follow-up.</p></br><a href="http://arxiv.org/pdf/2507.14441v1" target="_blank"><h2>New Frontiers in the Study of Magnetic Massive Stars with the Habitable
  Worlds Observatory</h2></a><strong><u>Authors:</u></strong>  Alexandre David-Uraz, Véronique Petit, Coralie Neiner, Jean-Claude Bouret, Yaël Nazé, Christiana Erba, Miriam Garcia, Kenneth Gayley, Richard Ignace, Jiři Krtička, Hugues Sana, Nicole St-Louis, Asif ud-Doula</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA, astro-ph.HE, astro-ph.SR</br><strong><u>Comments:</u></strong> 11 pages, 4 figures. HWO science case, to be presented at the conference "Towards the Habitable Worlds Observatory: Visionary Science and Transformational Technology" and to be submitted to Astronomical Society of the Pacific</br><strong><u>Matching Keywords:</u></strong> VAE (abstract)</br><p><strong><u>Abstract:</u></strong> High-mass stars are notable for several reasons: they are characterized by
strong winds, which inject momentum and enriched material into their
surroundings, and die spectacularly as supernovae, leaving behind compact
remnants and heavy elements (such as those that make life on Earth possible).
Despite their relative rarity, they play a disproportionate role in the
evolution of the galaxies that host them, and likely also played a significant
role in the early days of the Universe. A subset ($\sim$10\%) of these stars
was also found to host magnetic fields on their surface. These fields impact
their evolution, and may lead to exotic physics (e.g., heavy stellar-mass black
holes, pair-instability supernovae, magnetars, etc.). However, the detection
and measurement of magnetic fields is limited, due to current instrumentation,
to nearby massive stars in the Milky Way. To truly understand how magnetism
arises in massive stars, and what role it might have played in earlier stages
of our Universe, we require next-generation hardware, such as the proposed
near-infrared-to-ultraviolet spectropolarimeter Pollux, on the Habitable Worlds
Observatory (HWO). In this contribution, we detail how Pollux @ HWO will enable
new frontiers in the study of magnetic massive stars, delivering results that
will profoundly impact the fields of stellar formation, stellar evolution,
compact objects, and stellar feedback.</p></br><a href="http://arxiv.org/pdf/2507.15900v1" target="_blank"><h2>Improving the Generation of VAEs with High Dimensional Latent Spaces by
  the use of Hyperspherical Coordinates</h2></a><strong><u>Authors:</u></strong>  Alejandro Ascarate, Leo Lebrat, Rodrigo Santa Cruz, Clinton Fookes, Olivier Salvado</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 8 pages, 3 figures, published in IJCNN25 (in press)</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), latent space (title, abstract)</br><p><strong><u>Abstract:</u></strong> Variational autoencoders (VAE) encode data into lower-dimensional latent
vectors before decoding those vectors back to data. Once trained, decoding a
random latent vector from the prior usually does not produce meaningful data,
at least when the latent space has more than a dozen dimensions. In this paper,
we investigate this issue by drawing insight from high dimensional statistics:
in these regimes, the latent vectors of a standard VAE are by construction
distributed uniformly on a hypersphere. We propose to formulate the latent
variables of a VAE using hyperspherical coordinates, which allows compressing
the latent vectors towards an island on the hypersphere, thereby reducing the
latent sparsity and we show that this improves the generation ability of the
VAE. We propose a new parameterization of the latent space with limited
computational overhead.</p></br><a href="http://arxiv.org/pdf/2507.14706v1" target="_blank"><h2>Fraud is Not Just Rarity: A Causal Prototype Attention Approach to
  Realistic Synthetic Oversampling</h2></a><strong><u>Authors:</u></strong>  Claudio Giusti, Luca Guarnera, Mirko Casu, Sebastiano Battiato</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 23 pages, 14 figures</br><strong><u>Matching Keywords:</u></strong> VAE (abstract), latent space (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Detecting fraudulent credit card transactions remains a significant
challenge, due to the extreme class imbalance in real-world data and the often
subtle patterns that separate fraud from legitimate activity. Existing research
commonly attempts to address this by generating synthetic samples for the
minority class using approaches such as GANs, VAEs, or hybrid generative
models. However, these techniques, particularly when applied only to
minority-class data, tend to result in overconfident classifiers and poor
latent cluster separation, ultimately limiting real-world detection
performance. In this study, we propose the Causal Prototype Attention
Classifier (CPAC), an interpretable architecture that promotes class-aware
clustering and improved latent space structure through prototype-based
attention mechanisms and we will couple it with the encoder in a VAE-GAN
allowing it to offer a better cluster separation moving beyond post-hoc sample
augmentation. We compared CPAC-augmented models to traditional oversamplers,
such as SMOTE, as well as to state-of-the-art generative models, both with and
without CPAC-based latent classifiers. Our results show that classifier-guided
latent shaping with CPAC delivers superior performance, achieving an F1-score
of 93.14\% percent and recall of 90.18\%, along with improved latent cluster
separation. Further ablation studies and visualizations provide deeper insight
into the benefits and limitations of classifier-driven representation learning
for fraud detection. The codebase for this work will be available at final
submission.</p></br><a href="http://arxiv.org/pdf/2507.16817v1" target="_blank"><h2>Mixture-of-Expert Variational Autoencoders for Cross-Modality Embedding
  of Type Ia Supernova Data</h2></a><strong><u>Authors:</u></strong>  Yunyi Shen, Alexander T. Gagliano</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE</br><strong><u>Comments:</u></strong> Accepted to the Machine Learning for Astrophysics Workshop co-located at ICML 2025 and selected for a spotlight talk</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title, abstract), latent space (abstract), multi-modal (abstract), time-domain (abstract)</br><p><strong><u>Abstract:</u></strong> Time-domain astrophysics relies on heterogeneous and multi-modal data.
Specialized models are often constructed to extract information from a single
modality, but this approach ignores the wealth of cross-modality information
that may be relevant for the tasks to which the model is applied. In this work,
we propose a multi-modal, mixture-of-expert variational autoencoder to learn a
joint embedding for supernova light curves and spectra. Our method, which is
inspired by the Perceiver architecture, natively accommodates variable-length
inputs and the irregular temporal sampling inherent to supernova light curves.
We train our model on radiative transfer simulations and validate its
performance on cross-modality reconstruction of supernova spectra and physical
parameters from the simulation. Our model achieves superior performance in
cross-modality generation to nearest-neighbor searches in a
contrastively-trained latent space, showing its promise for constructing
informative latent representations of multi-modal astronomical datasets.</p></br><a href="http://arxiv.org/pdf/2507.15470v2" target="_blank"><h2>FedMultiEmo: Real-Time Emotion Recognition via Multimodal Federated
  Learning</h2></a><strong><u>Authors:</u></strong>  Baran Can Gül, Suraksha Nadig, Stefanos Tziampazis, Nasser Jazdi, Michael Weyrich</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Preprint version. Accepted for publication at IEEE ICECCME 2025</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> In-vehicle emotion recognition underpins adaptive driver-assistance systems
and, ultimately, occupant safety. However, practical deployment is hindered by
(i) modality fragility - poor lighting and occlusions degrade vision-based
methods; (ii) physiological variability - heart-rate and skin-conductance
patterns differ across individuals; and (iii) privacy risk - centralized
training requires transmission of sensitive data. To address these challenges,
we present FedMultiEmo, a privacy-preserving framework that fuses two
complementary modalities at the decision level: visual features extracted by a
Convolutional Neural Network from facial images, and physiological cues (heart
rate, electrodermal activity, and skin temperature) classified by a Random
Forest. FedMultiEmo builds on three key elements: (1) a multimodal federated
learning pipeline with majority-vote fusion, (2) an end-to-end edge-to-cloud
prototype on Raspberry Pi clients and a Flower server, and (3) a personalized
Federated Averaging scheme that weights client updates by local data volume.
Evaluated on FER2013 and a custom physiological dataset, the federated
Convolutional Neural Network attains 77% accuracy, the Random Forest 74%, and
their fusion 87%, matching a centralized baseline while keeping all raw data
local. The developed system converges in 18 rounds, with an average round time
of 120 seconds and a per-client memory footprint below 200 MB. These results
indicate that FedMultiEmo offers a practical approach to real-time,
privacy-aware emotion recognition in automotive settings.</p></br><a href="http://arxiv.org/pdf/2507.13954v1" target="_blank"><h2>Robust Anomaly Detection with Graph Neural Networks using
  Controllability</h2></a><strong><u>Authors:</u></strong>  Yifan Wei, Anwar Said, Waseem Abbas, Xenofon Koutsoukos</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> conference paper published in IEEE CAI 2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (title)</br><p><strong><u>Abstract:</u></strong> Anomaly detection in complex domains poses significant challenges due to the
need for extensive labeled data and the inherently imbalanced nature of
anomalous versus benign samples. Graph-based machine learning models have
emerged as a promising solution that combines attribute and relational data to
uncover intricate patterns. However, the scarcity of anomalous data exacerbates
the challenge, which requires innovative strategies to enhance model learning
with limited information. In this paper, we hypothesize that the incorporation
of the influence of the nodes, quantified through average controllability, can
significantly improve the performance of anomaly detection. We propose two
novel approaches to integrate average controllability into graph-based
frameworks: (1) using average controllability as an edge weight and (2)
encoding it as a one-hot edge attribute vector. Through rigorous evaluation on
real-world and synthetic networks with six state-of-the-art baselines, our
proposed methods demonstrate improved performance in identifying anomalies,
highlighting the critical role of controllability measures in enhancing the
performance of graph machine learning models. This work underscores the
potential of integrating average controllability as additional metrics to
address the challenges of anomaly detection in sparse and imbalanced datasets.</p></br><a href="http://arxiv.org/pdf/2507.15910v1" target="_blank"><h2>Physical parameter regression from black hole images via a multiscale
  adaptive neural network</h2></a><strong><u>Authors:</u></strong>  Jialei Wei, Ao Liu, Dejiang Li, Cuihong Wen</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.CO</br><strong><u>Comments:</u></strong> 15 pages, 6 figures; The manuscript has been accepted by Chinese Physics C</br><strong><u>Matching Keywords:</u></strong> neural network (title), attention (abstract)</br><p><strong><u>Abstract:</u></strong> High-precision regression of physical parameters from black hole images
generated by General Relativistic Ray Tracing (GRRT) is essential for
investigating spacetime curvature and advancing black hole astrophysics.
However, due to limitations in observational resolution, high observational
costs, and imbalanced distributions of positive and negative samples, black
hole images often suffer from data scarcity, sparse parameter spaces, and
complex structural characteristics. These factors pose significant challenges
to conventional regression methods based on simplified physical models. To
overcome these challenges, this study introduces Multiscale Adaptive Network
(MANet) , a novel regression framework grounded in deep learning. MANet
integrates an Adaptive Channel Attention (ACA) module to selectively enhance
features in physically informative regions. Meanwhile, a Multiscale Enhancement
Feature Pyramid (MEFP) is employed to capture fine-grained spatial structures
such as photon rings and accretion disks, while alleviating information loss
due to downsampling. Experimental evaluations on GRRT-simulated datasets
demonstrate that MANet substantially improves parameter estimation accuracy and
generalization capability in high-dimensional parameter spaces, outperforming
existing baseline approaches. This framework presents a promising avenue for
high-precision parameter regression in Event Horizon Telescope (EHT) data
analysis and broader astrophysical imaging applications characterized by sparse
and noisy data.</p></br><a href="http://arxiv.org/pdf/2507.14507v1" target="_blank"><h2>Diffusion Models for Time Series Forecasting: A Survey</h2></a><strong><u>Authors:</u></strong>  Chen Su, Zhengzhou Cai, Yuanhe Tian, Zihong Zheng, Yan Song</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> attention (abstract)</br><p><strong><u>Abstract:</u></strong> Diffusion models, initially developed for image synthesis, demonstrate
remarkable generative capabilities. Recently, their application has expanded to
time series forecasting (TSF), yielding promising results. In this survey, we
firstly introduce the standard diffusion models and their prevalent variants,
explaining their adaptation to TSF tasks. We then provide a comprehensive
review of diffusion models for TSF, paying special attention to the sources of
conditional information and the mechanisms for integrating this conditioning
within the models. In analyzing existing approaches using diffusion models for
TSF, we provide a systematic categorization and a comprehensive summary of them
in this survey. Furthermore, we examine several foundational diffusion models
applied to TSF, alongside commonly used datasets and evaluation metrics.
Finally, we discuss current limitations in these approaches and potential
future research directions. Overall, this survey details recent progress and
future prospects for diffusion models in TSF, serving as a reference for
researchers in the field.</p></br><a href="http://arxiv.org/pdf/2507.17725v1" target="_blank"><h2>On the Interaction of Compressibility and Adversarial Robustness</h2></a><strong><u>Authors:</u></strong>  Melih Barsbey, Antônio H. Ribeiro, Umut Şimşekli, Tolga Birdal</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transfer learning (abstract)</br><p><strong><u>Abstract:</u></strong> Modern neural networks are expected to simultaneously satisfy a host of
desirable properties: accurate fitting to training data, generalization to
unseen inputs, parameter and computational efficiency, and robustness to
adversarial perturbations. While compressibility and robustness have each been
studied extensively, a unified understanding of their interaction still remains
elusive. In this work, we develop a principled framework to analyze how
different forms of compressibility - such as neuron-level sparsity and spectral
compressibility - affect adversarial robustness. We show that these forms of
compression can induce a small number of highly sensitive directions in the
representation space, which adversaries can exploit to construct effective
perturbations. Our analysis yields a simple yet instructive robustness bound,
revealing how neuron and spectral compressibility impact $L_\infty$ and $L_2$
robustness via their effects on the learned representations. Crucially, the
vulnerabilities we identify arise irrespective of how compression is achieved -
whether via regularization, architectural bias, or implicit learning dynamics.
Through empirical evaluations across synthetic and realistic tasks, we confirm
our theoretical predictions, and further demonstrate that these vulnerabilities
persist under adversarial training and transfer learning, and contribute to the
emergence of universal adversarial perturbations. Our findings show a
fundamental tension between structured compressibility and robustness, and
suggest new pathways for designing models that are both efficient and secure.</p></br><a href="http://arxiv.org/pdf/2507.15246v1" target="_blank"><h2>Spatio-Temporal Demand Prediction for Food Delivery Using
  Attention-Driven Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Rabia Latief Bhat, Iqra Altaf Gillani</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Accurate demand forecasting is critical for enhancing the efficiency and
responsiveness of food delivery platforms, where spatial heterogeneity and
temporal fluctuations in order volumes directly influence operational
decisions. This paper proposes an attention-based Graph Neural Network
framework that captures spatial-temporal dependencies by modeling the food
delivery environment as a graph. In this graph, nodes represent urban delivery
zones, while edges reflect spatial proximity and inter-regional order flow
patterns derived from historical data. The attention mechanism dynamically
weighs the influence of neighboring zones, enabling the model to focus on the
most contextually relevant areas during prediction. Temporal trends are jointly
learned alongside spatial interactions, allowing the model to adapt to evolving
demand patterns. Extensive experiments on real-world food delivery datasets
demonstrate the superiority of the proposed model in forecasting future order
volumes with high accuracy. The framework offers a scalable and adaptive
solution to support proactive fleet positioning, resource allocation, and
dispatch optimization in urban food delivery operations.</p></br><a href="http://arxiv.org/pdf/2507.17392v1" target="_blank"><h2>Learning from ASTRI-Horn: products and applications of Variance data</h2></a><strong><u>Authors:</u></strong>  Simone Iovenitti, Silvia Crestan, Teresa Mineo, Giuseppe Leto, Andrea Giuliani, Saverio Lombardi</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE</br><strong><u>Comments:</u></strong> 5 pages, 6 figures</br><strong><u>Matching Keywords:</u></strong> time sequence (abstract)</br><p><strong><u>Abstract:</u></strong> In the context of the ASTRI MiniArray project (9 dual-mirror air Cherenkov
telescopes being installed at the Observatorio del Teide in the Canary
Islands), the ASTRI- Horn prototype was previously implemented in Italy
(Sicily). It was a crucial test bench for establishing observation strategies,
hardware upgrades, and software solutions. Specifically, during the winter
2022/2023 observing campaign, we implemented significant enhancements in using
the so-called Variance mode, an auxiliary output of the ASTRI Cherenkov camera
able to take images of the night sky background in the near UV/visible band.
Variance data are now processed online and on site using a dedicated pipeline
and stored in tech files. This data can infer possible telescope mis-pointing,
background level, number of identified stars, and point spread function. In
this contribution, we briefly present these quantities and their importance
together with the algorithms adopted for their calculation. They provide
valuable monitoring of telescope health and sky conditions during scientific
data collection, enabling the selection of optimal time sequences for Cherenkov
data reduction.</p></br><a href="http://arxiv.org/pdf/2507.14499v1" target="_blank"><h2>Neural Brownian Motion</h2></a><strong><u>Authors:</u></strong>  Qian Qi</br><strong><u>Categories:</u></strong> math.PR, cs.AI, cs.LG, math.OC, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> This paper introduces the Neural-Brownian Motion (NBM), a new class of
stochastic processes for modeling dynamics under learned uncertainty. The NBM
is defined axiomatically by replacing the classical martingale property with
respect to linear expectation with one relative to a non-linear Neural
Expectation Operator, $\varepsilon^\theta$, generated by a Backward Stochastic
Differential Equation (BSDE) whose driver $f_\theta$ is parameterized by a
neural network. Our main result is a representation theorem for a canonical
NBM, which we define as a continuous $\varepsilon^\theta$-martingale with zero
drift under the physical measure. We prove that, under a key structural
assumption on the driver, such a canonical NBM exists and is the unique strong
solution to a stochastic differential equation of the form ${\rm d} M_t =
\nu_\theta(t, M_t) {\rm d} W_t$. Crucially, the volatility function
$\nu_\theta$ is not postulated a priori but is implicitly defined by the
algebraic constraint $g_\theta(t, M_t, \nu_\theta(t, M_t)) = 0$, where
$g_\theta$ is a specialization of the BSDE driver. We develop the stochastic
calculus for this process and prove a Girsanov-type theorem for the quadratic
case, showing that an NBM acquires a drift under a new, learned measure. The
character of this measure, whether pessimistic or optimistic, is endogenously
determined by the learned parameters $\theta$, providing a rigorous foundation
for models where the attitude towards uncertainty is a discoverable feature.</p></br><a href="http://arxiv.org/pdf/2507.14592v1" target="_blank"><h2>A Transformer-Based Conditional GAN with Multiple Instance Learning for
  UAV Signal Detection and Classification</h2></a><strong><u>Authors:</u></strong>  Haochen Liu, Jia Bi, Xiaomin Wang, Xin Yang, Ling Wang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 13 pages, 7 figures</br><strong><u>Matching Keywords:</u></strong> explainable (abstract), transformer (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Unmanned Aerial Vehicles (UAVs) are increasingly used in surveillance,
logistics, agriculture, disaster management, and military operations. Accurate
detection and classification of UAV flight states, such as hovering, cruising,
ascending, or transitioning, which are essential for safe and effective
operations. However, conventional time series classification (TSC) methods
often lack robustness and generalization for dynamic UAV environments, while
state of the art(SOTA) models like Transformers and LSTM based architectures
typically require large datasets and entail high computational costs,
especially with high-dimensional data streams. This paper proposes a novel
framework that integrates a Transformer-based Generative Adversarial Network
(GAN) with Multiple Instance Locally Explainable Learning (MILET) to address
these challenges in UAV flight state classification. The Transformer encoder
captures long-range temporal dependencies and complex telemetry dynamics, while
the GAN module augments limited datasets with realistic synthetic samples. MIL
is incorporated to focus attention on the most discriminative input segments,
reducing noise and computational overhead. Experimental results show that the
proposed method achieves superior accuracy 96.5% on the DroneDetect dataset and
98.6% on the DroneRF dataset that outperforming other SOTA approaches. The
framework also demonstrates strong computational efficiency and robust
generalization across diverse UAV platforms and flight states, highlighting its
potential for real-time deployment in resource constrained environments.</p></br><a href="http://arxiv.org/pdf/2507.17394v1" target="_blank"><h2>HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in
  Tuning-Free Multimodal LLMs</h2></a><strong><u>Authors:</u></strong>  Zhaolin Cai, Fan Li, Ziwei Zheng, Yanjun Qin</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> Accepted by ACM MM 2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Video Anomaly Detection (VAD) aims to identify and locate deviations from
normal patterns in video sequences. Traditional methods often struggle with
substantial computational demands and a reliance on extensive labeled datasets,
thereby restricting their practical applicability. To address these
constraints, we propose HiProbe-VAD, a novel framework that leverages
pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring
fine-tuning. In this paper, we discover that the intermediate hidden states of
MLLMs contain information-rich representations, exhibiting higher sensitivity
and linear separability for anomalies compared to the output layer. To
capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP)
mechanism that intelligently identifies and extracts the most informative
hidden states from the optimal intermediate layer during the MLLMs reasoning.
Then a lightweight anomaly scorer and temporal localization module efficiently
detects anomalies using these extracted hidden states and finally generate
explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate
that HiProbe-VAD outperforms existing training-free and most traditional
approaches. Furthermore, our framework exhibits remarkable cross-model
generalization capabilities in different MLLMs without any tuning, unlocking
the potential of pre-trained MLLMs for video anomaly detection and paving the
way for more practical and scalable solutions.</p></br><a href="http://arxiv.org/pdf/2507.15678v1" target="_blank"><h2>GeoHNNs: Geometric Hamiltonian Neural Networks</h2></a><strong><u>Authors:</u></strong>  Amine Mohamed Aboussalah, Abdessalam Ed-dib</br><strong><u>Categories:</u></strong> cs.LG, math.DG, math.DS, math.SG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> latent space (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> The fundamental laws of physics are intrinsically geometric, dictating the
evolution of systems through principles of symmetry and conservation. While
modern machine learning offers powerful tools for modeling complex dynamics
from data, common methods often ignore this underlying geometric fabric.
Physics-informed neural networks, for instance, can violate fundamental
physical principles, leading to predictions that are unstable over long
periods, particularly for high-dimensional and chaotic systems. Here, we
introduce \textit{Geometric Hamiltonian Neural Networks (GeoHNN)}, a framework
that learns dynamics by explicitly encoding the geometric priors inherent to
physical laws. Our approach enforces two fundamental structures: the Riemannian
geometry of inertia, by parameterizing inertia matrices in their natural
mathematical space of symmetric positive-definite matrices, and the symplectic
geometry of phase space, using a constrained autoencoder to ensure the
preservation of phase space volume in a reduced latent space. We demonstrate
through experiments on systems ranging from coupled oscillators to
high-dimensional deformable objects that GeoHNN significantly outperforms
existing models. It achieves superior long-term stability, accuracy, and energy
conservation, confirming that embedding the geometry of physics is not just a
theoretical appeal but a practical necessity for creating robust and
generalizable models of the physical world.</p></br><a href="http://arxiv.org/pdf/2507.16241v1" target="_blank"><h2>eX-NIDS: A Framework for Explainable Network Intrusion Detection
  Leveraging Large Language Models</h2></a><strong><u>Authors:</u></strong>  Paul R. B. Houssel, Siamak Layeghy, Priyanka Singh, Marius Portmann</br><strong><u>Categories:</u></strong> cs.CR, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title)</br><p><strong><u>Abstract:</u></strong> This paper introduces eX-NIDS, a framework designed to enhance
interpretability in flow-based Network Intrusion Detection Systems (NIDS) by
leveraging Large Language Models (LLMs). In our proposed framework, flows
labelled as malicious by NIDS are initially processed through a module called
the Prompt Augmenter. This module extracts contextual information and Cyber
Threat Intelligence (CTI)-related knowledge from these flows. This enriched,
context-specific data is then integrated with an input prompt for an LLM,
enabling it to generate detailed explanations and interpretations of why the
flow was identified as malicious by NIDS. We compare the generated
interpretations against a Basic-Prompt Explainer baseline, which does not
incorporate any contextual information into the LLM's input prompt. Our
framework is quantitatively evaluated using the Llama 3 and GPT-4 models,
employing a novel evaluation method tailored for natural language explanations,
focusing on their correctness and consistency. The results demonstrate that
augmented LLMs can produce accurate and consistent explanations, serving as
valuable complementary tools in NIDS to explain the classification of malicious
flows. The use of augmented prompts enhances performance by over 20% compared
to the Basic-Prompt Explainer.</p></br><a href="http://arxiv.org/pdf/2507.15253v1" target="_blank"><h2>Disentangling Homophily and Heterophily in Multimodal Graph Clustering</h2></a><strong><u>Authors:</u></strong>  Zhaochen Guo, Zhixiang Shen, Xuanting Xie, Liangjian Wen, Zhao Kang</br><strong><u>Categories:</u></strong> cs.AI, cs.LG, cs.SI</br><strong><u>Comments:</u></strong> Appear in ACM Multimedia 2025</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal graphs, which integrate unstructured heterogeneous data with
structured interconnections, offer substantial real-world utility but remain
insufficiently explored in unsupervised learning. In this work, we initiate the
study of multimodal graph clustering, aiming to bridge this critical gap.
Through empirical analysis, we observe that real-world multimodal graphs often
exhibit hybrid neighborhood patterns, combining both homophilic and
heterophilic relationships. To address this challenge, we propose a novel
framework -- \textsc{Disentangled Multimodal Graph Clustering (DMGC)} -- which
decomposes the original hybrid graph into two complementary views: (1) a
homophily-enhanced graph that captures cross-modal class consistency, and (2)
heterophily-aware graphs that preserve modality-specific inter-class
distinctions. We introduce a \emph{Multimodal Dual-frequency Fusion} mechanism
that jointly filters these disentangled graphs through a dual-pass strategy,
enabling effective multimodal integration while mitigating category confusion.
Our self-supervised alignment objectives further guide the learning process
without requiring labels. Extensive experiments on both multimodal and
multi-relational graph datasets demonstrate that DMGC achieves state-of-the-art
performance, highlighting its effectiveness and generalizability across diverse
settings. Our code is available at https://github.com/Uncnbb/DMGC.</p></br><a href="http://arxiv.org/pdf/2507.14652v1" target="_blank"><h2>Accelerating Hamiltonian Monte Carlo for Bayesian Inference in Neural
  Networks and Neural Operators</h2></a><strong><u>Authors:</u></strong>  Ponkrshnan Thiagarajan, Tamer A. Zaki, Michael D. Shields</br><strong><u>Categories:</u></strong> stat.ML, cs.CE, cs.LG, physics.data-an</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Hamiltonian Monte Carlo (HMC) is a powerful and accurate method to sample
from the posterior distribution in Bayesian inference. However, HMC techniques
are computationally demanding for Bayesian neural networks due to the high
dimensionality of the network's parameter space and the non-convexity of their
posterior distributions. Therefore, various approximation techniques, such as
variational inference (VI) or stochastic gradient MCMC, are often employed to
infer the posterior distribution of the network parameters. Such approximations
introduce inaccuracies in the inferred distributions, resulting in unreliable
uncertainty estimates. In this work, we propose a hybrid approach that combines
inexpensive VI and accurate HMC methods to efficiently and accurately quantify
uncertainties in neural networks and neural operators. The proposed approach
leverages an initial VI training on the full network. We examine the influence
of individual parameters on the prediction uncertainty, which shows that a
large proportion of the parameters do not contribute substantially to
uncertainty in the network predictions. This information is then used to
significantly reduce the dimension of the parameter space, and HMC is performed
only for the subset of network parameters that strongly influence prediction
uncertainties. This yields a framework for accelerating the full batch HMC for
posterior inference in neural networks. We demonstrate the efficiency and
accuracy of the proposed framework on deep neural networks and operator
networks, showing that inference can be performed for large networks with tens
to hundreds of thousands of parameters. We show that this method can
effectively learn surrogates for complex physical systems by modeling the
operator that maps from upstream conditions to wall-pressure data on a cone in
hypersonic flow.</p></br><a href="http://arxiv.org/pdf/2507.13920v1" target="_blank"><h2>Reframing attention as a reinforcement learning problem for causal
  discovery</h2></a><strong><u>Authors:</u></strong>  Turan Orujlu, Christian Gumbsch, Martin V. Butz, Charley M Wu</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract), causality (abstract)</br><p><strong><u>Abstract:</u></strong> Formal frameworks of causality have operated largely parallel to modern
trends in deep reinforcement learning (RL). However, there has been a revival
of interest in formally grounding the representations learned by neural
networks in causal concepts. Yet, most attempts at neural models of causality
assume static causal graphs and ignore the dynamic nature of causal
interactions. In this work, we introduce Causal Process framework as a novel
theory for representing dynamic hypotheses about causal structure. Furthermore,
we present Causal Process Model as an implementation of this framework. This
allows us to reformulate the attention mechanism popularized by Transformer
networks within an RL setting with the goal to infer interpretable causal
processes from visual observations. Here, causal inference corresponds to
constructing a causal graph hypothesis which itself becomes an RL task nested
within the original RL problem. To create an instance of such hypothesis, we
employ RL agents. These agents establish links between units similar to the
original Transformer attention mechanism. We demonstrate the effectiveness of
our approach in an RL environment where we outperform current alternatives in
causal representation learning and agent performance, and uniquely recover
graphs of dynamic causal processes.</p></br><a href="http://arxiv.org/pdf/2507.16540v1" target="_blank"><h2>Explainable Vulnerability Detection in C/C++ Using Edge-Aware Graph
  Attention Networks</h2></a><strong><u>Authors:</u></strong>  Radowanul Haque, Aftab Ali, Sally McClean, Naveed Khan</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.SE</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Detecting security vulnerabilities in source code remains challenging,
particularly due to class imbalance in real-world datasets where vulnerable
functions are under-represented. Existing learning-based methods often optimise
for recall, leading to high false positive rates and reduced usability in
development workflows. Furthermore, many approaches lack explainability,
limiting their integration into security workflows. This paper presents
ExplainVulD, a graph-based framework for vulnerability detection in C/C++ code.
The method constructs Code Property Graphs and represents nodes using
dual-channel embeddings that capture both semantic and structural information.
These are processed by an edge-aware attention mechanism that incorporates
edge-type embeddings to distinguish among program relations. To address class
imbalance, the model is trained using class-weighted cross-entropy loss.
ExplainVulD achieves a mean accuracy of 88.25 percent and an F1 score of 48.23
percent across 30 independent runs on the ReVeal dataset. These results
represent relative improvements of 4.6 percent in accuracy and 16.9 percent in
F1 score compared to the ReVeal model, a prior learning-based method. The
framework also outperforms static analysis tools, with relative gains of 14.0
to 14.1 percent in accuracy and 132.2 to 201.2 percent in F1 score. Beyond
improved detection performance, ExplainVulD produces explainable outputs by
identifying the most influential code regions within each function, supporting
transparency and trust in security triage.</p></br><a href="http://arxiv.org/pdf/2507.17255v1" target="_blank"><h2>Rethinking VAE: From Continuous to Discrete Representations Without
  Probabilistic Assumptions</h2></a><strong><u>Authors:</u></strong>  Songxuan Shi</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> This paper explores the generative capabilities of Autoencoders (AEs) and
establishes connections between Variational Autoencoders (VAEs) and Vector
Quantized-Variational Autoencoders (VQ-VAEs) through a reformulated training
framework. We demonstrate that AEs exhibit generative potential via latent
space interpolation and perturbation, albeit limited by undefined regions in
the encoding space. To address this, we propose a new VAE-like training method
that introduces clustering centers to enhance data compactness and ensure
well-defined latent spaces without relying on traditional KL divergence or
reparameterization techniques. Experimental results on MNIST, CelebA, and
FashionMNIST datasets show smooth interpolative transitions, though blurriness
persists. Extending this approach to multiple learnable vectors, we observe a
natural progression toward a VQ-VAE-like model in continuous space. However,
when the encoder outputs multiple vectors, the model degenerates into a
discrete Autoencoder (VQ-AE), which combines image fragments without learning
semantic representations. Our findings highlight the critical role of encoding
space compactness and dispersion in generative modeling and provide insights
into the intrinsic connections between VAEs and VQ-VAEs, offering a new
perspective on their design and limitations.</p></br><a href="http://arxiv.org/pdf/2507.15990v1" target="_blank"><h2>Generative AI Models for Learning Flow Maps of Stochastic Dynamical
  Systems in Bounded Domains</h2></a><strong><u>Authors:</u></strong>  Minglei Yang, Yanfang Liu, Diego del-Castillo-Negrete, Yanzhao Cao, Guannan Zhang</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Simulating stochastic differential equations (SDEs) in bounded domains,
presents significant computational challenges due to particle exit phenomena,
which requires accurate modeling of interior stochastic dynamics and boundary
interactions. Despite the success of machine learning-based methods in learning
SDEs, existing learning methods are not applicable to SDEs in bounded domains
because they cannot accurately capture the particle exit dynamics. We present a
unified hybrid data-driven approach that combines a conditional diffusion model
with an exit prediction neural network to capture both interior stochastic
dynamics and boundary exit phenomena. Our ML model consists of two major
components: a neural network that learns exit probabilities using binary
cross-entropy loss with rigorous convergence guarantees, and a training-free
diffusion model that generates state transitions for non-exiting particles
using closed-form score functions. The two components are integrated through a
probabilistic sampling algorithm that determines particle exit at each time
step and generates appropriate state transitions. The performance of the
proposed approach is demonstrated via three test cases: a one-dimensional
simplified problem for theoretical verification, a two-dimensional
advection-diffusion problem in a bounded domain, and a three-dimensional
problem of interest to magnetically confined fusion plasmas.</p></br><a href="http://arxiv.org/pdf/2507.14824v1" target="_blank"><h2>Benchmarking Foundation Models with Multimodal Public Electronic Health
  Records</h2></a><strong><u>Authors:</u></strong>  Kunyu Yu, Rui Yang, Jingchi Liao, Siqi Li, Huitao Li, Irene Li, Yifan Peng, Rishikesan Kamaleswaran, Nan Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Foundation models have emerged as a powerful approach for processing
electronic health records (EHRs), offering flexibility to handle diverse
medical data modalities. In this study, we present a comprehensive benchmark
that evaluates the performance, fairness, and interpretability of foundation
models, both as unimodal encoders and as multimodal learners, using the
publicly available MIMIC-IV database. To support consistent and reproducible
evaluation, we developed a standardized data processing pipeline that
harmonizes heterogeneous clinical records into an analysis-ready format. We
systematically compared eight foundation models, encompassing both unimodal and
multimodal models, as well as domain-specific and general-purpose variants. Our
findings demonstrate that incorporating multiple data modalities leads to
consistent improvements in predictive performance without introducing
additional bias. Through this benchmark, we aim to support the development of
effective and trustworthy multimodal artificial intelligence (AI) systems for
real-world clinical applications. Our code is available at
https://github.com/nliulab/MIMIC-Multimodal.</p></br><a href="http://arxiv.org/pdf/2507.17472v1" target="_blank"><h2>BGM-HAN: A Hierarchical Attention Network for Accurate and Fair Decision
  Assessment on Semi-Structured Profiles</h2></a><strong><u>Authors:</u></strong>  Junhua Liu, Roy Ka-Wei Lee, Kwan Hui Lim</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.IR</br><strong><u>Comments:</u></strong> Accepted at ASONAM 2025</br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Human decision-making in high-stakes domains often relies on expertise and
heuristics, but is vulnerable to hard-to-detect cognitive biases that threaten
fairness and long-term outcomes. This work presents a novel approach to
enhancing complex decision-making workflows through the integration of
hierarchical learning alongside various enhancements. Focusing on university
admissions as a representative high-stakes domain, we propose BGM-HAN, an
enhanced Byte-Pair Encoded, Gated Multi-head Hierarchical Attention Network,
designed to effectively model semi-structured applicant data. BGM-HAN captures
multi-level representations that are crucial for nuanced assessment, improving
both interpretability and predictive performance. Experimental results on real
admissions data demonstrate that our proposed model significantly outperforms
both state-of-the-art baselines from traditional machine learning to large
language models, offering a promising framework for augmenting decision-making
in domains where structure, context, and fairness matter. Source code is
available at: https://github.com/junhua/bgm-han.</p></br><a href="http://arxiv.org/pdf/2507.16672v1" target="_blank"><h2>Meta-Learning for Cold-Start Personalization in Prompt-Tuned LLMs</h2></a><strong><u>Authors:</u></strong>  Yushang Zhao, Huijie Shen, Dannier Li, Lu Chang, Chengrui Zhou, Yinuo Yang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (abstract)</br><p><strong><u>Abstract:</u></strong> Generative, explainable, and flexible recommender systems, derived using
Large Language Models (LLM) are promising and poorly adapted to the cold-start
user situation, where there is little to no history of interaction. The current
solutions i.e. supervised fine-tuning and collaborative filtering are
dense-user-item focused and would be expensive to maintain and update. This
paper introduces a meta-learning framework, that can be used to perform
parameter-efficient prompt-tuning, to effectively personalize LLM-based
recommender systems quickly at cold-start. The model learns soft prompt
embeddings with first-order (Reptile) and second-order (MAML) optimization by
treating each of the users as the tasks. As augmentations to the input tokens,
these learnable vectors are the differentiable control variables that represent
user behavioral priors. The prompts are meta-optimized through episodic
sampling, inner-loop adaptation, and outer-loop generalization. On
MovieLens-1M, Amazon Reviews, and Recbole, we can see that our adaptive model
outperforms strong baselines in NDCG@10, HR@10, and MRR, and it runs in
real-time (i.e., below 300 ms) on consumer GPUs. Zero-history personalization
is also supported by this scalable solution, and its 275 ms rate of adaptation
allows successful real-time risk profiling of financial systems by shortening
detection latency and improving payment network stability. Crucially, the 275
ms adaptation capability can enable real-time risk profiling for financial
institutions, reducing systemic vulnerability detection latency significantly
versus traditional compliance checks. By preventing contagion in payment
networks (e.g., Fedwire), the framework strengthens national financial
infrastructure resilience.</p></br><a href="http://arxiv.org/pdf/2507.15336v1" target="_blank"><h2>Beyond Model Base Selection: Weaving Knowledge to Master Fine-grained
  Neural Network Design</h2></a><strong><u>Authors:</u></strong>  Jialiang Wang, Hanmo Liu, Shimin Di, Zhili Wang, Jiachuan Wang, Lei Chen, Xiaofang Zhou</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.DB</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Database systems have recently advocated for embedding machine learning (ML)
capabilities, offering declarative model queries over large, managed model
repositories, thereby circumventing the huge computational overhead of
traditional ML-based algorithms in automated neural network model selection.
Pioneering database studies aim to organize existing benchmark repositories as
model bases (MB), querying them for the model records with the highest
performance estimation metrics for given tasks. However, this static model
selection practice overlooks the fine-grained, evolving relational dependencies
between diverse task queries and model architecture variations, resulting in
suboptimal matches and failing to further refine the model effectively. To fill
the model refinement gap in database research, we propose M-DESIGN, a curated
model knowledge base (MKB) pipeline for mastering neural network refinement by
adaptively weaving prior insights about model architecture modification. First,
we propose a knowledge weaving engine that reframes model refinement as an
adaptive query problem over task metadata. Given a user's task query, M-DESIGN
quickly matches and iteratively refines candidate models by leveraging a
graph-relational knowledge schema that explicitly encodes data properties,
architecture variations, and pairwise performance deltas as joinable relations.
This schema supports fine-grained relational analytics over architecture tweaks
and drives a predictive query planner that can detect and adapt to
out-of-distribution (OOD) tasks. We instantiate M-DESIGN for graph analytics
tasks, where our model knowledge base enriches existing benchmarks with
structured metadata covering 3 graph tasks and 22 graph datasets, contributing
data records of 67,760 graph models. Empirical results demonstrate that
M-DESIGN delivers the optimal model in 26 of 33 data-task pairs within limited
budgets.</p></br><a href="http://arxiv.org/pdf/2507.16854v1" target="_blank"><h2>CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive
  Fusion for Multimodal Aspect-Based Sentiment Analysis</h2></a><strong><u>Authors:</u></strong>  Xiaoqiang He</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspect
terms within paired image-text data and determine their fine grained sentiment
polarities, representing a fundamental task for improving the effectiveness of
applications such as product review systems and public opinion monitoring.
Existing methods face challenges such as cross modal alignment noise and
insufficient consistency in fine-grained representations. While global modality
alignment methods often overlook the connection between aspect terms and their
corresponding local visual regions, bridging the representation gap between
text and images remains a challenge. To address these limitations, this paper
introduces an end to end Contrastive Learning framework with Adaptive
Multi-loss and Progressive Attention Fusion(CLAMP). The framework is composed
of three novel modules: Progressive Attention Fusion network, Multi-task
Contrastive Learning, and Adaptive Multi-loss Aggregation. The Progressive
Attention Fusion network enhances fine-grained alignment between textual
features and image regions via hierarchical, multi-stage cross modal
interactions, effectively suppressing irrelevant visual noise. Secondly,
multi-task contrastive learning combines global modal contrast and local
granularity alignment to enhance cross modal representation consistency.
Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weighting
mechanism to calibrate loss contributions according to each task's uncertainty,
thereby mitigating gradient interference. Evaluation on standard public
benchmarks demonstrates that CLAMP consistently outperforms the vast majority
of existing state of the art methods.</p></br><a href="http://arxiv.org/pdf/2507.13416v1" target="_blank"><h2>Single- to multi-fidelity history-dependent learning with uncertainty
  quantification and disentanglement: application to data-driven constitutive
  modeling</h2></a><strong><u>Authors:</u></strong>  Jiaxiang Yi, Bernardo P. Ferreira, Miguel A. Bessa</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 40 pages, 32 figures</br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Data-driven learning is generalized to consider history-dependent
multi-fidelity data, while quantifying epistemic uncertainty and disentangling
it from data noise (aleatoric uncertainty). This generalization is hierarchical
and adapts to different learning scenarios: from training the simplest
single-fidelity deterministic neural networks up to the proposed multi-fidelity
variance estimation Bayesian recurrent neural networks. The versatility and
generality of the proposed methodology are demonstrated by applying it to
different data-driven constitutive modeling scenarios that include multiple
fidelities with and without aleatoric uncertainty (noise). The method
accurately predicts the response and quantifies model error while also
discovering the noise distribution (when present). This opens opportunities for
future real-world applications in diverse scientific and engineering domains;
especially, the most challenging cases involving design and analysis under
uncertainty.</p></br><a href="http://arxiv.org/pdf/2507.16876v1" target="_blank"><h2>Machine learning-based multimodal prognostic models integrating
  pathology images and high-throughput omic data for overall survival
  prediction in cancer: a systematic review</h2></a><strong><u>Authors:</u></strong>  Charlotte Jennings, Andrew Broad, Lucy Godson, Emily Clarke, David Westhead, Darren Treanor</br><strong><u>Categories:</u></strong> q-bio.QM, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Main article (50 pages, inc 3 tables, 4 figures). Supplementary material included with additional methodological information and data</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal machine learning integrating histopathology and molecular data
shows promise for cancer prognostication. We systematically reviewed studies
combining whole slide images (WSIs) and high-throughput omics to predict
overall survival. Searches of EMBASE, PubMed, and Cochrane CENTRAL
(12/08/2024), plus citation screening, identified eligible studies. Data
extraction used CHARMS; bias was assessed with PROBAST+AI; synthesis followed
SWiM and PRISMA 2020. Protocol: PROSPERO (CRD42024594745).
  Forty-eight studies (all since 2017) across 19 cancer types met criteria; all
used The Cancer Genome Atlas. Approaches included regularised Cox regression
(n=4), classical ML (n=13), and deep learning (n=31). Reported c-indices ranged
0.550-0.857; multimodal models typically outperformed unimodal ones. However,
all studies showed unclear/high bias, limited external validation, and little
focus on clinical utility.
  Multimodal WSI-omics survival prediction is a fast-growing field with
promising results but needs improved methodological rigor, broader datasets,
and clinical evaluation.
  Funded by NPIC, Leeds Teaching Hospitals NHS Trust, UK (Project 104687),
supported by UKRI Industrial Strategy Challenge Fund.</p></br><a href="http://arxiv.org/pdf/2507.14805v1" target="_blank"><h2>Subliminal Learning: Language models transmit behavioral traits via
  hidden signals in data</h2></a><strong><u>Authors:</u></strong>  Alex Cloud, Minh Le, James Chua, Jan Betley, Anna Sztyber-Betley, Jacob Hilton, Samuel Marks, Owain Evans</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> We study subliminal learning, a surprising phenomenon where language models
transmit behavioral traits via semantically unrelated data. In our main
experiments, a "teacher" model with some trait T (such as liking owls or being
misaligned) generates a dataset consisting solely of number sequences.
Remarkably, a "student" model trained on this dataset learns T. This occurs
even when the data is filtered to remove references to T. We observe the same
effect when training on code or reasoning traces generated by the same teacher
model. However, we do not observe the effect when the teacher and student have
different base models. To help explain our findings, we prove a theoretical
result showing that subliminal learning occurs in all neural networks under
certain conditions, and demonstrate subliminal learning in a simple MLP
classifier. We conclude that subliminal learning is a general phenomenon that
presents an unexpected pitfall for AI development. Distillation could propagate
unintended traits, even when developers try to prevent this via data filtering.</p></br><a href="http://arxiv.org/pdf/2507.13542v1" target="_blank"><h2>Acoustic Index: A Novel AI-Driven Parameter for Cardiac Disease Risk
  Stratification Using Echocardiography</h2></a><strong><u>Authors:</u></strong>  Beka Begiashvili, Carlos J. Fernandez-Candel, Matías Pérez Paredes</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Traditional echocardiographic parameters such as ejection fraction (EF) and
global longitudinal strain (GLS) have limitations in the early detection of
cardiac dysfunction. EF often remains normal despite underlying pathology, and
GLS is influenced by load conditions and vendor variability. There is a growing
need for reproducible, interpretable, and operator-independent parameters that
capture subtle and global cardiac functional alterations.
  We introduce the Acoustic Index, a novel AI-derived echocardiographic
parameter designed to quantify cardiac dysfunction from standard ultrasound
views. The model combines Extended Dynamic Mode Decomposition (EDMD) based on
Koopman operator theory with a hybrid neural network that incorporates clinical
metadata. Spatiotemporal dynamics are extracted from echocardiographic
sequences to identify coherent motion patterns. These are weighted via
attention mechanisms and fused with clinical data using manifold learning,
resulting in a continuous score from 0 (low risk) to 1 (high risk).
  In a prospective cohort of 736 patients, encompassing various cardiac
pathologies and normal controls, the Acoustic Index achieved an area under the
curve (AUC) of 0.89 in an independent test set. Cross-validation across five
folds confirmed the robustness of the model, showing that both sensitivity and
specificity exceeded 0.8 when evaluated on independent data. Threshold-based
analysis demonstrated stable trade-offs between sensitivity and specificity,
with optimal discrimination near this threshold.
  The Acoustic Index represents a physics-informed, interpretable AI biomarker
for cardiac function. It shows promise as a scalable, vendor-independent tool
for early detection, triage, and longitudinal monitoring. Future directions
include external validation, longitudinal studies, and adaptation to
disease-specific classifiers.</p></br><a href="http://arxiv.org/pdf/2507.14874v1" target="_blank"><h2>The Tsetlin Machine Goes Deep: Logical Learning and Reasoning With
  Graphs</h2></a><strong><u>Authors:</u></strong>  Ole-Christoffer Granmo, Youmna Abdelwahab, Per-Arne Andersen, Paul F. A. Clarke, Kunal Dumbre, Ylva Grønninsæter, Vojtech Halenka, Runar Helin, Lei Jiao, Ahmed Khalid, Rebekka Omslandseter, Rupsa Saha, Mayur Shende, Xuan Zhang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 34 pages, 10 figures</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multimodal (abstract), multimodality (abstract)</br><p><strong><u>Abstract:</u></strong> Pattern recognition with concise and flat AND-rules makes the Tsetlin Machine
(TM) both interpretable and efficient, while the power of Tsetlin automata
enables accuracy comparable to deep learning on an increasing number of
datasets. We introduce the Graph Tsetlin Machine (GraphTM) for learning
interpretable deep clauses from graph-structured input. Moving beyond flat,
fixed-length input, the GraphTM gets more versatile, supporting sequences,
grids, relations, and multimodality. Through message passing, the GraphTM
builds nested deep clauses to recognize sub-graph patterns with exponentially
fewer clauses, increasing both interpretability and data utilization. For image
classification, GraphTM preserves interpretability and achieves 3.86%-points
higher accuracy on CIFAR-10 than a convolutional TM. For tracking action
coreference, faced with increasingly challenging tasks, GraphTM outperforms
other reinforcement learning methods by up to 20.6%-points. In recommendation
systems, it tolerates increasing noise to a greater extent than a Graph
Convolutional Neural Network (GCN), e.g., for noise ratio 0.1, GraphTM obtains
accuracy 89.86% compared to GCN's 70.87%. Finally, for viral genome sequence
data, GraphTM is competitive with BiLSTM-CNN and GCN accuracy-wise, training
2.5x faster than GCN. The GraphTM's application to these varied fields
demonstrates how graph representation learning and deep clauses bring new
possibilities for TM learning.</p></br><a href="http://arxiv.org/pdf/2507.17486v1" target="_blank"><h2>Unsupervised anomaly detection using Bayesian flow networks: application
  to brain FDG PET in the context of Alzheimer's disease</h2></a><strong><u>Authors:</u></strong>  Hugues Roy, Reuben Dorent, Ninon Burgos</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> VAE (abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for
identifying deviations from healthy subject data and thus facilitating the
diagnosis of neurological disorders. In this work, we focus on Bayesian flow
networks (BFNs), a novel class of generative models, which have not yet been
applied to medical imaging or anomaly detection. BFNs combine the strength of
diffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension
of BFNs for UAD, designed to: i) perform conditional image generation under
high levels of spatially correlated noise, and ii) preserve subject specificity
by incorporating a recursive feedback from the input image throughout the
generative process. We evaluate AnoBFN on the challenging task of Alzheimer's
disease-related anomaly detection in FDG PET images. Our approach outperforms
other state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and
diffusion models (AnoDDPM), demonstrating its effectiveness at detecting
anomalies while reducing false positive rates.</p></br><a href="http://arxiv.org/pdf/2507.17083v1" target="_blank"><h2>SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D
  Multimodal Occupancy Prediction</h2></a><strong><u>Authors:</u></strong>  Zaipeng Duan, Chenxu Dang, Xuzhong Hu, Pei An, Junfeng Ding, Jie Zhan, Yunbiao Xu, Jie Ma</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> accepted by CVPR2025</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal 3D occupancy prediction has garnered significant attention for its
potential in autonomous driving. However, most existing approaches are
single-modality: camera-based methods lack depth information, while LiDAR-based
methods struggle with occlusions. Current lightweight methods primarily rely on
the Lift-Splat-Shoot (LSS) pipeline, which suffers from inaccurate depth
estimation and fails to fully exploit the geometric and semantic information of
3D LiDAR points. Therefore, we propose a novel multimodal occupancy prediction
network called SDG-OCC, which incorporates a joint semantic and depth-guided
view transformation coupled with a fusion-to-occupancy-driven active
distillation. The enhanced view transformation constructs accurate depth
distributions by integrating pixel semantics and co-point depth through
diffusion and bilinear discretization. The fusion-to-occupancy-driven active
distillation extracts rich semantic information from multimodal data and
selectively transfers knowledge to image features based on LiDAR-identified
regions. Finally, for optimal performance, we introduce SDG-Fusion, which uses
fusion alone, and SDG-KL, which integrates both fusion and distillation for
faster inference. Our method achieves state-of-the-art (SOTA) performance with
real-time processing on the Occ3D-nuScenes dataset and shows comparable
performance on the more challenging SurroundOcc-nuScenes dataset, demonstrating
its effectiveness and robustness. The code will be released at
https://github.com/DzpLab/SDGOCC.</p></br><a href="http://arxiv.org/pdf/2507.14677v1" target="_blank"><h2>Revisiting Graph Contrastive Learning on Anomaly Detection: A Structural
  Imbalance Perspective</h2></a><strong><u>Authors:</u></strong>  Yiming Xu, Zhen Peng, Bin Shi, Xu Hua, Bo Dong, Song Wang, Chen Chen</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Accepted by AAAI2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> The superiority of graph contrastive learning (GCL) has prompted its
application to anomaly detection tasks for more powerful risk warning systems.
Unfortunately, existing GCL-based models tend to excessively prioritize overall
detection performance while neglecting robustness to structural imbalance,
which can be problematic for many real-world networks following power-law
degree distributions. Particularly, GCL-based methods may fail to capture tail
anomalies (abnormal nodes with low degrees). This raises concerns about the
security and robustness of current anomaly detection algorithms and therefore
hinders their applicability in a variety of realistic high-risk scenarios. To
the best of our knowledge, research on the robustness of graph anomaly
detection to structural imbalance has received little scrutiny. To address the
above issues, this paper presents a novel GCL-based framework named AD-GCL. It
devises the neighbor pruning strategy to filter noisy edges for head nodes and
facilitate the detection of genuine tail nodes by aligning from head nodes to
forged tail nodes. Moreover, AD-GCL actively explores potential neighbors to
enlarge the receptive field of tail nodes through anomaly-guided neighbor
completion. We further introduce intra- and inter-view consistency loss of the
original and augmentation graph for enhanced representation. The performance
evaluation of the whole, head, and tail nodes on multiple datasets validates
the comprehensive superiority of the proposed AD-GCL in detecting both head
anomalies and tail anomalies.</p></br><a href="http://arxiv.org/pdf/2507.14467v1" target="_blank"><h2>Learning Stochastic Hamiltonian Systems via Stochastic Generating
  Function Neural Network</h2></a><strong><u>Authors:</u></strong>  Chen Chen, Lijin Wang, Yanzhao Cao, Xupeng Cheng</br><strong><u>Categories:</u></strong> math.DS, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> In this paper we propose a novel neural network model for learning stochastic
Hamiltonian systems (SHSs) from observational data, termed the stochastic
generating function neural network (SGFNN). SGFNN preserves symplectic
structure of the underlying stochastic Hamiltonian system and produces
symplectic predictions. Our model utilizes the autoencoder framework to
identify the randomness of the latent system by the encoder network, and
detects the stochastic generating function of the system through the decoder
network based on the random variables extracted from the encoder. Symplectic
predictions can then be generated by the stochastic generating function.
Numerical experiments are performed on several stochastic Hamiltonian systems,
varying from additive to multiplicative, and from separable to non-separable
SHSs with single or multiple noises. Compared with the benchmark stochastic
flow map learning (sFML) neural network, our SGFNN model exhibits higher
accuracy across various prediction metrics, especially in long-term
predictions, with the property of maintaining the symplectic structure of the
underlying SHSs.</p></br><a href="http://arxiv.org/pdf/2507.14444v1" target="_blank"><h2>Statistical and Algorithmic Foundations of Reinforcement Learning</h2></a><strong><u>Authors:</u></strong>  Yuejie Chi, Yuxin Chen, Yuting Wei</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG, math.OC, math.ST, stat.TH</br><strong><u>Comments:</u></strong> reading materials for INFORMS Tutorial in OR 2025</br><strong><u>Matching Keywords:</u></strong> attention (abstract)</br><p><strong><u>Abstract:</u></strong> As a paradigm for sequential decision making in unknown environments,
reinforcement learning (RL) has received a flurry of attention in recent years.
However, the explosion of model complexity in emerging applications and the
presence of nonconvexity exacerbate the challenge of achieving efficient RL in
sample-starved situations, where data collection is expensive, time-consuming,
or even high-stakes (e.g., in clinical trials, autonomous systems, and online
advertising). How to understand and enhance the sample and computational
efficacies of RL algorithms is thus of great interest. In this tutorial, we aim
to introduce several important algorithmic and theoretical developments in RL,
highlighting the connections between new ideas and classical topics. Employing
Markov Decision Processes as the central mathematical model, we cover several
distinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL,
robust RL, and RL with human feedback), and present several mainstream RL
approaches (i.e., model-based approach, value-based approach, and policy
optimization). Our discussions gravitate around the issues of sample
complexity, computational efficiency, as well as algorithm-dependent and
information-theoretic lower bounds from a non-asymptotic viewpoint.</p></br><a href="http://arxiv.org/pdf/2507.15205v1" target="_blank"><h2>Long-Short Distance Graph Neural Networks and Improved Curriculum
  Learning for Emotion Recognition in Conversation</h2></a><strong><u>Authors:</u></strong>  Xinran Li, Xiujuan Xu, Jiaqi Qiao</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL</br><strong><u>Comments:</u></strong> Accepted by the 28th European Conference on Artificial Intelligence (ECAI 2025)</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Emotion Recognition in Conversation (ERC) is a practical and challenging
task. This paper proposes a novel multimodal approach, the Long-Short Distance
Graph Neural Network (LSDGNN). Based on the Directed Acyclic Graph (DAG), it
constructs a long-distance graph neural network and a short-distance graph
neural network to obtain multimodal features of distant and nearby utterances,
respectively. To ensure that long- and short-distance features are as distinct
as possible in representation while enabling mutual influence between the two
modules, we employ a Differential Regularizer and incorporate a BiAffine Module
to facilitate feature interaction. In addition, we propose an Improved
Curriculum Learning (ICL) to address the challenge of data imbalance. By
computing the similarity between different emotions to emphasize the shifts in
similar emotions, we design a "weighted emotional shift" metric and develop a
difficulty measurer, enabling a training process that prioritizes learning easy
samples before harder ones. Experimental results on the IEMOCAP and MELD
datasets demonstrate that our model outperforms existing benchmarks.</p></br><a href="http://arxiv.org/pdf/2507.15255v1" target="_blank"><h2>MEETI: A Multimodal ECG Dataset from MIMIC-IV-ECG with Signals, Images,
  Features and Interpretations</h2></a><strong><u>Authors:</u></strong>  Deyun Zhang, Xiang Lan, Shijia Geng, Qinghao Zhao, Sumei Fan, Mengling Feng, Shenda Hong</br><strong><u>Categories:</u></strong> eess.SP, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (abstract), multimodal (title, abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Electrocardiogram (ECG) plays a foundational role in modern cardiovascular
care, enabling non-invasive diagnosis of arrhythmias, myocardial ischemia, and
conduction disorders. While machine learning has achieved expert-level
performance in ECG interpretation, the development of clinically deployable
multimodal AI systems remains constrained, primarily due to the lack of
publicly available datasets that simultaneously incorporate raw signals,
diagnostic images, and interpretation text. Most existing ECG datasets provide
only single-modality data or, at most, dual modalities, making it difficult to
build models that can understand and integrate diverse ECG information in
real-world settings. To address this gap, we introduce MEETI (MIMIC-IV-Ext
ECG-Text-Image), the first large-scale ECG dataset that synchronizes raw
waveform data, high-resolution plotted images, and detailed textual
interpretations generated by large language models. In addition, MEETI includes
beat-level quantitative ECG parameters extracted from each lead, offering
structured parameters that support fine-grained analysis and model
interpretability. Each MEETI record is aligned across four components: (1) the
raw ECG waveform, (2) the corresponding plotted image, (3) extracted feature
parameters, and (4) detailed interpretation text. This alignment is achieved
using consistent, unique identifiers. This unified structure supports
transformer-based multimodal learning and supports fine-grained, interpretable
reasoning about cardiac health. By bridging the gap between traditional signal
analysis, image-based interpretation, and language-driven understanding, MEETI
established a robust foundation for the next generation of explainable,
multimodal cardiovascular AI. It offers the research community a comprehensive
benchmark for developing and evaluating ECG-based AI systems.</p></br><a href="http://arxiv.org/pdf/2507.14121v1" target="_blank"><h2>Kolmogorov Arnold Networks (KANs) for Imbalanced Data -- An Empirical
  Perspective</h2></a><strong><u>Authors:</u></strong>  Pankaj Yadav, Vivek Vijay</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 9 Pages, 4 figures</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Kolmogorov Arnold Networks (KANs) are recent architectural advancement in
neural computation that offer a mathematically grounded alternative to standard
neural networks. This study presents an empirical evaluation of KANs in context
of class imbalanced classification, using ten benchmark datasets. We observe
that KANs can inherently perform well on raw imbalanced data more effectively
than Multi-Layer Perceptrons (MLPs) without any resampling strategy. However,
conventional imbalance strategies fundamentally conflict with KANs mathematical
structure as resampling and focal loss implementations significantly degrade
KANs performance, while marginally benefiting MLPs. Crucially, KANs suffer from
prohibitive computational costs without proportional performance gains.
Statistical validation confirms that MLPs with imbalance techniques achieve
equivalence with KANs (|d| < 0.08 across metrics) at minimal resource costs.
These findings reveal that KANs represent a specialized solution for raw
imbalanced data where resources permit. But their severe performance-resource
tradeoffs and incompatibility with standard resampling techniques currently
limits practical deployment. We identify critical research priorities as
developing KAN specific architectural modifications for imbalance learning,
optimizing computational efficiency, and theoretical reconciling their conflict
with data augmentation. This work establishes foundational insights for next
generation KAN architectures in imbalanced classification scenarios.</p></br><a href="http://arxiv.org/pdf/2507.17010v1" target="_blank"><h2>Towards Trustworthy AI: Secure Deepfake Detection using CNNs and
  Zero-Knowledge Proofs</h2></a><strong><u>Authors:</u></strong>  H M Mohaimanul Islam, Huynh Q. N. Vo, Aditya Rane</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Submitted for peer-review in TrustXR - 2025</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> In the era of synthetic media, deepfake manipulations pose a significant
threat to information integrity. To address this challenge, we propose
TrustDefender, a two-stage framework comprising (i) a lightweight convolutional
neural network (CNN) that detects deepfake imagery in real-time extended
reality (XR) streams, and (ii) an integrated succinct zero-knowledge proof
(ZKP) protocol that validates detection results without disclosing raw user
data. Our design addresses both the computational constraints of XR platforms
while adhering to the stringent privacy requirements in sensitive settings.
Experimental evaluations on multiple benchmark deepfake datasets demonstrate
that TrustDefender achieves 95.3% detection accuracy, coupled with efficient
proof generation underpinned by rigorous cryptography, ensuring seamless
integration with high-performance artificial intelligence (AI) systems. By
fusing advanced computer vision models with provable security mechanisms, our
work establishes a foundation for reliable AI in immersive and
privacy-sensitive applications.</p></br><a href="http://arxiv.org/pdf/2507.16206v1" target="_blank"><h2>METER: Multi-modal Evidence-based Thinking and Explainable Reasoning --
  Algorithm and Benchmark</h2></a><strong><u>Authors:</u></strong>  Xu Yang, Qi Zhang, Shuming Jiang, Yaowen Xu, Zhaofan Zou, Hao Sun, Xuelong Li</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, 68T45, I.4.8; I.2.6; I.2.7</br><strong><u>Comments:</u></strong> 9 pages,3 figures ICCV format</br><strong><u>Matching Keywords:</u></strong> explainable (title), multi-modal (title, abstract)</br><p><strong><u>Abstract:</u></strong> With the rapid advancement of generative AI, synthetic content across images,
videos, and audio has become increasingly realistic, amplifying the risk of
misinformation. Existing detection approaches predominantly focus on binary
classification while lacking detailed and interpretable explanations of
forgeries, which limits their applicability in safety-critical scenarios.
Moreover, current methods often treat each modality separately, without a
unified benchmark for cross-modal forgery detection and interpretation. To
address these challenges, we introduce METER, a unified, multi-modal benchmark
for interpretable forgery detection spanning images, videos, audio, and
audio-visual content. Our dataset comprises four tracks, each requiring not
only real-vs-fake classification but also evidence-chain-based explanations,
including spatio-temporal localization, textual rationales, and forgery type
tracing. Compared to prior benchmarks, METER offers broader modality coverage
and richer interpretability metrics such as spatial/temporal IoU, multi-class
tracing, and evidence consistency. We further propose a human-aligned,
three-stage Chain-of-Thought (CoT) training strategy combining SFT, DPO, and a
novel GRPO stage that integrates a human-aligned evaluator with CoT reasoning.
We hope METER will serve as a standardized foundation for advancing
generalizable and interpretable forgery detection in the era of generative
media.</p></br><a href="http://arxiv.org/pdf/2507.17245v1" target="_blank"><h2>DistrAttention: An Efficient and Flexible Self-Attention Mechanism on
  Modern GPUs</h2></a><strong><u>Authors:</u></strong>  Haolin Jin, Mengbai Xiao, Yuan Yuan, Xiao Zhang, Dongxiao Yu, Guanghui Zhang, Haoliang Wang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> The Transformer architecture has revolutionized deep learning, delivering the
state-of-the-art performance in areas such as natural language processing,
computer vision, and time series prediction. However, its core component,
self-attention, has the quadratic time complexity relative to input sequence
length, which hinders the scalability of Transformers. The exsiting approaches
on optimizing self-attention either discard full-contextual information or lack
of flexibility. In this work, we design DistrAttention, an effcient and
flexible self-attention mechanism with the full context. DistrAttention
achieves this by grouping data on the embedding dimensionality, usually
referred to as $d$. We realize DistrAttention with a lightweight sampling and
fusion method that exploits locality-sensitive hashing to group similar data. A
block-wise grouping framework is further designed to limit the errors
introduced by locality sensitive hashing. By optimizing the selection of block
sizes, DistrAttention could be easily integrated with FlashAttention-2, gaining
high-performance on modern GPUs. We evaluate DistrAttention with extensive
experiments. The results show that our method is 37% faster than
FlashAttention-2 on calculating self-attention. In ViT inference,
DistrAttention is the fastest and the most accurate among approximate
self-attention mechanisms. In Llama3-1B, DistrAttention still achieves the
lowest inference time with only 1% accuray loss.</p></br><a href="http://arxiv.org/pdf/2507.15431v1" target="_blank"><h2>The calculus of variations of the Transformer on the hyperspherical
  tangent bundle</h2></a><strong><u>Authors:</u></strong>  Andrew Gracyk</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> First version</br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)</br><p><strong><u>Abstract:</u></strong> We offer a theoretical mathematical background to Transformers through
Lagrangian optimization across the token space. The Transformer, as a flow map,
exists in the tangent fiber for each token along the high-dimensional unit
sphere. The circumstance of the hypersphere across the latent data is
reasonable due to the trained diagonal matrix equal to the identity, which has
various empirical justifications. Thus, under the continuum limit of the
dynamics, the latent vectors flow among the tangent bundle. Using these facts,
we devise a mathematical framework for the Transformer through calculus of
variations. We develop a functional and show that the continuous flow map
induced by the Transformer satisfies this functional, therefore the Transformer
can be viewed as a natural solver of a calculus of variations problem. We
invent new scenarios of when our methods are applicable based on loss
optimization with respect to path optimality. We derive the Euler-Lagrange
equation for the Transformer. The variant of the Euler-Lagrange equation we
present has various appearances in literature, but, to our understanding,
oftentimes not foundationally proven or under other specialized cases. Our
overarching proof is new: our techniques are classical and the use of the flow
map object is original. We provide several other relevant results, primarily
ones specific to neural scenarios. In particular, much of our analysis will be
attempting to quantify Transformer data in variational contexts under neural
approximations. Calculus of variations on manifolds is a well-nourished
research area, but for the Transformer specifically, it is uncharted: we lay
the foundation for this area through an introduction to the Lagrangian for the
Transformer.</p></br><a href="http://arxiv.org/pdf/2507.14579v1" target="_blank"><h2>Exploring Human-AI Complementarity in CPS Diagnosis Using Unimodal and
  Multimodal BERT Models</h2></a><strong><u>Authors:</u></strong>  Kester Wong, Sahan Bulathwela, Mutlu Cukurova</br><strong><u>Categories:</u></strong> cs.CL, cs.AI</br><strong><u>Comments:</u></strong> Accepted to appear in the workshop proceedings for the HEXED'25 workshop in the 26th International Conference on Artificial Intelligence in Education 2025 (AIED 2025), 22 July 2025, Palermo, Italy. 5 pages</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), multimodal (title, abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Detecting collaborative problem solving (CPS) indicators from dialogue using
machine learning techniques is a significant challenge for the field of AI in
Education. Recent studies have explored the use of Bidirectional Encoder
Representations from Transformers (BERT) models on transcription data to
reliably detect meaningful CPS indicators. A notable advancement involved the
multimodal BERT variant, AudiBERT, which integrates speech and
acoustic-prosodic audio features to enhance CPS diagnosis. Although initial
results demonstrated multimodal improvements, the statistical significance of
these enhancements remained unclear, and there was insufficient guidance on
leveraging human-AI complementarity for CPS diagnosis tasks. This workshop
paper extends the previous research by highlighting that the AudiBERT model not
only improved the classification of classes that were sparse in the dataset,
but it also had statistically significant class-wise improvements over the BERT
model for classifications in the social-cognitive dimension. However, similar
significant class-wise improvements over the BERT model were not observed for
classifications in the affective dimension. A correlation analysis highlighted
that larger training data was significantly associated with higher recall
performance for both the AudiBERT and BERT models. Additionally, the precision
of the BERT model was significantly associated with high inter-rater agreement
among human coders. When employing the BERT model to diagnose indicators within
these subskills that were well-detected by the AudiBERT model, the performance
across all indicators was inconsistent. We conclude the paper by outlining a
structured approach towards achieving human-AI complementarity for CPS
diagnosis, highlighting the crucial inclusion of model explainability to
support human agency and engagement in the reflective coding process.</p></br><a href="http://arxiv.org/pdf/2507.15243v1" target="_blank"><h2>Cross-Domain Few-Shot Learning with Coalescent Projections and Latent
  Space Reservation</h2></a><strong><u>Authors:</u></strong>  Naeem Paeedeh, Mahardhika Pratama, Wolfgang Mayer, Jimmy Cao, Ryszard Kowlczyk</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Despite the progress in Cross-Domain Few-Shot Learning (CD-FSL), a model
pre-trained with DINO combined with a prototypical classifier outperforms the
latest SOTA methods. A crucial limitation that needs to be overcome is that
updating too many parameters of the transformers leads to overfitting due to
the scarcity of labeled samples. To address this challenge, we propose a new
concept, Coalescent Projection (CP), as an effective successor to soft prompts.
Additionally, we propose a novel pseudo-class generation method combined with
Self-Supervised Transformations (SSTs) that relies solely on the base domain to
prepare the network for encountering unseen samples from different domains. The
proposed method exhibits its effectiveness in comprehensive experiments on the
extreme domain shift scenario of the BSCD-FSL benchmark. Our code is published
at https://github.com/Naeem-Paeedeh/CPLSR.</p></br><a href="http://arxiv.org/pdf/2507.16039v1" target="_blank"><h2>Reactivation: Empirical NTK Dynamics Under Task Shifts</h2></a><strong><u>Authors:</u></strong>  Yuzhi Liu, Zixuan Chen, Zirui Zhang, Yufei Liu, Giulia Lanzillotta</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The Neural Tangent Kernel (NTK) offers a powerful tool to study the
functional dynamics of neural networks. In the so-called lazy, or kernel
regime, the NTK remains static during training and the network function is
linear in the static neural tangents feature space. The evolution of the NTK
during training is necessary for feature learning, a key driver of deep
learning success. The study of the NTK dynamics has led to several critical
discoveries in recent years, in generalization and scaling behaviours. However,
this body of work has been limited to the single task setting, where the data
distribution is assumed constant over time. In this work, we present a
comprehensive empirical analysis of NTK dynamics in continual learning, where
the data distribution shifts over time. Our findings highlight continual
learning as a rich and underutilized testbed for probing the dynamics of neural
training. At the same time, they challenge the validity of static-kernel
approximations in theoretical treatments of continual learning, even at large
scale.</p></br><a href="http://arxiv.org/pdf/2507.15361v1" target="_blank"><h2>Latent Space Synergy: Text-Guided Data Augmentation for Direct Diffusion
  Biomedical Segmentation</h2></a><strong><u>Authors:</u></strong>  Muhammad Aqeel, Maham Nazir, Zanxi Ruan, Francesco Setti</br><strong><u>Categories:</u></strong> eess.IV, cs.AI, cs.CV</br><strong><u>Comments:</u></strong> Accepted to CVGMMI Workshop at ICIAP 2025</br><strong><u>Matching Keywords:</u></strong> latent space (title), data augmentation (title)</br><p><strong><u>Abstract:</u></strong> Medical image segmentation suffers from data scarcity, particularly in polyp
detection where annotation requires specialized expertise. We present SynDiff,
a framework combining text-guided synthetic data generation with efficient
diffusion-based segmentation. Our approach employs latent diffusion models to
generate clinically realistic synthetic polyps through text-conditioned
inpainting, augmenting limited training data with semantically diverse samples.
Unlike traditional diffusion methods requiring iterative denoising, we
introduce direct latent estimation enabling single-step inference with T x
computational speedup. On CVC-ClinicDB, SynDiff achieves 96.0% Dice and 92.9%
IoU while maintaining real-time capability suitable for clinical deployment.
The framework demonstrates that controlled synthetic augmentation improves
segmentation robustness without distribution shift. SynDiff bridges the gap
between data-hungry deep learning models and clinical constraints, offering an
efficient solution for deployment in resourcelimited medical settings.</p></br><a href="http://arxiv.org/pdf/2507.17016v1" target="_blank"><h2>Causal Graph Fuzzy LLMs: A First Introduction and Applications in Time
  Series Forecasting</h2></a><strong><u>Authors:</u></strong>  Omid Orang, Patricia O. Lucas, Gabriel I. F. Paiva, Petronio C. L. Silva, Felipe Augusto Rocha da Silva, Adriano Alonso Veloso, Frederico Gadelha Guimaraes</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted for publication at the Brazilian Congress of Artificial Intelligence (CBIC)</br><strong><u>Matching Keywords:</u></strong> attention (abstract)</br><p><strong><u>Abstract:</u></strong> In recent years, the application of Large Language Models (LLMs) to time
series forecasting (TSF) has garnered significant attention among researchers.
This study presents a new frame of LLMs named CGF-LLM using GPT-2 combined with
fuzzy time series (FTS) and causal graph to predict multivariate time series,
marking the first such architecture in the literature. The key objective is to
convert numerical time series into interpretable forms through the parallel
application of fuzzification and causal analysis, enabling both semantic
understanding and structural insight as input for the pretrained GPT-2 model.
The resulting textual representation offers a more interpretable view of the
complex dynamics underlying the original time series. The reported results
confirm the effectiveness of our proposed LLM-based time series forecasting
model, as demonstrated across four different multivariate time series datasets.
This initiative paves promising future directions in the domain of TSF using
LLMs based on FTS.</p></br><a href="http://arxiv.org/pdf/2507.13880v1" target="_blank"><h2>Real-Time Fusion of Visual and Chart Data for Enhanced Maritime Vision</h2></a><strong><u>Authors:</u></strong>  Marten Kreis, Benjamin Kiefer</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract)</br><p><strong><u>Abstract:</u></strong> This paper presents a novel approach to enhancing marine vision by fusing
real-time visual data with chart information. Our system overlays nautical
chart data onto live video feeds by accurately matching detected navigational
aids, such as buoys, with their corresponding representations in chart data. To
achieve robust association, we introduce a transformer-based end-to-end neural
network that predicts bounding boxes and confidence scores for buoy queries,
enabling the direct matching of image-domain detections with world-space chart
markers. The proposed method is compared against baseline approaches, including
a ray-casting model that estimates buoy positions via camera projection and a
YOLOv7-based network extended with a distance estimation module. Experimental
results on a dataset of real-world maritime scenes demonstrate that our
approach significantly improves object localization and association accuracy in
dynamic and challenging environments.</p></br><a href="http://arxiv.org/pdf/2507.13415v1" target="_blank"><h2>SEER: Semantic Enhancement and Emotional Reasoning Network for
  Multimodal Fake News Detection</h2></a><strong><u>Authors:</u></strong>  Peican Zhu, Yubo Jing, Le Cheng, Bin Chen, Xiaodong Cui, Lianwei Wu, Keke Tang</br><strong><u>Categories:</u></strong> cs.MM, cs.AI</br><strong><u>Comments:</u></strong> Accepted by SMC 2025</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Previous studies on multimodal fake news detection mainly focus on the
alignment and integration of cross-modal features, as well as the application
of text-image consistency. However, they overlook the semantic enhancement
effects of large multimodal models and pay little attention to the emotional
features of news. In addition, people find that fake news is more inclined to
contain negative emotions than real ones. Therefore, we propose a novel
Semantic Enhancement and Emotional Reasoning (SEER) Network for multimodal fake
news detection. We generate summarized captions for image semantic
understanding and utilize the products of large multimodal models for semantic
enhancement. Inspired by the perceived relationship between news authenticity
and emotional tendencies, we propose an expert emotional reasoning module that
simulates real-life scenarios to optimize emotional features and infer the
authenticity of news. Extensive experiments on two real-world datasets
demonstrate the superiority of our SEER over state-of-the-art baselines.</p></br><a href="http://arxiv.org/pdf/2507.16518v1" target="_blank"><h2>C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving
  Reasoning</h2></a><strong><u>Authors:</u></strong>  Xiuwei Chen, Wentao Hu, Hanhui Li, Jun Zhou, Zisheng Chen, Meng Cao, Yihan Zeng, Kui Zhang, Yu-Jie Yuan, Jianhua Han, Hang Xu, Xiaodan Liang</br><strong><u>Categories:</u></strong> cs.CV, cs.CL, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Recent advances in multimodal large language models (MLLMs) have shown
impressive reasoning capabilities. However, further enhancing existing MLLMs
necessitates high-quality vision-language datasets with carefully curated task
complexities, which are both costly and challenging to scale. Although recent
self-improving models that iteratively refine themselves offer a feasible
solution, they still suffer from two core challenges: (i) most existing methods
augment visual or textual data separately, resulting in discrepancies in data
complexity (e.g., over-simplified diagrams paired with redundant textual
descriptions); and (ii) the evolution of data and models is also separated,
leading to scenarios where models are exposed to tasks with mismatched
difficulty levels. To address these issues, we propose C2-Evo, an automatic,
closed-loop self-improving framework that jointly evolves both training data
and model capabilities. Specifically, given a base dataset and a base model,
C2-Evo enhances them by a cross-modal data evolution loop and a data-model
evolution loop. The former loop expands the base dataset by generating complex
multimodal problems that combine structured textual sub-problems with
iteratively specified geometric diagrams, while the latter loop adaptively
selects the generated problems based on the performance of the base model, to
conduct supervised fine-tuning and reinforcement learning alternately.
Consequently, our method continuously refines its model and training data, and
consistently obtains considerable performance gains across multiple
mathematical reasoning benchmarks. Our code, models, and datasets will be
released.</p></br><a href="http://arxiv.org/pdf/2507.12818v1" target="_blank"><h2>Self Balancing Neural Network: A Novel Method to Estimate Average
  Treatment Effect</h2></a><strong><u>Authors:</u></strong>  Atomsa Gemechu Abdisa, Yingchun Zhou, Yuqi Qiu</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> In observational studies, confounding variables affect both treatment and
outcome. Moreover, instrumental variables also influence the treatment
assignment mechanism. This situation sets the study apart from a standard
randomized controlled trial, where the treatment assignment is random. Due to
this situation, the estimated average treatment effect becomes biased. To
address this issue, a standard approach is to incorporate the estimated
propensity score when estimating the average treatment effect. However, these
methods incur the risk of misspecification in propensity score models. To solve
this issue, a novel method called the "Self balancing neural network" (Sbnet),
which lets the model itself obtain its pseudo propensity score from the
balancing net, is proposed in this study. The proposed method estimates the
average treatment effect by using the balancing net as a key part of the
feedforward neural network. This formulation resolves the estimation of the
average treatment effect in one step. Moreover, the multi-pseudo propensity
score framework, which is estimated from the diversified balancing net and used
for the estimation of the average treatment effect, is presented. Finally, the
proposed methods are compared with state-of-the-art methods on three simulation
setups and real-world datasets. It has been shown that the proposed
self-balancing neural network shows better performance than state-of-the-art
methods.</p></br></body>