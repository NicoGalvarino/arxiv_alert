<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 18 Jun 2025 to 20 Jun 2025 (16 new papers out of 20 total)</em></font><a href="http://arxiv.org/pdf/2506.15230v1" target="_blank"><h2>Evolutionary models for the Very Massive Stars in the R136 cluster of 30
  Doradus in the Large Magellanic Cloud</h2></a><strong><u>Authors:</u></strong>  Z. Keszthelyi, S. A. Brands, A. de Koter, N. Langer, J. Puls</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.GA, astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> Accepted for publication in A&A</br><strong><u>Matching Keywords:</u></strong> None found</br><p><strong><u>Abstract:</u></strong> The cluster R136 in the LMC contains a population of stars in excess of 100
M$_\odot$, including R136a1, the most massive star known. Very Massive Stars
(VMSs) play an influential role in feedback processes and may potentially
produce exotic supernova types and black holes of tens of solar masses. The
evolutionary history and final fate of the three most luminous stars, R136a1,
R136a2, and R136a3, has been a puzzling issue. We aim to resolve this by
rotating single-star MESA models. We produce interpolated model grids and apply
a Markov-Chain Monte Carlo analysis to compare our models with observations.
The nature of supernova progenitors strongly depends on mass loss and the AM
coupling schemes. We predict no pair-instability and no GRB progenitors from
our fiducial model grid at LMC metallicity. The onset of Wolf-Rayet-type
mass-loss rates on the main sequence leads to a rapid decrease in stellar mass
and luminosity. The mass turnover implies that the evolutionary history can
only be inferred if additional constraints are available. We utilise the
surface helium abundance, which poses a conundrum: R136a1, the most luminous
star, is less enriched in helium than R136a2 and R136a3. We propose that this
can be explained if both R136a2 and R136a3 were initially more massive than
R136a1. From a rigorous confrontation of our models to
spectroscopically-derived observables, we estimate an initial mass of
346$\pm41$ M$_\odot$ for R136a1, and $\gtrsim$500 M$_\odot$ for R136a2 and
R136a3. Even though VMSs are only present in the youngest clusters below 2 Myr
of age, our study strengthens their role in local and galaxy evolution. At LMC
metallicity, they will be observable as helium-enriched massive stars after
their drastic mass loss, produced via single-star evolution. If the core
collapse leads to a supernova, it will be of Type Ib/c. [abridged]</p></br><a href="http://arxiv.org/pdf/2506.15408v1" target="_blank"><h2>Unifying VXAI: A Systematic Review and Framework for the Evaluation of
  Explainable AI</h2></a><strong><u>Authors:</u></strong>  David Dembinsky, Adriano Lucieri, Stanislav Frolov, Hiba Najjar, Ko Watanabe, Andreas Dengel</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Submitted to TMLR, under review</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract), neural network (abstract), literature review (abstract)</br><p><strong><u>Abstract:</u></strong> Modern AI systems frequently rely on opaque black-box models, most notably
Deep Neural Networks, whose performance stems from complex architectures with
millions of learned parameters. While powerful, their complexity poses a major
challenge to trustworthiness, particularly due to a lack of transparency.
Explainable AI (XAI) addresses this issue by providing human-understandable
explanations of model behavior. However, to ensure their usefulness and
trustworthiness, such explanations must be rigorously evaluated. Despite the
growing number of XAI methods, the field lacks standardized evaluation
protocols and consensus on appropriate metrics. To address this gap, we conduct
a systematic literature review following the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) guidelines and introduce a
unified framework for the eValuation of XAI (VXAI). We identify 362 relevant
publications and aggregate their contributions into 41 functionally similar
metric groups. In addition, we propose a three-dimensional categorization
scheme spanning explanation type, evaluation contextuality, and explanation
quality desiderata. Our framework provides the most comprehensive and
structured overview of VXAI to date. It supports systematic metric selection,
promotes comparability across methods, and offers a flexible foundation for
future extensions.</p></br><a href="http://arxiv.org/pdf/2506.15559v1" target="_blank"><h2>Towards Explainable Indoor Localization: Interpreting Neural Network
  Learning on Wi-Fi Fingerprints Using Logic Gates</h2></a><strong><u>Authors:</u></strong>  Danish Gufran, Sudeep Pasricha</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title), neural network (title)</br><p><strong><u>Abstract:</u></strong> Indoor localization using deep learning (DL) has demonstrated strong accuracy
in mapping Wi-Fi RSS fingerprints to physical locations; however, most existing
DL frameworks function as black-box models, offering limited insight into how
predictions are made or how models respond to real-world noise over time. This
lack of interpretability hampers our ability to understand the impact of
temporal variations - caused by environmental dynamics - and to adapt models
for long-term reliability. To address this, we introduce LogNet, a novel logic
gate-based framework designed to interpret and enhance DL-based indoor
localization. LogNet enables transparent reasoning by identifying which access
points (APs) are most influential for each reference point (RP) and reveals how
environmental noise disrupts DL-driven localization decisions. This
interpretability allows us to trace and diagnose model failures and adapt DL
systems for more stable long-term deployments. Evaluations across multiple
real-world building floorplans and over two years of temporal variation show
that LogNet not only interprets the internal behavior of DL models but also
improves performance-achieving up to 1.1x to 2.8x lower localization error,
3.4x to 43.3x smaller model size, and 1.5x to 3.6x lower latency compared to
prior DL-based models.</p></br><a href="http://arxiv.org/pdf/2506.15079v1" target="_blank"><h2>Neural Canonical Polyadic Factorization for Traffic Analysis</h2></a><strong><u>Authors:</u></strong>  Yikai Hou, Peng Tang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Modern intelligent transportation systems rely on accurate spatiotemporal
traffic analysis to optimize urban mobility and infrastructure resilience.
However, pervasive missing data caused by sensor failures and heterogeneous
sensing gaps fundamentally hinders reliable traffic modeling. This paper
proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes
low-rank tensor algebra with deep representation learning for robust traffic
data imputation. The model innovatively embeds CP decomposition into neural
architecture through learnable embedding projections, where sparse traffic
tensors are encoded into dense latent factors across road segments, time
intervals, and mobility metrics. A hierarchical feature fusion mechanism
employs Hadamard products to explicitly model multilinear interactions, while
stacked multilayer perceptron layers nonlinearly refine these representations
to capture complex spatiotemporal couplings. Extensive evaluations on six urban
traffic datasets demonstrate NCPF's superiority over six state-of-the-art
baselines. By unifying CP decomposition's interpretable factor analysis with
neural network's nonlinear expressive power, NCPF provides a principled yet
flexible approaches for high-dimensional traffic data imputation, offering
critical support for next-generation transportation digital twins and adaptive
traffic control systems.</p></br><a href="http://arxiv.org/pdf/2506.15452v1" target="_blank"><h2>Warping and Matching Subsequences Between Time Series</h2></a><strong><u>Authors:</u></strong>  Simiao Lin, Wannes Meert, Pieter Robberechts, Hendrik Blockeel</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> None found</br><p><strong><u>Abstract:</u></strong> Comparing time series is essential in various tasks such as clustering and
classification. While elastic distance measures that allow warping provide a
robust quantitative comparison, a qualitative comparison on top of them is
missing. Traditional visualizations focus on point-to-point alignment and do
not convey the broader structural relationships at the level of subsequences.
This limitation makes it difficult to understand how and where one time series
shifts, speeds up or slows down with respect to another. To address this, we
propose a novel technique that simplifies the warping path to highlight,
quantify and visualize key transformations (shift, compression, difference in
amplitude). By offering a clearer representation of how subsequences match
between time series, our method enhances interpretability in time series
comparison.</p></br><a href="http://arxiv.org/pdf/2506.15309v1" target="_blank"><h2>Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target
  Inhibitor Generation</h2></a><strong><u>Authors:</u></strong>  JÃºlia Vilalta-Mor, Alexis Molina, Laura Ortega Varga, Isaac Filella-Merce, Victor Guallar</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, q-bio.BM</br><strong><u>Comments:</u></strong> 16 pages, 7 figures</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (title), VAE (abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Simultaneously optimizing molecules against multiple therapeutic targets
remains a profound challenge in drug discovery, particularly due to sparse
rewards and conflicting design constraints. We propose a structured active
learning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational
autoencoder (VAE) into iterative loops designed to balance chemical diversity,
molecular quality, and multi-target affinity. Our method alternates between
expanding chemically feasible regions of latent space and progressively
constraining molecules based on increasingly stringent multi-target docking
thresholds. In a proof-of-concept study targeting three related coronavirus
main proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently
generated a structurally diverse set of pan-inhibitor candidates. We
demonstrate that careful timing and strategic placement of chemical filters
within this active learning pipeline markedly enhance exploration of beneficial
chemical space, transforming the sparse-reward, multi-objective drug design
problem into an accessible computational task. Our framework thus provides a
generalizable roadmap for efficiently navigating complex polypharmacological
landscapes.</p></br><a href="http://arxiv.org/pdf/2506.15507v1" target="_blank"><h2>Over-squashing in Spatiotemporal Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Ivan Marisca, Jacob Bamberger, Cesare Alippi, Michael M. Bronstein</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) have achieved remarkable success across various
domains. However, recent theoretical advances have identified fundamental
limitations in their information propagation capabilities, such as
over-squashing, where distant nodes fail to effectively exchange information.
While extensively studied in static contexts, this issue remains unexplored in
Spatiotemporal GNNs (STGNNs), which process sequences associated with graph
nodes. Nonetheless, the temporal dimension amplifies this challenge by
increasing the information that must be propagated. In this work, we formalize
the spatiotemporal over-squashing problem and demonstrate its distinct
characteristics compared to the static case. Our analysis reveals that
counterintuitively, convolutional STGNNs favor information propagation from
points temporally distant rather than close in time. Moreover, we prove that
architectures that follow either time-and-space or time-then-space processing
paradigms are equally affected by this phenomenon, providing theoretical
justification for computationally efficient implementations. We validate our
findings on synthetic and real-world datasets, providing deeper insights into
their operational dynamics and principled guidance for more effective designs.</p></br><a href="http://arxiv.org/pdf/2506.15404v1" target="_blank"><h2>NERO: Explainable Out-of-Distribution Detection with Neuron-level
  Relevance</h2></a><strong><u>Authors:</u></strong>  Anju Chhetri, Jari Korhonen, Prashnna Gyawali, Binod Bhattarai</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> Ensuring reliability is paramount in deep learning, particularly within the
domain of medical imaging, where diagnostic decisions often hinge on model
outputs. The capacity to separate out-of-distribution (OOD) samples has proven
to be a valuable indicator of a model's reliability in research. In medical
imaging, this is especially critical, as identifying OOD inputs can help flag
potential anomalies that might otherwise go undetected. While many OOD
detection methods rely on feature or logit space representations, recent works
suggest these approaches may not fully capture OOD diversity. To address this,
we propose a novel OOD scoring mechanism, called NERO, that leverages
neuron-level relevance at the feature layer. Specifically, we cluster
neuron-level relevance for each in-distribution (ID) class to form
representative centroids and introduce a relevance distance metric to quantify
a new sample's deviation from these centroids, enhancing OOD separability.
Additionally, we refine performance by incorporating scaled relevance in the
bias term and combining feature norms. Our framework also enables explainable
OOD detection. We validate its effectiveness across multiple deep learning
architectures on the gastrointestinal imaging benchmarks Kvasir and
GastroVision, achieving improvements over state-of-the-art OOD detection
methods.</p></br><a href="http://arxiv.org/pdf/2506.15051v1" target="_blank"><h2>Sequential Policy Gradient for Adaptive Hyperparameter Optimization</h2></a><strong><u>Authors:</u></strong>  Zheng Li, Jerry Cheng, Huanying Helen Gu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 10 pages, 2 figures</br><strong><u>Matching Keywords:</u></strong> None found</br><p><strong><u>Abstract:</u></strong> Reinforcement learning is essential for neural architecture search and
hyperparameter optimization, but the conventional approaches impede widespread
use due to prohibitive time and computational costs. Inspired by DeepSeek-V3
multi-token prediction architecture, we propose Sequential Policy Gradient
modeling (SPG), a novel trajectory generation paradigm for lightweight online
hyperparameter optimization. In contrast to conventional policy gradient
methods, SPG extends the base model with temporary modules, enabling it to
generate state-action (padded) trajectories in a single forward pass. Our
experiments demonstrate that models gain performance when retrained with SPG on
their original datasets and also outperform standard transfer fine-tuning. We
evaluate on five datasets spanning computer vision (ImageNet, COCO), natural
language processing (GLUE, SQuAD), and audio (SUPERB) to assess the industrial
applicability of SPG. The proposed method demonstrates consistent improvements
across widely adopted models, achieving performance gains of $+0.2\sim7\%$,
with significantly low computational costs. Fully reproducible code and
pre-trained models: https://huggingface.co/UniversalAlgorithmic/SPG.</p></br><a href="http://arxiv.org/pdf/2506.15492v1" target="_blank"><h2>LIT-LVM: Structured Regularization for Interaction Terms in Linear
  Predictors using Latent Variable Models</h2></a><strong><u>Authors:</u></strong>  Mohammadreza Nemati, Zhipeng Huang, Kevin S. Xu</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> None found</br><p><strong><u>Abstract:</u></strong> Some of the simplest, yet most frequently used predictors in statistics and
machine learning use weighted linear combinations of features. Such linear
predictors can model non-linear relationships between features by adding
interaction terms corresponding to the products of all pairs of features. We
consider the problem of accurately estimating coefficients for interaction
terms in linear predictors. We hypothesize that the coefficients for different
interaction terms have an approximate low-dimensional structure and represent
each feature by a latent vector in a low-dimensional space. This
low-dimensional representation can be viewed as a structured regularization
approach that further mitigates overfitting in high-dimensional settings beyond
standard regularizers such as the lasso and elastic net. We demonstrate that
our approach, called LIT-LVM, achieves superior prediction accuracy compared to
elastic net and factorization machines on a wide variety of simulated and real
data, particularly when the number of interaction terms is high compared to the
number of samples. LIT-LVM also provides low-dimensional latent representations
for features that are useful for visualizing and analyzing their relationships.</p></br><a href="http://arxiv.org/pdf/2506.15505v1" target="_blank"><h2>Time-dependent density estimation using binary classifiers</h2></a><strong><u>Authors:</u></strong>  Agnimitra Dasgupta, Javier Murgoitio-Esandi, Ali Fardisi, Assad A Oberai</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), multi-modal (abstract)</br><p><strong><u>Abstract:</u></strong> We propose a data-driven method to learn the time-dependent probability
density of a multivariate stochastic process from sample paths, assuming that
the initial probability density is known and can be evaluated. Our method uses
a novel time-dependent binary classifier trained using a contrastive
estimation-based objective that trains the classifier to discriminate between
realizations of the stochastic process at two nearby time instants.
Significantly, the proposed method explicitly models the time-dependent
probability distribution, which means that it is possible to obtain the value
of the probability density within the time horizon of interest. Additionally,
the input before the final activation in the time-dependent classifier is a
second-order approximation to the partial derivative, with respect to time, of
the logarithm of the density. We apply the proposed approach to approximate the
time-dependent probability density functions for systems driven by stochastic
excitations. We also use the proposed approach to synthesize new samples of a
random vector from a given set of its realizations. In such applications, we
generate sample paths necessary for training using stochastic interpolants.
Subsequently, new samples are generated using gradient-based Markov chain Monte
Carlo methods because automatic differentiation can efficiently provide the
necessary gradient. Further, we demonstrate the utility of an explicit
approximation to the time-dependent probability density function through
applications in unsupervised outlier detection. Through several numerical
experiments, we show that the proposed method accurately reconstructs complex
time-dependent, multi-modal, and near-degenerate densities, scales effectively
to moderately high-dimensional problems, and reliably detects rare events among
real-world data.</p></br><a href="http://arxiv.org/pdf/2506.15199v1" target="_blank"><h2>Interpretability and Generalization Bounds for Learning Spatial Physics</h2></a><strong><u>Authors:</u></strong>  Alejandro Francisco Queiruga, Theo Gutman-Solo, Shuai Jiang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> While there are many applications of ML to scientific problems that look
promising, visuals can be deceiving. For scientific applications, actual
quantitative accuracy is crucial. This work applies the rigor of numerical
analysis for differential equations to machine learning by specifically
quantifying the accuracy of applying different ML techniques to the elementary
1D Poisson differential equation. Beyond the quantity and discretization of
data, we identify that the function space of the data is critical to the
generalization of the model. We prove generalization bounds and convergence
rates under finite data discretizations and restricted training data subspaces
by analyzing the training dynamics and deriving optimal parameters for both a
white-box differential equation discovery method and a black-box linear model.
The analytically derived generalization bounds are replicated empirically.
Similar lack of generalization is empirically demonstrated for deep linear
models, shallow neural networks, and physics-specific DeepONets and Neural
Operators. We theoretically and empirically demonstrate that generalization to
the true physical equation is not guaranteed in each explored case.
Surprisingly, we find that different classes of models can exhibit opposing
generalization behaviors. Based on our theoretical analysis, we also
demonstrate a new mechanistic interpretability lens on scientific models
whereby Green's function representations can be extracted from the weights of
black-box models. Our results inform a new cross-validation technique for
measuring generalization in physical systems. We propose applying it to the
Poisson equation as an evaluation benchmark of future methods.</p></br><a href="http://arxiv.org/pdf/2506.15460v1" target="_blank"><h2>Distances of Supernova Remnants Associated with Neutron Stars in the
  Galaxy</h2></a><strong><u>Authors:</u></strong>  Xiaohan Chen, Shu Wang, Xiaodian Chen</br><strong><u>Categories:</u></strong> astro-ph.GA, astro-ph.HE</br><strong><u>Comments:</u></strong> 23 pages, 5 figures, 1 table, Accepted for publication in ApJ</br><strong><u>Matching Keywords:</u></strong> None found</br><p><strong><u>Abstract:</u></strong> Accurate distance measurements to supernova remnants (SNRs) are essential for
determining their physical parameters, such as size, age, explosion energy, and
for constraining the properties of associated neutron stars (NSs). We present
an extinction--distance method that combines precise Gaia DR3 photometry,
parallax, and stellar parameters from the SHBoost catalog to homogeneously
construct extinction--distance profiles for 44 NS-associated Galactic SNRs.
Applying a statistical model, we identify clear extinction jumps along each
sightline, corresponding to probable SNR distances. We classify the results
into three reliability levels (A, B, and C), primarily based on comparisons
with previously reported kinematic distances, supplemented by independent
estimates from other methods. Our results show that the majority of reliable
distances (17 Level A and 8 Level B) are located within 5 kpc, predominantly in
the Local Arm. This study presents an independent and effective method for
determining distances to SNRs, particularly for those with small angular sizes
or located in the second and third Galactic quadrants. Although the current
method is limited to within 5 kpc due to the precision constraints of Gaia
parallax and photometry, the upcoming Gaia DR4 release, combined with
complementary infrared data, will extend its applicability to more distant and
heavily obscured SNRs, and help resolve kinematic distance ambiguities.</p></br><a href="http://arxiv.org/pdf/2506.15506v1" target="_blank"><h2>Insights on Adversarial Attacks for Tabular Machine Learning via a
  Systematic Literature Review</h2></a><strong><u>Authors:</u></strong>  Salijona Dyrmishi, Mohamed Djilani, Thibault Simonetto, Salah Ghamizi, Maxime Cordy</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> This paper is currently under review at ACM Computing Surveys</br><strong><u>Matching Keywords:</u></strong> literature review (title, abstract)</br><p><strong><u>Abstract:</u></strong> Adversarial attacks in machine learning have been extensively reviewed in
areas like computer vision and NLP, but research on tabular data remains
scattered. This paper provides the first systematic literature review focused
on adversarial attacks targeting tabular machine learning models. We highlight
key trends, categorize attack strategies and analyze how they address practical
considerations for real-world applicability. Additionally, we outline current
challenges and open research questions. By offering a clear and structured
overview, this review aims to guide future efforts in understanding and
addressing adversarial vulnerabilities in tabular machine learning.</p></br><a href="http://arxiv.org/pdf/2506.15554v1" target="_blank"><h2>DAILOC: Domain-Incremental Learning for Indoor Localization using
  Smartphones</h2></a><strong><u>Authors:</u></strong>  Akhil Singampalli, Danish Gufran, Sudeep Pasricha</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract)</br><p><strong><u>Abstract:</u></strong> Wi-Fi fingerprinting-based indoor localization faces significant challenges
in real-world deployments due to domain shifts arising from device
heterogeneity and temporal variations within indoor environments. Existing
approaches often address these issues independently, resulting in poor
generalization and susceptibility to catastrophic forgetting over time. In this
work, we propose DAILOC, a novel domain-incremental learning framework that
jointly addresses both temporal and device-induced domain shifts. DAILOC
introduces a novel disentanglement strategy that separates domain shifts from
location-relevant features using a multi-level variational autoencoder.
Additionally, we introduce a novel memory-guided class latent alignment
mechanism to address the effects of catastrophic forgetting over time.
Experiments across multiple smartphones, buildings, and time instances
demonstrate that DAILOC significantly outperforms state-of-the-art methods,
achieving up to 2.74x lower average error and 4.6x lower worst-case error.</p></br><a href="http://arxiv.org/pdf/2506.15075v1" target="_blank"><h2>CWGAN-GP Augmented CAE for Jamming Detection in 5G-NR in Non-IID
  Datasets</h2></a><strong><u>Authors:</u></strong>  Samhita Kuili, Mohammadreza Amini, Burak Kantarci</br><strong><u>Categories:</u></strong> cs.CR, cs.LG, eess.SP</br><strong><u>Comments:</u></strong> 6 pages, 5 figures, Accepted to IEEE International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC) 2025</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)</br><p><strong><u>Abstract:</u></strong> In the ever-expanding domain of 5G-NR wireless cellular networks,
over-the-air jamming attacks are prevalent as security attacks, compromising
the quality of the received signal. We simulate a jamming environment by
incorporating additive white Gaussian noise (AWGN) into the real-world In-phase
and Quadrature (I/Q) OFDM datasets. A Convolutional Autoencoder (CAE) is
exploited to implement a jamming detection over various characteristics such as
heterogenous I/Q datasets; extracting relevant information on Synchronization
Signal Blocks (SSBs), and fewer SSB observations with notable class imbalance.
Given the characteristics of datasets, balanced datasets are acquired by
employing a Conv1D conditional Wasserstein Generative Adversarial
Network-Gradient Penalty(CWGAN-GP) on both majority and minority SSB
observations. Additionally, we compare the performance and detection ability of
the proposed CAE model on augmented datasets with benchmark models:
Convolutional Denoising Autoencoder (CDAE) and Convolutional Sparse Autoencoder
(CSAE). Despite the complexity of data heterogeneity involved across all
datasets, CAE depicts the robustness in detection performance of jammed signal
by achieving average values of 97.33% precision, 91.33% recall, 94.08%
F1-score, and 94.35% accuracy over CDAE and CSAE.</p></br></body>