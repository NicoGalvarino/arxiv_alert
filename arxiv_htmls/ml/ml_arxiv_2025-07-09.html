<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 07 Jul 2025 to 09 Jul 2025</em></font><a href="http://arxiv.org/pdf/2507.06217v1" target="_blank"><h2>What ZTF Saw Where Rubin Looked: Anomaly Hunting in DR23</h2></a><strong><u>Authors:</u></strong>  Maria V. Pruzhinskaya, Anastasia D. Lavrukhina, Timofey A. Semenikhi, Alina A. Volnova, Sreevarsha Sreejith, Vadim V. Krushinsky, Emmanuel Gangler, Emille E. O. Ishida, Matwey V. Kornilov, Konstantin L. Malanchev</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA, astro-ph.SR, cs.LG</br><strong><u>Comments:</u></strong> 11 pages, 4 figures</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> We present results from the SNAD VIII Workshop, during which we conducted the
first systematic anomaly search in the ZTF fields also observed by LSSTComCam
during Rubin Scientific Pipeline commissioning. Using the PineForest active
anomaly detection algorithm, we analysed four selected fields (two galactic and
two extragalactic) and visually inspected 400 candidates. As a result, we
discovered six previously uncatalogued variable stars, including RS~CVn, BY
Draconis, ellipsoidal, and solar-type variables, and refined classifications
and periods for six known objects. These results demonstrate the effectiveness
of the SNAD anomaly detection pipeline and provide a preview of the discovery
potential in the upcoming LSST data.</p></br><a href="http://arxiv.org/pdf/2507.05498v1" target="_blank"><h2>Explainable Hierarchical Deep Learning Neural Networks (Ex-HiDeNN)</h2></a><strong><u>Authors:</u></strong>  Reza T. Batley, Chanwook Park, Wing Kam Liu, Sourav Saha</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), convolutional (abstract), explainable (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Data-driven science and computation have advanced immensely to construct
complex functional relationships using trainable parameters. However,
efficiently discovering interpretable and accurate closed-form expressions from
complex dataset remains a challenge. The article presents a novel approach
called Explainable Hierarchical Deep Learning Neural Networks or Ex-HiDeNN that
uses an accurate, frugal, fast, separable, and scalable neural architecture
with symbolic regression to discover closed-form expressions from limited
observation. The article presents the two-step Ex-HiDeNN algorithm with a
separability checker embedded in it. The accuracy and efficiency of Ex-HiDeNN
are tested on several benchmark problems, including discerning a dynamical
system from data, and the outcomes are reported. Ex-HiDeNN generally shows
outstanding approximation capability in these benchmarks, producing orders of
magnitude smaller errors compared to reference data and traditional symbolic
regression. Later, Ex-HiDeNN is applied to three engineering applications: a)
discovering a closed-form fatigue equation, b) identification of hardness from
micro-indentation test data, and c) discovering the expression for the yield
surface with data. In every case, Ex-HiDeNN outperformed the reference methods
used in the literature. The proposed method is built upon the foundation and
published works of the authors on Hierarchical Deep Learning Neural Network
(HiDeNN) and Convolutional HiDeNN. The article also provides a clear idea about
the current limitations and future extensions of Ex-HiDeNN.</p></br><a href="http://arxiv.org/pdf/2507.05333v1" target="_blank"><h2>Causal Foundation Models: Disentangling Physics from Instrument
  Properties</h2></a><strong><u>Authors:</u></strong>  Jeroen Audenaert, Daniel Muthukrishna, Paul F. Gregory, David W. Hogg, V. Ashley Villar</br><strong><u>Categories:</u></strong> cs.LG, astro-ph.IM, astro-ph.SR, cs.AI</br><strong><u>Comments:</u></strong> 8 pages, 5 figures. Accepted to the ICML 2025 Foundation Models for Structured Data Workshop and accepted to the Machine Learning for Astrophysics Workshop 2025</br><strong><u>Matching Keywords:</u></strong> latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Foundation models for structured time series data must contend with a
fundamental challenge: observations often conflate the true underlying physical
phenomena with systematic distortions introduced by measurement instruments.
This entanglement limits model generalization, especially in heterogeneous or
multi-instrument settings. We present a causally-motivated foundation model
that explicitly disentangles physical and instrumental factors using a
dual-encoder architecture trained with structured contrastive learning.
Leveraging naturally occurring observational triplets (i.e., where the same
target is measured under varying conditions, and distinct targets are measured
under shared conditions) our model learns separate latent representations for
the underlying physical signal and instrument effects. Evaluated on simulated
astronomical time series designed to resemble the complexity of variable stars
observed by missions like NASA's Transiting Exoplanet Survey Satellite (TESS),
our method significantly outperforms traditional single-latent space foundation
models on downstream prediction tasks, particularly in low-data regimes. These
results demonstrate that our model supports key capabilities of foundation
models, including few-shot generalization and efficient adaptation, and
highlight the importance of encoding causal structure into representation
learning for structured data.</p></br><a href="http://arxiv.org/pdf/2507.05644v1" target="_blank"><h2>FACT: the Features At Convergence Theorem for neural networks</h2></a><strong><u>Authors:</u></strong>  Enric Boix-Adsera, Neil Mallinar, James B. Simon, Mikhail Belkin</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> A central challenge in deep learning theory is to understand how neural
networks learn and represent features. To this end, we prove the Features at
Convergence Theorem (FACT), which gives a self-consistency equation that neural
network weights satisfy at convergence when trained with nonzero weight decay.
For each weight matrix $W$, this equation relates the "feature matrix" $W^\top
W$ to the set of input vectors passed into the matrix during forward
propagation and the loss gradients passed through it during backpropagation. We
validate this relation empirically, showing that neural features indeed satisfy
the FACT at convergence. Furthermore, by modifying the "Recursive Feature
Machines" of Radhakrishnan et al. 2024 so that they obey the FACT, we arrive at
a new learning algorithm, FACT-RFM. FACT-RFM achieves high performance on
tabular data and captures various feature learning behaviors that occur in
neural network training, including grokking in modular arithmetic and phase
transitions in learning sparse parities.</p></br><a href="http://arxiv.org/pdf/2507.05636v1" target="_blank"><h2>Graph Learning</h2></a><strong><u>Authors:</u></strong>  Feng Xia, Ciyuan Peng, Jing Ren, Falih Gozi Febrinanto, Renqiang Luo, Vidya Saikrishna, Shuo Yu, Xiangjie Kong</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, 68T09, 68R10, I.2.6; G.2.2; E.1</br><strong><u>Comments:</u></strong> 178 pages</br><strong><u>Matching Keywords:</u></strong> explainable (abstract), neural network (abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Graph learning has rapidly evolved into a critical subfield of machine
learning and artificial intelligence (AI). Its development began with early
graph-theoretic methods, gaining significant momentum with the advent of graph
neural networks (GNNs). Over the past decade, progress in scalable
architectures, dynamic graph modeling, multimodal learning, generative AI,
explainable AI (XAI), and responsible AI has broadened the applicability of
graph learning to various challenging environments. Graph learning is
significant due to its ability to model complex, non-Euclidean relationships
that traditional machine learning struggles to capture, thus better supporting
real-world applications ranging from drug discovery and fraud detection to
recommender systems and scientific reasoning. However, challenges like
scalability, generalization, heterogeneity, interpretability, and
trustworthiness must be addressed to unlock its full potential. This survey
provides a comprehensive introduction to graph learning, focusing on key
dimensions including scalable, temporal, multimodal, generative, explainable,
and responsible graph learning. We review state-of-the-art techniques for
efficiently handling large-scale graphs, capturing dynamic temporal
dependencies, integrating heterogeneous data modalities, generating novel graph
samples, and enhancing interpretability to foster trust and transparency. We
also explore ethical considerations, such as privacy and fairness, to ensure
responsible deployment of graph learning models. Additionally, we identify and
discuss emerging topics, highlighting recent integration of graph learning and
other AI paradigms and offering insights into future directions. This survey
serves as a valuable resource for researchers and practitioners seeking to
navigate the rapidly evolving landscape of graph learning.</p></br><a href="http://arxiv.org/pdf/2507.05591v1" target="_blank"><h2>MLlm-DR: Towards Explainable Depression Recognition with MultiModal
  Large Language Models</h2></a><strong><u>Authors:</u></strong>  Wei Zhang, Juan Chen, En Zhu, Wenhong Cheng, YunPeng Li, Yanbo J. Wang</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Automated depression diagnosis aims to analyze multimodal information from
interview videos to predict participants' depression scores. Previous studies
often lack clear explanations of how these scores were determined, limiting
their adoption in clinical practice. While the advent of LLMs provides a
possible pathway for explainable depression diagnosis, current LLMs capable of
processing multimodal data lack training on interview data, resulting in poor
diagnostic performance when used directly. In this paper, we propose a novel
multimodal large language model (MLlm-DR) that can understand multimodal
information inputs and supports explainable depression diagnosis. MLlm-DR
integrates a smaller LLMs and a lightweight query module (LQ-former).
Specifically, the smaller LLMs is designed to generate depression scores and
corresponding evaluation rationales. To enhance its logical reasoning for
domain-specific tasks while maintaining practicality, we constructed a robust
training dataset to fine-tune it. Meanwhile, the LQ-former captures
depression-related features from speech and visual data, aiding the model's
ability to process multimodal information, to achieve comprehensive depression
diagnosis. Our approach achieves state-of-the-art results on two
interview-based benchmark datasets, CMDC and E-DAIC-WOZ, demonstrating its
effectiveness and superiority.</p></br><a href="http://arxiv.org/pdf/2507.05540v1" target="_blank"><h2>Robust Learning on Noisy Graphs via Latent Space Constraints with
  External Knowledge</h2></a><strong><u>Authors:</u></strong>  Chunhui Gu, Mohammad Sadegh Nasr, James P. Long, Kim-Anh Do, Ehsan Irajizad</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> latent space (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) often struggle with noisy edges. We propose
Latent Space Constrained Graph Neural Networks (LSC-GNN) to incorporate
external "clean" links and guide embeddings of a noisy target graph. We train
two encoders--one on the full graph (target plus external edges) and another on
a regularization graph excluding the target's potentially noisy links--then
penalize discrepancies between their latent representations. This constraint
steers the model away from overfitting spurious edges. Experiments on benchmark
datasets show LSC-GNN outperforms standard and noise-resilient GNNs in graphs
subjected to moderate noise. We extend LSC-GNN to heterogeneous graphs and
validate it on a small protein-metabolite network, where metabolite-protein
interactions reduce noise in protein co-occurrence data. Our results highlight
LSC-GNN's potential to boost predictive performance and interpretability in
settings with noisy relational structures.</p></br><a href="http://arxiv.org/pdf/2507.05681v1" target="_blank"><h2>GATMesh: Clock Mesh Timing Analysis using Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Muhammad Hadir Khan, Matthew Guthaus</br><strong><u>Categories:</u></strong> cs.AR, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Clock meshes are essential in high-performance VLSI systems for minimizing
skew and handling PVT variations, but analyzing them is difficult due to
reconvergent paths, multi-source driving, and input mesh buffer skew. SPICE
simulations are accurate but slow; yet simplified models miss key effects like
slew and input skew. We propose GATMesh, a Graph Neural Network (GNN)-based
framework that models the clock mesh as a graph with augmented structural and
physical features. Trained on SPICE data, GATMesh achieves high accuracy with
average delay error of 5.27ps on unseen benchmarks, while achieving speed-ups
of 47146x over multi-threaded SPICE simulation.</p></br><a href="http://arxiv.org/pdf/2507.05584v1" target="_blank"><h2>The Fourier Spectral Transformer Networks For Efficient and
  Generalizable Nonlinear PDEs Prediction</h2></a><strong><u>Authors:</u></strong>  Beibei Li</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> In this work we propose a unified Fourier Spectral Transformer network that
integrates the strengths of classical spectral methods and attention based
neural architectures. By transforming the original PDEs into spectral ordinary
differential equations, we use high precision numerical solvers to generate
training data and use a Transformer network to model the evolution of the
spectral coefficients. We demonstrate the effectiveness of our approach on the
two dimensional incompressible Navier-Stokes equations and the one dimensional
Burgers' equation. The results show that our spectral Transformer can achieve
highly accurate long term predictions even with limited training data, better
than traditional numerical methods and machine learning methods in forecasting
future flow dynamics. The proposed framework generalizes well to unseen data,
bringing a promising paradigm for real time prediction and control of complex
dynamical systems.</p></br></body>