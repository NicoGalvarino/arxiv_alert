<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 05 Sep 2025 to 09 Sep 2025</em></font><a href="http://arxiv.org/pdf/2509.06419v1" target="_blank"><h2>CAPMix: Robust Time Series Anomaly Detection Based on Abnormal
  Assumptions with Dual-Space Mixup</h2></a><strong><u>Authors:</u></strong>  Xudong Mou, Rui Wang, Tiejun Wang, Renyu Yang, Shiru Chen, Jie Sun, Tianyu Wo, Xudong Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Time series anomaly detection (TSAD) is a vital yet challenging task,
particularly in scenarios where labeled anomalies are scarce and temporal
dependencies are complex. Recent anomaly assumption (AA) approaches alleviate
the lack of anomalies by injecting synthetic samples and training
discriminative models. Despite promising results, these methods often suffer
from two fundamental limitations: patchy generation, where scattered anomaly
knowledge leads to overly simplistic or incoherent anomaly injection, and
Anomaly Shift, where synthetic anomalies either resemble normal data too
closely or diverge unrealistically from real anomalies, thereby distorting
classification boundaries. In this paper, we propose CAPMix, a controllable
anomaly augmentation framework that addresses both issues. First, we design a
CutAddPaste mechanism to inject diverse and complex anomalies in a targeted
manner, avoiding patchy generation. Second, we introduce a label revision
strategy to adaptively refine anomaly labels, reducing the risk of anomaly
shift. Finally, we employ dual-space mixup within a temporal convolutional
network to enforce smoother and more robust decision boundaries. Extensive
experiments on five benchmark datasets, including AIOps, UCR, SWaT, WADI, and
ESA, demonstrate that CAPMix achieves significant improvements over
state-of-the-art baselines, with enhanced robustness against contaminated
training data. The code is available at https://github.com/alsike22/CAPMix.</p></br><a href="http://arxiv.org/pdf/2509.05671v1" target="_blank"><h2>GraMFedDHAR: Graph Based Multimodal Differentially Private Federated HAR</h2></a><strong><u>Authors:</u></strong>  Labani Halder, Tanmay Sen, Sarbani Palit</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CR, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Human Activity Recognition (HAR) using multimodal sensor data remains
challenging due to noisy or incomplete measurements, scarcity of labeled
examples, and privacy concerns. Traditional centralized deep learning
approaches are often constrained by infrastructure availability, network
latency, and data sharing restrictions. While federated learning (FL) addresses
privacy by training models locally and sharing only model parameters, it still
has to tackle issues arising from the use of heterogeneous multimodal data and
differential privacy requirements. In this article, a Graph-based Multimodal
Federated Learning framework, GraMFedDHAR, is proposed for HAR tasks. Diverse
sensor streams such as a pressure mat, depth camera, and multiple
accelerometers are modeled as modality-specific graphs, processed through
residual Graph Convolutional Neural Networks (GCNs), and fused via
attention-based weighting rather than simple concatenation. The fused
embeddings enable robust activity classification, while differential privacy
safeguards data during federated aggregation. Experimental results show that
the proposed MultiModalGCN model outperforms the baseline MultiModalFFN, with
up to 2 percent higher accuracy in non-DP settings in both centralized and
federated paradigms. More importantly, significant improvements are observed
under differential privacy constraints: MultiModalGCN consistently surpasses
MultiModalFFN, with performance gaps ranging from 7 to 13 percent depending on
the privacy budget and setting. These results highlight the robustness of
graph-based modeling in multimodal learning, where GNNs prove more resilient to
the performance degradation introduced by DP noise.</p></br><a href="http://arxiv.org/pdf/2509.05615v1" target="_blank"><h2>Causal Debiasing Medical Multimodal Representation Learning with Missing
  Modalities</h2></a><strong><u>Authors:</u></strong>  Xiaoguang Zhu, Lianlong Sun, Yang Liu, Pengyi Jiang, Uma Srivatsa, Nipavan Chiamvimonvat, Vladimir Filkov</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Submitted to IEEE TKDE</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Medical multimodal representation learning aims to integrate heterogeneous
clinical data into unified patient representations to support predictive
modeling, which remains an essential yet challenging task in the medical data
mining community. However, real-world medical datasets often suffer from
missing modalities due to cost, protocol, or patient-specific constraints.
Existing methods primarily address this issue by learning from the available
observations in either the raw data space or feature space, but typically
neglect the underlying bias introduced by the data acquisition process itself.
In this work, we identify two types of biases that hinder model generalization:
missingness bias, which results from non-random patterns in modality
availability, and distribution bias, which arises from latent confounders that
influence both observed features and outcomes. To address these challenges, we
perform a structural causal analysis of the data-generating process and propose
a unified framework that is compatible with existing direct prediction-based
multimodal learning methods. Our method consists of two key components: (1) a
missingness deconfounding module that approximates causal intervention based on
backdoor adjustment and (2) a dual-branch neural network that explicitly
disentangles causal features from spurious correlations. We evaluated our
method in real-world public and in-hospital datasets, demonstrating its
effectiveness and causal insights.</p></br><a href="http://arxiv.org/pdf/2509.05724v1" target="_blank"><h2>Robust variational neural posterior estimation for simulation-based
  inference</h2></a><strong><u>Authors:</u></strong>  Matthew O'Callaghan, Kaisey S. Mandel, Gerry Gilmore</br><strong><u>Categories:</u></strong> stat.ML, astro-ph.GA, cs.LG</br><strong><u>Comments:</u></strong> Main text: 16 pages, 6 figures</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)</br><p><strong><u>Abstract:</u></strong> Recent advances in neural density estimation have enabled powerful
simulation-based inference (SBI) methods that can flexibly approximate Bayesian
inference for intractable stochastic models. Although these methods have
demonstrated reliable posterior estimation when the simulator accurately
represents the underlying data generative process (GDP), recent work has shown
that they perform poorly in the presence of model misspecification. This poses
a significant problem for their use on real-world problems, due to simulators
always misrepresenting the true DGP to a certain degree. In this paper, we
introduce robust variational neural posterior estimation (RVNP), a method which
addresses the problem of misspecification in amortised SBI by bridging the
simulation-to-reality gap using variational inference and error modelling. We
test RVNP on multiple benchmark tasks, including using real data from
astronomy, and show that it can recover robust posterior inference in a
data-driven manner without adopting tunable hyperparameters or priors governing
the misspecification.</p></br><a href="http://arxiv.org/pdf/2509.05478v1" target="_blank"><h2>PLanTS: Periodicity-aware Latent-state Representation Learning for
  Multivariate Time Series</h2></a><strong><u>Authors:</u></strong>  Jia Wang, Xiao Wang, Chi Zhang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Multivariate time series (MTS) are ubiquitous in domains such as healthcare,
climate science, and industrial monitoring, but their high dimensionality,
limited labeled data, and non-stationary nature pose significant challenges for
conventional machine learning methods. While recent self-supervised learning
(SSL) approaches mitigate label scarcity by data augmentations or time
point-based contrastive strategy, they neglect the intrinsic periodic structure
of MTS and fail to capture the dynamic evolution of latent states. We propose
PLanTS, a periodicity-aware self-supervised learning framework that explicitly
models irregular latent states and their transitions. We first designed a
period-aware multi-granularity patching mechanism and a generalized contrastive
loss to preserve both instance-level and state-level similarities across
multiple temporal resolutions. To further capture temporal dynamics, we design
a next-transition prediction pretext task that encourages representations to
encode predictive information about future state evolution. We evaluate PLanTS
across a wide range of downstream tasks-including multi-class and multi-label
classification, forecasting, trajectory tracking and anomaly detection. PLanTS
consistently improves the representation quality over existing SSL methods and
demonstrates superior runtime efficiency compared to DTW-based methods.</p></br><a href="http://arxiv.org/pdf/2509.05887v1" target="_blank"><h2>Near Real-Time Dust Aerosol Detection with 3D Convolutional Neural
  Networks on MODIS Data</h2></a><strong><u>Authors:</u></strong>  Caleb Gates, Patrick Moorhead, Jayden Ferguson, Omar Darwish, Conner Stallman, Pablo Rivas, Paapa Quansah</br><strong><u>Categories:</u></strong> cs.CV, cs.LG, eess.IV, 68T07, 86A32, I.2.6; I.5.4</br><strong><u>Comments:</u></strong> 29th International Conference on Image Processing, Computer Vision, & Pattern Recognition (IPCV'25)</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Dust storms harm health and reduce visibility; quick detection from
satellites is needed. We present a near real-time system that flags dust at the
pixel level using multi-band images from NASA's Terra and Aqua (MODIS). A 3D
convolutional network learns patterns across all 36 bands, plus split thermal
bands, to separate dust from clouds and surface features. Simple normalization
and local filling handle missing data. An improved version raises training
speed by 21x and supports fast processing of full scenes. On 17 independent
MODIS scenes, the model reaches about 0.92 accuracy with a mean squared error
of 0.014. Maps show strong agreement in plume cores, with most misses along
edges. These results show that joint band-and-space learning can provide timely
dust alerts at global scale; using wider input windows or attention-based
models may further sharpen edges.</p></br><a href="http://arxiv.org/pdf/2509.06154v1" target="_blank"><h2>Data-Efficient Time-Dependent PDE Surrogates: Graph Neural Simulators vs
  Neural Operators</h2></a><strong><u>Authors:</u></strong>  Dibyajyoti Nayak, Somdatta Goswami</br><strong><u>Categories:</u></strong> cs.LG, stat.CO, stat.ML</br><strong><u>Comments:</u></strong> 21 pages including references. Supplementary Information provided</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), causality (abstract)</br><p><strong><u>Abstract:</u></strong> Neural operators (NOs) approximate mappings between infinite-dimensional
function spaces but require large datasets and struggle with scarce training
data. Many NO formulations don't explicitly encode causal, local-in-time
structure of physical evolution. While autoregressive models preserve causality
by predicting next time-steps, they suffer from rapid error accumulation. We
employ Graph Neural Simulators (GNS) - a message-passing graph neural network
framework - with explicit numerical time-stepping schemes to construct accurate
forward models that learn PDE solutions by modeling instantaneous time
derivatives. We evaluate our framework on three canonical PDE systems: (1) 2D
Burgers' scalar equation, (2) 2D coupled Burgers' vector equation, and (3) 2D
Allen-Cahn equation. Rigorous evaluations demonstrate GNS significantly
improves data efficiency, achieving higher generalization accuracy with
substantially fewer training trajectories compared to neural operator baselines
like DeepONet and FNO. GNS consistently achieves under 1% relative L2 errors
with only 30 training samples out of 1000 (3% of available data) across all
three PDE systems. It substantially reduces error accumulation over extended
temporal horizons: averaged across all cases, GNS reduces autoregressive error
by 82.48% relative to FNO AR and 99.86% relative to DON AR. We introduce a
PCA+KMeans trajectory selection strategy enhancing low-data performance.
Results indicate combining graph-based local inductive biases with conventional
time integrators yields accurate, physically consistent, and scalable surrogate
models for time-dependent PDEs.</p></br><a href="http://arxiv.org/pdf/2509.05766v1" target="_blank"><h2>Ensemble of Precision-Recall Curve (PRC) Classification Trees with
  Autoencoders</h2></a><strong><u>Authors:</u></strong>  Jiaju Miao, Wei Zhu</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection underpins critical applications from network security and
intrusion detection to fraud prevention, where recognizing aberrant patterns
rapidly is indispensable. Progress in this area is routinely impeded by two
obstacles: extreme class imbalance and the curse of dimensionality. To combat
the former, we previously introduced Precision-Recall Curve (PRC)
classification trees and their ensemble extension, the PRC Random Forest
(PRC-RF). Building on that foundation, we now propose a hybrid framework that
integrates PRC-RF with autoencoders, unsupervised machine learning methods that
learn compact latent representations, to confront both challenges
simultaneously. Extensive experiments across diverse benchmark datasets
demonstrate that the resulting Autoencoder-PRC-RF model achieves superior
accuracy, scalability, and interpretability relative to prior methods,
affirming its potential for high-stakes anomaly-detection tasks.</p></br><a href="http://arxiv.org/pdf/2509.06516v1" target="_blank"><h2>QualityFM: a Multimodal Physiological Signal Foundation Model with
  Self-Distillation for Signal Quality Challenges in Critically Ill Patients</h2></a><strong><u>Authors:</u></strong>  Zongheng Guo, Tao Chen, Manuela Ferrario</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, J.3</br><strong><u>Comments:</u></strong> 11 pages, 5 figures, 7 tables</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), transfer learning (abstract), transformer (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Photoplethysmogram (PPG) and electrocardiogram (ECG) are commonly recorded in
intesive care unit (ICU) and operating room (OR). However, the high incidence
of poor, incomplete, and inconsistent signal quality, can lead to false alarms
or diagnostic inaccuracies. The methods explored so far suffer from limited
generalizability, reliance on extensive labeled data, and poor cross-task
transferability. To overcome these challenges, we introduce QualityFM, a novel
multimodal foundation model for these physiological signals, designed to
acquire a general-purpose understanding of signal quality. Our model is
pre-trained on an large-scale dataset comprising over 21 million 30-second
waveforms and 179,757 hours of data. Our approach involves a dual-track
architecture that processes paired physiological signals of differing quality,
leveraging a self-distillation strategy where an encoder for high-quality
signals is used to guide the training of an encoder for low-quality signals. To
efficiently handle long sequential signals and capture essential local
quasi-periodic patterns, we integrate a windowed sparse attention mechanism
within our Transformer-based model. Furthermore, a composite loss function,
which combines direct distillation loss on encoder outputs with indirect
reconstruction loss based on power and phase spectra, ensures the preservation
of frequency-domain characteristics of the signals. We pre-train three models
with varying parameter counts (9.6 M to 319 M) and demonstrate their efficacy
and practical value through transfer learning on three distinct clinical tasks:
false alarm of ventricular tachycardia detection, the identification of atrial
fibrillation and the estimation of arterial blood pressure (ABP) from PPG and
ECG signals.</p></br><a href="http://arxiv.org/pdf/2509.06609v1" target="_blank"><h2>A Survey of Generalization of Graph Anomaly Detection: From Transfer
  Learning to Foundation Models</h2></a><strong><u>Authors:</u></strong>  Junjun Pan, Yu Zheng, Yue Tan, Yixin Liu</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Accepted by ICKG 2025. 8 pages, 5 figures</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), transfer learning (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Graph anomaly detection (GAD) has attracted increasing attention in recent
years for identifying malicious samples in a wide range of graph-based
applications, such as social media and e-commerce. However, most GAD methods
assume identical training and testing distributions and are tailored to
specific tasks, resulting in limited adaptability to real-world scenarios such
as shifting data distributions and scarce training samples in new applications.
To address the limitations, recent work has focused on improving the
generalization capability of GAD models through transfer learning that
leverages knowledge from related domains to enhance detection performance, or
developing "one-for-all" GAD foundation models that generalize across multiple
applications. Since a systematic understanding of generalization in GAD is
still lacking, in this paper, we provide a comprehensive review of
generalization in GAD. We first trace the evolution of generalization in GAD
and formalize the problem settings, which further leads to our systematic
taxonomy. Rooted in this fine-grained taxonomy, an up-to-date and comprehensive
review is conducted for the existing generalized GAD methods. Finally, we
identify current open challenges and suggest future directions to inspire
future research in this emerging field.</p></br><a href="http://arxiv.org/pdf/2509.06483v1" target="_blank"><h2>DyC-STG: Dynamic Causal Spatio-Temporal Graph Network for Real-time Data
  Credibility Analysis in IoT</h2></a><strong><u>Authors:</u></strong>  Guanjie Cheng, Boyi Li, Peihan Wu, Feiyi Chen, Xinkui Zhao, Mengying Zhu, Shuiguang Deng</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> causality (abstract)</br><p><strong><u>Abstract:</u></strong> The wide spreading of Internet of Things (IoT) sensors generates vast
spatio-temporal data streams, but ensuring data credibility is a critical yet
unsolved challenge for applications like smart homes. While spatio-temporal
graph (STG) models are a leading paradigm for such data, they often fall short
in dynamic, human-centric environments due to two fundamental limitations: (1)
their reliance on static graph topologies, which fail to capture physical,
event-driven dynamics, and (2) their tendency to confuse spurious correlations
with true causality, undermining robustness in human-centric environments. To
address these gaps, we propose the Dynamic Causal Spatio-Temporal Graph Network
(DyC-STG), a novel framework designed for real-time data credibility analysis
in IoT. Our framework features two synergistic contributions: an event-driven
dynamic graph module that adapts the graph topology in real-time to reflect
physical state changes, and a causal reasoning module to distill causally-aware
representations by strictly enforcing temporal precedence. To facilitate the
research in this domain we release two new real-world datasets. Comprehensive
experiments show that DyC-STG establishes a new state-of-the-art, outperforming
the strongest baselines by 1.4 percentage points and achieving an F1-Score of
up to 0.930.</p></br><a href="http://arxiv.org/pdf/2509.06213v1" target="_blank"><h2>Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments
  and Reinforcement Learning</h2></a><strong><u>Authors:</u></strong>  Christo Mathew, Wentian Wang, Lazaros Gallos, Paul Kantor, Vladimir Menkov, Hao Wang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract)</br><p><strong><u>Abstract:</u></strong> We investigate reinforcement learning in the Game Of Hidden Rules (GOHR)
environment, a complex puzzle in which an agent must infer and execute hidden
rules to clear a 6$\times$6 board by placing game pieces into buckets. We
explore two state representation strategies, namely Feature-Centric (FC) and
Object-Centric (OC), and employ a Transformer-based Advantage Actor-Critic
(A2C) algorithm for training. The agent has access only to partial observations
and must simultaneously infer the governing rule and learn the optimal policy
through experience. We evaluate our models across multiple rule-based and
trial-list-based experimental setups, analyzing transfer effects and the impact
of representation on learning efficiency.</p></br><a href="http://arxiv.org/pdf/2509.05449v1" target="_blank"><h2>Neural Breadcrumbs: Membership Inference Attacks on LLMs Through Hidden
  State and Attention Pattern Analysis</h2></a><strong><u>Authors:</u></strong>  Disha Makhija, Manoj Ghuhan Arivazhagan, Vinayshekhar Bannihatti Kumar, Rashmi Gangadharaiah</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Membership inference attacks (MIAs) reveal whether specific data was used to
train machine learning models, serving as important tools for privacy auditing
and compliance assessment. Recent studies have reported that MIAs perform only
marginally better than random guessing against large language models,
suggesting that modern pre-training approaches with massive datasets may be
free from privacy leakage risks. Our work offers a complementary perspective to
these findings by exploring how examining LLMs' internal representations,
rather than just their outputs, may provide additional insights into potential
membership inference signals. Our framework, \emph{memTrace}, follows what we
call \enquote{neural breadcrumbs} extracting informative signals from
transformer hidden states and attention patterns as they process candidate
sequences. By analyzing layer-wise representation dynamics, attention
distribution characteristics, and cross-layer transition patterns, we detect
potential memorization fingerprints that traditional loss-based approaches may
not capture. This approach yields strong membership detection across several
model families achieving average AUC scores of 0.85 on popular MIA benchmarks.
Our findings suggest that internal model behaviors can reveal aspects of
training data exposure even when output-based signals appear protected,
highlighting the need for further research into membership privacy and the
development of more robust privacy-preserving training techniques for large
language models.</p></br><a href="http://arxiv.org/pdf/2509.06550v1" target="_blank"><h2>Contrastive Self-Supervised Network Intrusion Detection using Augmented
  Negative Pairs</h2></a><strong><u>Authors:</u></strong>  Jack Wilkie, Hanan Hindy, Christos Tachtatzis, Robert Atkinson</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CR, cs.NI, I.2.6; K.6.5</br><strong><u>Comments:</u></strong> Published in: Proceedings of IEEE Conference on Cyber Security and Resilience (CSR), 2025. Official version:this https URLCode:this https URL</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Network intrusion detection remains a critical challenge in cybersecurity.
While supervised machine learning models achieve state-of-the-art performance,
their reliance on large labelled datasets makes them impractical for many
real-world applications. Anomaly detection methods, which train exclusively on
benign traffic to identify malicious activity, suffer from high false positive
rates, limiting their usability. Recently, self-supervised learning techniques
have demonstrated improved performance with lower false positive rates by
learning discriminative latent representations of benign traffic. In
particular, contrastive self-supervised models achieve this by minimizing the
distance between similar (positive) views of benign traffic while maximizing it
between dissimilar (negative) views. Existing approaches generate positive
views through data augmentation and treat other samples as negative. In
contrast, this work introduces Contrastive Learning using Augmented Negative
pairs (CLAN), a novel paradigm for network intrusion detection where augmented
samples are treated as negative views - representing potentially malicious
distributions - while other benign samples serve as positive views. This
approach enhances both classification accuracy and inference efficiency after
pretraining on benign traffic. Experimental evaluation on the Lycos2017 dataset
demonstrates that the proposed method surpasses existing self-supervised and
anomaly detection techniques in a binary classification task. Furthermore, when
fine-tuned on a limited labelled dataset, the proposed approach achieves
superior multi-class classification performance compared to existing
self-supervised models.</p></br><a href="http://arxiv.org/pdf/2509.05623v1" target="_blank"><h2>Segmentation and Tracking of Eruptive Solar Phenomena with Convolutional
  Neural Networks</h2></a><strong><u>Authors:</u></strong>  Oleg Stepanyuk, Kamen Kozarev</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.IM</br><strong><u>Comments:</u></strong> submitted to JGR: Machine Learning and Computation</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), convolutional (title, abstract), neural network (title)</br><p><strong><u>Abstract:</u></strong> Solar eruptive events are complex phenomena, which most often include coronal
mass ejections (CME), CME-driven compressive and shock waves, flares, and
filament eruptions. CMEs are large eruptions of magnetized plasma from the
Sun's outer atmosphere or corona, that propagate outward into the
interplanetary space. Over the last several decades a large amount of remote
solar eruption observational data has become available from ground-based and
space-borne instruments. This has recently required the development of software
approaches for automated characterisation of eruptive features. Most solar
feature detection and tracking algorithms currently in use have restricted
applicability and complicated processing chains, while complexity in
engineering machine learning (ML) training sets limit the use of data-driven
approaches for tracking or solar eruptive related phenomena. Recently, we
introduced Wavetrack - a general algorithmic method for smart characterization
and tracking of solar eruptive features. The method, based on a-trous wavelet
decomposition, intensity rankings and a set of filtering techniques, allows to
simplify and automate image processing and feature tracking. Previously, we
applied the method successfully to several types of remote solar observations.
Here we present the natural evolution of this approach. We discuss various
aspects of applying Machine Learning (ML) techniques towards segmentation of
high-dynamic range heliophysics observations. We trained Convolutional Neural
Network (CNN) image segmentation models using feature masks obtained from the
Wavetrack code. We present results from pre-trained models for segmentation of
solar eruptive features and demonstrate their performance on a set of CME
events based on SDO/AIA instrument data.</p></br><a href="http://arxiv.org/pdf/2509.06367v1" target="_blank"><h2>MRD-LiNet: A Novel Lightweight Hybrid CNN with Gradient-Guided
  Unlearning for Improved Drought Stress Identification</h2></a><strong><u>Authors:</u></strong>  Aswini Kumar Patra, Lingaraj Sahoo</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> 11 pages, 6 Figures, 3 Tables</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Drought stress is a major threat to global crop productivity, making its
early and precise detection essential for sustainable agricultural management.
Traditional approaches, though useful, are often time-consuming and
labor-intensive, which has motivated the adoption of deep learning methods. In
recent years, Convolutional Neural Network (CNN) and Vision Transformer
architectures have been widely explored for drought stress identification;
however, these models generally rely on a large number of trainable parameters,
restricting their use in resource-limited and real-time agricultural settings.
To address this challenge, we propose a novel lightweight hybrid CNN framework
inspired by ResNet, DenseNet, and MobileNet architectures. The framework
achieves a remarkable 15-fold reduction in trainable parameters compared to
conventional CNN and Vision Transformer models, while maintaining competitive
accuracy. In addition, we introduce a machine unlearning mechanism based on a
gradient norm-based influence function, which enables targeted removal of
specific training data influence, thereby improving model adaptability. The
method was evaluated on an aerial image dataset of potato fields with
expert-annotated healthy and drought-stressed regions. Experimental results
show that our framework achieves high accuracy while substantially lowering
computational costs. These findings highlight its potential as a practical,
scalable, and adaptive solution for drought stress monitoring in precision
agriculture, particularly under resource-constrained conditions.</p></br><a href="http://arxiv.org/pdf/2509.06788v1" target="_blank"><h2>An Interpretable AI Framework to Disentangle Self-Interacting and Cold
  Dark Matter in Galaxy Clusters: The CKAN Approach</h2></a><strong><u>Authors:</u></strong>  Zhenyang Huang, Haihao Shi, Zhiyong Liu, Na Wang</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.CO</br><strong><u>Comments:</u></strong> 15 pages, 8 figures; accepted for publication in The Astronomical Journal</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Convolutional neural networks have shown their ability to differentiate
between self-interacting dark matter (SIDM) and cold dark matter (CDM) on
galaxy cluster scales. However, their large parameter counts and ''black-box''
nature make it difficult to assess whether their decisions adhere to physical
principles. To address this issue, we have built a Convolutional
Kolmogorov-Arnold Network (CKAN) that reduces parameter count and enhances
interpretability, and propose a novel analytical framework to understand the
network's decision-making process. With this framework, we leverage our network
to qualitatively assess the offset between the dark matter distribution center
and the galaxy cluster center, as well as the size of heating regions in
different models. These findings are consistent with current theoretical
predictions and show the reliability and interpretability of our network. By
combining network interpretability with unseen test results, we also estimate
that for SIDM in galaxy clusters, the minimum cross-section
$(\sigma/m)_{\mathrm{th}}$ required to reliably identify its collisional nature
falls between $0.1\,\mathrm{cm}^2/\mathrm{g}$ and
$0.3\,\mathrm{cm}^2/\mathrm{g}$. Moreover, CKAN maintains robust performance
under simulated JWST and Euclid noise, highlighting its promise for application
to forthcoming observational surveys.</p></br><a href="http://arxiv.org/pdf/2509.05936v1" target="_blank"><h2>ALPHA: LLM-Enabled Active Learning for Human-Free Network Anomaly
  Detection</h2></a><strong><u>Authors:</u></strong>  Xuanhao Luo, Shivesh Madan Nath Jha, Akruti Sinha, Zhizhen Li, Yuchen Liu</br><strong><u>Categories:</u></strong> cs.NI, cs.LG</br><strong><u>Comments:</u></strong> Accepted at 44th IEEE International Performance Computing and Communications Conference (IPCCC 2025)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> Network log data analysis plays a critical role in detecting security threats
and operational anomalies. Traditional log analysis methods for anomaly
detection and root cause analysis rely heavily on expert knowledge or fully
supervised learning models, both of which require extensive labeled data and
significant human effort. To address these challenges, we propose ALPHA, the
first Active Learning Pipeline for Human-free log Analysis. ALPHA integrates
semantic embedding, clustering-based representative sampling, and large
language model (LLM)-assisted few-shot annotation to automate the anomaly
detection process. The LLM annotated labels are propagated across clusters,
enabling large-scale training of an anomaly detector with minimal supervision.
To enhance the annotation accuracy, we propose a two-step few-shot refinement
strategy that adaptively selects informative prompts based on the LLM's
observed error patterns. Extensive experiments on real-world log datasets
demonstrate that ALPHA achieves detection accuracy comparable to fully
supervised methods while mitigating human efforts in the loop. ALPHA also
supports interpretable analysis through LLM-driven root cause explanations in
the post-detection stage. These capabilities make ALPHA a scalable and
cost-efficient solution for truly automated log-based anomaly detection.</p></br><a href="http://arxiv.org/pdf/2509.05405v1" target="_blank"><h2>The Open mulTiwavelength Transient Event Repository (OTTER):
  Infrastructure Release and Tidal Disruption Event Catalog</h2></a><strong><u>Authors:</u></strong>  Noah Franz, Kate D Alexander, Sebastian Gomez, Collin T Christy, Tanmoy Laskar, Sjoert van Velzen, Nicholas Earl, Suvi Gezari, Mitchell Karmen, Raffaella Margutti, Jeniveve Pearson, V. Ashley Villar, Ann I Zabludoff</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> Submitted to ApJ. The OTTER web interface is available atthis https URLand the API documentation (including example python notebooks demonstrating usage) is available atthis https URL. Comments are welcome! Please submit any comments and feedback on GitHub atthis https URL</br><strong><u>Matching Keywords:</u></strong> VAE (abstract)</br><p><strong><u>Abstract:</u></strong> Multiwavelength analyses of astrophysical transients are essential for
understanding the physics of these events. To make such analyses more efficient
and effective, we present the Open mulTiwavelength Transient Event Repository
(OTTER), a publicly available catalog of published transient event metadata and
photometry. Unlike previous efforts, our data schema is optimized for the
storage of multiwavelength photometric datasets spanning the entire
electromagnetic spectrum. Open source software, including an application
programming interface (API) and web application, are available for viewing,
accessing, and analyzing the dataset. For the initial release of OTTER, we
present the largest ever photometric archive of tidal disruption events (TDEs),
including $\gtrsim 80,000$ observations of 232 TDEs spanning from radio to
X-ray wavelengths. We demonstrate the power of this infrastructure through four
example analyses of the TDE population. We plan to maintain this dataset as
more TDEs are discovered in the future and encourage other users to contribute
by uploading newly published data via our web application. The infrastructure
was built with the goal of archiving additional transient data (supernovae,
gamma-ray bursts, fast blue optical transients, fast radio bursts, etc.) in the
future. The web application is available at https://otter.idies.jhu.edu and the
API documentation is available at https://astro-otter.readthedocs.io.</p></br><a href="http://arxiv.org/pdf/2509.05663v1" target="_blank"><h2>DQS: A Low-Budget Query Strategy for Enhancing Unsupervised Data-driven
  Anomaly Detection Approaches</h2></a><strong><u>Authors:</u></strong>  Lucas Correia, Jan-Christoph Goos, Thomas Bäck, Anna V. Kononova</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Submitted to the Reliability Engineering & System Safety journal</br><strong><u>Matching Keywords:</u></strong> data-driven (title), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Truly unsupervised approaches for time series anomaly detection are rare in
the literature. Those that exist suffer from a poorly set threshold, which
hampers detection performance, while others, despite claiming to be
unsupervised, need to be calibrated using a labelled data subset, which is
often not available in the real world. This work integrates active learning
with an existing unsupervised anomaly detection method by selectively querying
the labels of multivariate time series, which are then used to refine the
threshold selection process. To achieve this, we introduce a novel query
strategy called the dissimilarity-based query strategy (DQS). DQS aims to
maximise the diversity of queried samples by evaluating the similarity between
anomaly scores using dynamic time warping. We assess the detection performance
of DQS in comparison to other query strategies and explore the impact of
mislabelling, a topic that is underexplored in the literature. Our findings
indicate that DQS performs best in small-budget scenarios, though the others
appear to be more robust when faced with mislabelling. Therefore, in the real
world, the choice of query strategy depends on the expertise of the oracle and
the number of samples they are willing to label. Regardless, all query
strategies outperform the unsupervised threshold even in the presence of
mislabelling. Thus, whenever it is feasible to query an oracle, employing an
active learning-based threshold is recommended.</p></br><a href="http://arxiv.org/pdf/2509.06120v1" target="_blank"><h2>If generative AI is the answer, what is the question?</h2></a><strong><u>Authors:</u></strong>  Ambuj Tewari</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> To appear as a book chapter in a Springer book titled "Statistical Foundations and Applications of Artificial Intelligence, Machine Learning and Deep Learning" and edited by S. Ejaz Ahmed, Pierre Alquier, Yi Li, Shuangge Ma</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract)</br><p><strong><u>Abstract:</u></strong> Beginning with text and images, generative AI has expanded to audio, video,
computer code, and molecules. Yet, if generative AI is the answer, what is the
question? We explore the foundations of generation as a distinct machine
learning task with connections to prediction, compression, and decision-making.
We survey five major generative model families: autoregressive models,
variational autoencoders, normalizing flows, generative adversarial networks,
and diffusion models. We then introduce a probabilistic framework that
emphasizes the distinction between density estimation and generation. We review
a game-theoretic framework with a two-player adversary-learner setup to study
generation. We discuss post-training modifications that prepare generative
models for deployment. We end by highlighting some important topics in socially
responsible generation such as privacy, detection of AI-generated content, and
copyright and IP. We adopt a task-first framing of generation, focusing on what
generation is as a machine learning problem, rather than only on how models
implement it.</p></br><a href="http://arxiv.org/pdf/2509.06713v1" target="_blank"><h2>MRI-Based Brain Tumor Detection through an Explainable EfficientNetV2
  and MLP-Mixer-Attention Architecture</h2></a><strong><u>Authors:</u></strong>  Mustafa Yurdakul, Şakir Taşdemir</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Brain tumors are serious health problems that require early diagnosis due to
their high mortality rates. Diagnosing tumors by examining Magnetic Resonance
Imaging (MRI) images is a process that requires expertise and is prone to
error. Therefore, the need for automated diagnosis systems is increasing day by
day. In this context, a robust and explainable Deep Learning (DL) model for the
classification of brain tumors is proposed. In this study, a publicly available
Figshare dataset containing 3,064 T1-weighted contrast-enhanced brain MRI
images of three tumor types was used. First, the classification performance of
nine well-known CNN architectures was evaluated to determine the most effective
backbone. Among these, EfficientNetV2 demonstrated the best performance and was
selected as the backbone for further development. Subsequently, an
attention-based MLP-Mixer architecture was integrated into EfficientNetV2 to
enhance its classification capability. The performance of the final model was
comprehensively compared with basic CNNs and the methods in the literature.
Additionally, Grad-CAM visualization was used to interpret and validate the
decision-making process of the proposed model. The proposed model's performance
was evaluated using the five-fold cross-validation method. The proposed model
demonstrated superior performance with 99.50% accuracy, 99.47% precision,
99.52% recall and 99.49% F1 score. The results obtained show that the model
outperforms the studies in the literature. Moreover, Grad-CAM visualizations
demonstrate that the model effectively focuses on relevant regions of MRI
images, thus improving interpretability and clinical reliability. A robust deep
learning model for clinical decision support systems has been obtained by
combining EfficientNetV2 and attention-based MLP-Mixer, providing high accuracy
and interpretability in brain tumor classification.</p></br><a href="http://arxiv.org/pdf/2509.05563v1" target="_blank"><h2>Interpretable dimension reduction for compositional data</h2></a><strong><u>Authors:</u></strong>  Junyoung Park, Cheolwoo Park, Jeongyoun Ahn</br><strong><u>Categories:</u></strong> stat.ME, math.ST, stat.AP, stat.ML, stat.TH</br><strong><u>Comments:</u></strong> 62 pages, 5 figures</br><strong><u>Matching Keywords:</u></strong> dimension reduction (title, abstract)</br><p><strong><u>Abstract:</u></strong> High-dimensional compositional data, such as those from human microbiome
studies, pose unique statistical challenges due to the simplex constraint and
excess zeros. While dimension reduction is indispensable for analyzing such
data, conventional approaches often rely on log-ratio transformations that
compromise interpretability and distort the data through ad hoc zero
replacements. We introduce a novel framework for interpretable dimension
reduction of compositional data that avoids extra transformations and zero
imputations. Our approach generalizes the concept of amalgamation by softening
its operation, mapping high-dimensional compositions directly to a
lower-dimensional simplex, which can be visualized in ternary plots. The
framework further provides joint visualization of the reduction matrix,
enabling intuitive, at-a-glance interpretation. To achieve optimal reduction
within our framework, we incorporate sufficient dimension reduction, which
defines a new identifiable objective: the central compositional subspace. For
estimation, we propose a compositional kernel dimension reduction (CKDR)
method. The estimator is provably consistent, exhibits sparsity that reveals
underlying amalgamation structures, and comes with an intrinsic predictive
model for downstream analyses. Applications to real microbiome datasets
demonstrate that our approach provides a powerful graphical exploration tool
for uncovering meaningful biological patterns, opening a new pathway for
analyzing high-dimensional compositional data.</p></br><a href="http://arxiv.org/pdf/2509.06269v1" target="_blank"><h2>REMI: A Novel Causal Schema Memory Architecture for Personalized
  Lifestyle Recommendation Agents</h2></a><strong><u>Authors:</u></strong>  Vishal Raman, Vijai Aravindh R, Abhijith Ragav</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> 8 pages, 2 figures, Accepted at the OARS Workshop, KDD 2025, Paper link:this https URL</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Personalized AI assistants often struggle to incorporate complex personal
data and causal knowledge, leading to generic advice that lacks explanatory
power. We propose REMI, a Causal Schema Memory architecture for a multimodal
lifestyle agent that integrates a personal causal knowledge graph, a causal
reasoning engine, and a schema based planning module. The idea is to deliver
explainable, personalized recommendations in domains like fashion, personal
wellness, and lifestyle planning. Our architecture uses a personal causal graph
of the user's life events and habits, performs goal directed causal traversals
enriched with external knowledge and hypothetical reasoning, and retrieves
adaptable plan schemas to generate tailored action plans. A Large Language
Model orchestrates these components, producing answers with transparent causal
explanations. We outline the CSM system design and introduce new evaluation
metrics for personalization and explainability, including Personalization
Salience Score and Causal Reasoning Accuracy, to rigorously assess its
performance. Results indicate that CSM based agents can provide more context
aware, user aligned recommendations compared to baseline LLM agents. This work
demonstrates a novel approach to memory augmented, causal reasoning in
personalized agents, advancing the development of transparent and trustworthy
AI lifestyle assistants.</p></br><a href="http://arxiv.org/pdf/2509.05685v1" target="_blank"><h2>MSRFormer: Road Network Representation Learning using Multi-scale
  Feature Fusion of Heterogeneous Spatial Interactions</h2></a><strong><u>Authors:</u></strong>  Jian Yang, Jiahui Wu, Li Fang, Hongchao Fan, Bianying Zhang, Huijie Zhao, Guangyi Yang, Rui Xin, Xiong You</br><strong><u>Categories:</u></strong> cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Transforming road network data into vector representations using deep
learning has proven effective for road network analysis. However, urban road
networks' heterogeneous and hierarchical nature poses challenges for accurate
representation learning. Graph neural networks, which aggregate features from
neighboring nodes, often struggle due to their homogeneity assumption and focus
on a single structural scale. To address these issues, this paper presents
MSRFormer, a novel road network representation learning framework that
integrates multi-scale spatial interactions by addressing their flow
heterogeneity and long-distance dependencies. It uses spatial flow convolution
to extract small-scale features from large trajectory datasets, and identifies
scale-dependent spatial interaction regions to capture the spatial structure of
road networks and flow heterogeneity. By employing a graph transformer,
MSRFormer effectively captures complex spatial dependencies across multiple
scales. The spatial interaction features are fused using residual connections,
which are fed to a contrastive learning algorithm to derive the final road
network representation. Validation on two real-world datasets demonstrates that
MSRFormer outperforms baseline methods in two road network analysis tasks. The
performance gains of MSRFormer suggest the traffic-related task benefits more
from incorporating trajectory data, also resulting in greater improvements in
complex road network structures with up to 16% improvements compared to the
most competitive baseline method. This research provides a practical framework
for developing task-agnostic road network representation models and highlights
distinct association patterns of the interplay between scale effects and flow
heterogeneity of spatial interactions.</p></br><a href="http://arxiv.org/pdf/2509.05801v1" target="_blank"><h2>time2time: Causal Intervention in Hidden States to Simulate Rare Events
  in Time Series Foundation Models</h2></a><strong><u>Authors:</u></strong>  Debdeep Sanyal, Aaryan Nagpal, Dhruv Kumar, Murari Mandal, Saurabh Deshpande</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract)</br><p><strong><u>Abstract:</u></strong> While transformer-based foundation models excel at forecasting routine
patterns, two questions remain: do they internalize semantic concepts such as
market regimes, or merely fit curves? And can their internal representations be
leveraged to simulate rare, high-stakes events such as market crashes? To
investigate this, we introduce activation transplantation, a causal
intervention that manipulates hidden states by imposing the statistical moments
of one event (e.g., a historical crash) onto another (e.g., a calm period)
during the forward pass. This procedure deterministically steers forecasts:
injecting crash semantics induces downturn predictions, while injecting calm
semantics suppresses crashes and restores stability. Beyond binary control, we
find that models encode a graded notion of event severity, with the latent
vector norm directly correlating with the magnitude of systemic shocks.
Validated across two architecturally distinct TSFMs, Toto (decoder only) and
Chronos (encoder-decoder), our results demonstrate that steerable, semantically
grounded representations are a robust property of large time series
transformers. Our findings provide evidence for a latent concept space that
governs model predictions, shifting interpretability from post-hoc attribution
to direct causal intervention, and enabling semantic "what-if" analysis for
strategic stress-testing.</p></br><a href="http://arxiv.org/pdf/2509.06289v1" target="_blank"><h2>A Spatio-Temporal Graph Neural Networks Approach for Predicting Silent
  Data Corruption inducing Circuit-Level Faults</h2></a><strong><u>Authors:</u></strong>  Shaoqi Wei, Senling Wang, Hiroshi Kai, Yoshinobu Higami, Ruijun Ma, Tianming Ni, Xiaoqing Wen, Hiroshi Takahashi</br><strong><u>Categories:</u></strong> cs.LG, cs.AR, cs.ET, B.7.3</br><strong><u>Comments:</u></strong> 21 pages, 9 figures, plan to submit to ACM TODAES</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title)</br><p><strong><u>Abstract:</u></strong> Silent Data Errors (SDEs) from time-zero defects and aging degrade
safety-critical systems. Functional testing detects SDE-related faults but is
expensive to simulate. We present a unified spatio-temporal graph convolutional
network (ST-GCN) for fast, accurate prediction of long-cycle fault impact
probabilities (FIPs) in large sequential circuits, supporting quantitative risk
assessment. Gate-level netlists are modeled as spatio-temporal graphs to
capture topology and signal timing; dedicated spatial and temporal encoders
predict multi-cycle FIPs efficiently. On ISCAS-89 benchmarks, the method
reduces simulation time by more than 10x while maintaining high accuracy (mean
absolute error 0.024 for 5-cycle predictions). The framework accepts features
from testability metrics or fault simulation, allowing efficiency-accuracy
trade-offs. A test-point selection study shows that choosing observation points
by predicted FIPs improves detection of long-cycle, hard-to-detect faults. The
approach scales to SoC-level test strategy optimization and fits downstream
electronic design automation flows.</p></br><a href="http://arxiv.org/pdf/2509.06665v1" target="_blank"><h2>TrajAware: Graph Cross-Attention and Trajectory-Aware for Generalisable
  VANETs under Partial Observations</h2></a><strong><u>Authors:</u></strong>  Xiaolu Fu, Ziyuan Bao, Eiman Kanjo</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 10 pages, 6 figures, 3 tables</br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Vehicular ad hoc networks (VANETs) are a crucial component of intelligent
transportation systems; however, routing remains challenging due to dynamic
topologies, incomplete observations, and the limited resources of edge devices.
Existing reinforcement learning (RL) approaches often assume fixed graph
structures and require retraining when network conditions change, making them
unsuitable for deployment on constrained hardware. We present TrajAware, an
RL-based framework designed for edge AI deployment in VANETs. TrajAware
integrates three components: (i) action space pruning, which reduces redundant
neighbour options while preserving two-hop reachability, alleviating the curse
of dimensionality; (ii) graph cross-attention, which maps pruned neighbours to
the global graph context, producing features that generalise across diverse
network sizes; and (iii) trajectory-aware prediction, which uses historical
routes and junction information to estimate real-time positions under partial
observations. We evaluate TrajAware in the open-source SUMO simulator using
real-world city maps with a leave-one-city-out setup. Results show that
TrajAware achieves near-shortest paths and high delivery ratios while
maintaining efficiency suitable for constrained edge devices, outperforming
state-of-the-art baselines in both full and partial observation scenarios.</p></br><a href="http://arxiv.org/pdf/2509.05886v1" target="_blank"><h2>SPINN: An Optimal Self-Supervised Physics-Informed Neural Network
  Framework</h2></a><strong><u>Authors:</u></strong>  Reza Pirayeshshirazinezhad</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transfer learning (abstract)</br><p><strong><u>Abstract:</u></strong> A surrogate model is developed to predict the convective heat transfer
coefficient of liquid sodium (Na) flow within rectangular miniature heat sinks.
Initially, kernel-based machine learning techniques and shallow neural network
are applied to a dataset with 87 Nusselt numbers for liquid sodium in
rectangular miniature heat sinks. Subsequently, a self-supervised
physics-informed neural network and transfer learning approach are used to
increase the estimation performance. In the self-supervised physics-informed
neural network, an additional layer determines the weight the of physics in the
loss function to balance data and physics based on their uncertainty for a
better estimation. For transfer learning, a shallow neural network trained on
water is adapted for use with Na. Validation results show that the
self-supervised physics-informed neural network successfully estimate the heat
transfer rates of Na with an error margin of approximately +8%. Using only
physics for regression, the error remains between 5% to 10%. Other machine
learning methods specify the prediction mostly within +8%. High-fidelity
modeling of turbulent forced convection of liquid metals using computational
fluid dynamics (CFD) is both time-consuming and computationally expensive.
Therefore, machine learning based models offer a powerful alternative tool for
the design and optimization of liquid-metal-cooled miniature heat sinks.</p></br><a href="http://arxiv.org/pdf/2509.06505v1" target="_blank"><h2>On optimal solutions of classical and sliced Wasserstein GANs with
  non-Gaussian data</h2></a><strong><u>Authors:</u></strong>  Yu-Jui Huang, Hsin-Hua Shen, Yu-Chih Huang, Wan-Yi Lin, Shih-Chun Lin</br><strong><u>Categories:</u></strong> cs.LG, cs.IT, math.IT, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The generative adversarial network (GAN) aims to approximate an unknown
distribution via a parameterized neural network (NN). While GANs have been
widely applied in reinforcement and semisupervised learning as well as computer
vision tasks, selecting their parameters often needs an exhaustive search and
only a few selection methods can be proved to be theoretically optimal. One of
the most promising GAN variants is the Wasserstein GAN (WGAN). Prior work on
optimal parameters for WGAN is limited to the linear-quadratic-Gaussian (LQG)
setting, where the NN is linear and the data is Gaussian. In this paper, we
focus on the characterization of optimal WGAN parameters beyond the LQG
setting. We derive closed-form optimal parameters for one-dimensional WGANs
when the NN has non-linear activation functions and the data is non-Gaussian.
To extend this to high-dimensional WGANs, we adopt the sliced Wasserstein
framework and replace the constraint on marginal distributions of the randomly
projected data by a constraint on the joint distribution of the original
(unprojected) data. We show that the linear generator can be asymptotically
optimal for sliced WGAN with non-Gaussian data. Empirical studies show that our
closed-form WGAN parameters have good convergence behavior with data under both
Gaussian and Laplace distributions. Also, compared to the r principal component
analysis (r-PCA) solution, our proposed solution for sliced WGAN can achieve
the same performance while requiring less computational resources.</p></br></body>