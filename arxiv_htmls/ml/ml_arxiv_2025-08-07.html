<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 05 Aug 2025 to 07 Aug 2025</em></font><a href="http://arxiv.org/pdf/2508.04427v1" target="_blank"><h2>Decoding the Multimodal Maze: A Systematic Review on the Adoption of
  Explainability in Multimodal Attention-based Models</h2></a><strong><u>Authors:</u></strong>  Md Raisul Kibria, Sébastien Lafond, Janan Arslan</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (title, abstract), explainable (abstract), multimodal (title, abstract), attention (title, abstract), literature review (abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal learning has witnessed remarkable advancements in recent years,
particularly with the integration of attention-based models, leading to
significant performance gains across a variety of tasks. Parallel to this
progress, the demand for explainable artificial intelligence (XAI) has spurred
a growing body of research aimed at interpreting the complex decision-making
processes of these models. This systematic literature review analyzes research
published between January 2020 and early 2024 that focuses on the
explainability of multimodal models. Framed within the broader goals of XAI, we
examine the literature across multiple dimensions, including model
architecture, modalities involved, explanation algorithms and evaluation
methodologies. Our analysis reveals that the majority of studies are
concentrated on vision-language and language-only models, with attention-based
techniques being the most commonly employed for explanation. However, these
methods often fall short in capturing the full spectrum of interactions between
modalities, a challenge further compounded by the architectural heterogeneity
across domains. Importantly, we find that evaluation methods for XAI in
multimodal settings are largely non-systematic, lacking consistency,
robustness, and consideration for modality-specific cognitive and contextual
factors. Based on these findings, we provide a comprehensive set of
recommendations aimed at promoting rigorous, transparent, and standardized
evaluation and reporting practices in multimodal XAI research. Our goal is to
support future research in more interpretable, accountable, and responsible
mulitmodal AI systems, with explainability at their core.</p></br><a href="http://arxiv.org/pdf/2508.03921v1" target="_blank"><h2>Active Learning and Transfer Learning for Anomaly Detection in
  Time-Series Data</h2></a><strong><u>Authors:</u></strong>  John D. Kelleher, Matthew Nicholson, Rahul Agrahari, Clare Conran</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper examines the effectiveness of combining active learning and
transfer learning for anomaly detection in cross-domain time-series data. Our
results indicate that there is an interaction between clustering and active
learning and in general the best performance is achieved using a single cluster
(in other words when clustering is not applied). Also, we find that adding new
samples to the training set using active learning does improve model
performance but that in general, the rate of improvement is slower than the
results reported in the literature suggest. We attribute this difference to an
improved experimental design where distinct data samples are used for the
sampling and testing pools. Finally, we assess the ceiling performance of
transfer learning in combination with active learning across several datasets
and find that performance does initially improve but eventually begins to tail
off as more target points are selected for inclusion in training. This tail-off
in performance may indicate that the active learning process is doing a good
job of sequencing data points for selection, pushing the less useful points
towards the end of the selection process and that this tail-off occurs when
these less useful points are eventually added. Taken together our results
indicate that active learning is effective but that the improvement in model
performance follows a linear flat function concerning the number of points
selected and labelled.</p></br><a href="http://arxiv.org/pdf/2508.03913v1" target="_blank"><h2>Fast and Accurate Explanations of Distance-Based Classifiers by
  Uncovering Latent Explanatory Structures</h2></a><strong><u>Authors:</u></strong>  Florian Bley, Jacob Kauffmann, Simon León Krug, Klaus-Robert Müller, Grégoire Montavon</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Distance-based classifiers, such as k-nearest neighbors and support vector
machines, continue to be a workhorse of machine learning, widely used in
science and industry. In practice, to derive insights from these models, it is
also important to ensure that their predictions are explainable. While the
field of Explainable AI has supplied methods that are in principle applicable
to any model, it has also emphasized the usefulness of latent structures (e.g.
the sequence of layers in a neural network) to produce explanations. In this
paper, we contribute by uncovering a hidden neural network structure in
distance-based classifiers (consisting of linear detection units combined with
nonlinear pooling layers) upon which Explainable AI techniques such as
layer-wise relevance propagation (LRP) become applicable. Through quantitative
evaluations, we demonstrate the advantage of our novel explanation approach
over several baselines. We also show the overall usefulness of explaining
distance-based models through two practical use cases.</p></br><a href="http://arxiv.org/pdf/2508.04630v1" target="_blank"><h2>CaPulse: Detecting Anomalies by Tuning in to the Causal Rhythms of Time
  Series</h2></a><strong><u>Authors:</u></strong>  Yutong Xia, Yingying Zhang, Yuxuan Liang, Lunting Fan, Qingsong Wen, Roger Zimmermann</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), attention (abstract), causality (abstract)</br><p><strong><u>Abstract:</u></strong> Time series anomaly detection has garnered considerable attention across
diverse domains. While existing methods often fail to capture the underlying
mechanisms behind anomaly generation in time series data. In addition, time
series anomaly detection often faces several data-related inherent challenges,
i.e., label scarcity, data imbalance, and complex multi-periodicity. In this
paper, we leverage causal tools and introduce a new causality-based framework,
CaPulse, which tunes in to the underlying causal pulse of time series data to
effectively detect anomalies. Concretely, we begin by building a structural
causal model to decipher the generation processes behind anomalies. To tackle
the challenges posed by the data, we propose Periodical Normalizing Flows with
a novel mask mechanism and carefully designed periodical learners, creating a
periodicity-aware, density-based anomaly detection approach. Extensive
experiments on seven real-world datasets demonstrate that CaPulse consistently
outperforms existing methods, achieving AUROC improvements of 3% to 17%, with
enhanced interpretability.</p></br><a href="http://arxiv.org/pdf/2508.04476v1" target="_blank"><h2>Metric Learning in an RKHS</h2></a><strong><u>Authors:</u></strong>  Gokcan Tatli, Yi Chen, Blake Mason, Robert Nowak, Ramya Korlakai Vinayak</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Appeared in the 41st Conference on Uncertainty in Artificial Intelligence (UAI 2025)</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Metric learning from a set of triplet comparisons in the form of "Do you
think item h is more similar to item i or item j?", indicating similarity and
differences between items, plays a key role in various applications including
image retrieval, recommendation systems, and cognitive psychology. The goal is
to learn a metric in the RKHS that reflects the comparisons. Nonlinear metric
learning using kernel methods and neural networks have shown great empirical
promise. While previous works have addressed certain aspects of this problem,
there is little or no theoretical understanding of such methods. The exception
is the special (linear) case in which the RKHS is the standard Euclidean space
$\mathbb{R}^d$; there is a comprehensive theory for metric learning in
$\mathbb{R}^d$. This paper develops a general RKHS framework for metric
learning and provides novel generalization guarantees and sample complexity
bounds. We validate our findings through a set of simulations and experiments
on real datasets. Our code is publicly available at
https://github.com/RamyaLab/metric-learning-RKHS.</p></br><a href="http://arxiv.org/pdf/2508.03940v1" target="_blank"><h2>FairPOT: Balancing AUC Performance and Fairness with Proportional
  Optimal Transport</h2></a><strong><u>Authors:</u></strong>  Pengxi Liu, Yi Shen, Matthew M. Engelhard, Benjamin A. Goldstein, Michael J. Pencina, Nicoleta J. Economou-Zavlanos, Michael M. Zavlanos</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CY, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> attention (abstract)</br><p><strong><u>Abstract:</u></strong> Fairness metrics utilizing the area under the receiver operator
characteristic curve (AUC) have gained increasing attention in high-stakes
domains such as healthcare, finance, and criminal justice. In these domains,
fairness is often evaluated over risk scores rather than binary outcomes, and a
common challenge is that enforcing strict fairness can significantly degrade
AUC performance. To address this challenge, we propose Fair Proportional
Optimal Transport (FairPOT), a novel, model-agnostic post-processing framework
that strategically aligns risk score distributions across different groups
using optimal transport, but does so selectively by transforming a controllable
proportion, i.e., the top-lambda quantile, of scores within the disadvantaged
group. By varying lambda, our method allows for a tunable trade-off between
reducing AUC disparities and maintaining overall AUC performance. Furthermore,
we extend FairPOT to the partial AUC setting, enabling fairness interventions
to concentrate on the highest-risk regions. Extensive experiments on synthetic,
public, and clinical datasets show that FairPOT consistently outperforms
existing post-processing techniques in both global and partial AUC scenarios,
often achieving improved fairness with slight AUC degradation or even positive
gains in utility. The computational efficiency and practical adaptability of
FairPOT make it a promising solution for real-world deployment.</p></br><a href="http://arxiv.org/pdf/2508.03827v1" target="_blank"><h2>Scalable Neural Network-based Blackbox Optimization</h2></a><strong><u>Authors:</u></strong>  Pavankumar Koratikere, Leifur Leifsson</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> This preprint has been submitted to Structural and Multidisciplinary Optimization for peer review. An open-source implementation of SNBO is available at:this https URL</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Bayesian Optimization (BO) is a widely used approach for blackbox
optimization that leverages a Gaussian process (GP) model and an acquisition
function to guide future sampling. While effective in low-dimensional settings,
BO faces scalability challenges in high-dimensional spaces and with large
number of function evaluations due to the computational complexity of GP
models. In contrast, neural networks (NNs) offer better scalability and can
model complex functions, which led to the development of NN-based BO
approaches. However, these methods typically rely on estimating model
uncertainty in NN prediction -- a process that is often computationally
intensive and complex, particularly in high dimensions. To address these
limitations, a novel method, called scalable neural network-based blackbox
optimization (SNBO), is proposed that does not rely on model uncertainty
estimation. Specifically, SNBO adds new samples using separate criteria for
exploration and exploitation, while adaptively controlling the sampling region
to ensure efficient optimization. SNBO is evaluated on a range of optimization
problems spanning from 10 to 102 dimensions and compared against four
state-of-the-art baseline algorithms. Across the majority of test problems,
SNBO attains function values better than the best-performing baseline
algorithm, while requiring 40-60% fewer function evaluations and reducing the
runtime by at least an order of magnitude.</p></br><a href="http://arxiv.org/pdf/2508.03839v1" target="_blank"><h2>VAE-DNN: Energy-Efficient Trainable-by-Parts Surrogate Model For
  Parametric Partial Differential Equations</h2></a><strong><u>Authors:</u></strong>  Yifei Zong, Alexandre M. Tartakovsky</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CE, 68</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), latent space (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> We propose a trainable-by-parts surrogate model for solving forward and
inverse parameterized nonlinear partial differential equations. Like several
other surrogate and operator learning models, the proposed approach employs an
encoder to reduce the high-dimensional input $y(\bm{x})$ to a lower-dimensional
latent space, $\bm\mu_{\bm\phi_y}$. Then, a fully connected neural network is
used to map $\bm\mu_{\bm\phi_y}$ to the latent space, $\bm\mu_{\bm\phi_h}$, of
the PDE solution $h(\bm{x},t)$. Finally, a decoder is utilized to reconstruct
$h(\bm{x},t)$. The innovative aspect of our model is its ability to train its
three components independently. This approach leads to a substantial decrease
in both the time and energy required for training when compared to leading
operator learning models such as FNO and DeepONet. The separable training is
achieved by training the encoder as part of the variational autoencoder (VAE)
for $y(\bm{x})$ and the decoder as part of the $h(\bm{x},t)$ VAE. We refer to
this model as the VAE-DNN model. VAE-DNN is compared to the FNO and DeepONet
models for obtaining forward and inverse solutions to the nonlinear diffusion
equation governing groundwater flow in an unconfined aquifer. Our findings
indicate that VAE-DNN not only demonstrates greater efficiency but also
delivers superior accuracy in both forward and inverse solutions compared to
the FNO and DeepONet models.</p></br><a href="http://arxiv.org/pdf/2508.04258v1" target="_blank"><h2>Deep Neural Network-Driven Adaptive Filtering</h2></a><strong><u>Authors:</u></strong>  Qizhen Wang, Gang Wang, Ying-Chang Liang</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper proposes a deep neural network (DNN)-driven framework to address
the longstanding generalization challenge in adaptive filtering (AF). In
contrast to traditional AF frameworks that emphasize explicit cost function
design, the proposed framework shifts the paradigm toward direct gradient
acquisition. The DNN, functioning as a universal nonlinear operator, is
structurally embedded into the core architecture of the AF system, establishing
a direct mapping between filtering residuals and learning gradients. The
maximum likelihood is adopted as the implicit cost function, rendering the
derived algorithm inherently data-driven and thus endowed with exemplary
generalization capability, which is validated by extensive numerical
experiments across a spectrum of non-Gaussian scenarios. Corresponding mean
value and mean square stability analyses are also conducted in detail.</p></br></body>