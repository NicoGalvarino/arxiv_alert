<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'><style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 10 Jun 2025 to 12 Jun 2025</em></font><a href="http://arxiv.org/pdf/2506.08932v1" target="_blank"><h2>Measurement of the Dispersion$\unicode{x2013}$Galaxy Cross-Power
  Spectrum with the Second CHIME/FRB Catalog</h2></a><strong><u>Authors:</u></strong>  Haochen Wang, Kiyoshi Masui, Shion Andrew, Emmanuel Fonseca, B. M. Gaensler, R. C. Joseph, Victoria M. Kaspi, Bikash Kharel, Adam E. Lanman, Calvin Leung, Lluis Mas-Ribas, Juan Mena-Parra, Kenzie Nimmo, Aaron B. Pearlman, Ue-Li Pen, J. Xavier Prochaska, Ryan Raikman, Kaitlyn Shin, Seth R. Siegel, Kendrick M. Smith, Ingrid H. Stairs</br><strong><u>Categories:</u></strong> astro-ph.CO, astro-ph.GA, astro-ph.HE, astro-ph.IM, gr-qc</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> The dispersion of extragalactic fast radio bursts (FRBs) can serve as a
powerful probe of the diffuse plasma between and surrounding galaxies, which
contains most of the Universe's baryons. By cross-correlating the dispersion of
background FRBs with the locations of foreground galaxies, we can study the
relative spatial distributions of plasma and galaxies on scales of 0.1 to 50
Mpc, which are strongly affected by feedback processes in galaxy formation.
Here we present the measurement of the dispersion$\unicode{x2013}$galaxy
angular cross-power spectrum between 2873 FRBs from the Second CHIME/FRB
Catalog and nearly 6 million galaxies from the Dark Energy Spectroscopic
Instrument (DESI) Legacy Imaging Survey. Over five photometric galaxy redshift
bins spanning $0.05 < z <0.5$ and at 5.1$\sigma$ significance, we make the
first definitive detection of spatial correlations in FRB dispersion measure
due to cosmic structure. While parameter inferences should be interpreted with
caution because of incomplete modelling of both the signal and systematic
errors, our data indicate that the plasma$\unicode{x2013}$galaxy cross-power
spectrum cuts off relative to the matter power spectrum at a scale
$k_\textrm{cut}^{-1}=0.9^{+0.4}_{-0.4}\,\textrm{Mpc}$. This scale is consistent
with those X-ray stacking analyses that suggest dark-matter halos with
group-scale masses are largely evacuated of their baryons by feedback
processes. Our study demonstrates that FRBs are promising tools to discern the
physics of baryonic structure formation and will only become more powerful as
FRB surveys expand.</p></br><a href="http://arxiv.org/pdf/2506.08783v1" target="_blank"><h2>syren-baryon: Analytic emulators for the impact of baryons on the matter
  power spectrum</h2></a><strong><u>Authors:</u></strong>  Lukas Kammerer, Deaglan J. Bartlett, Gabriel Kronberger, Harry Desmond, Pedro G. Ferreira</br><strong><u>Categories:</u></strong> astro-ph.CO, astro-ph.GA, astro-ph.IM, cs.LG, cs.NE</br><strong><u>Comments:</u></strong> 14 pages, 6 figures. Submitted to A&A</br><p><strong><u>Abstract:</u></strong> Baryonic physics has a considerable impact on the distribution of matter in
our Universe on scales probed by current and future cosmological surveys,
acting as a key systematic in such analyses. We seek simple symbolic
parametrisations for the impact of baryonic physics on the matter power
spectrum for a range of physically motivated models, as a function of
wavenumber, redshift, cosmology, and parameters controlling the baryonic
feedback. We use symbolic regression to construct analytic approximations for
the ratio of the matter power spectrum in the presence of baryons to that
without such effects. We obtain separate functions of each of four distinct
sub-grid prescriptions of baryonic physics from the CAMELS suite of
hydrodynamical simulations (Astrid, IllustrisTNG, SIMBA and Swift-EAGLE) as
well as for a baryonification algorithm. We also provide functions which
describe the uncertainty on these predictions, due to both the stochastic
nature of baryonic physics and the errors on our fits. The error on our
approximations to the hydrodynamical simulations is comparable to the sample
variance estimated through varying initial conditions, and our baryonification
expression has a root mean squared error of better than one percent, although
this increases on small scales. These errors are comparable to those of
previous numerical emulators for these models. Our expressions are enforced to
have the physically correct behaviour on large scales and at high redshift. Due
to their analytic form, we are able to directly interpret the impact of varying
cosmology and feedback parameters, and we can identify parameters which have
little to no effect. Each function is based on a different implementation of
baryonic physics, and can therefore be used to discriminate between these
models when applied to real data. We provide publicly available code for all
symbolic approximations found.</p></br><a href="http://arxiv.org/pdf/2506.08698v1" target="_blank"><h2>Variational Autoencoder-Based Approach to Latent Feature Analysis on
  Efficient Representation of Power Load Monitoring Data</h2></a><strong><u>Authors:</u></strong>  Boyu Xie, Tangtang Xie</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 9 pages, 2 figures</br><p><strong><u>Abstract:</u></strong> With the development of smart grids, High-Dimensional and Incomplete (HDI)
Power Load Monitoring (PLM) data challenges the performance of Power Load
Forecasting (PLF) models. In this paper, we propose a potential
characterization model VAE-LF based on Variational Autoencoder (VAE) for
efficiently representing and complementing PLM missing data. VAE-LF learns a
low-dimensional latent representation of the data using an Encoder-Decoder
structure by splitting the HDI PLM data into vectors and feeding them
sequentially into the VAE-LF model, and generates the complementary data.
Experiments on the UK-DALE dataset show that VAE-LF outperforms other benchmark
models in both 5% and 10% sparsity test cases, with significantly lower RMSE
and MAE, and especially outperforms on low sparsity ratio data. The method
provides an efficient data-completion solution for electric load management in
smart grids.</p></br><a href="http://arxiv.org/pdf/2506.08368v1" target="_blank"><h2>Prospects for Time-Domain and Multi-Messenger Science with eXTP</h2></a><strong><u>Authors:</u></strong>  Shu-Xu Yi, Wen Zhao, Ren-Xin Xu, Xue-Feng Wu, Giulia Stratta, Simone Dall'Osso, Yan-Jun Xu, Andrea Santangelo, Silvia Zane, Shuang-Nan Zhang, Hua Feng, Huan Yang, Junjie Mao, Junqiang Ge, Lijing Shao, Mi-Xiang Lan, He Gao, Lin Lin, Ning Jiang, Qingwen Wu, Tong Liu, Yun-Wei Yu, Xiang-Yu Wang, Jin Zhang, Dafne Guetta, Jin-Jun Geng, Di Xiao, Yong-Feng Huang, Yacheng Kang, Tian-Yong Cao, Zhen Zhang, Zhenwei Lyu, Zhen Pan, Yunfeng Chen, Yong Gao, Ang Li, Yu-Cong Fu, Shuo Xiao, Wei-Yang Wang, Fayin Wang, Zhenyin Zhao, Weihua Lei, Rong-Feng Shen, Lixin Dai, Guang-Lei Wu, Liang-Duan Liu, Jin Zhang, Xilong Fan, Xing-Jiang Zhu, Youjun Lu, Fan Xu, Kangfa Cheng, Da-Bin Lin, Xiao-Hong Zhao, Jun-Jie We, Bin-Bin Zhang, Ji-Rong Mao, Yongquan Xue, Xinwen Shu, Wenjie Zhang, Wei-Li Lin, Achille Fiore, Zhuo Li, Antonio Martin-Carrillo, Joseph Fisher, Fei Xie, Ye Li, Sandro Mereghetti, Shao-Lin Xiong, Yu-Han Yang, Eleonora Troja, Zi-Gao Dai, Da-Ming We, En-Wei Liang</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.CO, astro-ph.GA</br><strong><u>Comments:</u></strong> Submitted to the SCIENCE CHINA Physics, Mechanics & Astronomy</br><p><strong><u>Abstract:</u></strong> In this new era of time-domain and multi-messenger astronomy, various new
transients and new phenomena are constantly being discovered thanks to the
rapid advances in observations, which provide the excellent opportunity to
study the physics in the extreme environments. The enhanced X-ray Timing and
Polarimetry mission (eXTP), planned to be launched in 2030, has several key
advantages, including advanced polarimetry, high sensitivity & large effective
area, and wide energy range coverage, which make it a groundbreaking project in
high-energy astrophysics. In this article, we briefly introduce the potential
time-domain and multi-messenger targets for eXTP, including gravitational-wave
(GW) counterparts, gamma-ray bursts (GRBs), magnetars and fast radio bursts
(FRBs), tidal disruption events (TDEs), supernovae, high energy neutrinos and
TeV active galactic nucleus (AGNs), and so on. We discuss the advantages of
future eXTP observations for detecting these sources, their detection
capabilities, the abilities to distinguish theoretical models, and their
applications in gravity and cosmology.</p></br><a href="http://arxiv.org/pdf/2506.08367v1" target="_blank"><h2>Observatory Science with eXTP</h2></a><strong><u>Authors:</u></strong>  Ping Zhou, Jirong Mao, Liang Zhang, Alessandro Patruno, Enrico Bozzo, Yanjun Xu, Andrea Santangelo, Silvia Zane, Shuang-Nan Zhang, Hua Feng, Yuri Cavecchi, Barbara De Marco, Junhui Fan, Xian Hou, Pengfei Jiang, Patrizia Romano, Gloria Sala, Lian Tao, Alexandra Veledina, Jacco Vink, Song Wang, Junxian Wang, Yidi Wang, Shanshan Weng, Qingwen Wu, Fei Xie, Guobao Zhang, Jin Zhang, Zhanhao Zhao, Shijie Zheng, Samuzal Barua, Yue-Hong Chen, Yupeng Chen, Shi-Jiang Chen, Liang Chen, Yongyun Chen, Xin Cheng, Yi-Heng Chi, Lang Cui, Domitilla de Martino, Wei Deng, Lorenzo Ducci, Ruben Farinelli, Fabo Feng, Mingyu Ge, Minfeng Gu, Hengxiao Guo, Dawei Han, Xinke Hu, Yongfeng Huang, Jean in't Zand, Long Ji, Jialai Kang, Yves Kini, Panping Li, Zhaosheng Li, Kuan Liu, Jiren Liu, Jieying Liu, Ming Lyu, Alessio Marino, Alex Markowitz, Mar Mezcua, Matt Middleton, Guobin Mou, C. -Y. Ng, Alessandro Papitto, Zhiyuan Pei, Jingqiang Peng, Juri Poutanen, Qingcang Shui, Scaringi Simone, Yang Su, Ying Tan, Xilu Wang, Pengju Wang, Di Wang, Fayin Wang, Junfeng Wang, Mengye Wang, Yusong Wang, Jiancheng Wu, Hubing Xiao, Dingrong Xiong, Xiaojie Xu, Rui Xue, Zhen Yan, Ming Yang, Chuyuan Yang, Wenxin Yang, Wentao Ye, Zhuoli Yu, Yuhai Yuan, Xiao Zhang, Lixia Zhang, Shujie Zhao, Qingchang Zhao, Yonggang Zheng, Wei Zheng, Wenwen Zuo</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA, astro-ph.HE, astro-ph.SR</br><strong><u>Comments:</u></strong> Submitted to the SCIENCE CHINA Physics, Mechanics & Astronomy</br><p><strong><u>Abstract:</u></strong> Scheduled for launch in 2030, the enhanced X-ray Timing and Polarization
(eXTP) telescope is a Chinese space-based mission aimed at studying extreme
conditions and phenomena in astrophysics. eXTP will feature three main
payloads: Spectroscopy Focusing Arrays (SFAs), Polarimetry Focusing Arrays
(PFAs), and a Wide-field Camera (W2C). This white paper outlines observatory
science, incorporating key scientific advances and instrumental changes since
the publication of the previous white paper [1]. We will discuss perspectives
of eXTP on the research domains of flare stars, supernova remnants, pulsar wind
nebulae, cataclysmic variables, X-ray binaries, ultraluminous X-ray sources,
AGN, and pulsar-based positioning and timekeeping.</p></br><a href="http://arxiv.org/pdf/2506.09368v1" target="_blank"><h2>Anomaly Detection and Generation with Diffusion Models: A Survey</h2></a><strong><u>Authors:</u></strong>  Yang Liu, Jing Liu, Chengfang Li, Rui Xi, Wenchao Li, Liang Cao, Jin Wang, Laurence T. Yang, Junsong Yuan, Wei Zhou</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 20 pages, 11 figures, 13 tables</br><p><strong><u>Abstract:</u></strong> Anomaly detection (AD) plays a pivotal role across diverse domains, including
cybersecurity, finance, healthcare, and industrial manufacturing, by
identifying unexpected patterns that deviate from established norms in
real-world data. Recent advancements in deep learning, specifically diffusion
models (DMs), have sparked significant interest due to their ability to learn
complex data distributions and generate high-fidelity samples, offering a
robust framework for unsupervised AD. In this survey, we comprehensively review
anomaly detection and generation with diffusion models (ADGDM), presenting a
tutorial-style analysis of the theoretical foundations and practical
implementations and spanning images, videos, time series, tabular, and
multimodal data. Crucially, unlike existing surveys that often treat anomaly
detection and generation as separate problems, we highlight their inherent
synergistic relationship. We reveal how DMs enable a reinforcing cycle where
generation techniques directly address the fundamental challenge of anomaly
data scarcity, while detection methods provide critical feedback to improve
generation fidelity and relevance, advancing both capabilities beyond their
individual potential. A detailed taxonomy categorizes ADGDM methods based on
anomaly scoring mechanisms, conditioning strategies, and architectural designs,
analyzing their strengths and limitations. We final discuss key challenges
including scalability and computational efficiency, and outline promising
future directions such as efficient architectures, conditioning strategies, and
integration with foundation models (e.g., visual-language models and large
language models). By synthesizing recent advances and outlining open research
questions, this survey aims to guide researchers and practitioners in
leveraging DMs for innovative AD solutions across diverse applications.</p></br><a href="http://arxiv.org/pdf/2506.08475v1" target="_blank"><h2>Thermodynamically Consistent Latent Dynamics Identification for
  Parametric Systems</h2></a><strong><u>Authors:</u></strong>  Xiaolong He, Yeonjong Shin, Anthony Gruber, Sohyeon Jung, Kookjin Lee, Youngsoo Choi</br><strong><u>Categories:</u></strong> cs.LG, cs.CE, cs.NA, math.NA</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> We propose an efficient thermodynamics-informed latent space dynamics
identification (tLaSDI) framework for the reduced-order modeling of parametric
nonlinear dynamical systems. This framework integrates autoencoders for
dimensionality reduction with newly developed parametric GENERIC
formalism-informed neural networks (pGFINNs), which enable efficient learning
of parametric latent dynamics while preserving key thermodynamic principles
such as free energy conservation and entropy generation across the parameter
space. To further enhance model performance, a physics-informed active learning
strategy is incorporated, leveraging a greedy, residual-based error indicator
to adaptively sample informative training data, outperforming uniform sampling
at equivalent computational cost. Numerical experiments on the Burgers'
equation and the 1D/1V Vlasov-Poisson equation demonstrate that the proposed
method achieves up to 3,528x speed-up with 1-3% relative errors, and
significant reduction in training (50-90%) and inference (57-61%) cost.
Moreover, the learned latent space dynamics reveal the underlying thermodynamic
behavior of the system, offering valuable insights into the physical-space
dynamics.</p></br><a href="http://arxiv.org/pdf/2506.09101v1" target="_blank"><h2>Feature Shift Localization Network</h2></a><strong><u>Authors:</u></strong>  Míriam Barrabés, Daniel Mas Montserrat, Kapal Dev, Alexander G. Ioannidis</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> 9 pages, 2 figures, 4 tables</br><p><strong><u>Abstract:</u></strong> Feature shifts between data sources are present in many applications
involving healthcare, biomedical, socioeconomic, financial, survey, and
multi-sensor data, among others, where unharmonized heterogeneous data sources,
noisy data measurements, or inconsistent processing and standardization
pipelines can lead to erroneous features. Localizing shifted features is
important to address the underlying cause of the shift and correct or filter
the data to avoid degrading downstream analysis. While many techniques can
detect distribution shifts, localizing the features originating them is still
challenging, with current solutions being either inaccurate or not scalable to
large and high-dimensional datasets. In this work, we introduce the Feature
Shift Localization Network (FSL-Net), a neural network that can localize
feature shifts in large and high-dimensional datasets in a fast and accurate
manner. The network, trained with a large number of datasets, learns to extract
the statistical properties of the datasets and can localize feature shifts from
previously unseen datasets and shifts without the need for re-training. The
code and ready-to-use trained model are available at
https://github.com/AI-sandbox/FSL-Net.</p></br><a href="http://arxiv.org/pdf/2506.09163v1" target="_blank"><h2>Scalable Spatiotemporal Inference with Biased Scan Attention Transformer
  Neural Processes</h2></a><strong><u>Authors:</u></strong>  Daniel Jenson, Jhonathan Navott, Piotr Grynfelder, Mengyan Zhang, Makkunda Sharma, Elizaveta Semenova, Seth Flaxman</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Neural Processes (NPs) are a rapidly evolving class of models designed to
directly model the posterior predictive distribution of stochastic processes.
While early architectures were developed primarily as a scalable alternative to
Gaussian Processes (GPs), modern NPs tackle far more complex and data hungry
applications spanning geology, epidemiology, climate, and robotics. These
applications have placed increasing pressure on the scalability of these
models, with many architectures compromising accuracy for scalability. In this
paper, we demonstrate that this tradeoff is often unnecessary, particularly
when modeling fully or partially translation invariant processes. We propose a
versatile new architecture, the Biased Scan Attention Transformer Neural
Process (BSA-TNP), which introduces Kernel Regression Blocks (KRBlocks),
group-invariant attention biases, and memory-efficient Biased Scan Attention
(BSA). BSA-TNP is able to: (1) match or exceed the accuracy of the best models
while often training in a fraction of the time, (2) exhibit translation
invariance, enabling learning at multiple resolutions simultaneously, (3)
transparently model processes that evolve in both space and time, (4) support
high dimensional fixed effects, and (5) scale gracefully -- running inference
with over 1M test points with 100K context points in under a minute on a single
24GB GPU.</p></br><a href="http://arxiv.org/pdf/2506.08397v1" target="_blank"><h2>Spatiotemporal deep learning models for detection of rapid
  intensification in cyclones</h2></a><strong><u>Authors:</u></strong>  Vamshika Sutar, Amandeep Singh, Rohitash Chandra</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Cyclone rapid intensification is the rapid increase in cyclone wind
intensity, exceeding a threshold of 30 knots, within 24 hours. Rapid
intensification is considered an extreme event during a cyclone, and its
occurrence is relatively rare, contributing to a class imbalance in the
dataset. A diverse array of factors influences the likelihood of a cyclone
undergoing rapid intensification, further complicating the task for
conventional machine learning models. In this paper, we evaluate deep learning,
ensemble learning and data augmentation frameworks to detect cyclone rapid
intensification based on wind intensity and spatial coordinates. We note that
conventional data augmentation methods cannot be utilised for generating
spatiotemporal patterns replicating cyclones that undergo rapid
intensification. Therefore, our framework employs deep learning models to
generate spatial coordinates and wind intensity that replicate cyclones to
address the class imbalance problem of rapid intensification. We also use a
deep learning model for the classification module within the data augmentation
framework to differentiate between rapid and non-rapid intensification events
during a cyclone. Our results show that data augmentation improves the results
for rapid intensification detection in cyclones, and spatial coordinates play a
critical role as input features to the given models. This paves the way for
research in synthetic data generation for spatiotemporal data with extreme
events.</p></br><a href="http://arxiv.org/pdf/2506.08306v1" target="_blank"><h2>AstroCompress: A benchmark dataset for multi-purpose compression of
  astronomical data</h2></a><strong><u>Authors:</u></strong>  Tuan Truong, Rithwik Sudharsan, Yibo Yang, Peter Xiangyuan Ma, Ruihan Yang, Stephan Mandt, Joshua S. Bloom</br><strong><u>Categories:</u></strong> cs.AI, astro-ph.IM</br><strong><u>Comments:</u></strong> ICLR 2025 conference paper. See reviews atthis https URL</br><p><strong><u>Abstract:</u></strong> The site conditions that make astronomical observatories in space and on the
ground so desirable -- cold and dark -- demand a physical remoteness that leads
to limited data transmission capabilities. Such transmission limitations
directly bottleneck the amount of data acquired and in an era of costly modern
observatories, any improvements in lossless data compression has the potential
scale to billions of dollars worth of additional science that can be
accomplished on the same instrument. Traditional lossless methods for
compressing astrophysical data are manually designed. Neural data compression,
on the other hand, holds the promise of learning compression algorithms
end-to-end from data and outperforming classical techniques by leveraging the
unique spatial, temporal, and wavelength structures of astronomical images.
This paper introduces AstroCompress: a neural compression challenge for
astrophysics data, featuring four new datasets (and one legacy dataset) with
16-bit unsigned integer imaging data in various modes: space-based,
ground-based, multi-wavelength, and time-series imaging. We provide code to
easily access the data and benchmark seven lossless compression methods (three
neural and four non-neural, including all practical state-of-the-art
algorithms). Our results on lossless compression indicate that lossless neural
compression techniques can enhance data collection at observatories, and
provide guidance on the adoption of neural compression in scientific
applications. Though the scope of this paper is restricted to lossless
compression, we also comment on the potential exploration of lossy compression
methods in future studies.</p></br><a href="http://arxiv.org/pdf/2506.09940v1" target="_blank"><h2>The Sample Complexity of Online Strategic Decision Making with
  Information Asymmetry and Knowledge Transportability</h2></a><strong><u>Authors:</u></strong>  Jiachen Hu, Rui Ai, Han Zhong, Xiaoyu Chen, Liwei Wang, Zhaoran Wang, Zhuoran Yang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> Accepted at ICML 2025</br><p><strong><u>Abstract:</u></strong> Information asymmetry is a pervasive feature of multi-agent systems,
especially evident in economics and social sciences. In these settings, agents
tailor their actions based on private information to maximize their rewards.
These strategic behaviors often introduce complexities due to confounding
variables. Simultaneously, knowledge transportability poses another significant
challenge, arising from the difficulties of conducting experiments in target
environments. It requires transferring knowledge from environments where
empirical data is more readily available. Against these backdrops, this paper
explores a fundamental question in online learning: Can we employ non-i.i.d.
actions to learn about confounders even when requiring knowledge transfer? We
present a sample-efficient algorithm designed to accurately identify system
dynamics under information asymmetry and to navigate the challenges of
knowledge transfer effectively in reinforcement learning, framed within an
online strategic interaction model. Our method provably achieves learning of an
$\epsilon$-optimal policy with a tight sample complexity of $O(1/\epsilon^2)$.</p></br><a href="http://arxiv.org/pdf/2506.09338v1" target="_blank"><h2>Know What You Don't Know: Uncertainty Calibration of Process Reward
  Models</h2></a><strong><u>Authors:</u></strong>  Young-Jin Park, Kristjan Greenewald, Kaveh Alim, Hao Wang, Navid Azizan</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Process reward models (PRMs) play a central role in guiding inference-time
scaling algorithms for large language models (LLMs). However, we observe that
even state-of-the-art PRMs can be poorly calibrated and often overestimate
success probabilities. To address this, we present a calibration approach,
performed via quantile regression, that adjusts PRM outputs to better align
with true success probabilities. Leveraging these calibrated success estimates
and their associated confidence bounds, we introduce an \emph{instance-adaptive
scaling} (IAS) framework that dynamically adjusts the inference budget based on
the estimated likelihood that a partial reasoning trajectory will yield a
correct final answer. Unlike conventional methods that allocate a fixed number
of reasoning trajectories per query, this approach successfully adapts to each
instance and reasoning step when using our calibrated PRMs. Experiments on
mathematical reasoning benchmarks show that (i) our PRM calibration method
successfully achieves small calibration error, outperforming the baseline
methods, (ii) calibration is crucial for enabling effective adaptive scaling,
and (iii) the proposed IAS strategy reduces inference costs while maintaining
final answer accuracy, utilizing less compute on more confident problems as
desired.</p></br><a href="http://arxiv.org/pdf/2506.08572v1" target="_blank"><h2>The Geometries of Truth Are Orthogonal Across Tasks</h2></a><strong><u>Authors:</u></strong>  Waiss Azizian, Michael Kirchhof, Eugene Ndiaye, Louis Bethune, Michal Klein, Pierre Ablin, Marco Cuturi</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Large Language Models (LLMs) have demonstrated impressive generalization
capabilities across various tasks, but their claim to practical relevance is
still mired by concerns on their reliability. Recent works have proposed
examining the activations produced by an LLM at inference time to assess
whether its answer to a question is correct. Some works claim that a "geometry
of truth" can be learned from examples, in the sense that the activations that
generate correct answers can be distinguished from those leading to mistakes
with a linear classifier. In this work, we underline a limitation of these
approaches: we observe that these "geometries of truth" are intrinsically
task-dependent and fail to transfer across tasks. More precisely, we show that
linear classifiers trained across distinct tasks share little similarity and,
when trained with sparsity-enforcing regularizers, have almost disjoint
supports. We show that more sophisticated approaches (e.g., using mixtures of
probes and tasks) fail to overcome this limitation, likely because activation
vectors commonly used to classify answers form clearly separated clusters when
examined across tasks.</p></br><a href="http://arxiv.org/pdf/2506.08505v1" target="_blank"><h2>Explaining, Fast and Slow: Abstraction and Refinement of Provable
  Explanations</h2></a><strong><u>Authors:</u></strong>  Shahaf Bassan, Yizhak Yisrael Elboher, Tobias Ladner, Matthias Althoff, Guy Katz</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.LO</br><strong><u>Comments:</u></strong> To appear in ICML 2025</br><p><strong><u>Abstract:</u></strong> Despite significant advancements in post-hoc explainability techniques for
neural networks, many current methods rely on heuristics and do not provide
formally provable guarantees over the explanations provided. Recent work has
shown that it is possible to obtain explanations with formal guarantees by
identifying subsets of input features that are sufficient to determine that
predictions remain unchanged using neural network verification techniques.
Despite the appeal of these explanations, their computation faces significant
scalability challenges. In this work, we address this gap by proposing a novel
abstraction-refinement technique for efficiently computing provably sufficient
explanations of neural network predictions. Our method abstracts the original
large neural network by constructing a substantially reduced network, where a
sufficient explanation of the reduced network is also provably sufficient for
the original network, hence significantly speeding up the verification process.
If the explanation is in sufficient on the reduced network, we iteratively
refine the network size by gradually increasing it until convergence. Our
experiments demonstrate that our approach enhances the efficiency of obtaining
provably sufficient explanations for neural network predictions while
additionally providing a fine-grained interpretation of the network's
predictions across different abstraction levels.</p></br><a href="http://arxiv.org/pdf/2506.09508v1" target="_blank"><h2>Efficient Preference-Based Reinforcement Learning: Randomized
  Exploration Meets Experimental Design</h2></a><strong><u>Authors:</u></strong>  Andreas Schlaginhaufen, Reda Ouhamma, Maryam Kamgarpour</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.RO, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> We study reinforcement learning from human feedback in general Markov
decision processes, where agents learn from trajectory-level preference
comparisons. A central challenge in this setting is to design algorithms that
select informative preference queries to identify the underlying reward while
ensuring theoretical guarantees. We propose a meta-algorithm based on
randomized exploration, which avoids the computational challenges associated
with optimistic approaches and remains tractable. We establish both regret and
last-iterate guarantees under mild reinforcement learning oracle assumptions.
To improve query complexity, we introduce and analyze an improved algorithm
that collects batches of trajectory pairs and applies optimal experimental
design to select informative comparison queries. The batch structure also
enables parallelization of preference queries, which is relevant in practical
deployment as feedback can be gathered concurrently. Empirical evaluation
confirms that the proposed method is competitive with reward-based
reinforcement learning while requiring a small number of preference queries.</p></br><a href="http://arxiv.org/pdf/2506.09862v1" target="_blank"><h2>Guided Graph Compression for Quantum Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Mikel Casals, Vasilis Belis, Elias F. Combarro, Eduard Alarcón, Sofia Vallecorsa, Michele Grossi</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, hep-ex, quant-ph</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Graph Neural Networks (GNNs) are effective for processing graph-structured
data but face challenges with large graphs due to high memory requirements and
inefficient sparse matrix operations on GPUs. Quantum Computing (QC) offers a
promising avenue to address these issues and inspires new algorithmic
approaches. In particular, Quantum Graph Neural Networks (QGNNs) have been
explored in recent literature. However, current quantum hardware limits the
dimension of the data that can be effectively encoded. Existing approaches
either simplify datasets manually or use artificial graph datasets. This work
introduces the Guided Graph Compression (GGC) framework, which uses a graph
autoencoder to reduce both the number of nodes and the dimensionality of node
features. The compression is guided to enhance the performance of a downstream
classification task, which can be applied either with a quantum or a classical
classifier. The framework is evaluated on the Jet Tagging task, a
classification problem of fundamental importance in high energy physics that
involves distinguishing particle jets initiated by quarks from those by gluons.
The GGC is compared against using the autoencoder as a standalone preprocessing
step and against a baseline classical GNN classifier. Our numerical results
demonstrate that GGC outperforms both alternatives, while also facilitating the
testing of novel QGNN ansatzes on realistic datasets.</p></br><a href="http://arxiv.org/pdf/2506.09247v1" target="_blank"><h2>Agent-based Condition Monitoring Assistance with Multimodal Industrial
  Database Retrieval Augmented Generation</h2></a><strong><u>Authors:</u></strong>  Karl Löwenmark, Daniel Strömbergsson, Chang Liu, Marcus Liwicki, Fredrik Sandin</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Condition monitoring (CM) plays a crucial role in ensuring reliability and
efficiency in the process industry. Although computerised maintenance systems
effectively detect and classify faults, tasks like fault severity estimation,
and maintenance decisions still largely depend on human expert analysis. The
analysis and decision making automatically performed by current systems
typically exhibit considerable uncertainty and high false alarm rates, leading
to increased workload and reduced efficiency.
  This work integrates large language model (LLM)-based reasoning agents with
CM workflows to address analyst and industry needs, namely reducing false
alarms, enhancing fault severity estimation, improving decision support, and
offering explainable interfaces. We propose MindRAG, a modular framework
combining multimodal retrieval-augmented generation (RAG) with novel vector
store structures designed specifically for CM data. The framework leverages
existing annotations and maintenance work orders as surrogates for labels in a
supervised learning protocol, addressing the common challenge of training
predictive models on unlabelled and noisy real-world datasets.
  The primary contributions include: (1) an approach for structuring industry
CM data into a semi-structured multimodal vector store compatible with
LLM-driven workflows; (2) developing multimodal RAG techniques tailored for CM
data; (3) developing practical reasoning agents capable of addressing
real-world CM queries; and (4) presenting an experimental framework for
integrating and evaluating such agents in realistic industrial scenarios.
Preliminary results, evaluated with the help of an experienced analyst,
indicate that MindRAG provide meaningful decision support for more efficient
management of alarms, thereby improving the interpretability of CM systems.</p></br><a href="http://arxiv.org/pdf/2506.09120v1" target="_blank"><h2>New X-ray Supernova Remnants in NGC 7793</h2></a><strong><u>Authors:</u></strong>  Maria Kopsacheili, Konstantina Anastasopoulou, Nanda Rea, Claudia Patricia Gutiérrez, Lluís Galbany</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA</br><strong><u>Comments:</u></strong> 16 pages</br><p><strong><u>Abstract:</u></strong> This work focuses on the detection of X-ray Supernova Remnants (SNRs) in the
galaxy NGC 7793 and the study of their properties. X-ray SNRs in galaxies
beyond the Local Group are rare, mainly due to the limited sensitivity of
current X-ray instruments. Additionally, their identification requires an
optical counterpart, making incomplete optical identification methods an extra
challenge. Detecting X-ray SNRs in other galaxies is crucial for understanding
their feedback in different evolutionary phases and gaining insights into their
local interstellar medium. In NGC 7793, only one X-ray SNR was previously
known, while a recent study reported nearly 240 optical SNRs. The discovery of
a new, larger optical SNR sample motivated a re-examination of the X-ray SNR
population by comparing optical SNRs with X-ray sources. To identify X-ray
SNRs, we utilised Chandra's spatial resolution and analysed all available
archival data of NGC 7793, totaling 229.9 ks over 19 years. After data
reduction, we performed source detection and analysis, searching for X-ray
sources coinciding with optical SNRs. We also used XMM-Newton for spectral
analysis of the confirmed and candidate SNRs. We detected 58 X-ray sources down
to an observed luminosity of $\sim 1.5\times 10^{36}\, erg\, s^{-1}$. Among
them, five X-ray counterparts to optical SNRs were identified, all presenting
soft emission (<1.2 keV) with no short- or long-term variability. One
corresponds to the previously known X-ray SNR, while four are newly detected.
Spectral modeling of two SNRs shows thermal spectra exceeding 2.5 million K,
with strong OVII, OVIII, and NeIX emission lines. A correlation between
density, X-ray luminosity, and source softness was observed. We also report
X-ray emission from supernova 2008bk, refining its position, and suggest two
candidate X-ray SNRs with soft, non-variable spectra, one resembling the
identified X-ray SNRs.</p></br><a href="http://arxiv.org/pdf/2506.09237v1" target="_blank"><h2>PatchGuard: Adversarially Robust Anomaly Detection and Localization
  through Vision Transformers and Pseudo Anomalies</h2></a><strong><u>Authors:</u></strong>  Mojtaba Nafez, Amirhossein Koochakian, Arad Maleki, Jafar Habibi, Mohammad Hossein Rohban</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> Accepted to the Conference on Computer Vision and Pattern Recognition (CVPR) 2025</br><p><strong><u>Abstract:</u></strong> Anomaly Detection (AD) and Anomaly Localization (AL) are crucial in fields
that demand high reliability, such as medical imaging and industrial
monitoring. However, current AD and AL approaches are often susceptible to
adversarial attacks due to limitations in training data, which typically
include only normal, unlabeled samples. This study introduces PatchGuard, an
adversarially robust AD and AL method that incorporates pseudo anomalies with
localization masks within a Vision Transformer (ViT)-based architecture to
address these vulnerabilities. We begin by examining the essential properties
of pseudo anomalies, and follow it by providing theoretical insights into the
attention mechanisms required to enhance the adversarial robustness of AD and
AL systems. We then present our approach, which leverages Foreground-Aware
Pseudo-Anomalies to overcome the deficiencies of previous anomaly-aware
methods. Our method incorporates these crafted pseudo-anomaly samples into a
ViT-based framework, with adversarial training guided by a novel loss function
designed to improve model robustness, as supported by our theoretical analysis.
Experimental results on well-established industrial and medical datasets
demonstrate that PatchGuard significantly outperforms previous methods in
adversarial settings, achieving performance gains of $53.2\%$ in AD and
$68.5\%$ in AL, while also maintaining competitive accuracy in non-adversarial
settings. The code repository is available at
https://github.com/rohban-lab/PatchGuard .</p></br></body>