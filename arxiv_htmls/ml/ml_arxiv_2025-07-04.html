<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 02 Jul 2025 to 04 Jul 2025</em></font><a href="http://arxiv.org/pdf/2507.02291v1" target="_blank"><h2>Knowledge Graph-Based Explainable and Generalized Zero-Shot Semantic
  Communications</h2></a><strong><u>Authors:</u></strong>  Zhaoyu Zhang, Lingyi Wang, Wei Wu, Fuhui Zhou, Qihui Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.IT, math.IT</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), explainable (title)</br><p><strong><u>Abstract:</u></strong> Data-driven semantic communication is based on superficial statistical
patterns, thereby lacking interpretability and generalization, especially for
applications with the presence of unseen data. To address these challenges, we
propose a novel knowledge graph-enhanced zero-shot semantic communication
(KGZS-SC) network. Guided by the structured semantic information from a
knowledge graph-based semantic knowledge base (KG-SKB), our scheme provides
generalized semantic representations and enables reasoning for unseen cases.
Specifically, the KG-SKB aligns the semantic features in a shared category
semantics embedding space and enhances the generalization ability of the
transmitter through aligned semantic features, thus reducing communication
overhead by selectively transmitting compact visual semantics. At the receiver,
zero-shot learning (ZSL) is leveraged to enable direct classification for
unseen cases without the demand for retraining or additional computational
overhead, thereby enhancing the adaptability and efficiency of the
classification process in dynamic or resource-constrained environments. The
simulation results conducted on the APY datasets show that the proposed KGZS-SC
network exhibits robust generalization and significantly outperforms existing
SC frameworks in classifying unseen categories across a range of SNR levels.</p></br><a href="http://arxiv.org/pdf/2507.02342v1" target="_blank"><h2>DeltaSHAP: Explaining Prediction Evolutions in Online Patient Monitoring
  with Shapley Values</h2></a><strong><u>Authors:</u></strong>  Changhun Kim, Yechan Mun, Sangchul Hahn, Eunho Yang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted to ICML 2025 Workshop on Actionable Interpretability. Code is available atthis https URL</br><strong><u>Matching Keywords:</u></strong> explainable (abstract)</br><p><strong><u>Abstract:</u></strong> This study proposes DeltaSHAP, a novel explainable artificial intelligence
(XAI) algorithm specifically designed for online patient monitoring systems. In
clinical environments, discovering the causes driving patient risk evolution is
critical for timely intervention, yet existing XAI methods fail to address the
unique requirements of clinical time series explanation tasks. To this end,
DeltaSHAP addresses three key clinical needs: explaining the changes in the
consecutive predictions rather than isolated prediction scores, providing both
magnitude and direction of feature attributions, and delivering these insights
in real time. By adapting Shapley values to temporal settings, our approach
accurately captures feature coalition effects. It further attributes prediction
changes using only the actually observed feature combinations, making it
efficient and practical for time-sensitive clinical applications. We also
introduce new evaluation metrics to evaluate the faithfulness of the
attributions for online time series, and demonstrate through experiments on
online patient monitoring tasks that DeltaSHAP outperforms state-of-the-art XAI
methods in both explanation quality as 62% and computational efficiency as 33%
time reduction on the MIMIC-III decompensation benchmark. We release our code
at https://github.com/AITRICS/DeltaSHAP.</p></br><a href="http://arxiv.org/pdf/2507.02681v1" target="_blank"><h2>Detection of Disengagement from Voluntary Quizzes: An Explainable
  Machine Learning Approach in Higher Distance Education</h2></a><strong><u>Authors:</u></strong>  Behnam Parsaeifard, Christof Imhof, Tansu Pancar, Ioan-Sorin Comsa, Martin Hlosta, Nicole Bergamin, Per Bergamin</br><strong><u>Categories:</u></strong> cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> Students disengaging from their tasks can have serious long-term
consequences, including academic drop-out. This is particularly relevant for
students in distance education. One way to measure the level of disengagement
in distance education is to observe participation in non-mandatory exercises in
different online courses. In this paper, we detect student disengagement in the
non-mandatory quizzes of 42 courses in four semesters from a distance-based
university. We carefully identified the most informative student log data that
could be extracted and processed from Moodle. Then, eight machine learning
algorithms were trained and compared to obtain the highest possible prediction
accuracy. Using the SHAP method, we developed an explainable machine learning
framework that allows practitioners to better understand the decisions of the
trained algorithm. The experimental results show a balanced accuracy of 91\%,
where about 85\% of disengaged students were correctly detected. On top of the
highly predictive performance and explainable framework, we provide a
discussion on how to design a timely intervention to minimise disengagement
from voluntary tasks in online learning.</p></br><a href="http://arxiv.org/pdf/2507.02129v1" target="_blank"><h2>Generative Latent Diffusion for Efficient Spatiotemporal Data Reduction</h2></a><strong><u>Authors:</u></strong>  Xiao Li, Liangji Zhu, Anand Rangarajan, Sanjay Ranka</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> 10 pages</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Generative models have demonstrated strong performance in conditional
settings and can be viewed as a form of data compression, where the condition
serves as a compact representation. However, their limited controllability and
reconstruction accuracy restrict their practical application to data
compression. In this work, we propose an efficient latent diffusion framework
that bridges this gap by combining a variational autoencoder with a conditional
diffusion model. Our method compresses only a small number of keyframes into
latent space and uses them as conditioning inputs to reconstruct the remaining
frames via generative interpolation, eliminating the need to store latent
representations for every frame. This approach enables accurate spatiotemporal
reconstruction while significantly reducing storage costs. Experimental results
across multiple datasets show that our method achieves up to 10 times higher
compression ratios than rule-based state-of-the-art compressors such as SZ3,
and up to 63 percent better performance than leading learning-based methods
under the same reconstruction error.</p></br></body>