<!DOCTYPE html><html><head><meta charset='utf-8'><link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>
    body {font-family: 'Montserrat', sans-serif; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}
    h1 {font-size: 70px}
    a {color: #45ABC2}
    em {font-size: 120%}
    </style>
    </head><body><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 28 Nov 2025 to 30 Nov 2025</em></font><br><br><a href="https://arxiv.org/pdf/2511.23465v1" target="_blank"><h2>SmallWorlds: Assessing Dynamics Understanding of World Models in Isolated Environments</h2></a><strong><u>Authors:</u></strong> Xinyi Li, Zaishuo Xia, Weyl Lu, Chenjie Hao, Yubei Chen<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Current world models lack a unified and controlled setting for systematic evaluation, making it difficult to assess whether they truly capture the underlying rules that govern environment dynamics. In this work, we address this open challenge by introducing the SmallWorld Benchmark, a testbed designed to assess world model capability under isolated and precisely controlled dynamics without relying on handcrafted reward signals. Using this benchmark, we conduct comprehensive experiments in the fully observable state space on representative architectures including Recurrent State Space Model, Transformer, Diffusion model, and Neural ODE, examining their behavior across six distinct domains. The experimental results reveal how effectively these models capture environment structure and how their predictions deteriorate over extended rollouts, highlighting both the strengths and limitations of current modeling paradigms and offering insights into future improvement directions in representation learning and dynamics modeling.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23463v1" target="_blank"><h2>Kinetic Mixing and the Phantom Illusion: Axion-Dilaton Quintessence in Light of DESI DR2 <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Michael W. Toomey, Ellie Hughes, Mikhail M. Ivanov, James M. Sullivan<br><strong><u>Categories:</u></strong> astro-ph.CO, hep-ph<br><strong><u>Comments:</u></strong> 15 pages, 8 figures, 3 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> Recent results from DESI BAO analyses suggest that dark energy may not be a cosmological constant and is in fact dynamical. Furthermore, the data suggest that the equation of state may have been in the phantom regime in the distant past, recently undergoing a phantom crossing. In this work, we investigate whether this preference can be realized within a kinetically mixed axion-dilaton (KMIX) quintessence model, a string-motivated system in which an axion-like field couples exponentially to a dilaton-like (moduli) field. Crucially, KMIX can appear phantom in a standard Chevallier-Polarski-Linder (CPL) based analysis. To confront the model with data, we develop a fast pipeline based on normalizing flows that (i) learns a theory-informed prior on $(w_0,w_a)$ from KMIX realizations and (ii) provides an inverse mapping from CPL parameters back to the physical KMIX parameters. By importance-sampling pre-computed CPL chains using this framework, we effectively transform generic phenomenological constraints into direct, computationally efficient constraints on the underlying KMIX theory, avoiding the prohibitive cost of full parameter space exploration. Applied to Planck+DESI DR2 BAO measurements, our framework finds support for KMIX at $2.5σ$ compared to the base CPL fit at $3.1σ$, demonstrating that KMIX may account for the DESI preference without invoking true phantom behavior. When additionally including Type Ia supernovae data, we find that the preference remains above $3σ$ for Union3 and DES Y5, but drops to $2.1σ$ with Pantheon+. The latter, combined with the DESI full-shape power spectrum and bispectrum data, further reduces the preference to $1.7σ$. Ultimately, should the DESI deviation persist with future data, KMIX may offer a theoretically well-motivated explanation for the phantom-like signatures inferred from phenomenological fits.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23449v1" target="_blank"><h2>Physics-Informed Neural Networks for Thermophysical Property Retrieval</h2></a><strong><u>Authors:</u></strong> Ali Waseem, Malcolm Mielle<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CE, cs.CV<br><strong><u>Comments:</u></strong> 26 pages, 4 figures, 3 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title)<br><p><strong><u>Abstract:</u></strong> Inverse heat problems refer to the estimation of material thermophysical properties given observed or known heat diffusion behaviour. Inverse heat problems have wide-ranging uses, but a critical application lies in quantifying how building facade renovation reduces thermal transmittance, a key determinant of building energy efficiency. However, solving inverse heat problems with non-invasive data collected in situ is error-prone due to environmental variability or deviations from theoretically assumed conditions. Hence, current methods for measuring thermal conductivity are either invasive, require lengthy observation periods, or are sensitive to environmental and experimental conditions. Here, we present a PINN-based iterative framework to estimate the thermal conductivity k of a wall from a set of thermographs; our framework alternates between estimating the forward heat problem with a PINN for a fixed k, and optimizing k by comparing the thermographs and surface temperatures predicted by the PINN, repeating until the estimated k's convergence. Using both environmental data captured by a weather station and data generated from Finite-Volume-Method software simulations, we accurately predict k across different environmental conditions and data collection sampling times, given the temperature profile of the wall at dawn is close to steady state. Although violating the steady-state assumption impacts the accuracy of k's estimation, we show that our proposed framework still only exhibits a maximum MAE of 4.0851. Our work demonstrates the potential of PINN-based methods for reliable estimation of material properties in situ and under realistic conditions, without lengthy measurement campaigns. Given the lack of research on using machine learning, and more specifically on PINNs, for solving in-situ inverse problems, we expect our work to be a starting point for more research on the topic.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23443v1" target="_blank"><h2>Provable Benefits of Sinusoidal Activation for Modular Addition</h2></a><strong><u>Authors:</u></strong> Tianlong Huang, Zhiyuan Li<br><strong><u>Categories:</u></strong> cs.LG, stat.ML<br><strong><u>Comments:</u></strong> 60 pages, 15 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> This paper studies the role of activation functions in learning modular addition with two-layer neural networks. We first establish a sharp expressivity gap: sine MLPs admit width-$2$ exact realizations for any fixed length $m$ and, with bias, width-$2$ exact realizations uniformly over all lengths. In contrast, the width of ReLU networks must scale linearly with $m$ to interpolate, and they cannot simultaneously fit two lengths with different residues modulo $p$. We then provide a novel Natarajan-dimension generalization bound for sine networks, yielding nearly optimal sample complexity $\widetilde{\mathcal{O}}(p)$ for ERM over constant-width sine networks. We also derive width-independent, margin-based generalization for sine networks in the overparametrized regime and validate it. Empirically, sine networks generalize consistently better than ReLU networks across regimes and exhibit strong length extrapolation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23442v1" target="_blank"><h2>ASTRO: Adaptive Stitching via Dynamics-Guided Trajectory Rollouts</h2></a><strong><u>Authors:</u></strong> Hang Yu, Di Zhang, Qiwei Du, Yanping Zhao, Hai Zhang, Guang Chen, Eduardo E. Veas, Junqiao Zhao<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> Offline reinforcement learning (RL) enables agents to learn optimal policies from pre-collected datasets. However, datasets containing suboptimal and fragmented trajectories present challenges for reward propagation, resulting in inaccurate value estimation and degraded policy performance. While trajectory stitching via generative models offers a promising solution, existing augmentation methods frequently produce trajectories that are either confined to the support of the behavior policy or violate the underlying dynamics, thereby limiting their effectiveness for policy improvement. We propose ASTRO, a data augmentation framework that generates distributionally novel and dynamics-consistent trajectories for offline RL. ASTRO first learns a temporal-distance representation to identify distinct and reachable stitch targets. We then employ a dynamics-guided stitch planner that adaptively generates connecting action sequences via Rollout Deviation Feedback, defined as the gap between target state sequence and the actual arrived state sequence by executing predicted actions, to improve trajectory stitching's feasibility and reachability. This approach facilitates effective augmentation through stitching and ultimately enhances policy learning. ASTRO outperforms prior offline RL augmentation methods across various algorithms, achieving notable performance gain on the challenging OGBench suite and demonstrating consistent improvements on standard offline RL benchmarks such as D4RL.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23440v1" target="_blank"><h2>Accelerated Execution of Bayesian Neural Networks using a Single Probabilistic Forward Pass and Code Generation</h2></a><strong><u>Authors:</u></strong> Bernhard Klein, Falk Selker, Hendrik Borras, Sophie Steger, Franz Pernkopf, Holger Fröning<br><strong><u>Categories:</u></strong> cs.LG, cs.AR, cs.DC, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Machine learning models perform well across domains such as diagnostics, weather forecasting, NLP, and autonomous driving, but their limited uncertainty handling restricts use in safety-critical settings. Traditional neural networks often fail to detect out-of-domain (OOD) data and may output confident yet incorrect predictions. Bayesian neural networks (BNNs) address this by providing probabilistic estimates, but incur high computational cost because predictions require sampling weight distributions and multiple forward passes. The Probabilistic Forward Pass (PFP) offers a highly efficient approximation to Stochastic Variational Inference (SVI) by assuming Gaussian-distributed weights and activations, enabling fully analytic uncertainty propagation and replacing sampling with a single deterministic forward pass. We present an end-to-end pipeline for training, compiling, optimizing, and deploying PFP-based BNNs on embedded ARM CPUs. Using the TVM deep learning compiler, we implement a dedicated library of Gaussian-propagating operators for multilayer perceptrons and convolutional neural networks, combined with manual and automated tuning strategies. Ablation studies show that PFP consistently outperforms SVI in computational efficiency, achieving speedups of up to 4200x for small mini-batches. PFP-BNNs match SVI-BNNs on Dirty-MNIST in accuracy, uncertainty estimation, and OOD detection while greatly reducing compute cost. These results highlight the potential of combining Bayesian approximations with code generation to enable efficient BNN deployment on resource-constrained systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23404v1" target="_blank"><h2>LFM2 Technical Report</h2></a><strong><u>Authors:</u></strong> Alexander Amini, Anna Banaszak, Harold Benoit, Arthur Böök, Tarek Dakhran, Song Duong, Alfred Eng, Fernando Fernandes, Marc Härkönen, Anne Harrington, Ramin Hasani, Saniya Karwa, Yuri Khrustalev, Maxime Labonne, Mathias Lechner, Valentine Lechner, Simon Lee, Zetian Li, Noel Loo, Jacob Marks, Edoardo Mosca, Samuel J. Paech, Paul Pak, Rom N. Parnichkun, Alex Quach, Ryan Rogers, Daniela Rus, Nayan Saxena, Bettina Schlager, Tim Seyde, Jimmy T. H. Smith, Aditya Tadimeti, Neehal Tumma<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> We present LFM2, a family of Liquid Foundation Models designed for efficient on-device deployment and strong task capabilities. Using hardware-in-the-loop architecture search under edge latency and memory constraints, we obtain a compact hybrid backbone that combines gated short convolutions with a small number of grouped query attention blocks, delivering up to 2x faster prefill and decode on CPUs compared to similarly sized models. The LFM2 family covers 350M-8.3B parameters, including dense models (350M, 700M, 1.2B, 2.6B) and a mixture-of-experts variant (8.3B total, 1.5B active), all with 32K context length. LFM2's training pipeline includes a tempered, decoupled Top-K knowledge distillation objective that avoids support mismatch; curriculum learning with difficulty-ordered data; and a three-stage post-training recipe of supervised fine-tuning, length-normalized preference optimization, and model merging. Pre-trained on 10-12T tokens, LFM2 models achieve strong results across diverse benchmarks; for example, LFM2-2.6B reaches 79.56% on IFEval and 82.41% on GSM8K. We further build multimodal and retrieval variants: LFM2-VL for vision-language tasks, LFM2-Audio for speech, and LFM2-ColBERT for retrieval. LFM2-VL supports tunable accuracy-latency tradeoffs via token-efficient visual processing, while LFM2-Audio separates audio input and output pathways to enable real-time speech-to-speech interaction competitive with models 3x larger. LFM2-ColBERT provides a low-latency encoder for queries and documents, enabling high-performance retrieval across multiple languages. All models are released with open weights and deployment packages for ExecuTorch, llama.cpp, and vLLM, making LFM2 a practical base for edge applications that need fast, memory-efficient inference and strong task capabilities.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23402v1" target="_blank"><h2>Quantized-Tinyllava: a new multimodal foundation model enables efficient split learning</h2></a><strong><u>Authors:</u></strong> Jiajun Guo, Xin Luo, Jie Liu<br><strong><u>Categories:</u></strong> cs.LG, stat.ML<br><strong><u>Comments:</u></strong> 14pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Split learning is well known as a method for resolving data privacy concerns by training a model on distributed devices, thereby avoiding data sharing that raises privacy issues. However, high network communication costs are always an impediment to split learning, especially for large foundation models that require transmitting large amounts of high-dimensional data. To resolve this issue, we present a new multimodal model structure that incorporates a learning-based data compression method, which compresses model embeddings into low-bit integers while preserving the model's performance, greatly reducing the transmission costs between partitions. We then determine the optimal number of discrete representation levels based on a solid theoretical foundation from entropy coding.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23387v1" target="_blank"><h2>Hierarchical AI-Meteorologist: LLM-Agent System for Multi-Scale and Explainable Weather Forecast Reporting</h2></a><strong><u>Authors:</u></strong> Daniil Sukhorukov, Andrei Zakharov, Nikita Glazkov, Katsiaryna Yanchanka, Vladimir Kirilin, Maxim Dubovitsky, Roman Sultimov, Yuri Maksimov, Ilya Makarov<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> 9 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)<br><p><strong><u>Abstract:</u></strong> We present the Hierarchical AI-Meteorologist, an LLM-agent system that generates explainable weather reports using a hierarchical forecast reasoning and weather keyword generation. Unlike standard approaches that treat forecasts as flat time series, our framework performs multi-scale reasoning across hourly, 6-hour, and daily aggregations to capture both short-term dynamics and long-term trends. Its core reasoning agent converts structured meteorological inputs into coherent narratives while simultaneously extracting a few keywords effectively summarizing the dominant meteorological events. These keywords serve as semantic anchors for validating consistency, temporal coherence and factual alignment of the generated reports. Using OpenWeather and Meteostat data, we demonstrate that hierarchical context and keyword-based validation substantially improve interpretability and robustness of LLM-generated weather narratives, offering a reproducible framework for semantic evaluation of automated meteorological reporting and advancing agent-based scientific reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23347v1" target="_blank"><h2>Distributed Dynamic Associative Memory via Online Convex Optimization</h2></a><strong><u>Authors:</u></strong> Bowen Wang, Matteo Zecchin, Osvaldo Simeone<br><strong><u>Categories:</u></strong> cs.LG, eess.SP<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> An associative memory (AM) enables cue-response recall, and it has recently been recognized as a key mechanism underlying modern neural architectures such as Transformers. In this work, we introduce the concept of distributed dynamic associative memory (DDAM), which extends classical AM to settings with multiple agents and time-varying data streams. In DDAM, each agent maintains a local AM that must not only store its own associations but also selectively memorize information from other agents based on a specified interest matrix. To address this problem, we propose a novel tree-based distributed online gradient descent algorithm, termed DDAM-TOGD, which enables each agent to update its memory on the fly via inter-agent communication over designated routing trees. We derive rigorous performance guarantees for DDAM-TOGD, proving sublinear static regret in stationary environments and a path-length dependent dynamic regret bound in non-stationary environments. These theoretical results provide insights into how communication delays and network structure impact performance. Building on the regret analysis, we further introduce a combinatorial tree design strategy that optimizes the routing trees to minimize communication delays, thereby improving regret bounds. Numerical experiments demonstrate that the proposed DDAM-TOGD framework achieves superior accuracy and robustness compared to representative online learning baselines such as consensus-based distributed optimization, confirming the benefits of the proposed approach in dynamic, distributed environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23340v1" target="_blank"><h2>ParaGate: Parasitic-Driven Domain Adaptation Transfer Learning for Netlist Performance Prediction</h2></a><strong><u>Authors:</u></strong> Bin Sun, Jingyi Zhou, Jianan Mu, Zhiteng Chao, Tianmeng Yang, Ziyue Xu, Jing Ye, Huawei Li<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 8 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> domain adaptation (title), transfer learning (title)<br><p><strong><u>Abstract:</u></strong> In traditional EDA flows, layout-level performance metrics are only obtainable after placement and routing, hindering global optimization at earlier stages. Although some neural-network-based solutions predict layout-level performance directly from netlists, they often face generalization challenges due to the black-box heuristics of commercial placement-and-routing tools, which create disparate data across designs. To this end, we propose ParaGate, a three-step cross-stage prediction framework that infers layout-level timing and power from netlists. First, we propose a two-phase transfer-learning approach to predict parasitic parameters, pre-training on mid-scale circuits and fine-tuning on larger ones to capture extreme conditions. Next, we rely on EDA tools for timing analysis, offloading the long-path numerical reasoning. Finally, ParaGate performs global calibration using subgraph features. Experiments show that ParaGate achieves strong generalization with minimal fine-tuning data: on openE906, its arrival-time R2 from 0.119 to 0.897. These results demonstrate that ParaGate could provide guidance for global optimization in the synthesis and placement stages.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23335v1" target="_blank"><h2>Towards Improving Interpretability of Language Model Generation through a Structured Knowledge Discovery Approach</h2></a><strong><u>Authors:</u></strong> Shuqi Liu, Han Wu, Guanzhi Deng, Jianshu Chen, Xiaoyang Wang, Linqi Song<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> explainability (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Knowledge-enhanced text generation aims to enhance the quality of generated text by utilizing internal or external knowledge sources. While language models have demonstrated impressive capabilities in generating coherent and fluent text, the lack of interpretability presents a substantial obstacle. The limited interpretability of generated text significantly impacts its practical usability, particularly in knowledge-enhanced text generation tasks that necessitate reliability and explainability. Existing methods often employ domain-specific knowledge retrievers that are tailored to specific data characteristics, limiting their generalizability to diverse data types and tasks. To overcome this limitation, we directly leverage the two-tier architecture of structured knowledge, consisting of high-level entities and low-level knowledge triples, to design our task-agnostic structured knowledge hunter. Specifically, we employ a local-global interaction scheme for structured knowledge representation learning and a hierarchical transformer-based pointer network as the backbone for selecting relevant knowledge triples and entities. By combining the strong generative ability of language models with the high faithfulness of the knowledge hunter, our model achieves high interpretability, enabling users to comprehend the model output generation process. Furthermore, we empirically demonstrate the effectiveness of our model in both internal knowledge-enhanced table-to-text generation on the RotoWireFG dataset and external knowledge-enhanced dialogue response generation on the KdConv dataset. Our task-agnostic model outperforms state-of-the-art methods and corresponding language models, setting new standards on the benchmark.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23319v1" target="_blank"><h2>Every Token Counts: Generalizing 16M Ultra-Long Context in Large Language Models</h2></a><strong><u>Authors:</u></strong> Xiang Hu, Zhanchao Zhou, Ruiqi Liang, Zehuan Li, Wei Wu, Jianguo Li<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> This work explores the challenge of building ``Machines that Can Remember'', framing long-term memory as the problem of efficient ultra-long context modeling. We argue that this requires three key properties: \textbf{sparsity}, \textbf{random-access flexibility}, and \textbf{length generalization}. To address ultra-long-context modeling, we leverage Hierarchical Sparse Attention (HSA), a novel attention mechanism that satisfies all three properties. We integrate HSA into Transformers to build HSA-UltraLong, which is an 8B-parameter MoE model trained on over 8 trillion tokens and is rigorously evaluated on different tasks with in-domain and out-of-domain context lengths to demonstrate its capability in handling ultra-long contexts. Results show that our model performs comparably to full-attention baselines on in-domain lengths while achieving over 90\% accuracy on most in-context retrieval tasks with contexts up to 16M. This report outlines our experimental insights and open problems, contributing a foundation for future research in ultra-long context modeling.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23307v1" target="_blank"><h2>Hard-Constrained Neural Networks with Physics-Embedded Architecture for Residual Dynamics Learning and Invariant Enforcement in Cyber-Physical Systems</h2></a><strong><u>Authors:</u></strong> Enzo Nicolás Spotorno, Josafat Leal Filho, Antônio Augusto Fröhlich<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 41 pages (30 pages main text + 11 pages appendices), 3 figures, 8 tables. Submitted to JMLR<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> This paper presents a framework for physics-informed learning in complex cyber-physical systems governed by differential equations with both unknown dynamics and algebraic invariants. First, we formalize the Hybrid Recurrent Physics-Informed Neural Network (HRPINN), a general-purpose architecture that embeds known physics as a hard structural constraint within a recurrent integrator to learn only residual dynamics. Second, we introduce the Projected HRPINN (PHRPINN), a novel extension that integrates a predict-project mechanism to strictly enforce algebraic invariants by design. The framework is supported by a theoretical analysis of its representational capacity. We validate HRPINN on a real-world battery prognostics DAE and evaluate PHRPINN on a suite of standard constrained benchmarks. The results demonstrate the framework's potential for achieving high accuracy and data efficiency, while also highlighting critical trade-offs between physical consistency, computational cost, and numerical stability, providing practical guidance for its deployment.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23305v1" target="_blank"><h2>Calcium versus silicon ejecta velocities and decline rates in supernovae Ia: The role of high-velocity features <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> A. A. Hakobyan, M. H. Gevorgyan, A. G. Karapetyan, G. A. Mamon, D. Kunth, V. Adibekyan, L. V. Barkhudaryan<br><strong><u>Categories:</u></strong> astro-ph.GA<br><strong><u>Comments:</u></strong> 13 pages, 7 figures, 8 tables, online data, resubmitted to MNRAS after addressing referee's comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (title)<br><p><strong><u>Abstract:</u></strong> Photospheric and high-velocity features (PVFs and HVFs) of Si II $λ$6355 and Ca II IR3 lines in supernova Ia (SN Ia) spectra provide insights into ejecta structure, energetics, and circumstellar interaction, yet their interplay remains poorly understood. We analyse a representative sample of 145 nearby SNe Ia observed within $\pm$5 days of B-band maximum light, including normal, 91T-, and 91bg-like events with measured light-curve decline rates ($Δm_{15}$) and Si II and Ca II line properties from the literature. We model PVF and HVF velocity distributions using Gaussian Mixture Models, compare Si II and Ca II PVF velocity distributions, assess Ca II HVF properties, and test correlations between Si II PVF velocities and $Δm_{15}$, with emphasis on HVF effects. For the first time, we show that the Ca II PVF velocity distribution, measured for the same events at the same phases as Si II, is predominantly unimodal, in contrast to the well-known bimodal Si II PVF distribution that supports the high-velocity/normal-velocity division. This contrast likely reflects a subclass-dependent formation depth of the Ca II line, as supported by a positive correlation ($>3.3σ$) between $Δm_{15}$ and the velocity offset between Ca II and Si II PVFs, particularly in faster-declining SNe Ia. Importantly, HVFs do not significantly bias PVF velocity distributions. A significant negative correlation ($>3.3σ$) between Si II PVF velocity and $Δm_{15}$ is found only for HVF-weak SNe Ia, consistent with more energetic explosions yielding faster ejecta, while this trend vanishes in HVF-strong events, likely due to circumstellar interaction. These results underscore the critical role of HVFs and SN Ia subclass in interpreting ejecta kinematics in both models and observations.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23304v1" target="_blank"><h2>Multi-Modal Scene Graph with Kolmogorov-Arnold Experts for Audio-Visual Question Answering</h2></a><strong><u>Authors:</u></strong> Zijian Fu, Changsheng Lv, Mengshi Qi, Huadong Ma<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multi-modal (title, abstract)<br><p><strong><u>Abstract:</u></strong> In this paper, we propose a novel Multi-Modal Scene Graph with Kolmogorov-Arnold Expert Network for Audio-Visual Question Answering (SHRIKE). The task aims to mimic human reasoning by extracting and fusing information from audio-visual scenes, with the main challenge being the identification of question-relevant cues from the complex audio-visual content. Existing methods fail to capture the structural information within video, and suffer from insufficient fine-grained modeling of multi-modal features. To address these issues, we are the first to introduce a new multi-modal scene graph that explicitly models the objects and their relationship as a visually grounded, structured representation of the audio-visual scene. Furthermore, we design a Kolmogorov-Arnold Network~(KAN)-based Mixture of Experts (MoE) to enhance the expressive power of the temporal integration stage. This enables more fine-grained modeling of cross-modal interactions within the question-aware fused audio-visual representation, leading to capture richer and more nuanced patterns and then improve temporal reasoning performance. We evaluate the model on the established MUSIC-AVQA and MUSIC-AVQA v2 benchmarks, where it achieves state-of-the-art performance. Code and model checkpoints will be publicly released.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23290v1" target="_blank"><h2>Machine Learning for Scientific Visualization: Ensemble Data Analysis</h2></a><strong><u>Authors:</u></strong> Hamid Gadirov<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, cs.GR<br><strong><u>Comments:</u></strong> PhD thesis, University of Groningen, 2025<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), dimensionality reduction (abstract)<br><p><strong><u>Abstract:</u></strong> Scientific simulations and experimental measurements produce vast amounts of spatio-temporal data, yet extracting meaningful insights remains challenging due to high dimensionality, complex structures, and missing information. Traditional analysis methods often struggle with these issues, motivating the need for more robust, data-driven approaches. This dissertation explores deep learning methodologies to improve the analysis and visualization of spatio-temporal scientific ensembles, focusing on dimensionality reduction, flow estimation, and temporal interpolation. First, we address high-dimensional data representation through autoencoder-based dimensionality reduction for scientific ensembles. We evaluate the stability of projection metrics under partial labeling and introduce a Pareto-efficient selection strategy to identify optimal autoencoder variants, ensuring expressive and reliable low-dimensional embeddings. Next, we present FLINT, a deep learning model for high-quality flow estimation and temporal interpolation in both flow-supervised and flow-unsupervised settings. FLINT reconstructs missing velocity fields and generates high-fidelity temporal interpolants for scalar fields across 2D+time and 3D+time ensembles without domain-specific assumptions or extensive finetuning. To further improve adaptability and generalization, we introduce HyperFLINT, a hypernetwork-based approach that conditions on simulation parameters to estimate flow fields and interpolate scalar data. This parameter-aware adaptation yields more accurate reconstructions across diverse scientific domains, even with sparse or incomplete data. Overall, this dissertation advances deep learning techniques for scientific visualization, providing scalable, adaptable, and high-quality solutions for interpreting complex spatio-temporal ensembles.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23287v1" target="_blank"><h2>Transformer-Driven Triple Fusion Framework for Enhanced Multimodal Author Intent Classification in Low-Resource Bangla</h2></a><strong><u>Authors:</u></strong> Ariful Islam, Tanvir Mahmud, Md Rifat Hossen<br><strong><u>Categories:</u></strong> cs.LG, cs.CL<br><strong><u>Comments:</u></strong> Accepted at the 28th International Conference on Computer and Information Technology (ICCIT 2025). To be published in IEEE proceedings<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> The expansion of the Internet and social networks has led to an explosion of user-generated content. Author intent understanding plays a crucial role in interpreting social media content. This paper addresses author intent classification in Bangla social media posts by leveraging both textual and visual data. Recognizing limitations in previous unimodal approaches, we systematically benchmark transformer-based language models (mBERT, DistilBERT, XLM-RoBERTa) and vision architectures (ViT, Swin, SwiftFormer, ResNet, DenseNet, MobileNet), utilizing the Uddessho dataset of 3,048 posts spanning six practical intent categories. We introduce a novel intermediate fusion strategy that significantly outperforms early and late fusion on this task. Experimental results show that intermediate fusion, particularly with mBERT and Swin Transformer, achieves 84.11% macro-F1 score, establishing a new state-of-the-art with an 8.4 percentage-point improvement over prior Bangla multimodal approaches. Our analysis demonstrates that integrating visual context substantially enhances intent classification. Cross-modal feature integration at intermediate levels provides optimal balance between modality-specific representation and cross-modal learning. This research establishes new benchmarks and methodological standards for Bangla and other low-resource languages. We call our proposed framework BangACMM (Bangla Author Content MultiModal).</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23285v1" target="_blank"><h2>Properties of Core Collapse Supernovae from Binary Population Synthesis</h2></a><strong><u>Authors:</u></strong> Mark Martinez, Anna O'Grady, Katelyn Breivik, Gina Chen<br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.HE<br><strong><u>Comments:</u></strong> 30 pages, 11 figures; to be submitted to ApJ; comments welcome!<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (title, abstract)<br><p><strong><u>Abstract:</u></strong> Core collapse supernovae (CCSNe) impact many areas of astrophysics, including compact object formation and gravitational waves, but many uncertainties remain in our understanding of the evolution of their progenitors. We use the binary population synthesis code COSMIC to simulate populations of CCSNe across a wide range of metallicities and binary evolution assumptions. Our models vary the prescriptions for mass transfer stability, common envelope ejection efficiency, natal kick strength, and remnant mass-limited explodability to assess their impact on the resulting population of CCSNe. We find that reproducing the observed Type I to Type II rate requires either low common envelope efficiency or modified prescriptions for common envelope survival, highlighting the importance of stellar mergers in shaping the CCSN population. We further classify our synthetic CCSNe into subtypes and present their relative abundances using several different sets of classification criteria, highlighting the large uncertainties that persist in mapping progenitor properties to spectral classes. Finally, we present delay time distributions (DTDs) for our overall populations, separated into Type I and II, and into the full set of observed subtypes. Our DTDs show that models reproducing the observed Type I to Type II rate produce a larger fraction of late CCSNe than is expected under standard assumptions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23269v1" target="_blank"><h2>OctoMed: Data Recipes for State-of-the-Art Multimodal Medical Reasoning</h2></a><strong><u>Authors:</u></strong> Timothy Ossowski, Sheng Zhang, Qianchu Liu, Guanghui Qin, Reuben Tan, Tristan Naumann, Junjie Hu, Hoifung Poon<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> High-quality and carefully curated data is a cornerstone of training medical large language models, as it directly impacts both generalization and robustness to unseen clinical tasks. We investigate strategies for training and data curation to develop a robust multimodal reasoning model in the medical domain. Our work focuses on supervised fine-tuning (SFT) and explores data recipes that leverage structured reasoning traces. Using our proposed data recipe, we scale experiments to a dataset of over 8 million examples and 6.8 billion response tokens, achieving state-of-the-art performance among open-source models across diverse out-of-distribution medical benchmark tasks. Our results further indicate that curating a high-quality, diverse training dataset with varying structured reasoning trace lengths enables the fine-tuned model to self-calibrate its reasoning trajectory lengths based on the downstream task, without explicit supervision. We present key insights, describe the data curation strategy, and outline next steps toward developing robust medical vision-language reasoning system.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23264v1" target="_blank"><h2>BanglaSentNet: An Explainable Hybrid Deep Learning Framework for Multi-Aspect Sentiment Analysis with Cross-Domain Transfer Learning</h2></a><strong><u>Authors:</u></strong> Ariful Islam, Md Rifat Hossen, Tanvir Mahmud<br><strong><u>Categories:</u></strong> cs.LG, cs.CL<br><strong><u>Comments:</u></strong> Submitted to Springer Nature Computer Science (SNCS) as an extended version of our ICDSAIA 2025 conference paper<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), explainability (abstract), explainable (title, abstract), transfer learning (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Multi-aspect sentiment analysis of Bangla e-commerce reviews remains challenging due to limited annotated datasets, morphological complexity, code-mixing phenomena, and domain shift issues, affecting 300 million Bangla-speaking users. Existing approaches lack explainability and cross-domain generalization capabilities crucial for practical deployment. We present BanglaSentNet, an explainable hybrid deep learning framework integrating LSTM, BiLSTM, GRU, and BanglaBERT through dynamic weighted ensemble learning for multi-aspect sentiment classification. We introduce a dataset of 8,755 manually annotated Bangla product reviews across four aspects (Quality, Service, Price, Decoration) from major Bangladeshi e-commerce platforms. Our framework incorporates SHAP-based feature attribution and attention visualization for transparent insights. BanglaSentNet achieves 85% accuracy and 0.88 F1-score, outperforming standalone deep learning models by 3-7% and traditional approaches substantially. The explainability suite achieves 9.4/10 interpretability score with 87.6% human agreement. Cross-domain transfer learning experiments reveal robust generalization: zero-shot performance retains 67-76% effectiveness across diverse domains (BanglaBook reviews, social media, general e-commerce, news headlines); few-shot learning with 500-1000 samples achieves 90-95% of full fine-tuning performance, significantly reducing annotation costs. Real-world deployment demonstrates practical utility for Bangladeshi e-commerce platforms, enabling data-driven decision-making for pricing optimization, service improvement, and customer experience enhancement. This research establishes a new state-of-the-art benchmark for Bangla sentiment analysis, advances ensemble learning methodologies for low-resource languages, and provides actionable solutions for commercial applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23263v1" target="_blank"><h2>Macroscopic Dark Matter under siege: from White Dwarf Data to Gravitational Wave Detection <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Siyu Jiang, Aidi Yang, Fa Peng Huang<br><strong><u>Categories:</u></strong> astro-ph.HE, hep-ph<br><strong><u>Comments:</u></strong> 8+12 pages, 3+6 figures, 0+1 table, comments are welcome<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> The nature of dark matter (DM) remains a profound mystery. Macroscopic candidates, such as Fermi-balls, offer a distinct alternative to conventional particle DM, yet their low number density makes terrestrial detection challenging. In this work, we present a unified search strategy for sub-saturated Fermi-ball DM. We first revisit and significantly update astrophysical constraints from compact objects, utilizing rigorous expressions and additional white dwarf data related to ignition and subsequent supernovae. Crucially, we then explore novel signatures of Fermi-balls in future gravitational wave experiments like LISA and TianQin, performing detailed signal-to-noise ratio and Fisher matrix analyses. By combining these updated white dwarf/neutron star limits with the projected gravitational wave sensitivities, we derive the most comprehensive constraints on Fermi-ball parameter space to date, demonstrating the power of multi-messenger approaches for probing macroscopic DM.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23260v1" target="_blank"><h2>Time Series Forecasting via Direct Per-Step Probability Distribution Modeling</h2></a><strong><u>Authors:</u></strong> Linghao Kong, Xiaopeng Hong<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 16 pages, 8 figures. This is the preprint version of the paper and supplemental material to appear in AAAI, 2026. Please cite the final published version. Code is available atthis https URL<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Deep neural network-based time series prediction models have recently demonstrated superior capabilities in capturing complex temporal dependencies. However, it is challenging for these models to account for uncertainty associated with their predictions, because they directly output scalar values at each time step. To address such a challenge, we propose a novel model named interleaved dual-branch Probability Distribution Network (interPDN), which directly constructs discrete probability distributions per step instead of a scalar. The regression output at each time step is derived by computing the expectation of the predictive distribution on a predefined support set. To mitigate prediction anomalies, a dual-branch architecture is introduced with interleaved support sets, augmented by coarse temporal-scale branches for long-term trend forecasting. Outputs from another branch are treated as auxiliary signals to impose self-supervised consistency constraints on the current branch's prediction. Extensive experiments on multiple real-world datasets demonstrate the superior performance of interPDN.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23256v1" target="_blank"><h2>Robust HRRP Recognition under Interrupted Sampling Repeater Jamming using a Prior Jamming Information-Guided Network</h2></a><strong><u>Authors:</u></strong> Guozheng Sun, Lei Wang, Yanhao Wang, Jie Wang, Yimin Liu<br><strong><u>Categories:</u></strong> eess.SP, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Radar automatic target recognition (RATR) based on high-resolution range profile (HRRP) has attracted increasing attention due to its ability to capture fine-grained structural features. However, recognizing targets under electronic countermeasures (ECM), especially the mainstream interrupted-sampling repeater jamming (ISRJ), remains a significant challenge, as HRRPs often suffer from serious feature distortion. To address this, we propose a robust HRRP recognition method guided by prior jamming information. Specifically, we introduce a point spread function (PSF) as prior information to model the HRRP distortion induced by ISRJ. Based on this, we design a recognition network that leverages this prior through a prior-guided feature interaction module and a hybrid loss function to enhance the model's discriminative capability. With the aid of prior information, the model can learn invariant features within distorted HRRP under different jamming parameters. Both the simulated and measured-data experiments demonstrate that our method consistently outperforms state-of-the-art approaches and exhibits stronger generalization capabilities when facing unseen jamming parameters.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23243v1" target="_blank"><h2>Heteroscedastic Neural Networks for Path Loss Prediction with Link-Specific Uncertainty</h2></a><strong><u>Authors:</u></strong> Jonathan Ethier<br><strong><u>Categories:</u></strong> cs.LG, eess.SP<br><strong><u>Comments:</u></strong> Submitted to IEEE AWPL in December 2025. 5 pages, 2 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Traditional and modern machine learning-based path loss models typically assume a constant prediction variance. We propose a neural network that jointly predicts the mean and link-specific variance by minimizing a Gaussian negative log-likelihood, enabling heteroscedastic uncertainty estimates. We compare shared, partially shared, and independent-parameter architectures using accuracy, calibration, and sharpness metrics on blind test sets from large public RF drive-test datasets. The shared-parameter architecture performs best, achieving an RMSE of 7.4 dB, 95.1 percent coverage for 95 percent prediction intervals, and a mean interval width of 29.6 dB. These uncertainty estimates further support link-specific coverage margins, improve RF planning and interference analyses, and provide effective self-diagnostics of model weaknesses.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23239v1" target="_blank"><h2>Towards Understanding Transformers in Learning Random Walks</h2></a><strong><u>Authors:</u></strong> Wei Shi, Yuan Cao<br><strong><u>Categories:</u></strong> cs.LG, stat.ML<br><strong><u>Comments:</u></strong> 45 pages, 13 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> sequential data (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Transformers have proven highly effective across various applications, especially in handling sequential data such as natural languages and time series. However, transformer models often lack clear interpretability, and the success of transformers has not been well understood in theory. In this paper, we study the capability and interpretability of transformers in learning a family of classic statistical models, namely random walks on circles. We theoretically demonstrate that, after training with gradient descent, a one-layer transformer model can achieve optimal accuracy in predicting random walks. Importantly, our analysis reveals that the trained model is interpretable: the trained softmax attention serves as a token selector, focusing on the direct parent state; subsequently, the value matrix executes a one-step probability transition to predict the location of the next state based on this parent state. We also show that certain edge cases not covered by our theory are indeed failure cases, demonstrating that our theoretical conditions are tight. By investigating these success and failure cases, it is revealed that gradient descent with small initialization may fail or struggle to converge to a good solution in certain simple tasks even beyond random walks. Experiments are conducted to support our theoretical findings.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23238v1" target="_blank"><h2>SDE-Attention: Latent Attention in SDE-RNNs for Irregularly Sampled Time Series with Missing Data</h2></a><strong><u>Authors:</u></strong> Yuting Fang, Qouc Le Gia, Flora Salim<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 11 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Irregularly sampled time series with substantial missing observations are common in healthcare and sensor networks. We introduce SDE-Attention, a family of SDE-RNNs equipped with channel-level attention on the latent pre-RNN state, including channel recalibration, time-varying feature attention, and pyramidal multi-scale self-attention. We therefore conduct a comparison on a synthetic periodic dataset and real-world benchmarks, under varying missing rate. Latent-space attention consistently improves over a vanilla SDE-RNN. On the univariate UCR datasets, the LSTM-based time-varying feature model SDE-TVF-L achieves the highest average accuracy, raising mean performance by approximately 4, 6, and 10 percentage points over the baseline at 30%, 60% and 90% missingness, respectively (averaged across datasets). On multivariate UEA benchmarks, attention-augmented models again outperform the backbone, with SDE-TVF-L yielding up to a 7% gain in mean accuracy under high missingness. Among the proposed mechanisms, time-varying feature attention is the most robust on univariate datasets. On multivariate datasets, different attention types excel on different tasks, showing that SDE-Attention can be flexibly adapted to the structure of each problem.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23225v1" target="_blank"><h2>TWEO: Transformers Without Extreme Outliers Enables FP8 Training And Quantization For Dummies</h2></a><strong><u>Authors:</u></strong> Guang Liang, Jie Shao, Ningyuan Tang, Xinyao Liu, Jianxin Wu<br><strong><u>Categories:</u></strong> cs.CL, cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Native FP8 support in modern hardware is essential for training large Transformers, but is severely hindered by extreme activation outliers. Existing solutions either rely on complex mixed-precision engineering or invasive architectural modifications. This paper fundamentally challenges the conventional wisdom that outliers are data-driven. We demonstrate that extreme outliers are a data-independent, mechanically-produced artifact of training, originating from specific structural properties of the weight matrices (i.e., colinearity). Based on this insight, we propose TWEO (Transformers Without Extreme Outliers), a novel, non-invasive loss function. TWEO effectively prevents extreme outliers via a very simple loss term, which reduces outliers from 10000+ to less than 20. TWEO then enables full-model FP8 pre-training with neither engineering tricks nor architectural changes for both LLM and ViT. When standard FP8 training catastrophically collapses, TWEO achieves performance comparable to the BF16 baseline while delivering a 36% increase in training throughput. Also, TWEO enables a new quantization paradigm. Hardware-friendly W8A8 per-tensor static quantization of LLMs, previously considered completely unusable due to outliers, achieves SOTA performance for the first time on TWEO-trained models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23224v1" target="_blank"><h2>Nonstabilizerness Estimation using Graph Neural Networks</h2></a><strong><u>Authors:</u></strong> Vincenzo Lipardi, Domenica Dibenedetto, Georgios Stamoulis, Evert van Nieuwenburg, Mark H. M. Winands<br><strong><u>Categories:</u></strong> quant-ph, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> This article proposes a Graph Neural Network (GNN) approach to estimate nonstabilizerness in quantum circuits, measured by the stabilizer Rényi entropy (SRE). Nonstabilizerness is a fundamental resource for quantum advantage, and efficient SRE estimations are highly beneficial in practical applications. We address the nonstabilizerness estimation problem through three supervised learning formulations starting from easier classification tasks to the more challenging regression task. Experimental results show that the proposed GNN manages to capture meaningful features from the graph-based circuit representation, resulting in robust generalization performances achieved across diverse scenarios. In classification tasks, the GNN is trained on product states and generalizes on circuits evolved under Clifford operations, entangled states, and circuits with higher number of qubits. In the regression task, the GNN significantly improves the SRE estimation on out-of-distribution circuits with higher number of qubits and gate counts compared to previous work, for both random quantum circuits and structured circuits derived from the transverse-field Ising model. Moreover, the graph representation of quantum circuits naturally integrates hardware-specific information. Simulations on noisy quantum hardware highlight the potential of the proposed GNN to predict the SRE measured on quantum devices.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23205v1" target="_blank"><h2>A PLS-Integrated LASSO Method with Application in Index Tracking</h2></a><strong><u>Authors:</u></strong> Shiqin Tang, Yining Dong, S. Joe Qin<br><strong><u>Categories:</u></strong> stat.ML, cs.LG, stat.ME<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> dimension reduction (abstract)<br><p><strong><u>Abstract:</u></strong> In traditional multivariate data analysis, dimension reduction and regression have been treated as distinct endeavors. Established techniques such as principal component regression (PCR) and partial least squares (PLS) regression traditionally compute latent components as intermediary steps -- although with different underlying criteria -- before proceeding with the regression analysis. In this paper, we introduce an innovative regression methodology named PLS-integrated Lasso (PLS-Lasso) that integrates the concept of dimension reduction directly into the regression process. We present two distinct formulations for PLS-Lasso, denoted as PLS-Lasso-v1 and PLS-Lasso-v2, along with clear and effective algorithms that ensure convergence to global optima. PLS-Lasso-v1 and PLS-Lasso-v2 are compared with Lasso on the task of financial index tracking and show promising results.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23203v1" target="_blank"><h2>GAVINA: flexible aggressive undervolting for bit-serial mixed-precision DNN acceleration</h2></a><strong><u>Authors:</u></strong> Jordi Fornt, Pau Fontova-Musté, Adrian Gras, Omar Lahyani, Martí Caro, Jaume Abella, Francesc Moll, Josep Altet<br><strong><u>Categories:</u></strong> cs.AR, cs.AI<br><strong><u>Comments:</u></strong> Presented in the 2025 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED). Conference proceedings pending to be published<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Voltage overscaling, or undervolting, is an enticing approximate technique in the context of energy-efficient Deep Neural Network (DNN) acceleration, given the quadratic relationship between power and voltage. Nevertheless, its very high error rate has thwarted its general adoption. Moreover, recent undervolting accelerators rely on 8-bit arithmetic and cannot compete with state-of-the-art low-precision (<8b) architectures. To overcome these issues, we propose a new technique called Guarded Aggressive underVolting (GAV), which combines the ideas of undervolting and bit-serial computation to create a flexible approximation method based on aggressively lowering the supply voltage on a select number of least significant bit combinations. Based on this idea, we implement GAVINA (GAV mIxed-precisioN Accelerator), a novel architecture that supports arbitrary mixed precision and flexible undervolting, with an energy efficiency of up to 89 TOP/sW in its most aggressive configuration. By developing an error model of GAVINA, we show that GAV can achieve an energy efficiency boost of 20% via undervolting, with negligible accuracy degradation on ResNet-18.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23199v1" target="_blank"><h2>Vision Bridge Transformer at Scale</h2></a><strong><u>Authors:</u></strong> Zhenxiong Tan, Zeqing Wang, Xingyi Yang, Songhua Liu, Xinchao Wang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> We introduce Vision Bridge Transformer (ViBT), a large-scale instantiation of Brownian Bridge Models designed for conditional generation. Unlike traditional diffusion models that transform noise into data, Bridge Models directly model the trajectory between inputs and outputs, creating an efficient data-to-data translation paradigm. By scaling these models to 20B and 1.3B parameters, we demonstrate their effectiveness for image and video translation tasks. To support this scale, we adopt a Transformer architecture and propose a variance-stabilized velocity-matching objective for robust training. Together, these advances highlight the power of scaling Bridge Models for instruction-based image editing and complex video translation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23166v1" target="_blank"><h2>Energy-Efficient Vision Transformer Inference for Edge-AI Deployment</h2></a><strong><u>Authors:</u></strong> Nursultan Amanzhol, Jurn-Gyu Park<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> The growing deployment of Vision Transformers (ViTs) on energy-constrained devices requires evaluation methods that go beyond accuracy alone. We present a two-stage pipeline for assessing ViT energy efficiency that combines device-agnostic model selection with device-related measurements. We benchmark 13 ViT models on ImageNet-1K and CIFAR-10, running inference on NVIDIA Jetson TX2 (edge device) and an NVIDIA RTX 3050 (mobile GPU). The device-agnostic stage uses the NetScore metric for screening; the device-related stage ranks models with the Sustainable Accuracy Metric (SAM). Results show that hybrid models such as LeViT_Conv_192 reduce energy by up to 53% on TX2 relative to a ViT baseline (e.g., SAM5=1.44 on TX2/CIFAR-10), while distilled models such as TinyViT-11M_Distilled excel on the mobile GPU (e.g., SAM5=1.72 on RTX 3050/CIFAR-10 and SAM5=0.76 on RTX 3050/ImageNet-1K).</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23164v1" target="_blank"><h2>Bursty star formation, chemical enrichment, and star cluster formation in numerical analogues of GN-z11 <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Takayuki R. Saitoh, Yutaka Hirai, Michiko S. Fujii, Yuki Isobe<br><strong><u>Categories:</u></strong> astro-ph.GA<br><strong><u>Comments:</u></strong> 25 pages, 22 figures, submitted to PASJ<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> The James Webb Space Telescope reveals anomalous nitrogen enrichment (high N/O ratios) in compact, star-forming galaxies, such as GN-z11 at $z\sim10$. The origin of this chemical signature provides an insight into the early star and galaxy formation processes, yet remains unclear. We performed high-resolution cosmological zoom-in simulations of massive galaxies at high redshift ($z\sim10$) in rare density peaks, incorporating various chemical evolution channels including stellar winds, core-collapse, Type Ia supernovae, and asymptotic giant branch stars. Our simulations reproduce several key features of high-redshift galaxies: (1) stars form with high efficiencies ($>0.1$) at the center of rare peak halos, creating very compact galaxies similar to GN-z11; (2) high N/O ratios emerge during the first 10-20 Myr of intense starburst, before being diluted by CCSNe; (3) multiple star clusters form in and around the galaxy with high efficiency ($\sim20\%$), some of which exhibit high N/O ratios and sodium-oxygen anti-correlations similar to those observed in local globular clusters. Although our simulations can reproduce the high log(N/O) values (up to -0.61, exceeding the solar value by 0.25 dex), they remain below the observational lower limits of GN-z11, indicating room for improvement through additional chemical evolution channels, such as supermassive stars.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23158v1" target="_blank"><h2>REVEAL: Reasoning-enhanced Forensic Evidence Analysis for Explainable AI-generated Image Detection</h2></a><strong><u>Authors:</u></strong> Huangsen Cao, Qin Mei, Zhiheng Li, Yuxi Li, Ying Zhang, Chen Li, Zhimeng Zhang, Xin Ding, Yongwei Wang, Jing Lyu, Fei Wu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract), multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> With the rapid advancement of generative models, visually realistic AI-generated images have become increasingly difficult to distinguish from authentic ones, posing severe threats to social trust and information integrity. Consequently, there is an urgent need for efficient and truly explainable image forensic methods. Recent detection paradigms have shifted towards explainable forensics. However, state-of-the-art approaches primarily rely on post-hoc rationalizations or visual discrimination, lacking a verifiable chain of evidence. This reliance on surface-level pattern matching limits the generation of causally grounded explanations and often results in poor generalization. To bridge this critical gap, we introduce \textbf{REVEAL-Bench}, the first reasoning-enhanced multimodal benchmark for AI-generated image detection that is explicitly structured around a chain-of-evidence derived from multiple lightweight expert models, then records step-by-step reasoning traces and evidential justifications. Building upon this dataset, we propose \textbf{REVEAL} (\underline{R}easoning-\underline{e}nhanced Forensic E\underline{v}id\underline{e}nce \underline{A}na\underline{l}ysis), an effective and explainable forensic framework that integrates detection with a novel expert-grounded reinforcement learning. Our reward mechanism is specially tailored to jointly optimize detection accuracy, explanation fidelity, and logical coherence grounded in explicit forensic evidence, enabling REVEAL to produce fine-grained, interpretable, and verifiable reasoning chains alongside its detection outcomes. Extensive experimental results demonstrate that REVEAL significantly enhances detection accuracy, explanation fidelity, and robust cross-model generalization, benchmarking a new state of the art for explainable image forensics.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23142v1" target="_blank"><h2>Adapting Neural Audio Codecs to EEG</h2></a><strong><u>Authors:</u></strong> Ard Kastrati, Luca Lanzendörfer, Riccardo Rigoni, John Staib Matilla, Roger Wattenhofer<br><strong><u>Categories:</u></strong> cs.LG, cs.SD<br><strong><u>Comments:</u></strong> Foundation Models for the Brain and Body (BrainBodyFM@NeurIPS)<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> EEG and audio are inherently distinct modalities, differing in sampling rate, channel structure, and scale. Yet, we show that pretrained neural audio codecs can serve as effective starting points for EEG compression, provided that the data are preprocessed to be suitable to the codec's input constraints. Using DAC, a state-of-the-art neural audio codec as our base, we demonstrate that raw EEG can be mapped into the codec's stride-based framing, enabling direct reuse of the audio-pretrained encoder-decoder. Even without modification, this setup yields stable EEG reconstructions, and fine-tuning on EEG data further improves fidelity and generalization compared to training from scratch. We systematically explore compression-quality trade-offs by varying residual codebook depth, codebook (vocabulary) size, and input sampling rate. To capture spatial dependencies across electrodes, we propose DAC-MC, a multi-channel extension with attention-based cross-channel aggregation and channel-specific decoding, while retaining the audio-pretrained initialization. Evaluations on the TUH Abnormal and Epilepsy datasets show that the adapted codecs preserve clinically relevant information, as reflected in spectrogram-based reconstruction loss and downstream classification accuracy.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23135v1" target="_blank"><h2>Strategies to Minimize Out-of-Distribution Effects in Data-Driven MRS Quantification</h2></a><strong><u>Authors:</u></strong> Julian P. Merkofer, Antonia Kaiser, Anouk Schrantee, Oliver J. Gurney-Champion, Ruud J. G. van Sloun<br><strong><u>Categories:</u></strong> eess.SP, physics.med-ph, stat.ML<br><strong><u>Comments:</u></strong> Submitted to MRM<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> This study systematically compared data-driven and model-based strategies for metabolite quantification in magnetic resonance spectroscopy (MRS), focusing on resilience to out-of-distribution (OoD) effects and the balance between accuracy, robustness, and generalizability. A neural network designed for MRS quantification was trained using three distinct strategies: supervised regression, self-supervised learning, and test-time adaptation. These were compared against model-based fitting tools. Experiments combined large-scale simulated data, designed to probe metabolite concentration extrapolation and signal variability, with 1H single-voxel 7T in-vivo human brain spectra. In simulations, supervised learning achieved high accuracy for spectra similar to those in the training distribution, but showed marked degradation when extrapolated beyond the training distribution. Test-time adaptation proved more resilient to OoD effects, while self-supervised learning achieved intermediate performance. In-vivo experiments showed larger variance across the methods (data-driven and model-based) due to domain shift. Across all strategies, overlapping metabolites and baseline variability remained persistent challenges. While strong performance can be achieved by data-driven methods for MRS metabolite quantification, their reliability is contingent on careful consideration of the training distribution and potential OoD effects. When such conditions in the target distribution cannot be anticipated, test-time adaptation strategies ensure consistency between the quantification, the data, and the model, enabling reliable data-driven MRS pipelines.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23134v1" target="_blank"><h2>Blazar classification from multi-wavelength data using Deep Learning</h2></a><strong><u>Authors:</u></strong> Saqlain Afroz, Titir Mukherjee, Raj Prince<br><strong><u>Categories:</u></strong> astro-ph.HE<br><strong><u>Comments:</u></strong> 11 pages, 5 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The launch of the Fermi-LAT telescope has revolutionized gamma-ray astronomy by detecting over 7,000 gamma-ray emitting objects. A major fraction of the objects are blazars of known type, and a similar fraction of objects were classified as blazars of uncertain types (BCUs). Apart from that, some of the objects were found to be unassociated with any other classes, and no information is available in other wavebands. These types of objects are classified as unassociated objects in the Fermi catalog. To classify the unassociated objects into known categories and BCUs into a known type of blazar, numerous efforts have been made using the machine learning approach. The ideal way of classification would be to have multi-wavelength temporal and spectral information, which is nearly impossible to have for this number of objects in the near future. In this paper, we focus on classifying BCUs into other types of blazars, such as FSRQs and BL Lacs. For this purpose, we have developed for the first time a deep feed-forward Artificial Neural Network (ANN) to classify them, using multi-wavelength data. The complete understanding of blazars can only be known through multi-wavelength observation, and hence, we begin with four input parameters that cover broadband information (radio, optical, X-ray fluxes, and redshift) to train the neural network, and then extend the framework by including additional parameters to examine their impact on the outcome.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23120v1" target="_blank"><h2>Freeze, Diffuse, Decode: Geometry-Aware Adaptation of Pretrained Transformer Embeddings for Antimicrobial Peptide Design</h2></a><strong><u>Authors:</u></strong> Pankhil Gawade, Adam Izdebski, Myriam Lizotte, Kevin R. Moon, Jake S. Rhodes, Guy Wolf, Ewa Szczurek<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 16 pages, 4 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Pretrained transformers provide rich, general-purpose embeddings, which are transferred to downstream tasks. However, current transfer strategies: fine-tuning and probing, either distort the pretrained geometric structure of the embeddings or lack sufficient expressivity to capture task-relevant signals. These issues become even more pronounced when supervised data are scarce. Here, we introduce Freeze, Diffuse, Decode (FDD), a novel diffusion-based framework that adapts pre-trained embeddings to downstream tasks while preserving their underlying geometric structure. FDD propagates supervised signal along the intrinsic manifold of frozen embeddings, enabling a geometry-aware adaptation of the embedding space. Applied to antimicrobial peptide design, FDD yields low-dimensional, predictive, and interpretable representations that support property prediction, retrieval, and latent-space interpolation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23118v1" target="_blank"><h2>Machine learning for violence prediction: a systematic review and critical appraisal</h2></a><strong><u>Authors:</u></strong> Stefaniya Kozhevnikova, Denis Yukhnenko, Giulio Scola, Seena Fazel<br><strong><u>Categories:</u></strong> stat.ME, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> Purpose To conduct a systematic review of machine learning models for predicting violent behaviour by synthesising and appraising their validity, usefulness, and performance.
  Methods We systematically searched nine bibliographic databases and Google Scholar up to September 2025 for development and/or validation studies on machine learning methods for predicting all forms of violent behaviour. We synthesised the results by summarising discrimination and calibration performance statistics and evaluated study quality by examining risk of bias and clinical utility.
  Results We identified 38 studies reporting the development and validation of 40 models. Most studies reported Area Under the Curve (AUC) as the discrimination statistic with a range of 0.68-0.99. Only eight studies reported calibration performance, and three studies reported external validation. 31 studies had a high risk of bias, mainly in the analysis domain, and three studies had low risk of bias. The overall clinical utility of violence prediction models is poor, as indicated by risks of overfitting due to small samples, lack of transparent reporting, and low generalisability.
  Conclusion Although black box machine learning models currently have limited applicability in clinical settings, they may show promise for identifying high-risk individuals. We recommend five key considerations for violence prediction modelling: (i) ensuring methodological quality (e.g. following guidelines) and interdisciplinary collaborations; (ii) using black box algorithms only for highly complex data; (iii) incorporating dynamic predictions to allow for risk monitoring; (iv) developing more trustworthy algorithms using explainable methods; and (v) applying causal machine learning approaches where appropriate.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23113v1" target="_blank"><h2>db-SP: Accelerating Sparse Attention for Visual Generative Models with Dual-Balanced Sequence Parallelism</h2></a><strong><u>Authors:</u></strong> Siqi Chen, Ke Hong, Tianchen Zhao, Ruiqi Xie, Zhenhua Zhu, Xudong Zhang, Yu Wang<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Scaling Diffusion Transformer (DiT) inference via sequence parallelism is critical for reducing latency in visual generation, but is severely hampered by workload imbalance when applied to models employing block-wise sparse attention. The imbalance stems from the inherent variation in sparsity across attention heads and the irregular distribution of dense blocks within the sparse mask, when sequence parallelism is applied along the head dimension (as in Ulysses) or the block dimension (as in Ring Attention). In this paper, we formalize a sparse imbalance ratio to quantify the imbalance, and propose db-SP, a sparsity-aware sequence parallelism technique that tackles the challenge. db-SP contains a dual-level partitioning approach that achieves near-perfect workload balance at both the head and block levels with negligible overhead. Furthermore, to handle the evolving sparsity patterns across denoising steps and layers, db-SP dynamically determines the parallel degrees for the head and block dimensions at runtime. Experimental results demonstrate that db-SP delivers an end-to-end speedup of 1.25x and an attention-specific speedup of 1.40x over state-of-the-art sequence parallel methods on average. Code is available at https://github.com/thu-nics/db-SP.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23112v1" target="_blank"><h2>MathSight: A Benchmark Exploring Have Vision-Language Models Really Seen in University-Level Mathematical Reasoning?</h2></a><strong><u>Authors:</u></strong> Yuandong Wang, Yao Cui, Yuxin Zhao, Zhen Yang, Yangfu Zhu, Zhenzhou Shao<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> Comments: 32 pages, 15 figures, 9 tables, includes appendix. Project page:this https URL<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in Vision-Language Models (VLMs) have achieved impressive progress in multimodal mathematical reasoning. Yet, how much visual information truly contributes to reasoning remains unclear. Existing benchmarks report strong overall performance but seldom isolate the role of the image modality, leaving open whether VLMs genuinely leverage visual understanding or merely depend on linguistic priors. To address this, we present MathSight, a university-level multimodal mathematical reasoning benchmark designed to disentangle and quantify the effect of visual input. Each problem includes multiple visual variants -- original, hand-drawn, photo-captured -- and a text-only condition for controlled comparison. Experiments on state-of-the-art VLMs reveal a consistent trend: the contribution of visual information diminishes with increasing problem difficulty. Remarkably, Qwen3-VL without any image input surpasses both its multimodal variants and GPT-5, underscoring the need for benchmarks like MathSight to advance genuine vision-grounded reasoning in future models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23106v1" target="_blank"><h2>Consequences of radially correlated rotation curves for galaxy mass models <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Helena Chase, Diego Dado, Katherine E. Harborne, Kyle A. Oman<br><strong><u>Categories:</u></strong> astro-ph.GA<br><strong><u>Comments:</u></strong> Appendix C and python code file available in Ancillary files in right-hand panel<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Consecutive points in rotation curve measurements are correlated with each other, but this is usually ignored when constructing galaxy mass models. We apply the data-driven approach proposed by Posti (2022) to include the characteristic amplitude and scale length of such correlations as `nuisance parameters'. We construct mass models for $134$ galaxies from the SPARC rotation curve compilation with Navarro-Frenk-White (NFW) and pseudo-isothermal sphere (pISO) models for the dark halo. Allowing for correlations in the rotation curves generally improves the goodness of fit for both halo models, often yielding a formally good fit ($χ^2_\mathrm{r}\approx 1$) and model uncertainties that seem more representative of the constraining power of the data. For both halo models the inference on the typical correlation amplitude and scale length are very similar and physically plausible, $\sim 20\,\mathrm{km}\,\mathrm{s}^{-1}$ and $\sim 5\,\mathrm{kpc}$, respectively. The parametric form that we use to describe the correlations is intentionally simple, and our fitting approach makes the parameters describing possible correlations prone to `absorbing' other systematic errors, so we regard these estimates as upper limits. Without allowing for correlations we find a statistical preference for the pISO over the NFW model for $88$/$134$ galaxies; this preference essentially disappears when correlations are allowed for. Accounting for correlations in rotation curves when constructing mass models fundamentally affects how they are interpreted, highlighting an important systematic uncertainty that affects evidence for cusps or cores in dark matter haloes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23075v1" target="_blank"><h2>SpaceMind: Camera-Guided Modality Fusion for Spatial Reasoning in Vision-Language Models</h2></a><strong><u>Authors:</u></strong> Ruosen Zhao, Zhikang Zhang, Jialei Xu, Jiahao Chang, Dong Chen, Lingyun Li, Weijian Sun, Zizhuang Wei<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Large vision-language models (VLMs) show strong multimodal understanding but still struggle with 3D spatial reasoning, such as distance estimation, size comparison, and cross-view consistency. Existing 3D-aware methods either depend on auxiliary 3D information or enhance RGB-only VLMs with geometry encoders through shallow feature fusion. We propose SpaceMind, a multimodal large language model explicitly designed for spatial reasoning solely from RGB inputs. The model adopts a dual-encoder architecture, integrating VGGT as a spatial understanding encoder and InternViT as a 2D visual encoder. The key idea is to treat the camera representation as an active guiding modality rather than passive metadata. Specifically, SpaceMind introduces a lightweight Camera-Guided Modality Fusion module before the language model to replace shallow fusion. It applies camera-conditioned biasing to spatial tokens, assigns query-independent weights reflecting their geometric importance, and uses the camera embedding to gate the fused representation. Empirically, SpaceMind establishes new state-of-the-art results on VSI-Bench, SQA3D and SPBench, surpassing both open and proprietary systems on VSI-Bench and SPBench by large margins and achieving state-of-the-art performance on SQA3D. These results demonstrate that camera-guided modality fusion is an effective and practical inductive bias for equipping VLMs with genuinely spatially grounded intelligence. We will release code and model checkpoints to support future research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23070v1" target="_blank"><h2>Buffer replay enhances the robustness of multimodal learning under missing-modality</h2></a><strong><u>Authors:</u></strong> Hongye Zhu, Xuan Liu, Yanwen Ba, Jingye Xue, Shigeng Zhang<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), multi-modal (abstract), multi-modality (abstract)<br><p><strong><u>Abstract:</u></strong> Missing modalities consistently lead to significant performance degradation in multimodal models. Existing approaches either synthesize missing modalities at high computational cost or apply prompt-based fine-tuning that relies only on adjacent-layer features and overlooks long-distance contextual information, which may offer additional tolerance to errors when one or more modalities are missing. To address this, we introduce REplay Prompting (REP): (1) construct modality-wise feature buffers via a residual bypass to cache early-layer representations and replay them in deeper layers, mitigating information loss as network depth increases; (2) employ a private-shared feature decoupling strategy, where private buffers preserve modality-specific signals and shared buffers encode cross-modal semantics; and (3) design a task-aware dynamic initialization mechanism to configure these buffers differently, improving stability and generalization under diverse missing-modality conditions. Experiments on vision-language, vision-language-audio, and temporal multimodal benchmarks demonstrate that REP consistently outperforms prior methods under both single- and multi-modality missing scenarios, while introducing only negligible parameter overhead. These results establish REP as a lightweight and effective paradigm for robust multimodal learning in challenging missing-modality environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23057v1" target="_blank"><h2>Standard Occupation Classifier -- A Natural Language Processing Approach</h2></a><strong><u>Authors:</u></strong> Sidharth Rony, Jack Patman<br><strong><u>Categories:</u></strong> cs.CL, cs.LG, econ.GN<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Standard Occupational Classifiers (SOC) are systems used to categorize and classify different types of jobs and occupations based on their similarities in terms of job duties, skills, and qualifications. Integrating these facets with Big Data from job advertisement offers the prospect to investigate labour demand that is specific to various occupations. This project investigates the use of recent developments in natural language processing to construct a classifier capable of assigning an occupation code to a given job advertisement. We develop various classifiers for both UK ONS SOC and US O*NET SOC, using different Language Models. We find that an ensemble model, which combines Google BERT and a Neural Network classifier while considering job title, description, and skills, achieved the highest prediction accuracy. Specifically, the ensemble model exhibited a classification accuracy of up to 61% for the lower (or fourth) tier of SOC, and 72% for the third tier of SOC. This model could provide up to date, accurate information on the evolution of the labour market using job advertisements.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23055v1" target="_blank"><h2>MindPower: Enabling Theory-of-Mind Reasoning in VLM-based Embodied Agents</h2></a><strong><u>Authors:</u></strong> Ruoxuan Zhang, Qiyun Zheng, Zhiyu Zhou, Ziqi Liao, Siyu Wu, Jian-Yu Jiang-Lin, Bin Wen, Hongxia Xie, Jianlong Fu, Wen-Huang Cheng<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Theory of Mind (ToM) refers to the ability to infer others' mental states, such as beliefs, desires, and intentions. Current vision-language embodied agents lack ToM-based decision-making, and existing benchmarks focus solely on human mental states while ignoring the agent's own perspective, hindering coherent decision and action generation. To address this, we propose MindPower, a Robot-Centric framework integrating Perception, Mental Reasoning, Decision Making and Action. Given multimodal inputs, MindPower first perceives the environment and human states, then performs ToM Reasoning to model both self and others, and finally generates decisions and actions guided by inferred mental states. Furthermore, we introduce Mind-Reward, a novel optimization objective that encourages VLMs to produce consistent ToM Reasoning and behavior. Our model outperforms GPT-4o by 12.77% in decision making and 12.49% in action generation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23043v1" target="_blank"><h2>High-Resolution Probabilistic Data-Driven Weather Modeling with a Stretched-Grid</h2></a><strong><u>Authors:</u></strong> Even Marius Nordhagen, Håvard Homleid Haugen, Aram Farhad Shafiq Salihi, Magnus Sikora Ingstad, Thomas Nils Nipen, Ivar Ambjørn Seierstad, Inger-Lise Frogner, Mariana Clare, Simon Lang, Matthew Chantry, Peter Dueben, Jørn Kristiansen<br><strong><u>Categories:</u></strong> physics.ao-ph, cs.AI<br><strong><u>Comments:</u></strong> 14 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (title, abstract)<br><p><strong><u>Abstract:</u></strong> We present a probabilistic data-driven weather model capable of providing an ensemble of high spatial resolution realizations of 87 variables at arbitrary forecast length and ensemble size. The model uses a stretched grid, dedicating 2.5 km resolution to a region of interest, and 31 km resolution elsewhere. Based on a stochastic encoder-decoder architecture, the model is trained using a loss function based on the Continuous Ranked Probability Score (CRPS) evaluated point-wise in real and spectral space. The spectral loss components is shown to be necessary to create fields that are spatially coherent. The model is compared to high-resolution operational numerical weather prediction forecasts from the MetCoOp Ensemble Prediction System (MEPS), showing competitive forecasts when evaluated against observations from surface weather stations. The model produced fields that are more spatially coherent than mean squared error based models and CRPS based models without the spectral component in the loss.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23037v1" target="_blank"><h2>Time Extrapolation with Graph Convolutional Autoencoder and Tensor Train Decomposition</h2></a><strong><u>Authors:</u></strong> Yuanhong Chen, Federico Pichi, Zhen Gao, Gianluigi Rozza<br><strong><u>Categories:</u></strong> math.NA, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), attention (abstract), causality (abstract)<br><p><strong><u>Abstract:</u></strong> Graph autoencoders have gained attention in nonlinear reduced-order modeling of parameterized partial differential equations defined on unstructured grids. Despite they provide a geometrically consistent way of treating complex domains, applying such architectures to parameterized dynamical systems for temporal prediction beyond the training data, i.e. the extrapolation regime, is still a challenging task due to the simultaneous need of temporal causality and generalizability in the parametric space. In this work, we explore the integration of graph convolutional autoencoders (GCAs) with tensor train (TT) decomposition and Operator Inference (OpInf) to develop a time-consistent reduced-order model. In particular, high-fidelity snapshots are represented as a combination of parametric, spatial, and temporal cores via TT decomposition, while OpInf is used to learn the evolution of the latter. Moreover, we enhance the generalization performance by developing a multi-fidelity two-stages approach in the framework of Deep Operator Networks (DeepONet), treating the spatial and temporal cores as the trunk networks, and the parametric core as the branch network. Numerical results, including heat-conduction, advection-diffusion and vortex-shedding phenomena, demonstrate great performance in effectively learning the dynamic in the extrapolation regime for complex geometries, also in comparison with state-of-the-art approaches e.g. MeshGraphNets.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23036v1" target="_blank"><h2>Delta-XAI: A Unified Framework for Explaining Prediction Changes in Online Time Series Monitoring</h2></a><strong><u>Authors:</u></strong> Changhun Kim, Yechan Mun, Hyeongwon Jang, Eunseo Lee, Sangchul Hahn, Eunho Yang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Under review at ICLR 2026<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> explainability (abstract)<br><p><strong><u>Abstract:</u></strong> Explaining online time series monitoring models is crucial across sensitive domains such as healthcare and finance, where temporal and contextual prediction dynamics underpin critical decisions. While recent XAI methods have improved the explainability of time series models, they mostly analyze each time step independently, overlooking temporal dependencies. This results in further challenges: explaining prediction changes is non-trivial, methods fail to leverage online dynamics, and evaluation remains difficult. To address these challenges, we propose Delta-XAI, which adapts 14 existing XAI methods through a wrapper function and introduces a principled evaluation suite for the online setting, assessing diverse aspects, such as faithfulness, sufficiency, and coherence. Experiments reveal that classical gradient-based methods, such as Integrated Gradients (IG), can outperform recent approaches when adapted for temporal analysis. Building on this, we propose Shifted Window Integrated Gradients (SWING), which incorporates past observations in the integration path to systematically capture temporal dependencies and mitigate out-of-distribution effects. Extensive experiments consistently demonstrate the effectiveness of SWING across diverse settings with respect to diverse metrics. Our code is publicly available at https://anonymous.4open.science/r/Delta-XAI.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.23007v1" target="_blank"><h2>A transfer learning approach for automatic conflicts detection in software requirement sentence pairs based on dual encoders</h2></a><strong><u>Authors:</u></strong> Yizheng Wang, Tao Jiang, Jinyan Bai, Zhengbin Zou, Tiancheng Xue, Nan Zhang, Jie Luan<br><strong><u>Categories:</u></strong> cs.SE, cs.AI<br><strong><u>Comments:</u></strong> 22 pages, 7 figures, 3 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transfer learning (title, abstract)<br><p><strong><u>Abstract:</u></strong> Software Requirement Document (RD) typically contain tens of thousands of individual requirements, and ensuring consistency among these requirements is critical for the success of software engineering projects. Automated detection methods can significantly enhance efficiency and reduce costs; however, existing approaches still face several challenges, including low detection accuracy on imbalanced data, limited semantic extraction due to the use of a single encoder, and suboptimal performance in cross-domain transfer learning. To address these issues, this paper proposes a Transferable Software Requirement Conflict Detection Framework based on SBERT and SimCSE, termed TSRCDF-SS. First, the framework employs two independent encoders, Sentence-BERT (SBERT) and Simple Contrastive Sentence Embedding (SimCSE), to generate sentence embeddings for requirement pairs, followed by a six-element concatenation strategy. Furthermore, the classifier is enhanced by a two-layer fully connected feedforward neural network (FFNN) with a hybrid loss optimization strategy that integrates a variant of Focal Loss, domain-specific constraints, and a confidence-based penalty term. Finally, the framework synergistically integrates sequential and cross-domain transfer learning. Experimental results demonstrate that the proposed framework achieves a 10.4% improvement in both macro-F1 and weighted-F1 scores in in-domain settings, and an 11.4% increase in macro-F1 in cross-domain scenarios.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22998v1" target="_blank"><h2>TIM-PRM: Verifying multimodal reasoning with Tool-Integrated PRM</h2></a><strong><u>Authors:</u></strong> Peng Kuang, Xiangxiang Wang, Wentao Liu, Jian Dong, Kaidi Xu, Haohan Wang<br><strong><u>Categories:</u></strong> cs.AI<br><strong><u>Comments:</u></strong> 14 pages<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Large Language Models (MLLMs) have achieved impressive performances in mathematical reasoning, yet they remain vulnerable to visual hallucinations and logical inconsistencies that standard outcome-based supervision fails to mitigate. While Process Reward Models (PRMs) promise step-by-step verification, current approaches typically operate as scalar scorers or generative critics that suffer from sycophancy, blindly validating the flawed hypotheses rather than grounding them in visual reality. To bridge this gap, we introduce TIM-PRM (Tool-Integrated Multimodal PRM), a novel agentic framework that transforms verification from a passive classification task into an active, tool-augmented investigation. TIM-PRM is trained to explicitly plan verification strategies and utilizes a mechanism of Independent Question Asking to query evidence via external tools, effectively decoupling verification from the reasoning context to eliminate confirmation bias. We instantiate this method by curating a high-quality dataset of tool-integrated verification trajectories. Extensive experiments on VisualProcessBench demonstrate that our 8B parameter model surpasses existing open-source multimodal PRMs, significantly outperforming much larger models like Qwen2.5-72B and InternVL-78B, while offering interpretable insights into the verification process.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22987v1" target="_blank"><h2>Incorporating neutron star physics into gravitational wave inference with neural priors <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Thibeau Wouters, Peter T. H. Pang, Tim Dietrich, Chris Van Den Broeck<br><strong><u>Categories:</u></strong> astro-ph.HE, gr-qc, hep-ph<br><strong><u>Comments:</u></strong> 19 pages, 7 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Bayesian inference, widely used in gravitational-wave parameter estimation, depends on the choice of priors, i.e., on our previously existing knowledge. However, to investigate neutron star mergers, priors are often chosen in an agnostic way, leaving valuable information from nuclear physics and independent observations of neutron stars unused. In this work, we propose to encode information on neutron star physics into data-driven prior distributions constructed with normalizing flows, referred to as neural priors. These priors take input from constraints on the nuclear equation of state and neutron star population models. Applied to GW170817, GW190425, and GW230529, we highlight two contributions of the framework. First, we demonstrate its ability to provide source classification and to enable model selection of equation of state constraints for loud signals such as GW170817, directly from the gravitational-wave data. Second, we obtain narrower constraints on the source properties through these informed priors. As a result, the neural priors consistently recover higher luminosity distances compared to agnostic priors. Our method paves the way for classifying future ambiguous low-mass mergers observed through gravitational waves and for continuously incorporating advances in our understanding of neutron star properties into gravitational-wave data analysis.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22982v1" target="_blank"><h2>Ovis-Image Technical Report</h2></a><strong><u>Authors:</u></strong> Guo-Hua Wang, Liangfu Cao, Tianyu Cui, Minghao Fu, Xiaohao Chen, Pengxin Zhan, Jianshan Zhao, Lan Li, Bowen Fu, Jiaqi Liu, Qing-Guo Chen<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Code is released atthis https URL<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> We introduce $\textbf{Ovis-Image}$, a 7B text-to-image model specifically optimized for high-quality text rendering, designed to operate efficiently under stringent computational constraints. Built upon our previous Ovis-U1 framework, Ovis-Image integrates a diffusion-based visual decoder with the stronger Ovis 2.5 multimodal backbone, leveraging a text-centric training pipeline that combines large-scale pre-training with carefully tailored post-training refinements. Despite its compact architecture, Ovis-Image achieves text rendering performance on par with significantly larger open models such as Qwen-Image and approaches closed-source systems like Seedream and GPT4o. Crucially, the model remains deployable on a single high-end GPU with moderate memory, narrowing the gap between frontier-level text rendering and practical deployment. Our results indicate that combining a strong multimodal backbone with a carefully designed, text-focused training recipe is sufficient to achieve reliable bilingual text rendering without resorting to oversized or proprietary models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22977v1" target="_blank"><h2>Pooling Attention: Evaluating Pretrained Transformer Embeddings for Deception Classification</h2></a><strong><u>Authors:</u></strong> Sumit Mamtani, Abhijeet Bhure<br><strong><u>Categories:</u></strong> cs.CL, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Accepted at the IEEE 7th Computing, Communications and IoT Applications Conference (ComComAp 2025), Madrid, Spain, December 2025. 6 pages<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> This paper investigates fake news detection as a downstream evaluation of Transformer representations, benchmarking encoder-only and decoder-only pre-trained models (BERT, GPT-2, Transformer-XL) as frozen embedders paired with lightweight classifiers. Through controlled preprocessing comparing pooling versus padding and neural versus linear heads, results demonstrate that contextual self-attention encodings consistently transfer effectively. BERT embeddings combined with logistic regression outperform neural baselines on LIAR dataset splits, while analyses of sequence length and aggregation reveal robustness to truncation and advantages from simple max or average pooling. This work positions attention-based token encoders as robust, architecture-centric foundations for veracity tasks, isolating Transformer contributions from classifier complexity.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22938v1" target="_blank"><h2>CORGI: GNNs with Convolutional Residual Global Interactions for Lagrangian Simulation</h2></a><strong><u>Authors:</u></strong> Ethan Ji, Yuanzhou Chen, Arush Ramteke, Fang Sun, Tianrun Yu, Jai Parera, Wei Wang, Yizhou Sun<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract)<br><p><strong><u>Abstract:</u></strong> Partial differential equations (PDEs) are central to dynamical systems modeling, particularly in hydrodynamics, where traditional solvers often struggle with nonlinearity and computational cost. Lagrangian neural surrogates such as GNS and SEGNN have emerged as strong alternatives by learning from particle-based simulations. However, these models typically operate with limited receptive fields, making them inaccurate for capturing the inherently global interactions in fluid flows. Motivated by this observation, we introduce Convolutional Residual Global Interactions (CORGI), a hybrid architecture that augments any GNN-based solver with a lightweight Eulerian component for global context aggregation. By projecting particle features onto a grid, applying convolutional updates, and mapping them back to the particle domain, CORGI captures long-range dependencies without significant overhead. When applied to a GNS backbone, CORGI achieves a 57% improvement in rollout accuracy with only 13% more inference time and 31% more training time. Compared to SEGNN, CORGI improves accuracy by 49% while reducing inference time by 48% and training time by 30%. Even under identical runtime constraints, CORGI outperforms GNS by 47% on average, highlighting its versatility and performance on varied compute budgets.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22923v1" target="_blank"><h2>SN 2021ukt: A Transitional Supernova with a Short Plateau and Persistent Interaction</h2></a><strong><u>Authors:</u></strong> Neil R. Pichay, Sergiy S. Vasylyev, Audrey M. Liddle, Alexei V. Filippenko, WeiKang Zheng, Thomas G. Brink, Yi Yang, Matthew Graham, Daniel Stern, Daichi Hiramatsu, Claudia P. Gutiérrez, K. Azalee Bostroem, Estefania Padilla Gonzalez, D. Andrew Howell, Curtis McCully, Megan Newsome, Craig Pellegrino, Giacomo Terreran, Ivan Altunin, Raphael Baer-Way, Vidhi Chandler, Asia A. deGraw, Connor F. Jennings, Michael B. May<br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.HE<br><strong><u>Comments:</u></strong> 16 pages, 9 figures, 2 tables<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> We present spectroscopic and photometric observations of supernova (SN) 2021ukt, a peculiar short-plateau object that was originally identified as a Type IIn SN and later underwent an unprecedented transition to a Type Ib (possibly Type IIb) SN. The early-time light curves of SN 2021ukt exhibit a ~25 day plateau. Such a short phase of hydrogen recombination suggests a rather thin H-rich outer envelope of the progenitor star. The relatively narrow Balmer emission lines in spectra of SN 2021ukt during the first week indicate the interaction between the expanding ejecta and the immediate circumstellar material (CSM). This Hα line is observed throughout its helium-rich ejecta-dominated phase and nebular phase, suggesting persistent interaction with a radially extended CSM profile. We explore the synthetic light-curve model among grids of parameters generated by MESA+STELLA. We also compare the spectrophotometric evolution of SN 2021ukt with several well-sampled supernovae that exhibit a short plateau and persistent ejecta-CSM interaction. An estimate of the progenitor mass of SN 2021ukt is made based on the flux ratio between [Ca II] λλ 7291, 7324 and [O I] λλ 6300, 6364 during its nebular phase. Our analysis suggests that the progenitor star of SN 2021ukt has a zero-age main-sequence (ZAMS) mass of about 12 solar masses, a mass of radioactive nickel-56 synthesized in the SN ejecta of about 0.04 solar masses, and a mass of the H-rich envelope of about 0.5 solar masses. This study adds to the growing sample of transitional supernovae, reinforcing evidence for a continuum of underrepresented progenitors whose evolutionary pathways lie between those of standard SN models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22913v1" target="_blank"><h2>Optical diffraction neural networks assisted computational ghost imaging through dynamic scattering media</h2></a><strong><u>Authors:</u></strong> Yue-Gang Li, Ze Zheng, Jun-jie Wang, Ming He, Jianping Fan, Tailong Xiao, Guihua Zeng<br><strong><u>Categories:</u></strong> physics.optics, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Ghost imaging leverages a single-pixel detector with no spatial resolution to acquire object echo intensity signals, which are correlated with illumination patterns to reconstruct an image. This architecture inherently mitigates scattering interference between the object and the detector but sensitive to scattering between the light source and the object. To address this challenge, we propose an optical diffraction neural networks (ODNNs) assisted ghost imaging method for imaging through dynamic scattering media. In our scheme, a set of fixed ODNNs, trained on simulated datasets, is incorporated into the experimental optical path to actively correct random distortions induced by dynamic scattering media. Experimental validation using rotating single-layer and double-layer ground glass confirms the feasibility and effectiveness of our approach. Furthermore, our scheme can also be combined with physics-prior-based reconstruction algorithms, enabling high-quality imaging under undersampled conditions. This work demonstrates a novel strategy for imaging through dynamic scattering media, which can be extended to other imaging systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22904v1" target="_blank"><h2>Language-conditioned world model improves policy generalization by reading environmental descriptions</h2></a><strong><u>Authors:</u></strong> Anh Nguyen, Stefan Lee<br><strong><u>Categories:</u></strong> cs.CL, cs.LG<br><strong><u>Comments:</u></strong> NeuRIPS 2025. Workshop: LAW 2025: Bridging Language, Agent, and World Models<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> To interact effectively with humans in the real world, it is important for agents to understand language that describes the dynamics of the environment--that is, how the environment behaves--rather than just task instructions specifying "what to do". Understanding this dynamics-descriptive language is important for human-agent interaction and agent behavior. Recent work address this problem using a model-based approach: language is incorporated into a world model, which is then used to learn a behavior policy. However, these existing methods either do not demonstrate policy generalization to unseen games or rely on limiting assumptions. For instance, assuming that the latency induced by inference-time planning is tolerable for the target task or expert demonstrations are available. Expanding on this line of research, we focus on improving policy generalization from a language-conditioned world model while dropping these assumptions. We propose a model-based reinforcement learning approach, where a language-conditioned world model is trained through interaction with the environment, and a policy is learned from this model--without planning or expert demonstrations. Our method proposes Language-aware Encoder for Dreamer World Model (LED-WM) built on top of DreamerV3. LED-WM features an observation encoder that uses an attention mechanism to explicitly ground language descriptions to entities in the observation. We show that policies trained with LED-WM generalize more effectively to unseen games described by novel dynamics and language compared to other baselines in several settings in two environments: MESSENGER and MESSENGER-WM.To highlight how the policy can leverage the trained world model before real-world deployment, we demonstrate the policy can be improved through fine-tuning on synthetic test trajectories generated by the world model.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22887v1" target="_blank"><h2>Modeling Chaotic Pedestrian Behavior Using Chaos Indicators and Supervised Learning</h2></a><strong><u>Authors:</u></strong> Md. Muhtashim Shahrier, Nazmul Haque, Md Asif Raihan, Md. Hadiuzzaman<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> As cities around the world aim to improve walkability and safety, understanding the irregular and unpredictable nature of pedestrian behavior has become increasingly important. This study introduces a data-driven framework for modeling chaotic pedestrian movement using empirically observed trajectory data and supervised learning. Videos were recorded during both daytime and nighttime conditions to capture pedestrian dynamics under varying ambient and traffic contexts. Pedestrian trajectories were extracted through computer vision techniques, and behavioral chaos was quantified using four chaos metrics: Approximate Entropy and Lyapunov Exponent, each computed for both velocity and direction change. A Principal Component Analysis (PCA) was then applied to consolidate these indicators into a unified chaos score. A comprehensive set of individual, group-level, and contextual traffic features was engineered and used to train Random Forest and CatBoost regression models. CatBoost models consistently achieved superior performance. The best daytime PCA-based CatBoost model reached an R^2 of 0.8319, while the nighttime PCA-based CatBoost model attained an R^2 of 0.8574. SHAP analysis highlighted that features such as distance travel, movement duration, and speed variability were robust contributors to chaotic behavior. The proposed framework enables practitioners to quantify and anticipate behavioral instability in real-world settings. Planners and engineers can use chaos scores to identify high-risk pedestrian zones, apprise infrastructure improvements, and calibrate realistic microsimulation models. The approach also supports adaptive risk assessment in automated vehicle systems by capturing short-term motion unpredictability grounded in observable, interpretable features.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22866v1" target="_blank"><h2>ARM-Explainer -- Explaining and improving graph neural network predictions for the maximum clique problem using node features and association rule mining</h2></a><strong><u>Authors:</u></strong> Bharat Sharman, Elkafi Hassini<br><strong><u>Categories:</u></strong> cs.LG, math.OC<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Numerous graph neural network (GNN)-based algorithms have been proposed to solve graph-based combinatorial optimization problems (COPs), but methods to explain their predictions remain largely undeveloped. We introduce ARM-Explainer, a post-hoc, model-level explainer based on association rule mining, and demonstrate it on the predictions of the hybrid geometric scattering (HGS) GNN for the maximum clique problem (MCP), a canonical NP-hard graph-based COP. The eight most explanatory association rules discovered by ARM-Explainer achieve high median lift and confidence values of 2.42 and 0.49, respectively, on test instances from the TWITTER and BHOSLIB-DIMACS benchmark datasets. ARM-Explainer identifies the most important node features, together with their value ranges, that influence the GNN's predictions on these datasets. Furthermore, augmenting the GNN with informative node features substantially improves its performance on the MCP, increasing the median largest-found clique size by 22% (from 29.5 to 36) on large graphs from the BHOSLIB-DIMACS dataset.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22862v1" target="_blank"><h2>Bridging Modalities via Progressive Re-alignment for Multimodal Test-Time Adaptation</h2></a><strong><u>Authors:</u></strong> Jiacheng Li, Songhe Feng<br><strong><u>Categories:</u></strong> cs.LG, cs.CV<br><strong><u>Comments:</u></strong> Accepted by AAAI 2026 (Oral)<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Test-time adaptation (TTA) enables online model adaptation using only unlabeled test data, aiming to bridge the gap between source and target distributions. However, in multimodal scenarios, varying degrees of distribution shift across different modalities give rise to a complex coupling effect of unimodal shallow feature shift and cross-modal high-level semantic misalignment, posing a major obstacle to extending existing TTA methods to the multimodal field. To address this challenge, we propose a novel multimodal test-time adaptation (MMTTA) framework, termed as Bridging Modalities via Progressive Re-alignment (BriMPR). BriMPR, consisting of two progressively enhanced modules, tackles the coupling effect with a divide-and-conquer strategy. Specifically, we first decompose MMTTA into multiple unimodal feature alignment sub-problems. By leveraging the strong function approximation ability of prompt tuning, we calibrate the unimodal global feature distributions to their respective source distributions, so as to achieve the initial semantic re-alignment across modalities. Subsequently, we assign the credible pseudo-labels to combinations of masked and complete modalities, and introduce inter-modal instance-wise contrastive learning to further enhance the information interaction among modalities and refine the alignment. Extensive experiments on MMTTA tasks, including both corruption-based and real-world domain shift benchmarks, demonstrate the superiority of our method. Our source code is available at [this URL](https://github.com/Luchicken/BriMPR).</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22854v1" target="_blank"><h2>CRAwDAD: Causal Reasoning Augmentation with Dual-Agent Debate</h2></a><strong><u>Authors:</u></strong> Finn G. Vamosi, Nils D. Forkert<br><strong><u>Categories:</u></strong> cs.LG, cs.MA<br><strong><u>Comments:</u></strong> 12 pages, 8 figures. Code available atthis https URL<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> causation (abstract)<br><p><strong><u>Abstract:</u></strong> When people reason about cause and effect, they often consider many competing "what if" scenarios before deciding which explanation fits best. Analogously, advanced language models capable of causal inference can consider multiple interventions and counterfactuals to judge the validity of causal claims. Crucially, this type of reasoning is less like a single calculation and more like an internal dialogue between alternative hypotheses. In this paper, we make this dialogue explicit through a dual-agent debate framework where one model provides a structured causal inference, and the other critically examines this reasoning for logical flaws. When disagreements arise, agents attempt to persuade each other, challenging each other's logic and revising their conclusions until they converge on a mutually agreed answer. To take advantage of this deliberative process, we specifically use reasoning language models, whose strengths in both causal inference and adversarial debate remain under-explored relative to standard large language models. We evaluate our approach on the CLadder dataset, a benchmark linking natural language questions to formally defined causal graphs across all three rungs of Pearl's ladder of causation. With Qwen3 and DeepSeek-R1 as debater agents, we demonstrate that multi-agent debate improves DeepSeek-R1's overall accuracy in causal inference from 78.03% to 87.45%, with the counterfactual category specifically improving from 67.94% to 80.04% accuracy. Similarly, Qwen3's overall accuracy improves from 84.16% to 89.41%, and counterfactual questions from 71.53% to 80.35%, showing that strong models can still benefit greatly from debate with weaker agents. Our results highlight the potential of reasoning models as building blocks for multi-agent systems in causal inference, and demonstrate the importance of diverse perspectives in causal problem-solving.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22853v1" target="_blank"><h2>TARFVAE: Efficient One-Step Generative Time Series Forecasting via TARFLOW based VAE</h2></a><strong><u>Authors:</u></strong> Jiawen Wei, Lan Jiang, Pengbo Wei, Ziwen Ye, Teng Song, Chen Chen, Guangrui Ma<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), latent space (abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Time series data is ubiquitous, with forecasting applications spanning from finance to healthcare. Beyond popular deterministic methods, generative models are gaining attention due to advancements in areas like image synthesis and video generation, as well as their inherent ability to provide probabilistic predictions. However, existing generative approaches mostly involve recurrent generative operations or repeated denoising steps, making the prediction laborious, particularly for long-term forecasting. Most of them only conduct experiments for relatively short-term forecasting, with limited comparison to deterministic methods in long-term forecasting, leaving their practical advantages unclear. This paper presents TARFVAE, a novel generative framework that combines the Transformer-based autoregressive flow (TARFLOW) and variational autoencoder (VAE) for efficient one-step generative time series forecasting. Inspired by the rethinking that complex architectures for extracting time series representations might not be necessary, we add a flow module, TARFLOW, to VAE to promote spontaneous learning of latent variables that benefit predictions. TARFLOW enhances VAE's posterior estimation by breaking the Gaussian assumption, thereby enabling a more informative latent space. TARFVAE uses only the forward process of TARFLOW, avoiding autoregressive inverse operations and thus ensuring fast generation. During generation, it samples from the prior latent space and directly generates full-horizon forecasts via the VAE decoder. With simple MLP modules, TARFVAE achieves superior performance over state-of-the-art deterministic and generative models across different forecast horizons on benchmark datasets while maintaining efficient prediction speed, demonstrating its effectiveness as an efficient and powerful solution for generative time series forecasting.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22849v1" target="_blank"><h2>PerfMamba: Performance Analysis and Pruning of Selective State Space Models</h2></a><strong><u>Authors:</u></strong> Abdullah Al Asif, Mobina Kashaniyan, Sixing Yu, Juan Pablo Muñoz, Ali Jannesari<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Accepted in Bench 2025<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Recent advances in sequence modeling have introduced selective SSMs as promising alternatives to Transformer architectures, offering theoretical computational efficiency and sequence processing advantages. A comprehensive understanding of selective SSMs in runtime behavior, resource utilization patterns, and scaling characteristics still remains unexplored, thus obstructing their optimal deployment and further architectural improvements. This paper presents a thorough empirical study of Mamba-1 and Mamba-2, systematically profiled for performance to assess the design principles that contribute to their efficiency in state-space modeling. A detailed analysis of computation patterns, memory access, I/O characteristics, and scaling properties was performed for sequence lengths ranging from 64 to 16384 tokens. Our findings show that the SSM component, a central part of the selective SSM architecture, demands a significant portion of computational resources compared to other components in the Mamba block. Based on these insights, we propose a pruning technique that selectively removes low-activity states within the SSM component, achieving measurable throughput and memory gains while maintaining accuracy within a moderate pruning regime. This approach results in performance improvements across varying sequence lengths, achieving a 1.14x speedup and reducing memory usage by 11.50\%. These results offer valuable guidance for designing more efficient SSM architectures that can be applied to a wide range of real-world applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22828v1" target="_blank"><h2>Fast dynamical similarity analysis</h2></a><strong><u>Authors:</u></strong> Arman Behrad, Mitchell Ostrow, Mohammad Taha Fakharian, Ila Fiete, Christian Beste, Shervin Safavi<br><strong><u>Categories:</u></strong> cs.AI, q-bio.NC<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> To understand how neural systems process information, it is often essential to compare one circuit with another, one brain with another, or data with a model. Traditional similarity measures ignore the dynamical processes underlying neural representations. Dynamical similarity methods offer a framework to compare the temporal structure of dynamical systems by embedding their (possibly) nonlinear dynamics into a globally linear space and there computing conjugacy metrics. However, identifying the best embedding and computing these metrics can be computationally slow. Here we introduce fast Dynamical Similarity Analysis (fastDSA), which is computationally far more efficient than previous methods while maintaining their accuracy and robustness. FastDSA introduces two key components that boost efficiency: (1) automatic selection of the effective model order of the Hankel (delay) embedding from the data via a data-driven singular-value threshold that identifies the informative subspace and discards noise to lower computational cost without sacrificing signal, and (2) a novel optimization procedure and objective, which replaces the slow exact orthogonality constraint in finding a minimal distance between dynamics matrices with a lightweight process to keep the search close to the space of orthogonal transformations. We demonstrate that fastDSA is at least an order of magnitude faster than the previous methods. Furthermore, we demonstrate that fastDSA has the properties of its ancestor, including its invariances and sensitivities to system dynamics. FastDSA, therefore, provides a computationally efficient and accurate method for dynamical similarity analysis.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22819v1" target="_blank"><h2>Resolving Sharp Gradients of Unstable Singularities to Machine Precision via Neural Networks</h2></a><strong><u>Authors:</u></strong> Yongji Wang, Tristan Léger, Ching-Yao Lai, Tristan Buckmaster<br><strong><u>Categories:</u></strong> math.AP, cs.LG, physics.flu-dyn<br><strong><u>Comments:</u></strong> 27 pages, 12 figures<br><strong><u>Published:</u></strong> 2025-11-28<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Recent work introduced a robust computational framework combining embedded mathematical structures, advanced optimization, and neural network architecture, leading to the discovery of multiple unstable self-similar solutions for key fluid dynamics equations, including the Incompressible Porous Media (IPM) and 2D Boussinesq systems. While this framework confirmed the existence of these singularities, an accuracy level approaching double-float machine precision was only achieved for stable and 1st unstable solutions of the 1D Córdoba-Córdoba-Fontelos model. For highly unstable solutions characterized by extreme gradients, the accuracy remained insufficient for validation. The primary obstacle is the presence of sharp solution gradients. Those gradients tend to induce large, localized PDE residuals during training, which not only hinder convergence, but also obscure the subtle signals near the origin required to identify the correct self-similar scaling parameter lambda of the solutions. In this work, we introduce a gradient-normalized PDE residual re-weighting scheme to resolve the high-gradient challenge while amplifying the critical residual signals at the origin for lambda identification. Coupled with the multi-stage neural network architecture, the PDE residuals are reduced to the level of round-off error across a wide spectrum of unstable self-similar singularities previously discovered. Furthermore, our method enables the discovery of new highly unstable singularities, i.e. the 4th unstable solution for IPM equations and a novel family of highly unstable solitons for the Nonlinear Schrödinger equations. This results in achieving high-gradient solutions with high precision, providing an important ingredient for bridging the gap between numerical discovery and computer-assisted proofs for unstable phenomena in nonlinear PDEs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22813v1" target="_blank"><h2>Intelligent Neural Networks: From Layered Architectures to Graph-Organized Intelligence</h2></a><strong><u>Authors:</u></strong> Antoine Salomon<br><strong><u>Categories:</u></strong> cs.LG, cs.CL, cs.NE<br><strong><u>Comments:</u></strong> Code available atthis https URL<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Biological neurons exhibit remarkable intelligence: they maintain internal states, communicate selectively with other neurons, and self-organize into complex graphs rather than rigid hierarchical layers. What if artificial intelligence could emerge from similarly intelligent computational units? We introduce Intelligent Neural Networks (INN), a paradigm shift where neurons are first-class entities with internal memory and learned communication patterns, organized in complete graphs rather than sequential layers.
  Each Intelligent Neuron combines selective state-space dynamics (knowing when to activate) with attention-based routing (knowing to whom to send signals), enabling emergent computation through graph-structured interactions. On the standard Text8 character modeling benchmark, INN achieves 1.705 Bit-Per-Character (BPC), significantly outperforming a comparable Transformer (2.055 BPC) and matching a highly optimized LSTM baseline. Crucially, a parameter-matched baseline of stacked Mamba blocks fails to converge (>3.4 BPC) under the same training protocol, demonstrating that INN's graph topology provides essential training stability. Ablation studies confirm this: removing inter-neuron communication degrades performance or leads to instability, proving the value of learned neural routing.
  This work demonstrates that neuron-centric design with graph organization is not merely bio-inspired -- it is computationally effective, opening new directions for modular, interpretable, and scalable neural architectures.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22805v1" target="_blank"><h2>From Pixels to Feelings: Aligning MLLMs with Human Cognitive Perception of Images</h2></a><strong><u>Authors:</u></strong> Yiming Chen, Junlin Han, Tianyi Bai, Shengbang Tong, Filippos Kokkinos, Philip Torr<br><strong><u>Categories:</u></strong> cs.CV, cs.LG, cs.MM<br><strong><u>Comments:</u></strong> Project page with codes/datasets/models:this https URL<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> While Multimodal Large Language Models (MLLMs) are adept at answering what is in an image-identifying objects and describing scenes-they often lack the ability to understand how an image feels to a human observer. This gap is most evident when considering subjective cognitive properties, such as what makes an image memorable, funny, aesthetically pleasing, or emotionally evocative. To systematically address this challenge, we introduce CogIP-Bench, a comprehensive benchmark for evaluating MLLMs on such image cognitive properties. Our evaluation reveals a significant gap: current models are poorly aligned with human perception of these nuanced properties. We then demonstrate that a post-training phase can effectively bridge this gap, significantly enhancing the model's alignment with human judgments. Furthermore, we show that this learned cognitive alignment is not merely predictive but also transferable to downstream creative tasks. By integrating our cognitively-aligned MLLM into an image generation pipeline, we can guide the synthesis process to produce images that better embody desired traits, such as being more memorable or visually appealing. Our work provides a benchmark to measure this human-like perception, a post-training pipeline to enhance it, and a demonstration that this alignment unlocks more human-centric AI.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22794v1" target="_blank"><h2>Can Synthetic Data Improve Symbolic Regression Extrapolation Performance?</h2></a><strong><u>Authors:</u></strong> Fitria Wulandari Ramlan, Colm O'Riordan, Gabriel Kronberger, James McDermott<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 8 pages, 16 figures, GECCO 2025 Symbolic Regression Workshop<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Many machine learning models perform well when making predictions within the training data range, but often struggle when required to extrapolate beyond it. Symbolic regression (SR) using genetic programming (GP) can generate flexible models but is prone to unreliable behaviour in extrapolation. This paper investigates whether adding synthetic data can help improve performance in such cases. We apply Kernel Density Estimation (KDE) to identify regions in the input space where the training data is sparse. Synthetic data is then generated in those regions using a knowledge distillation approach: a teacher model generates predictions on new input points, which are then used to train a student model. We evaluate this method across six benchmark datasets, using neural networks (NN), random forests (RF), and GP both as teacher models (to generate synthetic data) and as student models (trained on the augmented data). Results show that GP models can often improve when trained on synthetic data, especially in extrapolation areas. However, the improvement depends on the dataset and teacher model used. The most important improvements are observed when synthetic data from GPe is used to train GPp in extrapolation regions. Changes in interpolation areas show only slight changes. We also observe heterogeneous errors, where model performance varies across different regions of the input space. Overall, this approach offers a practical solution for better extrapolation. Note: An earlier version of this work appeared in the GECCO 2025 Workshop on Symbolic Regression. This arXiv version corrects several parts of the original submission.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22791v1" target="_blank"><h2>An Efficient Privacy-preserving Intrusion Detection Scheme for UAV Swarm Networks</h2></a><strong><u>Authors:</u></strong> Kanchon Gharami, Shafika Showkat Moni<br><strong><u>Categories:</u></strong> cs.CR, cs.LG<br><strong><u>Comments:</u></strong> This paper has been accepted for publication in the Proceedings of the 44th AIAA/IEEE Digital Avionics Systems Conference (DASC) 2025, where it received the Best Paper of Session Award<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The rapid proliferation of unmanned aerial vehicles (UAVs) and their applications in diverse domains, such as surveillance, disaster management, agriculture, and defense, have revolutionized modern technology. While the potential benefits of swarm-based UAV networks are growing significantly, they are vulnerable to various security attacks that can jeopardize the overall mission success by degrading their performance, disrupting decision-making, and compromising the trajectory planning process. The Intrusion Detection System (IDS) plays a vital role in identifying potential security attacks to ensure the secure operation of UAV swarm networks. However, conventional IDS primarily focuses on binary classification with resource-intensive neural networks and faces challenges, including latency, privacy breaches, increased performance overhead, and model drift. This research aims to address these challenges by developing a novel lightweight and federated continuous learning-based IDS scheme. Our proposed model facilitates decentralized training across diverse UAV swarms to ensure data heterogeneity and privacy. The performance evaluation of our model demonstrates significant improvements, with classification accuracies of 99.45% on UKM-IDS, 99.99% on UAV-IDS, 96.85% on TLM-UAV dataset, and 98.05% on Cyber-Physical datasets.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22773v1" target="_blank"><h2>CAPE: Context-Aware Diffusion Policy Via Proximal Mode Expansion for Collision Avoidance</h2></a><strong><u>Authors:</u></strong> Rui Heng Yang, Xuan Zhao, Leo Maxime Brunswic, Montgomery Alban, Mateo Clemente, Tongtong Cao, Jun Jin, Amir Rasouli<br><strong><u>Categories:</u></strong> cs.RO, cs.AI<br><strong><u>Comments:</u></strong> 4 tables, 9 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> In robotics, diffusion models can capture multi-modal trajectories from demonstrations, making them a transformative approach in imitation learning. However, achieving optimal performance following this regiment requires a large-scale dataset, which is costly to obtain, especially for challenging tasks, such as collision avoidance. In those tasks, generalization at test time demands coverage of many obstacles types and their spatial configurations, which are impractical to acquire purely via data. To remedy this problem, we propose Context-Aware diffusion policy via Proximal mode Expansion (CAPE), a framework that expands trajectory distribution modes with context-aware prior and guidance at inference via a novel prior-seeded iterative guided refinement procedure. The framework generates an initial trajectory plan and executes a short prefix trajectory, and then the remaining trajectory segment is perturbed to an intermediate noise level, forming a trajectory prior. Such a prior is context-aware and preserves task intent. Repeating the process with context-aware guided denoising iteratively expands mode support to allow finding smoother, less collision-prone trajectories. For collision avoidance, CAPE expands trajectory distribution modes with collision-aware context, enabling the sampling of collision-free trajectories in previously unseen environments while maintaining goal consistency. We evaluate CAPE on diverse manipulation tasks in cluttered unseen simulated and real-world settings and show up to 26% and 80% higher success rates respectively compared to SOTA methods, demonstrating better generalization to unseen environments.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22739v1" target="_blank"><h2>All Centers Are at most a Few Tokens Apart: Knowledge Distillation with Domain Invariant Prompt Tuning</h2></a><strong><u>Authors:</u></strong> Amir Mohammad Ezzati, Alireza Malekhosseini, Armin Khosravi, Mohammad Hossein Rohban<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Domain generalization is critical in computational pathology (CPath) due to inherent domain shifts caused by variations in staining protocols, scanner devices, and imaging settings across clinical centers. Vision-language models (VLMs), such as PLIP-a pathology-tuned CLIP-trained on image-text pairs across diverse domains, serve as strong knowledge distillation sources. However, their zero-shot performance with predefined prompts remains limited due to sensitivity to prompt variations. Moreover, unlike natural images, histopathology centers lack semantic descriptors (e.g., 'sketch'), making it difficult to define domain-specific prompts for clinical centers. This requires a data-driven approach for learning domain-specific and ultimately class-generic continuous prompts. We propose Domain Invariant Prompt Tuning (DIPT) for knowledge distillation process, a novel step that learns multiple input tokens for each domain. These tokens are trained separately for each domain and are averaged across domains, leading to domain-invariant prompts. Our student model then distills knowledge from PLIP's text encoder by leveraging the prompts learned by DIPT. This leads to alignment of visual features with domain-invariant embeddings, enhancing generalization by training on multiple domains. Our method adds a significant improvement in average F1-score to existing state-of-the-art (SOTA) knowledge distillation approaches in domain generalization with histopathology datasets. This work helps the way of deploying robust CPath models in real-world clinical problems with heterogeneous data sources.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22737v1" target="_blank"><h2>Agentic AI Framework for Individuals with Disabilities and Neurodivergence: A Multi-Agent System for Healthy Eating, Daily Routines, and Inclusive Well-Being</h2></a><strong><u>Authors:</u></strong> Salman Jan, Toqeer Ali Syed, Gohar Ali, Ali Akarma, Mohammad Riyaz Belgaum, Ahmad Ali<br><strong><u>Categories:</u></strong> cs.AI, cs.HC<br><strong><u>Comments:</u></strong> Presented at International Conference on Business and Digital Technology, Bahrain, Springer Nature, 27 November 2025<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> The paper presents a detailed Agentic Artificial Intelligence (AI) model that would enable people with disabilities and neurodivergence to lead healthier lives and have more regular days. The system will use a multi-layer structure; it will include an Application and Interface Layer, an Agents Layer, and a Data Source Layer to provide adaptive, transparent, and inclusive support. Fundamentally, a hybrid reasoning engine will synchronize four special-purpose agents, which include: a personalized-nutrition-based, called a Meal Planner Agent; an adaptive-scheduling-based, called a Reminder Agent; interactive assistance during grocery shopping and cooking, called a Food Guidance Agent; and a continuous-intake-and-physiological-tracking, called a Monitoring Agent. All the agents interact through a central communicative system called the Blackboard/Event Bus, which allows autonomous interaction and real-time feedback loops with multimedia user interfaces. Privacy-sensitive data sources, including electronic health records (EHRs), nutritional databases, wearable sensors, and smart kitchen Internet of Things, are also included in the framework and placed into a policy-controlled layer, which ensures data safety and compliance with consent. Collaborative care and clinician dashboards allow common supervision, and discussable artificial intelligence (XAI) modules give brief explanations of why a decision was made, making users responsible and reliant. The proposed agentic AI framework is an extension beyond traditional assistive systems since it incorporates inclusiveness, personalization, and accessibility at all levels. It displays the intersection of multi-agent reasoning, multi-modal interfaces, and human-centered design that will enable the development of autonomy, health, and digital equity among people with disabilities and neurodivergence.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22715v1" target="_blank"><h2>ReAG: Reasoning-Augmented Generation for Knowledge-based Visual Question Answering</h2></a><strong><u>Authors:</u></strong> Alberto Compagnoni, Marco Morini, Sara Sarto, Federico Cocchi, Davide Caffagni, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL, cs.MM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Large Language Models (MLLMs) have shown impressive capabilities in jointly understanding text, images, and videos, often evaluated via Visual Question Answering (VQA). However, even state-of-the-art MLLMs struggle with domain-specific or knowledge-intensive queries, where relevant information is underrepresented in pre-training data. Knowledge-based VQA (KB-VQA) addresses this by retrieving external documents to condition answer generation, but current retrieval-augmented approaches suffer from low precision, noisy passages, and limited reasoning. To address this, we propose ReAG, a novel Reasoning-Augmented Multimodal RAG approach that combines coarse- and fine-grained retrieval with a critic model that filters irrelevant passages, ensuring high-quality additional context. The model follows a multi-stage training strategy leveraging reinforcement learning to enhance reasoning over retrieved content, while supervised fine-tuning serves only as a cold start. Extensive experiments on Encyclopedic-VQA and InfoSeek demonstrate that ReAG significantly outperforms prior methods, improving answer accuracy and providing interpretable reasoning grounded in retrieved evidence. Our source code is publicly available at: https://github.com/aimagelab/ReAG.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22707v1" target="_blank"><h2>CoFiRec: Coarse-to-Fine Tokenization for Generative Recommendation</h2></a><strong><u>Authors:</u></strong> Tianxin Wei, Xuying Ning, Xuxing Chen, Ruizhong Qiu, Yupeng Hou, Yan Xie, Shuang Yang, Zhigang Hua, Jingrui He<br><strong><u>Categories:</u></strong> cs.IR, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> In web environments, user preferences are often refined progressively as users move from browsing broad categories to exploring specific items. However, existing generative recommenders overlook this natural refinement process. Generative recommendation formulates next-item prediction as autoregressive generation over tokenized user histories, where each item is represented as a sequence of discrete tokens. Prior models typically fuse heterogeneous attributes such as ID, category, title, and description into a single embedding before quantization, which flattens the inherent semantic hierarchy of items and fails to capture the gradual evolution of user intent during web interactions. To address this limitation, we propose CoFiRec, a novel generative recommendation framework that explicitly incorporates the Coarse-to-Fine nature of item semantics into the tokenization process. Instead of compressing all attributes into a single latent space, CoFiRec decomposes item information into multiple semantic levels, ranging from high-level categories to detailed descriptions and collaborative filtering signals. Based on this design, we introduce the CoFiRec Tokenizer, which tokenizes each level independently while preserving structural order. During autoregressive decoding, the language model is instructed to generate item tokens from coarse to fine, progressively modeling user intent from general interests to specific item-level interests. Experiments across multiple public benchmarks and backbones demonstrate that CoFiRec outperforms existing methods, offering a new perspective for generative recommendation. Theoretically, we prove that structured tokenization leads to lower dissimilarity between generated and ground truth items, supporting its effectiveness in generative recommendation. Our code is available at https://github.com/YennNing/CoFiRec.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22696v1" target="_blank"><h2>Probabilistic Fusion and Calibration of Neural Speaker Diarization Models</h2></a><strong><u>Authors:</u></strong> Juan Ignacio Alvarez-Trejos, Sergio A. Balanya, Daniel Ramos, Alicia Lozano-Diez<br><strong><u>Categories:</u></strong> cs.SD, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> domain adaptation (abstract)<br><p><strong><u>Abstract:</u></strong> End-to-End Neural Diarization (EEND) systems produce frame-level probabilistic speaker activity estimates, yet since evaluation focuses primarily on Diarization Error Rate (DER), the reliability and calibration of these confidence scores have been largely neglected. When fusing multiple diarization systems, DOVER-Lap remains the only established approach, operating at the segment level with hard decisions. We propose working with continuous probability outputs, which enables more sophisticated calibration and fusion techniques that can leverage model uncertainty and complementary strengths across different architectures. This paper presents the first comprehensive framework for calibrating and fusing EEND models at the probability level. We investigate two output formulations (multilabel and powerset representations) and their impact on calibration and fusion effectiveness. Through extensive experiments on the CallHome two-speaker benchmark, we demonstrate that proper calibration provides substantial improvements even for individual models (up to 19% relative DER reduction), in some cases mitigating the absence of domain adaptation. We reveal that joint calibration in powerset space consistently outperforms independent per-speaker calibration, and that the Fuse-then-Calibrate ordering generally outperforms calibrating individual models before fusion while requiring calibration of only a single combined model. Our best configuration outperforms DOVER-Lap in terms of DER while providing reliable confidence estimates essential for downstream applications. This work proposes best practices for probability-level fusion of EEND systems and demonstrates the advantages of leveraging soft outputs over hard decisions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22656v1" target="_blank"><h2>Structure-aware Hybrid-order Similarity Learning for Multi-view Unsupervised Feature Selection</h2></a><strong><u>Authors:</u></strong> Lin Xu, Ke Li, Dongjie Wang, Fengmao Lv, Tianrui Li, Yanyong Huang<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract)<br><p><strong><u>Abstract:</u></strong> Multi-view unsupervised feature selection (MUFS) has recently emerged as an effective dimensionality reduction method for unlabeled multi-view data. However, most existing methods mainly use first-order similarity graphs to preserve local structure, often overlooking the global structure that can be captured by second-order similarity. In addition, a few MUFS methods leverage predefined second-order similarity graphs, making them vulnerable to noise and outliers and resulting in suboptimal feature selection performance. In this paper, we propose a novel MUFS method, termed Structure-aware Hybrid-order sImilarity learNing for multi-viEw unsupervised Feature Selection (SHINE-FS), to address the aforementioned problem. SHINE-FS first learns consensus anchors and the corresponding anchor graph to capture the cross-view relationships between the anchors and the samples. Based on the acquired cross-view consensus information, it generates low-dimensional representations of the samples, which facilitate the reconstruction of multi-view data by identifying discriminative features. Subsequently, it employs the anchor-sample relationships to learn a second-order similarity graph. Furthermore, by jointly learning first-order and second-order similarity graphs, SHINE-FS constructs a hybrid-order similarity graph that captures both local and global structures, thereby revealing the intrinsic data structure to enhance feature selection. Comprehensive experimental results on real multi-view datasets show that SHINE-FS outperforms the state-of-the-art methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22648v1" target="_blank"><h2>Spatially Aware Dictionary-Free Eigenfunction Identification for Modeling and Control of Nonlinear Dynamical Systems</h2></a><strong><u>Authors:</u></strong> David Grasev<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 31 pages, 24 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> A new approach to data-driven discovery of Koopman eigenfunctions without a pre-defined set of basis functions is proposed. The approach is based on a reference trajectory, for which the Koopman mode amplitudes are first identified, and the Koopman mode decomposition is transformed to a new basis, which contains fundamental functions of eigenvalues and time. The initial values of the eigenfunctions are obtained by projecting trajectories onto this basis via a regularized least-squares fit. A global optimizer was employed to optimize the eigenvalues. Mapping initial-state values to eigenfunction values reveals their spatial structure, enabling the numerical computation of their gradients. Thus, deviations from the Koopman partial differential equation are penalized, leading to more robust solutions. The approach was successfully tested on several benchmark nonlinear dynamical systems, including the FitzHugh-Nagumo system with inputs, van der Pol and Duffing oscillators, and a 2-spool turbojet engine with control. The study demonstrates that incorporating principal eigenvalues and spatial structure integrity promotion significantly improves the accuracy of Koopman predictors. The approach effectively discovers Koopman spectral components even with sparse state-space sampling and reveals geometric features of the state space, such as invariant partitions. Finally, the numerical approximation of the eigenfunction gradient can be used for input dynamics modeling and control design. The results support the practicality of the approach for use with various dynamical systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22634v1" target="_blank"><h2>Identifying Transient Hosts in LSST's Deep Drilling Fields with Galaxy Catalogues</h2></a><strong><u>Authors:</u></strong> Josh G. Weston, David R. Young, Stephen J. Smartt, Matt Nicholl, Matt J. Jarvis, I. H. Whittam<br><strong><u>Categories:</u></strong> astro-ph.IM<br><strong><u>Comments:</u></strong> Submitted to ApJ<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> The upcoming Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) will enable astronomers to discover rare and distant astrophysical transients. Host-galaxy association is crucial for selecting the most scientifically interesting transients for follow-up. LSST Deep Drilling Field observations will detect distant transients occurring in galaxies below the detection limits of most all-sky catalogues. Here we investigate the use of pre-existing smaller-scale, field-specific catalogues for host identification in the Deep Drilling Fields (DDFs) and a ranking of their usefulness. We have compiled a database of 70 deep catalogues that overlap with the Rubin DDFs and constructed thin catalogues to be homogenised and combined for transient-host matching. A systematic ranking of their utility is discussed and applied based on the inclusion of information such as spectroscopic redshifts and morphological information. Utilising this data against a Dark Energy Survey (DES) sample of supernovae with pre-identified hosts in the XMM-LSS and ECDFS fields, we evaluate different methods for transient-host association in terms of both accuracy and processing speed. We also apply light data-cleaning techniques to identify and remove contaminants within our associations, such as diffraction spikes and blended galaxies where the correct host cannot be determined with confidence. We use a lightweight machine learning approach in the form of extreme gradient boosting to generate confidence scores in our contaminant selections and associated metrics. Finally, we discuss the computational expense of implementation within the LSST transient alert brokers, which will require efficient, fast-paced processing to handle the large stream of survey data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22615v1" target="_blank"><h2>Stable-Drift: A Patient-Aware Latent Drift Replay Method for Stabilizing Representations in Continual Learning</h2></a><strong><u>Authors:</u></strong> Paraskevi-Antonia Theofilou, Anuhya Thota, Stefanos Kollias, Mamatha Thota<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> 8 pages, 2 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> domain adaptation (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> When deep learning models are sequentially trained on new data, they tend to abruptly lose performance on previously learned tasks, a critical failure known as catastrophic forgetting. This challenge severely limits the deployment of AI in medical imaging, where models must continually adapt to data from new hospitals without compromising established diagnostic knowledge. To address this, we introduce a latent drift-guided replay method that identifies and replays samples with high representational instability. Specifically, our method quantifies this instability via latent drift, the change in a sample internal feature representation after naive domain adaptation. To ensure diversity and clinical relevance, we aggregate drift at the patient level, our memory buffer stores the per patient slices exhibiting the greatest multi-layer representation shift. Evaluated on a cross-hospital COVID-19 CT classification task using state-of-the-art CNN and Vision Transformer backbones, our method substantially reduces forgetting compared to naive fine-tuning and random replay. This work highlights latent drift as a practical and interpretable replay signal for advancing robust continual learning in real world medical settings.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22597v1" target="_blank"><h2>The NANOGrav 12.5-year Data Set: Chromatic Noise Characterization & Mitigation with Time-Domain Kernels <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Jeffrey S. Hazboun, Joseph Simon, Jeremy Baier, Bjorn Larsen, Daniel J. Oliver, Paul T. Baker, Bence Bécsy, Siyuan Chen, Alberto Diaz Hernandez, Justin A. Ellis, A. Miguel Holgado, Kristina Islo, Aaron Johnson, Andrew R. Kaiser, Nima Laal, Alexander McEwen, Nihan S. Pol, Joey Shapiro Key, Min Young Kim, Matthew Samson, Brent J. Shapiro-Albert, Jerry P. Sun, Stephen R. Taylor, Caitlin A. Witt, Jeremy Volpe, Christine Ye, Harsha Blumer, Paul R. Brook, Shami Chatterjee, James M. Cordes, Fronefield Crawford, H. Thankful Cromartie, Megan E. DeCesar, Paul B. Demorest, Timothy Dolch, Robert D. Ferdman, Elizabeth C. Ferrara, William Fiore, Emmanuel Fonseca, Nathan Garver-Daniels, Peter A. Gentile, Deborah C. Good, Ross J. Jennings, Megan L. Jones, David L. Kaplan, Michael T. Lam, T. Joseph W. Lazio, Duncan R. Lorimer, Jing Luo, Ryan S. Lynch, Dustin R. Madison, Maura A. McLaughlin, Chiara M. F. Mingarelli, Cherry Ng, David J. Nice, Timothy T. Pennucci, Scott M. Ransom, Paul S. Ray, Xavier Siemens, Renée Spiewak, Ingrid H. Stairs, Daniel R. Stinebring, Kevin Stovall, Joseph K. Swiggum, Jacob E. Turner, Michele Vallisneri, Sarah J. Vigeland<br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE, gr-qc<br><strong><u>Comments:</u></strong> 30 pages, 12 Figures, 6 Tables<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> time-domain (title, abstract)<br><p><strong><u>Abstract:</u></strong> Pulsar timing arrays (PTAs) have recently entered the detection era, quickly moving beyond the goal of simply improving sensitivity at the lowest frequencies for the sake of observing the stochastic gravitational wave background (GWB), and focusing on its accurate spectral characterization. While all PTA collaborations around the world use Fourier-domain Gaussian processes to model the GWB and intrinsic long time-correlated (red) noise, techniques to model the time-correlated radio frequency-dependent (chromatic) processes have varied from collaboration to collaboration. Here we test a new class of models for PTA data, Gaussian processes based on time-domain kernels that model the statistics of the chromatic processes starting from the covariance matrix. As we will show, these models can be effectively equivalent to Fourier-domain models in mitigating chromatic noise. This work presents a method for Bayesian model selection across the various choices of kernel as well as deterministic chromatic models for non-stationary chromatic events and the solar wind. As PTAs turn towards high frequency (>1/yr) sensitivity, the size of the basis used to model these processes will need to increase, and these time-domain models present some computational efficiencies compared to Fourier-domain models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22567v1" target="_blank"><h2>Where to Measure: Epistemic Uncertainty-Based Sensor Placement with ConvCNPs</h2></a><strong><u>Authors:</u></strong> Feyza Eksen, Stefan Oehmcke, Stefan Lüdtke<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate sensor placement is critical for modeling spatio-temporal systems such as environmental and climate processes. Neural Processes (NPs), particularly Convolutional Conditional Neural Processes (ConvCNPs), provide scalable probabilistic models with uncertainty estimates, making them well-suited for data-driven sensor placement. However, existing approaches rely on total predictive uncertainty, which conflates epistemic and aleatoric components, that may lead to suboptimal sensor selection in ambiguous regions. To address this, we propose expected reduction in epistemic uncertainty as a new acquisition function for sensor placement. To enable this, we extend ConvCNPs with a Mixture Density Networks (MDNs) output head for epistemic uncertainty estimation. Preliminary results suggest that epistemic uncertainty driven sensor placement more effectively reduces model error than approaches based on overall uncertainty.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22536v1" target="_blank"><h2>A Computable Game-Theoretic Framework for Multi-Agent Theory of Mind</h2></a><strong><u>Authors:</u></strong> Fengming Zhu, Yuxin Pan, Xiaomeng Zhu, Fangzhen Lin<br><strong><u>Categories:</u></strong> cs.AI, cs.GT, cs.MA<br><strong><u>Comments:</u></strong> Ongoing work. A preliminary version has been accepted by the AAAI 2026 Theory of Mind for AI (ToM4AI) Workshop<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Originating in psychology, $\textit{Theory of Mind}$ (ToM) has attracted significant attention across multiple research communities, especially logic, economics, and robotics. Most psychological work does not aim at formalizing those central concepts, namely $\textit{goals}$, $\textit{intentions}$, and $\textit{beliefs}$, to automate a ToM-based computational process, which, by contrast, has been extensively studied by logicians. In this paper, we offer a different perspective by proposing a computational framework viewed through the lens of game theory. On the one hand, the framework prescribes how to make boudedly rational decisions while maintaining a theory of mind about others (and recursively, each of the others holding a theory of mind about the rest); on the other hand, it employs statistical techniques and approximate solutions to retain computability of the inherent computational problem.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22532v1" target="_blank"><h2>CoT4AD: A Vision-Language-Action Model with Explicit Chain-of-Thought Reasoning for Autonomous Driving</h2></a><strong><u>Authors:</u></strong> Zhaohui Wang, Tengbo Yu, Hao Tang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 3 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Vision-Language-Action (VLA) models have recently attracted growing attention in end-to-end autonomous driving for their strong reasoning capabilities and rich world knowledge. However, existing VLAs often suffer from limited numerical reasoning ability and overly simplified input-output mappings, which hinder their performance in complex driving scenarios requiring step-by-step causal reasoning. To address these challenges, we propose CoT4AD, a novel VLA framework that introduces Chain-of-Thought (CoT) reasoning for autonomous driving to enhance both numerical and causal reasoning in Vision-Language Models (VLMs). CoT4AD integrates visual observations and language instructions to perform semantic reasoning, scene understanding, and trajectory planning. During training, it explicitly models a perception-question-prediction-action CoT to align the reasoning space with the action space across multiple driving tasks. During inference, it performs implicit CoT reasoning to enable consistent numerical reasoning and robust decision-making in dynamic environments. Extensive experiments on both real-world and simulated benchmarks, including nuScenes and Bench2Drive, demonstrate that CoT4AD achieves state-of-the-art performance in both open-loop and closed-loop evaluations. Code will be released upon paper acceptance.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22522v1" target="_blank"><h2>AdS/Deep-Learning made easy II: neural network-based approaches to holography and inverse problems</h2></a><strong><u>Authors:</u></strong> Hyun-Sik Jeong, Hanse Kim, Keun-Young Kim, Gaya Yun, Hyeonwoo Yu, Kwan Yun<br><strong><u>Categories:</u></strong> hep-th, cs.LG<br><strong><u>Comments:</u></strong> 31pages, 17 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> We apply physics-informed machine learning (PIML) to solve inverse problems in holography and classical mechanics, focusing on neural ordinary differential equations (Neural ODEs) and physics-informed neural networks (PINNs) for solving non-linear differential equations of motion. First, we introduce holographic inverse problems and demonstrate how PIML can reconstruct bulk spacetime and effective potentials from boundary quantum data. To illustrate this, two case studies are explored: the QCD equation of state in holographic QCD and $T$-linear resistivity in holographic strange metals. Additionally, we explicitly show how such holographic problems can be analogized to inverse problems in classical mechanics, modeling frictional forces with neural networks. We also explore Kolmogorov-Arnold Networks (KANs) as an alternative to traditional neural networks, offering more efficient solutions in certain cases. This manuscript aim to provide a systematic framework for using neural networks in inverse problems, serving as a comprehensive reference for researchers in machine learning for high-energy physics, with methodologies that also have broader applications in mathematics, engineering, and the natural sciences.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22515v1" target="_blank"><h2>Privacy-Utility-Bias Trade-offs for Privacy-Preserving Recommender Systems</h2></a><strong><u>Authors:</u></strong> Shiva Parsarad, Isabel Wagner<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (abstract)<br><p><strong><u>Abstract:</u></strong> Recommender systems (RSs) output ranked lists of items, such as movies or restaurants, that users may find interesting, based on the user's past ratings and ratings from other users. RSs increasingly incorporate differential privacy (DP) to protect user data, raising questions about how privacy mechanisms affect both recommendation accuracy and fairness. We conduct a comprehensive, cross-model evaluation of two DP mechanisms, differentially private stochastic gradient descent (DPSGD) and local differential privacy (LDP), applied to four recommender systems (Neural Collaborative Filtering (NCF), Bayesian Personalized Ranking (BPR), Singular Value Decomposition (SVD), and Variational Autoencoder (VAE)) on the MovieLens-1M and Yelp datasets. We find that stronger privacy consistently reduces utility, but not uniformly. NCF under DPSGD shows the smallest accuracy loss (under 10 percent at epsilon approximately 1), whereas SVD and BPR experience larger drops, especially for users with niche preferences. VAE is the most sensitive to privacy, with sharp declines for sparsely represented groups. The impact on bias metrics is similarly heterogeneous. DPSGD generally reduces the gap between recommendations of popular and less popular items, whereas LDP preserves existing patterns more closely. These results highlight that no single DP mechanism is uniformly superior; instead, each provides trade-offs under different privacy regimes and data conditions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22498v1" target="_blank"><h2>Space Explanations of Neural Network Classification</h2></a><strong><u>Authors:</u></strong> Faezeh Labbaf, Tomáš Kolárik, Martin Blicha, Grigory Fedyukovich, Michael Wand, Natasha Sharygina<br><strong><u>Categories:</u></strong> cs.LG, cs.LO<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> We present a novel logic-based concept called Space Explanations for classifying neural networks that gives provable guarantees of the behavior of the network in continuous areas of the input feature space. To automatically generate space explanations, we leverage a range of flexible Craig interpolation algorithms and unsatisfiable core generation. Based on real-life case studies, ranging from small to medium to large size, we demonstrate that the generated explanations are more meaningful than those computed by state-of-the-art.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22493v1" target="_blank"><h2>HW-GNN: Homophily-Aware Gaussian-Window Constrained Graph Spectral Network for Social Network Bot Detection</h2></a><strong><u>Authors:</u></strong> Zida Liu, Jun Gao, Zhang Ji, Li Zhao<br><strong><u>Categories:</u></strong> cs.SI, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Social bots are increasingly polluting online platforms by spreading misinformation and engaging in coordinated manipulation, posing severe threats to cybersecurity. Graph Neural Networks (GNNs) have become mainstream for social bot detection due to their ability to integrate structural and attribute features, with spectral-based approaches demonstrating particular efficacy due to discriminative patterns in the spectral domain. However, current spectral GNN methods face two limitations: (1) their broad-spectrum fitting mechanisms degrade the focus on bot-specific spectral features, and (2) certain domain knowledge valuable for bot detection, e.g., low homophily correlates with high-frequency features, has not been fully incorporated into existing methods.
  To address these challenges, we propose HW-GNN, a novel homophily-aware graph spectral network with Gaussian window constraints. Our framework introduces two key innovations: (i) a Gaussian-window constrained spectral network that employs learnable Gaussian windows to highlight bot-related spectral features, and (ii) a homophily-aware adaptation mechanism that injects domain knowledge between homophily ratios and frequency features into the Gaussian window optimization process. Through extensive experimentation on multiple benchmark datasets, we demonstrate that HW-GNN achieves state-of-the-art bot detection performance, outperforming existing methods with an average improvement of 4.3% in F1-score, while exhibiting strong plug-in compatibility with existing spectral GNNs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22486v1" target="_blank"><h2>The Machine Learning Approach to Moment Closure Relations for Plasma: A Review</h2></a><strong><u>Authors:</u></strong> Samuel Burles, Enrico Camporeale<br><strong><u>Categories:</u></strong> physics.plasm-ph, cs.LG<br><strong><u>Comments:</u></strong> 30 pages, 2 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> The requirement for large-scale global simulations of plasma is an ongoing challenge in both space and laboratory plasma physics. Any simulation based on a fluid model inherently requires a closure relation for the high order plasma moments. This review compiles and analyses the recent surge of machine learning approaches developing improved plasma closure models capable of capturing kinetic phenomena within plasma fluid models. The purpose of this review is both to collect and analyse the various methods employed on the plasma closure problem, including both equation discovery methods and neural network surrogate approaches, as well as to provide a general overview of the state of the problem. In particular, we highlight the challenges of developing a data-driven closure as well as the direction future work should take toward addressing these challenges, in the pursuit of a computationally viable large-scale global simulation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22478v1" target="_blank"><h2>Clustering in dynamical dark energy: observational constraints from DESI, CMB, and supernovae <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Yuhang Yang, Qingqing Wang, Xin Ren, Emmanuel N. Saridakis, Yi-Fu Cai<br><strong><u>Categories:</u></strong> astro-ph.CO<br><strong><u>Comments:</u></strong> 13 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> VAE (title)<br><p><strong><u>Abstract:</u></strong> We investigate the clustering properties of dynamical dark energy using the latest cosmological observations. We describe the dark energy perturbation within two complementary frameworks, namely the Parameterized Post-Friedmann (PPF) approach and the Effective Field Theory (EFT) of dark energy. Using DESI DR2 baryon acoustic oscillations together with Planck 2018 CMB data and the Union3 supernova sample, we constrain the effective sound speed of dark energy in both the $w$CDM and $w_0w_a$CDM backgrounds. Within the PPF description, the sound speed remains unconstrained for $w$CDM, while for the $w_0w_a$CDM case we obtain $\log_{10} c_s^2 = -3.00^{+2.9}_{-0.99}$. Additionally, in the EFT framework, both models favor a small sound speed, with a mean value $c_s^2 \simeq 0.3$--$0.4$ but with significant uncertainties. For dynamical dark energy, the reconstructed equation of state clearly exhibits a quintom-B behavior, and its deviation from $Λ$CDM reaches $3.42σ$, rising to $3.63σ$ when PPF perturbations are included and reducing to $3.19σ$ in the EFT case. Finally, model comparison using information criteria shows that the $w_0w_a$CDM model with a smooth, non-clustering dark energy component ($c_s^2 = 1$) is preferred by AIC, whereas BIC favors $Λ$CDM. In summary, current data indicate a mild preference for dynamical dark energy but no evidence for significant clustering, which implies the need for future high-precision observations to probe the perturbative behavior more definitively.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22451v1" target="_blank"><h2>Benchmarking machine learning models for multi-class state recognition in double duantum dot data</h2></a><strong><u>Authors:</u></strong> Valeria Díaz Moreno, Ryan P Khalili, Daniel Schug, Patrick J. Walsh, Justyna P. Zwolak<br><strong><u>Categories:</u></strong> cs.CV, cond-mat.mes-hall, cs.LG<br><strong><u>Comments:</u></strong> 12 pages, 4 figures, 2 tables<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Semiconductor quantum dots (QDs) are a leading platform for scalable quantum processors. However, scaling to large arrays requires reliable, automated tuning strategies for devices' bootstrapping, calibration, and operation, with many tuning aspects depending on accurately identifying QD device states from charge-stability diagrams (CSDs). In this work, we present a comprehensive benchmarking study of four modern machine learning (ML) architectures for multi-class state recognition in double-QD CSDs. We evaluate their performance across different data budgets and normalization schemes using both synthetic and experimental data. We find that the more resource-intensive models -- U-Nets and visual transformers (ViTs) -- achieve the highest MSE score (defined as $1-\mathrm{MSE}$) on synthetic data (over $0.98$) but fail to generalize to experimental data. MDNs are the most computationally efficient and exhibit highly stable training, but with substantially lower peak performance. CNNs offer the most favorable trade-off on experimental CSDs, achieving strong accuracy with two orders of magnitude fewer parameters than the U-Nets and ViTs. Normalization plays a nontrivial role: min-max scaling generally yields higher MSE scores but less stable convergence, whereas z-score normalization produces more predictable training dynamics but at reduced accuracy for most models. Overall, our study shows that CNNs with min-max normalization are a practical approach for QD CSDs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22434v1" target="_blank"><h2>FastFHE: Packing-Scalable and Depthwise-Separable CNN Inference Over FHE</h2></a><strong><u>Authors:</u></strong> Wenbo Song, Xinxin Fan, Quanliang Jing, Shaoye Luo, Wenqi Wei, Chi Lin, Yunfeng Lu, Ling Liu<br><strong><u>Categories:</u></strong> cs.CR, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> The deep learning (DL) has been penetrating daily life in many domains, how to keep the DL model inference secure and sample privacy in an encrypted environment has become an urgent and increasingly important issue for various security-critical applications. To date, several approaches have been proposed based on the Residue Number System variant of the Cheon-Kim-Kim-Song (RNS-CKKS) scheme. However, they all suffer from high latency, which severely limits the applications in real-world tasks. Currently, the research on encrypted inference in deep CNNs confronts three main bottlenecks: i) the time and storage costs of convolution calculation; ii) the time overhead of huge bootstrapping operations; and iii) the consumption of circuit multiplication depth. Towards these three challenges, we in this paper propose an efficient and effective mechanism FastFHE to accelerate the model inference while simultaneously retaining high inference accuracy over fully homomorphic encryption. Concretely, our work elaborates four unique novelties. First, we propose a new scalable ciphertext data-packing scheme to save the time and storage consumptions. Second, we work out a depthwise-separable convolution fashion to degrade the computation load of convolution calculation. Third, we figure out a BN dot-product fusion matrix to merge the ciphertext convolutional layer with the batch-normalization layer without incurring extra multiplicative depth. Last but not least, we adopt the low-degree Legendre polynomial to approximate the nonlinear smooth activation function SiLU under the guarantee of tiny accuracy error before and after encrypted inference. Finally, we execute multi-facet experiments to verify the efficiency and effectiveness of our proposed approach.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22420v1" target="_blank"><h2>MATCH: Engineering Transparent and Controllable Conversational XAI Systems through Composable Building Blocks</h2></a><strong><u>Authors:</u></strong> Sebe Vanbrabant, Gustavo Rovelo Ruiz, Davy Vanacken<br><strong><u>Categories:</u></strong> cs.HC, cs.AI, cs.LG, cs.MA<br><strong><u>Comments:</u></strong> Submitted Version accepted for publication in an LNCS Volume "Engineering Interactive Computer Systems - EICS 2025 - International Workshops and Doctoral Consortium"<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> explainable (abstract)<br><p><strong><u>Abstract:</u></strong> While the increased integration of AI technologies into interactive systems enables them to solve an increasing number of tasks, the black-box problem of AI models continues to spread throughout the interactive system as a whole. Explainable AI (XAI) techniques can make AI models more accessible by employing post-hoc methods or transitioning to inherently interpretable models. While this makes individual AI models clearer, the overarching system architecture remains opaque. This challenge not only pertains to standard XAI techniques but also to human examination and conversational XAI approaches that need access to model internals to interpret them correctly and completely. To this end, we propose conceptually representing such interactive systems as sequences of structural building blocks. These include the AI models themselves, as well as control mechanisms grounded in literature. The structural building blocks can then be explained through complementary explanatory building blocks, such as established XAI techniques like LIME and SHAP. The flow and APIs of the structural building blocks form an unambiguous overview of the underlying system, serving as a communication basis for both human and automated agents, thus aligning human and machine interpretability of the embedded AI models. In this paper, we present our flow-based approach and a selection of building blocks as MATCH: a framework for engineering Multi-Agent Transparent and Controllable Human-centered systems. This research contributes to the field of (conversational) XAI by facilitating the integration of interpretability into existing interactive systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22396v1" target="_blank"><h2>Asking like Socrates: Socrates helps VLMs understand remote sensing images</h2></a><strong><u>Authors:</u></strong> Run Shao, Ziyu Li, Zhaoyang Zhang, Linrui Xu, Xinran He, Hongyuan Yuan, Bolei He, Yongxing Dai, Yiming Yan, Yijun Chen, Wang Guo, Haifeng Li<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 20 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Recent multimodal reasoning models, inspired by DeepSeek-R1, have significantly advanced vision-language systems. However, in remote sensing (RS) tasks, we observe widespread pseudo reasoning: models narrate the process of reasoning rather than genuinely reason toward the correct answer based on visual evidence. We attribute this to the Glance Effect, where a single, coarse perception of large-scale RS imagery results in incomplete understanding and reasoning based on linguistic self-consistency instead of visual evidence. To address this, we propose RS-EoT (Remote Sensing Evidence-of-Thought), a language-driven, iterative visual evidence-seeking paradigm. To instill this paradigm, we propose SocraticAgent, a self-play multi-agent system that synthesizes reasoning traces via alternating cycles of reasoning and visual inspection. To enhance and generalize these patterns, we propose a two-stage progressive RL strategy: first, RL on fine-grained Grounding tasks to enhance RS-EoT capabilities, followed by RL on RS VQA to generalize to broader understanding scenarios. Experiments show RS-EoT achieves state-of-the-art performance on multiple RS VQA and grounding benchmarks. Analyses reveal clear iterative cycles of reasoning and evidence seeking, confirming RS-EoT mitigates the Glance Effect and enables genuine evidence-grounded reasoning. Our code, data, and models are available at https://geox-lab.github.io/Asking_like_Socrates</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22364v1" target="_blank"><h2>BINDER: Instantly Adaptive Mobile Manipulation with Open-Vocabulary Commands</h2></a><strong><u>Authors:</u></strong> Seongwon Cho, Daechul Ahn, Donghyun Shin, Hyeonbeom Choi, San Kim, Jonghyun Choi<br><strong><u>Categories:</u></strong> cs.RO, cs.AI<br><strong><u>Comments:</u></strong> 12 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Open-vocabulary mobile manipulation (OVMM) requires robots to follow language instructions, navigate, and manipulate while updating their world representation under dynamic environmental changes. However, most prior approaches update their world representation only at discrete update points such as navigation targets, waypoints, or the end of an action step, leaving robots blind between updates and causing cascading failures: overlooked objects, late error detection, and delayed replanning. To address this limitation, we propose BINDER (Bridging INstant and DEliberative Reasoning), a dual process framework that decouples strategic planning from continuous environment monitoring. Specifically, BINDER integrates a Deliberative Response Module (DRM, a multimodal LLM for task planning) with an Instant Response Module (IRM, a VideoLLM for continuous monitoring). The two modules play complementary roles: the DRM performs strategic planning with structured 3D scene updates and guides what the IRM attends to, while the IRM analyzes video streams to update memory, correct ongoing actions, and trigger replanning when necessary. Through this bidirectional coordination, the modules address the trade off between maintaining awareness and avoiding costly updates, enabling robust adaptation under dynamic conditions. Evaluated in three real world environments with dynamic object placement, BINDER achieves substantially higher success and efficiency than SoTA baselines, demonstrating its effectiveness for real world deployment.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22362v1" target="_blank"><h2>Efficient-Husformer: Efficient Multimodal Transformer Hyperparameter Optimization for Stress and Cognitive Loads</h2></a><strong><u>Authors:</u></strong> Merey Orazaly, Fariza Temirkhanova, Jurn-Gyu Park<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Transformer-based models have gained considerable attention in the field of physiological signal analysis. They leverage long-range dependencies and complex patterns in temporal signals, allowing them to achieve performance superior to traditional RNN and CNN models. However, they require high computational intensity and memory demands. In this work, we present Efficient-Husformer, a novel Transformer-based architecture developed with hyperparameter optimization (HPO) for multi-class stress detection across two multimodal physiological datasets (WESAD and CogLoad). The main contributions of this work are: (1) the design of a structured search space, targeting effective hyperparameter optimization; (2) a comprehensive ablation study evaluating the impact of architectural decisions; (3) consistent performance improvements over the original Husformer, with the best configuration achieving an accuracy of 88.41 and 92.61 (improvements of 13.83% and 6.98%) on WESAD and CogLoad datasets, respectively. The best-performing configuration is achieved with the (L + dm) or (L + FFN) modality combinations, using a single layer, 3 attention heads, a model dimension of 18/30, and FFN dimension of 120/30, resulting in a compact model with only about 30k parameters.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22341v1" target="_blank"><h2>Unexplored flaws in multiple-choice VQA evaluations</h2></a><strong><u>Authors:</u></strong> Fabio Rosenthal, Sebastian Schmidt, Thorsten Graf, Thorsten Bagodonat, Stephan Günnemann, Leo Schwinn<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal Large Language Models (MLLMs) demonstrate strong capabilities in handling image-text inputs. A common way to assess this ability is through multiple-choice Visual Question Answering (VQA). Earlier works have already revealed that these benchmarks are sensitive to answer choice order, a limitation that can be mitigated through careful design. Yet, we highlight additional, unexplored biases in prompt formatting that question the reliability of current MLLM evaluations. Specifically, we identify three key variation factors in prompt formatting and analyze their impact through a large-scale study involving $\mathbf{\text{seven}}$ MLLMs and $\mathbf{\text{five}}$ VQA datasets, spanning $\mathbf{48}$ distinct $\mathbf{\text{prompt format variations}}$. Our findings reveal that multiple-choice VQA is highly sensitive to minor prompt format changes, even when these changes are semantically neutral. We further demonstrate that these biases persist independently of known order biases or the MLLM's confidence in the correct answer. Finally, we demonstrate that existing bias mitigation strategies fail to address these newly identified biases.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22321v1" target="_blank"><h2>RELiQ: Scalable Entanglement Routing via Reinforcement Learning in Quantum Networks</h2></a><strong><u>Authors:</u></strong> Tobias Meuser, Jannis Weil, Aninda Lahiri, Marius Paraschiv<br><strong><u>Categories:</u></strong> quant-ph, cs.AI, cs.NI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Quantum networks are becoming increasingly important because of advancements in quantum computing and quantum sensing, such as recent developments in distributed quantum computing and federated quantum machine learning. Routing entanglement in quantum networks poses several fundamental as well as technical challenges, including the high dynamicity of quantum network links and the probabilistic nature of quantum operations. Consequently, designing hand-crafted heuristics is difficult and often leads to suboptimal performance, especially if global network topology information is unavailable.
  In this paper, we propose RELiQ, a reinforcement learning-based approach to entanglement routing that only relies on local information and iterative message exchange. Utilizing a graph neural network, RELiQ learns graph representations and avoids overfitting to specific network topologies - a prevalent issue for learning-based approaches. Our approach, trained on random graphs, consistently outperforms existing local information heuristics and learning-based approaches when applied to random and real-world topologies. When compared to global information heuristics, our method achieves similar or superior performance because of its rapid response to topology changes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22314v1" target="_blank"><h2>DeXposure: A Dataset and Benchmarks for Inter-protocol Credit Exposure in Decentralized Financial Networks</h2></a><strong><u>Authors:</u></strong> Wenbin Wu, Kejiang Qian, Alexis Lui, Christopher Jack, Yue Wu, Peter McBurney, Fengxiang He, Bryan Zhang<br><strong><u>Categories:</u></strong> cs.LG, cs.CE, cs.SI, econ.GN<br><strong><u>Comments:</u></strong> Data and code:this https URL- Visualisation:this https URL<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> We curate the DeXposure dataset, the first large-scale dataset for inter-protocol credit exposure in decentralized financial networks, covering global markets of 43.7 million entries across 4.3 thousand protocols, 602 blockchains, and 24.3 thousand tokens, from 2020 to 2025. A new measure, value-linked credit exposure between protocols, is defined as the inferred financial dependency relationships derived from changes in Total Value Locked (TVL). We develop a token-to-protocol model using DefiLlama metadata to infer inter-protocol credit exposure from the token's stock dynamics, as reported by the protocols. Based on the curated dataset, we develop three benchmarks for machine learning research with financial applications: (1) graph clustering for global network measurement, tracking the structural evolution of credit exposure networks, (2) vector autoregression for sector-level credit exposure dynamics during major shocks (Terra and FTX), and (3) temporal graph neural networks for dynamic link prediction on temporal graphs. From the analysis, we observe (1) a rapid growth of network volume, (2) a trend of concentration to key protocols, (3) a decline of network density (the ratio of actual connections to possible connections), and (4) distinct shock propagation across sectors, such as lending platforms, trading exchanges, and asset management protocols. The DeXposure dataset and code have been released publicly. We envision they will help with research and practice in machine learning as well as financial risk monitoring, policy analysis, DeFi market modeling, amongst others. The dataset also contributes to machine learning research by offering benchmarks for graph clustering, vector autoregression, and temporal graph analysis.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22309v1" target="_blank"><h2>Astrophysical constraints from future measurements of the kinetic Sunyaev-Zel'dovich power spectrum</h2></a><strong><u>Authors:</u></strong> Lisa McBride, Adélie Gorce, Marian Douspis, Romain Meriot, Benoît Semelin, Lukas T. Hergt, Stephane Ilić, Miren Muñoz-Echeverría, Etienne Pointecouteau, Laura Salvati, Matthieu Tristram<br><strong><u>Categories:</u></strong> astro-ph.CO<br><strong><u>Comments:</u></strong> 14 pages, 13 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> High-precision measurements of the Cosmic Microwave Background (CMB) will soon allow for the unprecedented detection of small-scale secondary anisotropies, such as the kinetic Sunyaev-Zel'dovich (kSZ) effect. Linking the kSZ power spectrum to the properties of ionising sources would provide an opportunity to use such observations to access astrophysical and cosmological information from the Epoch of Reionisation, including the morphology of ionised regions, while simultaneously improving CMB analyses. The aim of this work is to assess this potential of the kSZ power spectrum to measure reionisation-era galaxy properties. We repurpose the publicly available LoReLi II simulations, which track the evolution of neutral hydrogen during reionisation, to generate a training set of patchy kSZ angular power spectra. We then train an emulator using neural network regression in order to allow for efficient Bayesian inference, and conduct forecasts assuming mock observations from current and future CMB experiments. We find that measurements of the kSZ power spectrum from such surveys can provide meaningful constraints on several of the astrophysical model parameters of the LoReLi II suite, including the ionising escape fraction for which we expect a 14% relative error, on average. They also provide an independent measurement of the CMB optical depth, marginalised over the astrophysics and with error bars competitive with the cosmic variance limit from large scale surveys. The kSZ power spectrum offers a promising avenue for probing the properties of reionisation-era galaxies and providing an independent measurement of the CMB optical depth with upcoming CMB experiments. Since the error budget of our mock observations is dominated by emulator reconstruction errors, we expect our results could be further improved with a more extended simulation training set.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22307v1" target="_blank"><h2>Enhanced Conditional Generation of Double Perovskite by Knowledge-Guided Language Model Feedback</h2></a><strong><u>Authors:</u></strong> Inhyo Lee, Junhyeong Lee, Jongwon Park, KyungTae Lim, Seunghwa Ryu<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Double perovskites (DPs) are promising candidates for sustainable energy technologies due to their compositional tunability and compatibility with low-energy fabrication, yet their vast design space poses a major challenge for conditional materials discovery. This work introduces a multi-agent, text gradient-driven framework that performs DP composition generation under natural-language conditions by integrating three complementary feedback sources: LLM-based self-evaluation, DP-specific domain knowledge-informed feedback, and ML surrogate-based feedback. Analogous to how knowledge-informed machine learning improves the reliability of conventional data-driven models, our framework incorporates domain-informed text gradients to guide the generative process toward physically meaningful regions of the DP composition space. Systematic comparison of three incremental configurations, (i) pure LLM generation, (ii) LLM generation with LLM reasoning-based feedback, and (iii) LLM generation with domain knowledge-guided feedback, shows that iterative guidance from knowledge-informed gradients improves stability-condition satisfaction without additional training data, achieving over 98% compositional validity and up to 54% stable or metastable candidates, surpassing both the LLM-only baseline (43%) and prior GAN-based results (27%). Analyses of ML-based gradients further reveal that they enhance performance in in-distribution (ID) regions but become unreliable in out-of-distribution (OOD) regimes. Overall, this work provides the first systematic analysis of multi-agent, knowledge-guided text gradients for DP discovery and establishes a generalizable blueprint for MAS-driven generative materials design aimed at advancing sustainable technologies.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22296v1" target="_blank"><h2>Data-driven informative priors for Bayesian inference with quasi-periodic data</h2></a><strong><u>Authors:</u></strong> Javier Lopez-Santiago, Luca Martino, Joaquin Miguez, Gonzalo Vazquez-Vilar<br><strong><u>Categories:</u></strong> stat.ML, astro-ph.IM, astro-ph.SR, cs.LG<br><strong><u>Comments:</u></strong> Accepted for publication in AJ. 19 pages (one column), 14 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (title)<br><p><strong><u>Abstract:</u></strong> Bayesian computational strategies for inference can be inefficient in approximating the posterior distribution in models that exhibit some form of periodicity. This is because the probability mass of the marginal posterior distribution of the parameter representing the period is usually highly concentrated in a very small region of the parameter space. Therefore, it is necessary to provide as much information as possible to the inference method through the parameter prior distribution. We intend to show that it is possible to construct a prior distribution from the data by fitting a Gaussian process (GP) with a periodic kernel. More specifically, we want to show that it is possible to approximate the marginal posterior distribution of the hyperparameter corresponding to the period in the kernel. Subsequently, this distribution can be used as a prior distribution for the inference method. We use an adaptive importance sampling method to approximate the posterior distribution of the hyperparameters of the GP. Then, we use the marginal posterior distribution of the hyperparameter related to the periodicity in order to construct a prior distribution for the period of the parametric model. This workflow is empirical Bayes, implemented as a modular (cut) transfer of a GP posterior for the period to the parametric model. We applied the proposed methodology to both synthetic and real data. We approximated the posterior distribution of the period of the GP kernel and then passed it forward as a posterior-as-prior with no feedback. Finally, we analyzed its impact on the marginal posterior distribution.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22292v1" target="_blank"><h2>Adaptive tumor growth forecasting via neural & universal ODEs</h2></a><strong><u>Authors:</u></strong> Kavya Subramanian, Prathamesh Dinesh Joshi, Raj Abhijit Dandekar, Rajat Dandekar, Sreedath Panat<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted at JuliaCon 2025 conference<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Forecasting tumor growth is critical for optimizing treatment. Classical growth models such as the Gompertz and Bertalanffy equations capture general tumor dynamics but may fail to adapt to patient-specific variability, particularly with limited data available. In this study, we leverage Neural Ordinary Differential Equations (Neural ODEs) and Universal Differential Equations (UDEs), two pillars of Scientific Machine Learning (SciML), to construct adaptive tumor growth models capable of learning from experimental data. Using the Gompertz model as a baseline, we replace rigid terms with adaptive neural networks to capture hidden dynamics through robust modeling in the Julia programming language. We use our models to perform forecasting under data constraints and symbolic recovery to transform the learned dynamics into explicit mathematical expressions. Our approach has the potential to improve predictive accuracy, guiding dynamic and effective treatment strategies for improved clinical outcomes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22291v1" target="_blank"><h2>Online Dynamic Pricing of Complementary Products</h2></a><strong><u>Authors:</u></strong> Marco Mussi, Marcello Restelli<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Traditional pricing paradigms, once dominated by static models and rule-based heuristics, are increasingly being replaced by dynamic, data-driven approaches powered by machine learning algorithms. Despite their growing sophistication, most dynamic pricing algorithms focus on optimizing the price of each product independently, disregarding potential interactions among items. By neglecting these interdependencies in consumer demand across related goods, sellers may fail to capture the full potential of coordinated pricing strategies. In this paper, we address this problem by exploring dynamic pricing mechanisms designed explicitly for complementary products, aiming to exploit their joint demand structure to maximize overall revenue. We present an online learning algorithm considering both positive and negative interactions between products' demands. The algorithm utilizes transaction data to identify advantageous complementary relationships through an integer programming problem between different items, and then optimizes pricing strategies using data-driven and computationally efficient multi-armed bandit solutions based on heteroscedastic Gaussian processes. We validate our solution in a simulated environment, and we demonstrate that our solution improves the revenue w.r.t. a comparable learning algorithm ignoring such interactions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22270v1" target="_blank"><h2>Towards Understanding Generalization in DP-GD: A Case Study in Training Two-Layer CNNs</h2></a><strong><u>Authors:</u></strong> Zhongjie Shi, Puyu Wang, Chenyang Zhang, Yuan Cao<br><strong><u>Categories:</u></strong> stat.ML, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Modern deep learning techniques focus on extracting intricate information from data to achieve accurate predictions. However, the training datasets may be crowdsourced and include sensitive information, such as personal contact details, financial data, and medical records. As a result, there is a growing emphasis on developing privacy-preserving training algorithms for neural networks that maintain good performance while preserving privacy. In this paper, we investigate the generalization and privacy performances of the differentially private gradient descent (DP-GD) algorithm, which is a private variant of the gradient descent (GD) by incorporating additional noise into the gradients during each iteration. Moreover, we identify a concrete learning task where DP-GD can achieve superior generalization performance compared to GD in training two-layer Huberized ReLU convolutional neural networks (CNNs). Specifically, we demonstrate that, under mild conditions, a small signal-to-noise ratio can result in GD producing training models with poor test accuracy, whereas DP-GD can yield training models with good test accuracy and privacy guarantees if the signal-to-noise ratio is not too small. This indicates that DP-GD has the potential to enhance model performance while ensuring privacy protection in certain learning tasks. Numerical simulations are further conducted to support our theoretical results.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22246v1" target="_blank"><h2>An interpretable unsupervised representation learning for high precision measurement in particle physics</h2></a><strong><u>Authors:</u></strong> Xing-Jian Lv, De-Xing Miao, Zi-Jun Xu, Jian-Chun Wang<br><strong><u>Categories:</u></strong> hep-ex, cs.AI, physics.ins-det<br><strong><u>Comments:</u></strong> 8 pages, 7 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> latent space (abstract)<br><p><strong><u>Abstract:</u></strong> Unsupervised learning has been widely applied to various tasks in particle physics. However, existing models lack precise control over their learned representations, limiting physical interpretability and hindering their use for accurate measurements. We propose the Histogram AutoEncoder (HistoAE), an unsupervised representation learning network featuring a custom histogram-based loss that enforces a physically structured latent space. Applied to silicon microstrip detectors, HistoAE learns an interpretable two-dimensional latent space corresponding to the particle's charge and impact position. After simple post-processing, it achieves a charge resolution of $0.25\,e$ and a position resolution of $3\,μ\mathrm{m}$ on beam-test data, comparable to the conventional approach. These results demonstrate that unsupervised deep learning models can enable physically meaningful and quantitatively precise measurements. Moreover, the generative capacity of HistoAE enables straightforward extensions to fast detector simulations.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22240v1" target="_blank"><h2>Evaluating Embedding Models and Pipeline Optimization for AI Search Quality</h2></a><strong><u>Authors:</u></strong> Philip Zhong, Kent Chen, Don Wang<br><strong><u>Categories:</u></strong> cs.IR, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> We evaluate the performance of various text embedding models and pipeline configurations for AI-driven search systems. We compare sentence-transformer and generative embedding models (e.g., All-MPNet, BGE, GTE, and Qwen) at different dimensions, indexing methods (Milvus HNSW/IVF), and chunking strategies. A custom evaluation dataset of 11,975 query-chunk pairs was synthesized from US City Council meeting transcripts using a local large language model (LLM). The data pipeline includes preprocessing, automated question generation per chunk, manual validation, and continuous integration/continuous deployment (CI/CD) integration. We measure retrieval accuracy using reference-based metrics: Top-K Accuracy and Normalized Discounted Cumulative Gain (NDCG). Our results demonstrate that higher-dimensional embeddings significantly boost search quality (e.g., Qwen3-Embedding-8B/4096 achieves Top-3 accuracy about 0.571 versus 0.412 for GTE-large/1024), and that neural re-rankers (e.g., a BGE cross-encoder) further improve ranking accuracy (Top-3 up to 0.527). Finer-grained chunking (512 characters versus 2000 characters) also improves accuracy. We discuss the impact of these factors and outline future directions for pipeline automation and evaluation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22232v1" target="_blank"><h2>From Compound Figures to Composite Understanding: Developing a Multi-Modal LLM from Biomedical Literature with Medical Multiple-Image Benchmarking and Validation</h2></a><strong><u>Authors:</u></strong> Zhen Chen, Yihang Fu, Gabriel Madera, Mauro Giuffre, Serina Applebaum, Hyunjae Kim, Hua Xu, Qingyu Chen<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CL<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multi-modal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multi-modal large language models (MLLMs) have shown promise in advancing healthcare. However, most existing models remain confined to single-image understanding, which greatly limits their applicability in clinical workflows. In practice, medical diagnosis and progression often require synthesizing information across multiple images from different modalities or time points. The development of medical MLLMs capable of such multi-image understanding has been hindered by the lack of large-scale, high-quality annotated training data. To address this limitation, we propose a novel framework that leverages license-permissive compound images in biomedical literature, as a rich yet underutilized data source for multi-image analysis. Specifically, we design a five-stage, context-aware instruction generation paradigm underpinned by a divide-and-conquer strategy. By decomposing multi-image analysis into manageable sub-tasks, this paradigm empowers MLLMs to move beyond single-panel analysis and provide a composite understanding by learning the complex spatial, temporal, and cross-modal relationships inherent in these compound figures. By parsing over 237,000 compound figures and their contextual text for instruction generation, we develop M3LLM, a medical multi-image multi-modal large language model. For benchmarking, we construct PMC-MI-Bench for composite understanding, manually validated by medical experts. Extensive experiments show that M3LLM significantly outperforms both general-purpose and specialized medical MLLMs across multi-image, single-image, text-only, and multi-choice scenarios. Notably, M3LLM exhibits strong generalization to longitudinal chest X-ray analysis using the MIMIC dataset. This work establishes a scalable and efficient paradigm for developing medical MLLMs capable of composite reasoning, bridging the gap between biomedical literature and real-world clinical applications.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22188v1" target="_blank"><h2>ARPGNet: Appearance- and Relation-aware Parallel Graph Attention Fusion Network for Facial Expression Recognition</h2></a><strong><u>Authors:</u></strong> Yan Li, Yong Zhao, Xiaohan Xia, Dongmei Jiang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> Accepted by IEEE Transactions on Affective Computing. Submitted in August 2023; Accepted in October 2025<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> The key to facial expression recognition is to learn discriminative spatial-temporal representations that embed facial expression dynamics. Previous studies predominantly rely on pre-trained Convolutional Neural Networks (CNNs) to learn facial appearance representations, overlooking the relationships between facial regions. To address this issue, this paper presents an Appearance- and Relation-aware Parallel Graph attention fusion Network (ARPGNet) to learn mutually enhanced spatial-temporal representations of appearance and relation information. Specifically, we construct a facial region relation graph and leverage the graph attention mechanism to model the relationships between facial regions. The resulting relational representation sequences, along with CNN-based appearance representation sequences, are then fed into a parallel graph attention fusion module for mutual interaction and enhancement. This module simultaneously explores the complementarity between different representation sequences and the temporal dynamics within each sequence. Experimental results on three facial expression recognition datasets demonstrate that the proposed ARPGNet outperforms or is comparable to state-of-the-art methods.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22181v1" target="_blank"><h2>MTR-VP: Towards End-to-End Trajectory Planning through Context-Driven Image Encoding and Multiple Trajectory Prediction</h2></a><strong><u>Authors:</u></strong> Maitrayee Keskar, Mohan Trivedi, Ross Greer<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.RO<br><strong><u>Comments:</u></strong> 8 pages, 3 figures, 4 tables<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> We present a method for trajectory planning for autonomous driving, learning image-based context embeddings that align with motion prediction frameworks and planning-based intention input. Within our method, a ViT encoder takes raw images and past kinematic state as input and is trained to produce context embeddings, drawing inspiration from those generated by the recent MTR (Motion Transformer) encoder, effectively substituting map-based features with learned visual representations. MTR provides a strong foundation for multimodal trajectory prediction by localizing agent intent and refining motion iteratively via motion query pairs; we name our approach MTR-VP (Motion Transformer for Vision-based Planning), and instead of the learnable intention queries used in the MTR decoder, we use cross attention on the intent and the context embeddings, which reflect a combination of information encoded from the driving scene and past vehicle states. We evaluate our methods on the Waymo End-to-End Driving Dataset, which requires predicting the agent's future 5-second trajectory in bird's-eye-view coordinates using prior camera images, agent pose history, and routing goals. We analyze our architecture using ablation studies, removing input images and multiple trajectory output. Our results suggest that transformer-based methods that are used to combine the visual features along with the kinetic features such as the past trajectory features are not effective at combining both modes to produce useful scene context embeddings, even when intention embeddings are augmented with foundation-model representations of scene context from CLIP and DINOv2, but that predicting a distribution over multiple futures instead of a single future trajectory boosts planning performance.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22178v1" target="_blank"><h2>Enhanced Graph Convolutional Network with Chebyshev Spectral Graph and Graph Attention for Autism Spectrum Disorder Classification</h2></a><strong><u>Authors:</u></strong> Adnan Ferdous Ashrafi, Hasanul Kabir<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 6 pages, 2 figures, 2 tables, Accepted and presented at Image and Vision Computing New Zealand (IVCNZ) 2025<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (abstract), multimodal (abstract), attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> ASD is a complicated neurodevelopmental disorder marked by variation in symptom presentation and neurological underpinnings, making early and objective diagnosis extremely problematic. This paper presents a Graph Convolutional Network (GCN) model, incorporating Chebyshev Spectral Graph Convolution and Graph Attention Networks (GAT), to increase the classification accuracy of ASD utilizing multimodal neuroimaging and phenotypic data. Leveraging the ABIDE I dataset, which contains resting-state functional MRI (rs-fMRI), structural MRI (sMRI), and phenotypic variables from 870 patients, the model leverages a multi-branch architecture that processes each modality individually before merging them via concatenation. Graph structure is encoded using site-based similarity to generate a population graph, which helps in understanding relationship connections across individuals. Chebyshev polynomial filters provide localized spectral learning with lower computational complexity, whereas GAT layers increase node representations by attention-weighted aggregation of surrounding information. The proposed model is trained using stratified five-fold cross-validation with a total input dimension of 5,206 features per individual. Extensive trials demonstrate the enhanced model's superiority, achieving a test accuracy of 74.82\% and an AUC of 0.82 on the entire dataset, surpassing multiple state-of-the-art baselines, including conventional GCNs, autoencoder-based deep neural networks, and multimodal CNNs.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22176v1" target="_blank"><h2>Focused Chain-of-Thought: Efficient LLM Reasoning via Structured Input Information</h2></a><strong><u>Authors:</u></strong> Lukas Struppek, Dominik Hintersdorf, Hannah Struppek, Daniel Neider, Kristian Kersting<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Recent large language models achieve strong reasoning performance by generating detailed chain-of-thought traces, but this often leads to excessive token use and high inference latency. Existing efficiency approaches typically focus on model-centric interventions, such as reinforcement learning or supervised fine-tuning, to reduce verbosity. In contrast, we propose a training-free, input-centric approach. Inspired by cognitive psychology, we introduce Focused Chain-of-Thought (F-CoT), which separates information extraction from the reasoning process. F-CoT first organizes the essential information from a query into a concise, structured context and then guides the model to reason exclusively over this context. By preventing attention to irrelevant details, F-CoT naturally produces shorter reasoning paths. On arithmetic word problems, F-CoT reduces generated tokens by 2-3x while maintaining accuracy comparable to standard zero-shot CoT. These results highlight structured input as a simple yet effective lever for more efficient LLM reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22167v1" target="_blank"><h2>IMTalker: Efficient Audio-driven Talking Face Generation with Implicit Motion Transfer</h2></a><strong><u>Authors:</u></strong> Bo Chen, Tao Liu, Qi Chen, Xie Chen, Zilong Zheng<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 11 pages, 5 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Talking face generation aims to synthesize realistic speaking portraits from a single image, yet existing methods often rely on explicit optical flow and local warping, which fail to model complex global motions and cause identity drift. We present IMTalker, a novel framework that achieves efficient and high-fidelity talking face generation through implicit motion transfer. The core idea is to replace traditional flow-based warping with a cross-attention mechanism that implicitly models motion discrepancy and identity alignment within a unified latent space, enabling robust global motion rendering. To further preserve speaker identity during cross-identity reenactment, we introduce an identity-adaptive module that projects motion latents into personalized spaces, ensuring clear disentanglement between motion and identity. In addition, a lightweight flow-matching motion generator produces vivid and controllable implicit motion vectors from audio, pose, and gaze cues. Extensive experiments demonstrate that IMTalker surpasses prior methods in motion accuracy, identity preservation, and audio-lip synchronization, achieving state-of-the-art quality with superior efficiency, operating at 40 FPS for video-driven and 42 FPS for audio-driven generation on an RTX 4090 GPU. We will release our code and pre-trained models to facilitate applications and future research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22153v1" target="_blank"><h2>A Theoretically Grounded Hybrid Ensemble for Reliable Detection of LLM-Generated Text</h2></a><strong><u>Authors:</u></strong> Sepyan Purnama Kristanto, Lutfi Hakim<br><strong><u>Categories:</u></strong> cs.CL, cs.AI<br><strong><u>Comments:</u></strong> 24 pages<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> The rapid proliferation of Large Language Models (LLMs) has blurred the line between human and machine authorship, creating practical risks for academic integrity and information reliability. Existing text detectors typically rely on a single methodological paradigm and suffer from poor generalization and high false positive rates (FPR), especially on high-stakes academic text. We propose a theoretically grounded hybrid ensemble that systematically fuses three complementary detection paradigms: (i) a RoBERTa-based transformer classifier for deep semantic feature extraction, (ii) a GPT-2-based probabilistic detector using perturbation-induced likelihood curvature, and (iii) a statistical linguistic feature analyzer capturing stylometric patterns. The core novelty lies in an optimized weighted voting framework, where ensemble weights are learned on the probability simplex to maximize F1-score rather than set heuristically. We provide a bias-variance analysis and empirically demonstrate low inter-model correlation (rho ~ 0.35-0.42), a key condition for variance reduction. Evaluated on a large-scale, multigenerator corpus of 30,000 documents, our system achieves 94.2% accuracy and an AUC of 0.978, with a 35% relative reduction in false positives on academic text. This yields a more reliable and ethically responsible detector for real-world deployment in education and other high-stakes domains.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22143v1" target="_blank"><h2>Stacked Ensemble of Fine-Tuned CNNs for Knee Osteoarthritis Severity Grading</h2></a><strong><u>Authors:</u></strong> Adarsh Gupta, Japleen Kaur, Tanvi Doshi, Teena Sharma, Nishchal K. Verma, Shantaram Vasikarla<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> Accepted and Presented at IEEE UEMCON, IBM T.J. Watson Research Center, New York, USA, 2024<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Knee Osteoarthritis (KOA) is a musculoskeletal condition that can cause significant limitations and impairments in daily activities, especially among older individuals. To evaluate the severity of KOA, typically, X-ray images of the affected knee are analyzed, and a grade is assigned based on the Kellgren-Lawrence (KL) grading system, which classifies KOA severity into five levels, ranging from 0 to 4. This approach requires a high level of expertise and time and is susceptible to subjective interpretation, thereby introducing potential diagnostic inaccuracies. To address this problem a stacked ensemble model of fine-tuned Convolutional Neural Networks (CNNs) was developed for two classification tasks: a binary classifier for detecting the presence of KOA, and a multiclass classifier for precise grading across the KL spectrum. The proposed stacked ensemble model consists of a diverse set of pre-trained architectures, including MobileNetV2, You Only Look Once (YOLOv8), and DenseNet201 as base learners and Categorical Boosting (CatBoost) as the meta-learner. This proposed model had a balanced test accuracy of 73% in multiclass classification and 87.5% in binary classification, which is higher than previous works in extant literature.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22133v1" target="_blank"><h2>Probabilistic Digital Twin for Misspecified Structural Dynamical Systems via Latent Force Modeling and Bayesian Neural Networks</h2></a><strong><u>Authors:</u></strong> Sahil Kashyap, Rajdip Nayek<br><strong><u>Categories:</u></strong> cs.LG, stat.AP, stat.ML<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> This work presents a probabilistic digital twin framework for response prediction in dynamical systems governed by misspecified physics. The approach integrates Gaussian Process Latent Force Models (GPLFM) and Bayesian Neural Networks (BNNs) to enable end-to-end uncertainty-aware inference and prediction. In the diagnosis phase, model-form errors (MFEs) are treated as latent input forces to a nominal linear dynamical system and jointly estimated with system states using GPLFM from sensor measurements. A BNN is then trained on posterior samples to learn a probabilistic nonlinear mapping from system states to MFEs, while capturing diagnostic uncertainty. For prognosis, this mapping is used to generate pseudo-measurements, enabling state prediction via Kalman filtering. The framework allows for systematic propagation of uncertainty from diagnosis to prediction, a key capability for trustworthy digital twins. The framework is demonstrated using four nonlinear examples: a single degree of freedom (DOF) oscillator, a multi-DOF system, and two established benchmarks -- the Bouc-Wen hysteretic system and the Silverbox experimental dataset -- highlighting its predictive accuracy and robustness to model misspecification.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22128v1" target="_blank"><h2>A Variational Manifold Embedding Framework for Nonlinear Dimensionality Reduction</h2></a><strong><u>Authors:</u></strong> John J. Vastola, Samuel J. Gershman, Kanaka Rajan<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Accepted to the NeurIPS 2025 Workshop on Symmetry and Geometry in Neural Representations (NeurReps)<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract)<br><p><strong><u>Abstract:</u></strong> Dimensionality reduction algorithms like principal component analysis (PCA) are workhorses of machine learning and neuroscience, but each has well-known limitations. Variants of PCA are simple and interpretable, but not flexible enough to capture nonlinear data manifold structure. More flexible approaches have other problems: autoencoders are generally difficult to interpret, and graph-embedding-based methods can produce pathological distortions in manifold geometry. Motivated by these shortcomings, we propose a variational framework that casts dimensionality reduction algorithms as solutions to an optimal manifold embedding problem. By construction, this framework permits nonlinear embeddings, allowing its solutions to be more flexible than PCA. Moreover, the variational nature of the framework has useful consequences for interpretability: each solution satisfies a set of partial differential equations, and can be shown to reflect symmetries of the embedding objective. We discuss these features in detail and show that solutions can be analytically characterized in some cases. Interestingly, one special case exactly recovers PCA.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22116v1" target="_blank"><h2>IVGAE: Handling Incomplete Heterogeneous Data with a Variational Graph Autoencoder</h2></a><strong><u>Authors:</u></strong> Youran Zhou, Mohamed Reda Bouadjenek, Sunil Aryal%<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Handling missing data remains a fundamental challenge in real-world tabular datasets, especially when data are heterogeneous with both numerical and categorical features. Existing imputation methods often fail to capture complex structural dependencies and handle heterogeneous data effectively. We present \textbf{IVGAE}, a Variational Graph Autoencoder framework for robust imputation of incomplete heterogeneous data. IVGAE constructs a bipartite graph to represent sample-feature relationships and applies graph representation learning to model structural dependencies. A key innovation is its \textit{dual-decoder architecture}, where one decoder reconstructs feature embeddings and the other models missingness patterns, providing structural priors aware of missing mechanisms. To better encode categorical variables, we introduce a Transformer-based heterogeneous embedding module that avoids high-dimensional one-hot encoding. Extensive experiments on 16 real-world datasets show that IVGAE achieves consistent improvements in RMSE and downstream F1 across MCAR, MAR, and MNAR missing scenarios under 30\% missing rates. Code and data are available at: https://github.com/echoid/IVGAE.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22112v1" target="_blank"><h2>Toward Data-Driven Surrogates of the Solar Wind with Spherical Fourier Neural Operator</h2></a><strong><u>Authors:</u></strong> Reza Mansouri, Dustin Kempton, Pete Riley, Rafal Angryk<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> International Conference on Machine Learning and Applications (ICMLA 2025)<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (title)<br><p><strong><u>Abstract:</u></strong> The solar wind, a continuous stream of charged particles from the Sun's corona, shapes the heliosphere and impacts space systems near Earth. Variations such as high-speed streams and coronal mass ejections can disrupt satellites, power grids, and communications, making accurate modeling essential for space weather forecasting. While 3D magnetohydrodynamic (MHD) models are used to simulate and investigate these variations in the solar wind, they tend to be computationally expensive, limiting their usefulness in investigating the impacts of boundary condition uncertainty. In this work, we develop a surrogate for steady state solar wind modeling, using a Spherical Fourier Neural Operator (SFNO). We compare our model to a previously developed numerical surrogate for this task called HUX, and we show that the SFNO achieves comparable or better performance across several metrics. Though HUX retains advantages in physical smoothness, this underscores the need for improved evaluation criteria rather than a flaw in SFNO. As a flexible and trainable approach, SFNO enables efficient real-time forecasting and can improve with more data. The source code and more visual results are available at https://github.com/rezmansouri/solarwind-sfno-velocity.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22108v1" target="_blank"><h2>An energy-efficient spiking neural network with continuous learning for self-adaptive brain-machine interface</h2></a><strong><u>Authors:</u></strong> Zhou Biyan, Arindam Basu<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> The number of simultaneously recorded neurons follows an exponentially increasing trend in implantable brain-machine interfaces (iBMIs). Integrating the neural decoder in the implant is an effective data compression method for future wireless iBMIs. However, the non-stationarity of the system makes the performance of the decoder unreliable. To avoid frequent retraining of the decoder and to ensure the safety and comfort of the iBMI user, continuous learning is essential for real-life applications. Since Deep Spiking Neural Networks (DSNNs) are being recognized as a promising approach for developing resource-efficient neural decoder, we propose continuous learning approaches with Reinforcement Learning (RL) algorithms adapted for DSNNs. Banditron and AGREL are chosen as the two candidate RL algorithms since they can be trained with limited computational resources, effectively addressing the non-stationary problem and fitting the energy constraints of implantable devices. To assess the effectiveness of the proposed methods, we conducted both open-loop and closed-loop experiments. The accuracy of open-loop experiments conducted with DSNN Banditron and DSNN AGREL remains stable over extended periods. Meanwhile, the time-to-target in the closed-loop experiment with perturbations, DSNN Banditron performed comparably to that of DSNN AGREL while achieving reductions of 98% in memory access usage and 99% in the requirements for multiply- and-accumulate (MAC) operations during training. Compared to previous continuous learning SNN decoders, DSNN Banditron requires 98% less computes making it a prime candidate for future wireless iBMI systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22102v1" target="_blank"><h2>MRI-Based Brain Age Estimation with Supervised Contrastive Learning of Continuous Representation</h2></a><strong><u>Authors:</u></strong> Simon Joseph Clément Crête, Marta Kersten-Oertel, Yiming Xiao<br><strong><u>Categories:</u></strong> cs.CV, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> MRI-based brain age estimation models aim to assess a subject's biological brain age based on information, such as neuroanatomical features. Various factors, including neurodegenerative diseases, can accelerate brain aging and measuring this phenomena could serve as a potential biomarker for clinical applications. While deep learning (DL)-based regression has recently attracted major attention, existing approaches often fail to capture the continuous nature of neuromorphological changes, potentially resulting in sub-optimal feature representation and results. To address this, we propose to use supervised contrastive learning with the recent Rank-N-Contrast (RNC) loss to estimate brain age based on widely used T1w structural MRI for the first time and leverage Grad-RAM to visually explain regression results. Experiments show that our proposed method achieves a mean absolute error (MAE) of 4.27 years and an $R^2$ of 0.93 with a limited dataset of training samples, significantly outperforming conventional deep regression with the same ResNet backbone while performing better or comparably with the state-of-the-art methods with significantly larger training data. Furthermore, Grad-RAM revealed more nuanced features related to age regression with the RNC loss than conventional deep regression. As an exploratory study, we employed the proposed method to estimate the gap between the biological and chronological brain ages in Alzheimer's Disease and Parkinson's disease patients, and revealed the correlation between the brain age gap and disease severity, demonstrating its potential as a biomarker in neurodegenerative disorders.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22095v1" target="_blank"><h2>Binary-30K: A Heterogeneous Dataset for Deep Learning in Binary Analysis and Malware Detection</h2></a><strong><u>Authors:</u></strong> Michael J. Bommarito<br><strong><u>Categories:</u></strong> cs.CR, cs.AI<br><strong><u>Comments:</u></strong> 35 pages, 7 figures, 11 tables, 4 appendices. Dataset available atthis https URL<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transfer learning (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Deep learning research for binary analysis faces a critical infrastructure gap. Today, existing datasets target single platforms, require specialized tooling, or provide only hand-engineered features incompatible with modern neural architectures; no single dataset supports accessible research and pedagogy on realistic use cases. To solve this, we introduce Binary-30K, the first heterogeneous binary dataset designed for sequence-based models like transformers. Critically, Binary-30K covers Windows, Linux, macOS, and Android across 15+ CPU architectures. With 29,793 binaries and approximately 26.93% malware representation, Binary-30K enables research on platform-invariant detection, cross-target transfer learning, and long-context binary understanding. The dataset provides pre-computed byte-level BPE tokenization alongside comprehensive structural metadata, supporting both sequence modeling and structure-aware approaches. Platform-first stratified sampling ensures representative coverage across operating systems and architectures, while distribution via Hugging Face with official train/validation/test splits enables reproducible benchmarking. The dataset is publicly available at https://huggingface.co/datasets/mjbommar/binary-30k, providing an accessible resource for researchers, practitioners, and students alike.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22093v1" target="_blank"><h2>Characterizing Binary Black Hole Subpopulations in GWTC-4 with Binned Gaussian Processes: On the Origins of the $35M_{\odot}$ Peak</h2></a><strong><u>Authors:</u></strong> Omkar Sridhar, Anarya Ray, Vicky Kalogera<br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA<br><strong><u>Comments:</u></strong> 16 pages, 8 figures<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Understanding the astrophysical origins of binary black holes requires accurate and flexible modeling of multi-dimensional population properties. In this paper, using a data-driven framework based on binned Gaussian processes, we characterize the joint distribution of BBH primary masses, mass ratios, and effective inspiral spins. We identify three distinct subpopulations in the GWTC-4 sample of observations and investigate their astrophysical origins. We find that only one of the three subpopulations exhibits the $35M_{\odot}$ peak, which is characterized by a strong preference for equal mass systems and isotropic spin orientations. Our inferred distributions are consistent with a predominantly dynamical origin of this feature. By comparing with theoretical simulations, we further show that the subpopulation that exhibits the $35M_{\sun}$ peak can exclusively comprise dynamically assembled systems in globular clusters, specifically if black hole birth spins are in the range~$(0.1-0.2)$, whereas the other two subpopulations require substantial contributions from alternative formation channels. We constrain the \textit{lower bound} on the merger rate of BBHs in globular clusters to be $0.69^{+0.23}_{-0.33} \rm{Gpc}^{-3}\rm{yr}^{-1}$, which is consistent with theoretical predictions. We conclude that dynamical formation in globular clusters remains a strong candidate for the origin of this excess near $30-40M_{\odot}$ and that more data and targeted parametric models are necessary to rigorously establish this interpretation.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22078v1" target="_blank"><h2>ARES: Anomaly Recognition Model For Edge Streams</h2></a><strong><u>Authors:</u></strong> Simone Mungari, Albert Bifet, Giuseppe Manco, Bernhard Pfahringer<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> Accepted at KDD 2026<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), latent space (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Many real-world scenarios involving streaming information can be represented as temporal graphs, where data flows through dynamic changes in edges over time. Anomaly detection in this context has the objective of identifying unusual temporal connections within the graph structure. Detecting edge anomalies in real time is crucial for mitigating potential risks. Unlike traditional anomaly detection, this task is particularly challenging due to concept drifts, large data volumes, and the need for real-time response. To face these challenges, we introduce ARES, an unsupervised anomaly detection framework for edge streams. ARES combines Graph Neural Networks (GNNs) for feature extraction with Half-Space Trees (HST) for anomaly scoring. GNNs capture both spike and burst anomalous behaviors within streams by embedding node and edge properties in a latent space, while HST partitions this space to isolate anomalies efficiently. ARES operates in an unsupervised way without the need for prior data labeling. To further validate its detection capabilities, we additionally incorporate a simple yet effective supervised thresholding mechanism. This approach leverages statistical dispersion among anomaly scores to determine the optimal threshold using a minimal set of labeled data, ensuring adaptability across different domains. We validate ARES through extensive evaluations across several real-world cyber-attack scenarios, comparing its performance against existing methods while analyzing its space and time complexity.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22072v1" target="_blank"><h2>A Multi-View Multi-Timescale Hypergraph-Empowered Spatiotemporal Framework for EV Charging Forecasting</h2></a><strong><u>Authors:</u></strong> Jinhao Li, Hao Wang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 14 pages<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> neural network (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Accurate electric vehicle (EV) charging demand forecasting is essential for stable grid operation and proactive EV participation in electricity market. Existing forecasting methods, particularly those based on graph neural networks, are often limited to modeling pairwise relationships between stations, failing to capture the complex, group-wise dynamics inherent in urban charging networks. To address this gap, we develop a novel forecasting framework namely HyperCast, leveraging the expressive power of hypergraphs to model the higher-order spatiotemporal dependencies hidden in EV charging patterns. HyperCast integrates multi-view hypergraphs, which capture both static geographical proximity and dynamic demand-based functional similarities, along with multi-timescale inputs to differentiate between recent trends and weekly periodicities. The framework employs specialized hyper-spatiotemporal blocks and tailored cross-attention mechanisms to effectively fuse information from these diverse sources: views and timescales. Extensive experiments on four public datasets demonstrate that HyperCast significantly outperforms a wide array of state-of-the-art baselines, demonstrating the effectiveness of explicitly modeling collective charging behaviors for more accurate forecasting.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22071v1" target="_blank"><h2>A Catalogue of Mid-infrared Variable Sources from unTimely <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Zihan kang, Jingyi Zhang, Yanxia Zhang, Changhua Li, Xiao Kong, Minzhi Kong, Jinghang Shi, Shirui Wei, Xue-Bing Wu<br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.GA<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> time-domain (abstract)<br><p><strong><u>Abstract:</u></strong> The WISE and NEOWISE missions have provided the only mid-infrared all-sky time-domain data, opening a unique observational window for variability studies. Yet, a comprehensive and systematic catalog of mid-infrared variable sources has remained unavailable. In this work, we construct the first large-scale mid-infrared variability catalog based on the unTimely coadded photometry, covering tens of millions of sources. By employing a Bayesian Gaussian mixture model with a Dirichlet process, we identified 8,256,042 variable sources in the W1 band and 7,147,661 in the W2 band, significantly expanding the landscape of known mid-infrared variables. In addition to robust variability metrics, our analysis highlights rare and extreme outliers through dedicated outlier-detection algorithms, enabling the discovery of unusual classes of objects such as eruptive young stellar objects, highly variable active galactic nuclei, and other rare transients. This unprecedented dataset provides a new foundation for time-domain astronomy in the mid-infrared, offering complementary insights to optical and near-infrared surveys, and opening the door to systematic investigations of stellar evolution, accretion processes, and dust-enshrouded astrophysical environments on a Galactic and extragalactic scale.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22036v1" target="_blank"><h2>ResearchArcade: Graph Interface for Academic Tasks</h2></a><strong><u>Authors:</u></strong> Jingjun Xu, Chongshan Lin, Haofei Yu, Tao Feng, Jiaxuan You<br><strong><u>Categories:</u></strong> cs.CL, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> multi-modal (abstract)<br><p><strong><u>Abstract:</u></strong> Academic research generates diverse data sources, and as researchers increasingly use machine learning to assist research tasks, a crucial question arises: Can we build a unified data interface to support the development of machine learning models for various academic tasks? Models trained on such a unified interface can better support human researchers throughout the research process, eventually accelerating knowledge discovery. In this work, we introduce ResearchArcade, a graph-based interface that connects multiple academic data sources, unifies task definitions, and supports a wide range of base models to address key academic challenges. ResearchArcade utilizes a coherent multi-table format with graph structures to organize data from different sources, including academic corpora from ArXiv and peer reviews from OpenReview, while capturing information with multiple modalities, such as text, figures, and tables. ResearchArcade also preserves temporal evolution at both the manuscript and community levels, supporting the study of paper revisions as well as broader research trends over time. Additionally, ResearchArcade unifies diverse academic task definitions and supports various models with distinct input requirements. Our experiments across six academic tasks demonstrate that combining cross-source and multi-modal information enables a broader range of tasks, while incorporating graph structures consistently improves performance over baseline methods. This highlights the effectiveness of ResearchArcade and its potential to advance research progress.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22030v1" target="_blank"><h2>Calibration-Free EEG-based Driver Drowsiness Detection with Online Test-Time Adaptation</h2></a><strong><u>Authors:</u></strong> Geun-Deok Jang, Dong-Kyun Han, Seo-Hyeon Park, Seong-Whan Lee<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 10 pages, Submitted to IEEE Transactions on Human-Machine Systems<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> Drowsy driving is a growing cause of traffic accidents, prompting recent exploration of electroencephalography (EEG)-based drowsiness detection systems. However, the inherent variability of EEG signals due to psychological and physical factors necessitates a cumbersome calibration process. In particular, the inter-subject variability of EEG signals leads to a domain shift problem, which makes it challenging to generalize drowsiness detection models to unseen target subjects. To address these issues, we propose a novel driver drowsiness detection framework that leverages online test-time adaptation (TTA) methods to dynamically adjust to target subject distributions. Our proposed method updates the learnable parameters in batch normalization (BN) layers, while preserving pretrained normalization statistics, resulting in a modified configuration that ensures effective adaptation during test time. We incorporate a memory bank that dynamically manages streaming EEG segments, selecting samples based on their reliability determined by negative energy scores and persistence time. In addition, we introduce prototype learning to ensure robust predictions against distribution shifts over time. We validated our method on the sustained-attention driving dataset collected in a simulated environment, where drowsiness was estimated from delayed reaction times during monotonous lane-keeping tasks. Our experiments show that our method outperforms all baselines, achieving an average F1-score of 81.73\%, an improvement of 11.73\% over the best TTA baseline. This demonstrates that our proposed method significantly enhances the adaptability of EEG-based drowsiness detection systems in non-i.i.d. scenarios.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.22001v1" target="_blank"><h2>When Do Domain-Specific Foundation Models Justify Their Cost? A Systematic Evaluation Across Retinal Imaging Tasks</h2></a><strong><u>Authors:</u></strong> David Isztl, Tahm Spitznagel, Gabor Mark Somfai, Rui Santos<br><strong><u>Categories:</u></strong> eess.IV, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-27<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Large vision foundation models have been widely adopted for retinal disease classification without systematic evidence justifying their parameter requirements. In the present work we address two critical questions: First, are large domain-specific foundation models essential, or do compact general-purpose architectures suffice? Second, does specialized retinal pretraining justify its computational cost? To answer this, we benchmark initialization strategies across four retinal imaging classification tasks spanning Optical Coherence Tomography (OCT) and Color Fundus Photography (CFP) modalities: 8-class OCT classification, 3-class diabetic macular edema (DME), 5-class diabetic retinopathy (DR), and 3-class glaucoma (GL) detection. We evaluate 12-13 model configurations per task, including vision transformers (22.8M-86.6M parameters), Swin Transformers (27.6M-28.3M), ConvNeXt (28.6M), and the domain-specific RETFound models (303M), under identical training conditions. Our results challenge prevailing assumptions: First, we demonstrate that pretraining provides universal benefits (5.18-18.41% improvement), scaling with task difficulty. Second, compact architectures (27-29M) dominate Pareto frontiers; SwinV2-tiny achieves top-1 performance on three datasets. Third, RETFound (303M) justifies its computational cost only for challenging DR grading (accuracy of 71.15%), while ImageNet pretraining proves to be sufficient with all other tasks (DME accuracy: 99.24%, OCT accuracy: 97.96%). CFP tasks show larger pretraining accuracy gains (9.13-18.41%) than OCT (5.18%). Thus, the evidence suggests that compact general-purpose models deliver near-optimal performance for most retinal classification tasks; specialized foundation models warranted only for fine-grained discrimination under extreme class imbalance.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21982v1" target="_blank"><h2>DialBench: Towards Accurate Reading Recognition of Pointer Meter using Large Foundation Models</h2></a><strong><u>Authors:</u></strong> Futian Wang, Chaoliu Weng, Xiao Wang, Zhen Chen, Zhicheng Zhao, Jin Tang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> attention (abstract)<br><p><strong><u>Abstract:</u></strong> The precise reading recognition of pointer meters plays a key role in smart power systems, but existing approaches remain fragile due to challenges like reflections, occlusions, dynamic viewing angles, and overly between thin pointers and scale markings. Up to now, this area still lacks large-scale datasets to support the development of robust algorithms. To address these challenges, this paper first presents a new large-scale benchmark dataset for dial reading, termed RPM-10K, which contains 10730 meter images that fully reflect the aforementioned key challenges. Built upon the dataset, we propose a novel vision-language model for pointer meter reading recognition, termed MRLM, based on physical relation injection. Instead of exhaustively learning image-level correlations, MRLM explicitly encodes the geometric and causal relationships between the pointer and the scale, aligning perception with physical reasoning in the spirit of world-model perspectives. Through cross-attentional fusion and adaptive expert selection, the model learns to interpret dial configurations and generate precise numeric readings. Extensive experiments fully validated the effectiveness of our proposed framework on the newly proposed benchmark dataset. Both the dataset and source code will be released on https://github.com/Event-AHU/DialBench</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21970v1" target="_blank"><h2>MOTIF-RF: Multi-template On-chip Transformer Synthesis Incorporating Frequency-domain Self-transfer Learning for RFIC Design Automation</h2></a><strong><u>Authors:</u></strong> Houbo He, Yizhou Xu, Lei Xia, Yaolong Hu, Fan Cai, Taiyun Chi<br><strong><u>Categories:</u></strong> cs.LG, eess.SP<br><strong><u>Comments:</u></strong> Accepted at ASP-DAC 2026<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> transfer learning (title, abstract), transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> This paper presents a systematic study on developing multi-template machine learning (ML) surrogate models and applying them to the inverse design of transformers (XFMRs) in radio-frequency integrated circuits (RFICs). Our study starts with benchmarking four widely used ML architectures, including MLP-, CNN-, UNet-, and GT-based models, using the same datasets across different XFMR topologies. To improve modeling accuracy beyond these baselines, we then propose a new frequency-domain self-transfer learning technique that exploits correlations between adjacent frequency bands, leading to around 30%-50% accuracy improvement in the S-parameters prediction. Building on these models, we further develop an inverse design framework based on the covariance matrix adaptation evolutionary strategy (CMA-ES) algorithm. This framework is validated using multiple impedance-matching tasks, all demonstrating fast convergence and trustworthy performance. These results advance the goal of AI-assisted specs-to-GDS automation for RFICs and provide RFIC designers with actionable tools for integrating AI into their workflows.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21963v1" target="_blank"><h2>CTR Prediction on Alibaba's Taobao Advertising Dataset Using Traditional and Deep Learning Models</h2></a><strong><u>Authors:</u></strong> Hongyu Yang, Chunxi Wen, Jiyin Zhang, Nanfei Shen, Shijiao Zhang, Xiyan Han<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Click-through rates prediction is critical in modern advertising systems, where ranking relevance and user engagement directly impact platform efficiency and business value. In this project, we explore how to model CTR more effectively using a large-scale Taobao dataset released by Alibaba. We start with supervised learning models, including logistic regression and Light-GBM, that are trained on static features such as user demographics, ad attributes, and contextual metadata. These models provide fast, interpretable benchmarks, but have limited capabilities to capture patterns of behavior that drive clicks. To better model user intent, we combined behavioral data from hundreds of millions of interactions over a 22-day period. By extracting and encoding user action sequences, we construct representations of user interests over time. We use deep learning models to fuse behavioral embeddings with static features. Among them, multilayer perceptrons (MLPs) have achieved significant performance improvements. To capture temporal dynamics, we designed a Transformer-based architecture that uses a self-attention mechanism to learn contextual dependencies across behavioral sequences, modeling not only what the user interacts with, but also the timing and frequency of interactions. Transformer improves AUC by 2.81 % over the baseline (LR model), with the largest gains observed for users whose interests are diverse or change over time. In addition to modeling, we propose an A/B testing strategy for real-world evaluation. We also think about the broader implications: personalized ad targeting technology can be applied to public health scenarios to achieve precise delivery of health information or behavior guidance. Our research provides a roadmap for advancing click-through rate predictions and extending their value beyond e-commerce.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21959v1" target="_blank"><h2>DeepGI: Explainable Deep Learning for Gastrointestinal Image Classification</h2></a><strong><u>Authors:</u></strong> Walid Houmaidi, Mohamed Hadadi, Youssef Sabiri, Yousra Chtouki<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CY, cs.LG<br><strong><u>Comments:</u></strong> 7 pages, 4 figures, 2 tables. Accepted at DASET 2026<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title, abstract)<br><p><strong><u>Abstract:</u></strong> This paper presents a comprehensive comparative model analysis on a novel gastrointestinal medical imaging dataset, comprised of 4,000 endoscopic images spanning four critical disease classes: Diverticulosis, Neoplasm, Peritonitis, and Ureters. Leveraging state-of-the-art deep learning techniques, the study confronts common endoscopic challenges such as variable lighting, fluctuating camera angles, and frequent imaging artifacts. The best performing models, VGG16 and MobileNetV2, each achieved a test accuracy of 96.5%, while Xception reached 94.24%, establishing robust benchmarks and baselines for automated disease classification. In addition to strong classification performance, the approach includes explainable AI via Grad-CAM visualization, enabling identification of image regions most influential to model predictions and enhancing clinical interpretability. Experimental results demonstrate the potential for robust, accurate, and interpretable medical image analysis even in complex real-world conditions. This work contributes original benchmarks, comparative insights, and visual explanations, advancing the landscape of gastrointestinal computer-aided diagnosis and underscoring the importance of diverse, clinically relevant datasets and model explainability in medical AI research.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21952v1" target="_blank"><h2>ABLE: Using Adversarial Pairs to Construct Local Models for Explaining Model Predictions</h2></a><strong><u>Authors:</u></strong> Krishna Khadka, Sunny Shree, Pujan Budhathoki, Yu Lei, Raghu Kacker, D. Richard Kuhn<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> 10 pages, 2 figures. Accepted to KDD 2026 (Research Track)<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Machine learning models are increasingly used in critical applications but are mostly "black boxes" due to their lack of transparency. Local explanation approaches, such as LIME, address this issue by approximating the behavior of complex models near a test instance using simple, interpretable models. However, these approaches often suffer from instability and poor local fidelity. In this paper, we propose a novel approach called Adversarially Bracketed Local Explanation (ABLE) to address these limitations. Our approach first generates a set of neighborhood points near the test instance, x_test, by adding bounded Gaussian noise. For each neighborhood point D, we apply an adversarial attack to generate an adversarial point A with minimal perturbation that results in a different label than D. A second adversarial attack is then performed on A to generate a point A' that has the same label as D (and thus different than A). The points A and A' form an adversarial pair that brackets the local decision boundary for x_test. We then train a linear model on these adversarial pairs to approximate the local decision boundary. Experimental results on six UCI benchmark datasets across three deep neural network architectures demonstrate that our approach achieves higher stability and fidelity than the state-of-the-art.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21947v1" target="_blank"><h2>WalkCLIP: Multimodal Learning for Urban Walkability Prediction</h2></a><strong><u>Authors:</u></strong> Shilong Xiang, JangHyeon Lee, Min Namgung, Yao-Yi Chiang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Urban walkability is a cornerstone of public health, sustainability, and quality of life. Traditional walkability assessments rely on surveys and field audits, which are costly and difficult to scale. Recent studies have used satellite imagery, street view imagery, or population indicators to estimate walkability, but these single-source approaches capture only one dimension of the walking environment. Satellite data describe the built environment from above, but overlook the pedestrian perspective. Street view imagery captures conditions at the ground level, but lacks broader spatial context. Population dynamics reveal patterns of human activity but not the visual form of the environment. We introduce WalkCLIP, a multimodal framework that integrates these complementary viewpoints to predict urban walkability. WalkCLIP learns walkability-aware vision-language representations from GPT-4o generated image captions, refines these representations with a spatial aggregation module that incorporates neighborhood context, and fuses the resulting features with representations from a population dynamics foundation model. Evaluated at 4,660 locations throughout Minneapolis-Saint Paul, WalkCLIP outperforms unimodal and multimodal baselines in both predictive accuracy and spatial alignment. These results show that the integration of visual and behavioral signals yields reliable predictions of the walking environment.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21940v1" target="_blank"><h2>Deep Learning Architectures for Code-Modulated Visual Evoked Potentials Detection</h2></a><strong><u>Authors:</u></strong> Kiran Nair, Hubert Cecotti<br><strong><u>Categories:</u></strong> cs.LG, eess.SP, q-bio.NC<br><strong><u>Comments:</u></strong> 20 Pages, prepared for a Journal<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), convolutional (abstract), neural network (abstract), data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> Non-invasive Brain-Computer Interfaces (BCIs) based on Code-Modulated Visual Evoked Potentials (C-VEPs) require highly robust decoding methods to address temporal variability and session-dependent noise in EEG signals. This study proposes and evaluates several deep learning architectures, including convolutional neural networks (CNNs) for 63-bit m-sequence reconstruction and classification, and Siamese networks for similarity-based decoding, alongside canonical correlation analysis (CCA) baselines. EEG data were recorded from 13 healthy adults under single-target flicker stimulation. The proposed deep models significantly outperformed traditional approaches, with distance-based decoding using Earth Mover's Distance (EMD) and constrained EMD showing greater robustness to latency variations than Euclidean and Mahalanobis metrics. Temporal data augmentation with small shifts further improved generalization across sessions. Among all models, the multi-class Siamese network achieved the best overall performance with an average accuracy of 96.89%, demonstrating the potential of data-driven deep architectures for reliable, single-trial C-VEP decoding in adaptive non-invasive BCI systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21934v1" target="_blank"><h2>Heterogeneous Multi-Agent Reinforcement Learning with Attention for Cooperative and Scalable Feature Transformation</h2></a><strong><u>Authors:</u></strong> Tao Zhe, Huazhen Fang, Kunpeng Liu, Qian Lou, Tamzidul Hoque, Dongjie Wang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> Accepted at KDD 2026 Research Track<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> Feature transformation enhances downstream task performance by generating informative features through mathematical feature crossing. Despite the advancements in deep learning, feature transformation remains essential for structured data, where deep models often struggle to capture complex feature interactions. Prior literature on automated feature transformation has achieved success but often relies on heuristics or exhaustive searches, leading to inefficient and time-consuming processes. Recent works employ reinforcement learning (RL) to enhance traditional approaches through a more effective trial-and-error way. However, two limitations remain: 1) Dynamic feature expansion during the transformation process, which causes instability and increases the learning complexity for RL agents; 2) Insufficient cooperation and communication between agents, which results in suboptimal feature crossing operations and degraded model performance. To address them, we propose a novel heterogeneous multi-agent RL framework to enable cooperative and scalable feature transformation. The framework comprises three heterogeneous agents, grouped into two types, each designed to select essential features and operations for feature crossing. To enhance communication among these agents, we implement a shared critic mechanism that facilitates information exchange during feature transformation. To handle the dynamically expanding feature space, we tailor multi-head attention-based feature agents to select suitable features for feature crossing. Additionally, we introduce a state encoding technique during the optimization process to stabilize and enhance the learning dynamics of the RL agents, resulting in more robust and reliable transformation policies. Finally, we conduct extensive experiments to validate the effectiveness, efficiency, robustness, and interpretability of our model.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21932v1" target="_blank"><h2>Modeling Quantum Autoencoder Trainable Kernel for IoT Anomaly Detection</h2></a><strong><u>Authors:</u></strong> Swathi Chandrasekhar, Shiva Raj Pokhrel, Swati Kumari, Navneet Singh<br><strong><u>Categories:</u></strong> cs.LG, quant-ph<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)<br><p><strong><u>Abstract:</u></strong> Escalating cyber threats and the high-dimensional complexity of IoT traffic have outpaced classical anomaly detection methods. While deep learning offers improvements, computational bottlenecks limit real-time deployment at scale. We present a quantum autoencoder (QAE) framework that compresses network traffic into discriminative latent representations and employs quantum support vector classification (QSVC) for intrusion detection. Evaluated on three datasets, our approach achieves improved accuracy on ideal simulators and on the IBM Quantum hardware demonstrating practical quantum advantage on current NISQ devices. Crucially, moderate depolarizing noise acts as implicit regularization, stabilizing training and enhancing generalization. This work establishes quantum machine learning as a viable, hardware-ready solution for real-world cybersecurity challenges.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21923v1" target="_blank"><h2>Exploring Dynamic Properties of Backdoor Training Through Information Bottleneck</h2></a><strong><u>Authors:</u></strong> Xinyu Liu, Xu Zhang, Can Chen, Ren Wang<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Understanding how backdoor data influences neural network training dynamics remains a complex and underexplored challenge. In this paper, we present a rigorous analysis of the impact of backdoor data on the learning process, with a particular focus on the distinct behaviors between the target class and other clean classes. Leveraging the Information Bottleneck (IB) principle connected with clustering of internal representation, We find that backdoor attacks create unique mutual information (MI) signatures, which evolve across training phases and differ based on the attack mechanism. Our analysis uncovers a surprising trade-off: visually conspicuous attacks like BadNets can achieve high stealthiness from an information-theoretic perspective, integrating more seamlessly into the model than many visually imperceptible attacks. Building on these insights, we propose a novel, dynamics-based stealthiness metric that quantifies an attack's integration at the model level. We validate our findings and the proposed metric across multiple datasets and diverse attack types, offering a new dimension for understanding and evaluating backdoor threats. Our code is available in: https://github.com/XinyuLiu71/Information_Bottleneck_Backdoor.git.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21908v1" target="_blank"><h2>Multi-Modal Machine Learning for Early Trust Prediction in Human-AI Interaction Using Face Image and GSR Bio Signals</h2></a><strong><u>Authors:</u></strong> Hamid Shamszare, Avishek Choudhury<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), multi-modal (title, abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Predicting human trust in AI systems is crucial for safe integration of AI-based decision support tools, especially in healthcare. This study proposes a multi-modal machine learning framework that combines image and galvanic skin response (GSR) data to predict early user trust in AI- or human-generated recommendations in a simulated ADHD mHealth context. Facial video data were processed using OpenCV for frame extraction and transferred learning with a pre-trained transformer model to derive emotional features. Concurrently, GSR signals were decomposed into tonic and phasic components to capture physiological arousal patterns. Two temporal windows were defined for trust prediction: the Early Detection Window (6 to 3 seconds before decision-making) and the Proximal Detection Window (3 to 0 seconds before decision-making). For each window, trust prediction was conducted separately using image-based, GSR-based, and multimodal (image + GSR) features. Each modality was analyzed using machine learning algorithms, and the top-performing unimodal models were integrated through a multimodal stacking ensemble for final prediction. Experimental results showed that combining facial and physiological cues significantly improved prediction performance. The multimodal stacking framework achieved an accuracy of 0.83, F1-score of 0.88, and ROC-AUC of 0.87 in the Early Detection Window, and an accuracy of 0.75, F1-score of 0.82, and ROC-AUC of 0.66 in the Proximal Detection Window. These results demonstrate the potential of bio signals as real-time, objective markers of user trust, enabling adaptive AI systems that dynamically adjust their responses to maintain calibrated trust which is a critical capability in mental health applications where mis-calibrated trust can affect diagnostic and treatment outcomes.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21902v1" target="_blank"><h2>PathReasoning: A multimodal reasoning agent for query-based ROI navigation on whole-slide images</h2></a><strong><u>Authors:</u></strong> Kunpeng Zhang, Hanwen Xu, Sheng Wang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title), multi-modal (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Deciphering tumor microenvironment from Whole Slide Images (WSIs) is intriguing as it is key to cancer diagnosis, prognosis and treatment response. While these gigapixel images on one hand offer a comprehensive portrait of cancer, on the other hand, the extremely large size, as much as more than 10 billion pixels, make it challenging and time-consuming to navigate to corresponding regions to support diverse clinical inspection. Inspired by pathologists who conducted navigation on WSIs with a combination of sampling, reasoning and self-reflection, we proposed "PathReasoning", a multi-modal reasoning agent that iteratively navigates across WSIs through multiple rounds of reasoning and refinements. Specifically, starting with randomly sampled candidate regions, PathReasoning reviews current selections with self-reflection, reasoning over the correspondence between visual observations and clinical questions, and concludes by proposing new regions to explore. Across rounds, PathReasoning builds a reasoning chain that gradually directs attention to diagnostically relevant areas. PathReasoning turns each whole slide into a sequence of question-guided views, allowing the model to efficiently find informative ROIs within a fixed number of steps, without the need for dense pixel-level annotations. PathReasoning can substantially outperform strong ROI-selection approaches by 6.7% and 3.1% of AUROC on subtyping and longitudinal analysis tasks. The high-quality ROIs further support accurate report generation on breast cancer, significantly outperforming the standard GPT-4o by 10% in accuracy. PathReasoning prioritizes question-specific regions and constructs interpretable reasoning chains, supporting efficient slide review, consistent diagnostic interpretations, comprehensive reporting, and evidence traceability in digital pathology.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21900v1" target="_blank"><h2>Beyond Atoms: Evaluating Electron Density Representation for 3D Molecular Learning</h2></a><strong><u>Authors:</u></strong> Patricia Suriana, Joshua A. Rackers, Ewa M. Nowara, Pedro O. Pinheiro, John M. Nicoloudis, Vishnu Sresht<br><strong><u>Categories:</u></strong> cs.LG, q-bio.BM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)<br><p><strong><u>Abstract:</u></strong> Machine learning models for 3D molecular property prediction typically rely on atom-based representations, which may overlook subtle physical information. Electron density maps -- the direct output of X-ray crystallography and cryo-electron microscopy -- offer a continuous, physically grounded alternative. We compare three voxel-based input types for 3D convolutional neural networks (CNNs): atom types, raw electron density, and density gradient magnitude, across two molecular tasks -- protein-ligand binding affinity prediction (PDBbind) and quantum property prediction (QM9). We focus on voxel-based CNNs because electron density is inherently volumetric, and voxel grids provide the most natural representation for both experimental and computed densities. On PDBbind, all representations perform similarly with full data, but in low-data regimes, density-based inputs outperform atom types, while a shape-based baseline performs comparably -- suggesting that spatial occupancy dominates this task. On QM9, where labels are derived from Density Functional Theory (DFT) but input densities from a lower-level method (XTB), density-based inputs still outperform atom-based ones at scale, reflecting the rich structural and electronic information encoded in density. Overall, these results highlight the task- and regime-dependent strengths of density-derived inputs, improving data efficiency in affinity prediction and accuracy in quantum property modeling.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21893v1" target="_blank"><h2>Breaking the Illusion: Consensus-Based Generative Mitigation of Adversarial Illusions in Multi-Modal Embeddings</h2></a><strong><u>Authors:</u></strong> Fatemeh Akbarian, Anahita Baninajjar, Yingyi Zhang, Ananth Balashankar, Amir Aminifar<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (abstract), multi-modal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multi-modal foundation models align images, text, and other modalities in a shared embedding space but remain vulnerable to adversarial illusions (Zhang et al., 2025), where imperceptible perturbations disrupt cross-modal alignment and mislead downstream tasks. To counteract the effects of adversarial illusions, we propose a task-agnostic mitigation mechanism that reconstructs the input from the attacker's perturbed input through generative models, e.g., Variational Autoencoders (VAEs), to maintain natural alignment. To further enhance our proposed defense mechanism, we adopt a generative sampling strategy combined with a consensus-based aggregation scheme over the outcomes of the generated samples. Our experiments on the state-of-the-art multi-modal encoders show that our approach substantially reduces the illusion attack success rates to near-zero and improves cross-modal alignment by 4% (42 to 46) and 11% (32 to 43) in unperturbed and perturbed input settings respectively, providing an effective and model-agnostic defense against adversarial illusions.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21889v1" target="_blank"><h2>Exploring Fusion Strategies for Multimodal Vision-Language Systems</h2></a><strong><u>Authors:</u></strong> Regan Willis, Jason Bakos<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Modern machine learning models often combine multiple input streams of data to more accurately capture the information that informs their decisions. In multimodal machine learning, choosing the strategy for fusing data together requires careful consideration of the application's accuracy and latency requirements, as fusing the data at earlier or later stages in the model architecture can lead to performance changes in accuracy and latency. To demonstrate this tradeoff, we investigate different fusion strategies using a hybrid BERT and vision network framework that integrates image and text data. We explore two different vision networks: MobileNetV2 and ViT. We propose three models for each vision network, which fuse data at late, intermediate, and early stages in the architecture. We evaluate the proposed models on the CMU MOSI dataset and benchmark their latency on an NVIDIA Jetson Orin AGX. Our experimental results demonstrate that while late fusion yields the highest accuracy, early fusion offers the lowest inference latency. We describe the three proposed model architectures and discuss the accuracy and latency tradeoffs, concluding that data fusion earlier in the model architecture results in faster inference times at the cost of accuracy.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21883v1" target="_blank"><h2>Physically Interpretable Representation Learning with Gaussian Mixture Variational AutoEncoder (GM-VAE)</h2></a><strong><u>Authors:</u></strong> Tiffany Fan, Murray Cutforth, Marta D'Elia, Alexandre Cortiella, Alireza Doostan, Eric Darve<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), variational autoencoder (title, abstract), VAE (title, abstract)<br><p><strong><u>Abstract:</u></strong> Extracting compact, physically interpretable representations from high-dimensional scientific data is a persistent challenge due to the complex, nonlinear structures inherent in physical systems. We propose a Gaussian Mixture Variational Autoencoder (GM-VAE) framework designed to address this by integrating an Expectation-Maximization (EM)-inspired training scheme with a novel spectral interpretability metric. Unlike conventional VAEs that jointly optimize reconstruction and clustering (often leading to training instability), our method utilizes a block-coordinate descent strategy, alternating between expectation and maximization steps. This approach stabilizes training and naturally aligns latent clusters with distinct physical regimes. To objectively evaluate the learned representations, we introduce a quantitative metric based on graph-Laplacian smoothness, which measures the coherence of physical quantities across the latent manifold. We demonstrate the efficacy of this framework on datasets of increasing complexity: surface reaction ODEs, Navier-Stokes wake flows, and experimental laser-induced combustion Schlieren images. The results show that our GM-VAE yields smooth, physically consistent manifolds and accurate regime clustering, offering a robust data-driven tool for interpreting turbulent and reactive flow systems.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21882v1" target="_blank"><h2>Closed-Loop Transformers: Autoregressive Modeling as Iterative Latent Equilibrium</h2></a><strong><u>Authors:</u></strong> Akbar Anbar Jafari, Gholamreza Anbarjafari<br><strong><u>Categories:</u></strong> cs.LG, cs.CV<br><strong><u>Comments:</u></strong> 22 pages, 1 figure, 1 table<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> latent space (abstract), transformer (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Contemporary autoregressive transformers operate in open loop: each hidden state is computed in a single forward pass and never revised, causing errors to propagate uncorrected through the sequence. We identify this open-loop bottleneck as a fundamental architectural limitation underlying well-documented failures in long-range reasoning, factual consistency, and multi-step planning. To address this limitation, we introduce the closed-loop prediction principle, which requires that models iteratively refine latent representations until reaching a self-consistent equilibrium before committing to each token. We instantiate this principle as Equilibrium Transformers (EqT), which augment standard transformer layers with an Equilibrium Refinement Module that minimizes a learned energy function via gradient descent in latent space. The energy function enforces bidirectional prediction consistency, episodic memory coherence, and output confidence, all computed without external supervision. Theoretically, we prove that EqT performs approximate MAP inference in a latent energy-based model, establish linear convergence guarantees, and show that refinement improves predictions precisely on hard instances where one-shot inference is suboptimal. The framework unifies deep equilibrium models, diffusion language models, and test-time training as special cases. Preliminary experiments on the binary parity task demonstrate +3.28% average improvement on challenging sequences, with gains reaching +8.07% where standard transformers approach random performance, validating that the benefit of deliberation scales with task difficulty. Just as attention mechanisms resolved the sequential bottleneck of recurrent networks, we propose that closed-loop equilibrium may resolve the commitment bottleneck of open-loop autoregression, representing a foundational step toward language models.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21872v1" target="_blank"><h2>Advancing Marine Bioacoustics with Deep Generative Models: A Hybrid Augmentation Strategy for Southern Resident Killer Whale Detection</h2></a><strong><u>Authors:</u></strong> Bruno Padovese, Fabio Frazao, Michael Dowd, Ruth Joy<br><strong><u>Categories:</u></strong> cs.SD, cs.AI, cs.LG, eess.AS<br><strong><u>Comments:</u></strong> 16 pages, 6 Figures, 2 Tables, submitted to Marine Mammal Science as part of a special issue on Machine Learning and Artificial Intelligence in Marine Mammal Research<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), data augmentation (abstract)<br><p><strong><u>Abstract:</u></strong> Automated detection and classification of marine mammals vocalizations is critical for conservation and management efforts but is hindered by limited annotated datasets and the acoustic complexity of real-world marine environments. Data augmentation has proven to be an effective strategy to address this limitation by increasing dataset diversity and improving model generalization without requiring additional field data. However, most augmentation techniques used to date rely on effective but relatively simple transformations, leaving open the question of whether deep generative models can provide additional benefits. In this study, we evaluate the potential of deep generative for data augmentation in marine mammal call detection including: Variational Autoencoders, Generative Adversarial Networks, and Denoising Diffusion Probabilistic Models. Using Southern Resident Killer Whale (Orcinus orca) vocalizations from two long-term hydrophone deployments in the Salish Sea, we compare these approaches against traditional augmentation methods such as time-shifting and vocalization masking. While all generative approaches improved classification performance relative to the baseline, diffusion-based augmentation yielded the highest recall (0.87) and overall F1-score (0.75). A hybrid strategy combining generative-based synthesis with traditional methods achieved the best overall performance with an F1-score of 0.81. We hope this study encourages further exploration of deep generative models as complementary augmentation strategies to advance acoustic monitoring of threatened marine mammal populations.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21846v1" target="_blank"><h2>LILAD: Learning In-context Lyapunov-stable Adaptive Dynamics Models</h2></a><strong><u>Authors:</u></strong> Amit Jena, Na Li, Le Xie<br><strong><u>Categories:</u></strong> eess.SY, cs.AI, cs.LG<br><strong><u>Comments:</u></strong> This article has been accepted for AAAI-26 (The 40th Annual AAAI Conference on Artificial Intelligence)<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> neural network (abstract)<br><p><strong><u>Abstract:</u></strong> System identification in control theory aims to approximate dynamical systems from trajectory data. While neural networks have demonstrated strong predictive accuracy, they often fail to preserve critical physical properties such as stability and typically assume stationary dynamics, limiting their applicability under distribution shifts. Existing approaches generally address either stability or adaptability in isolation, lacking a unified framework that ensures both. We propose LILAD (Learning In-Context Lyapunov-stable Adaptive Dynamics), a novel framework for system identification that jointly guarantees adaptability and stability. LILAD simultaneously learns a dynamics model and a Lyapunov function through in-context learning (ICL), explicitly accounting for parametric uncertainty. Trained across a diverse set of tasks, LILAD produces a stability-aware, adaptive dynamics model alongside an adaptive Lyapunov certificate. At test time, both components adapt to a new system instance using a short trajectory prompt, which enables fast generalization. To rigorously ensure stability, LILAD also computes a state-dependent attenuator that enforces a sufficient decrease condition on the Lyapunov function for any state in the new system instance. This mechanism extends stability guarantees even under out-of-distribution and out-of-task scenarios. We evaluate LILAD on benchmark autonomous systems and demonstrate that it outperforms adaptive, robust, and non-adaptive baselines in predictive accuracy.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21842v1" target="_blank"><h2>Unsupervised Anomaly Detection for Smart IoT Devices: Performance and Resource Comparison</h2></a><strong><u>Authors:</u></strong> Md. Sad Abdullah Sami, Mushfiquzzaman Abid<br><strong><u>Categories:</u></strong> cs.LG, cs.CR<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)<br><p><strong><u>Abstract:</u></strong> The rapid expansion of Internet of Things (IoT) deployments across diverse sectors has significantly enhanced operational efficiency, yet concurrently elevated cybersecurity vulnerabilities due to increased exposure to cyber threats. Given the limitations of traditional signature-based Anomaly Detection Systems (ADS) in identifying emerging and zero-day threats, this study investigates the effectiveness of two unsupervised anomaly detection techniques, Isolation Forest (IF) and One-Class Support Vector Machine (OC-SVM), using the TON_IoT thermostat dataset. A comprehensive evaluation was performed based on standard metrics (accuracy, precision, recall, and F1-score) alongside critical resource utilization metrics such as inference time, model size, and peak RAM usage. Experimental results revealed that IF consistently outperformed OC-SVM, achieving higher detection accuracy, superior precision, and recall, along with a significantly better F1-score. Furthermore, Isolation Forest demonstrated a markedly superior computational footprint, making it more suitable for deployment on resource-constrained IoT edge devices. These findings underscore Isolation Forest's robustness in high-dimensional and imbalanced IoT environments and highlight its practical viability for real-time anomaly detection.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21827v1" target="_blank"><h2>Evaluating Strategies for Synthesizing Clinical Notes for Medical Multimodal AI</h2></a><strong><u>Authors:</u></strong> Niccolo Marini, Zhaohui Liang, Sivaramakrishnan Rajaraman, Zhiyun Xue, Sameer Antani<br><strong><u>Categories:</u></strong> cs.AI, cs.CV<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Multimodal (MM) learning is emerging as a promising paradigm in biomedical artificial intelligence (AI) applications, integrating complementary modality, which highlight different aspects of patient health. The scarcity of large heterogeneous biomedical MM data has restrained the development of robust models for medical AI applications. In the dermatology domain, for instance, skin lesion datasets typically include only images linked to minimal metadata describing the condition, thereby limiting the benefits of MM data integration for reliable and generalizable predictions. Recent advances in Large Language Models (LLMs) enable the synthesis of textual description of image findings, potentially allowing the combination of image and text representations. However, LLMs are not specifically trained for use in the medical domain, and their naive inclusion has raised concerns about the risk of hallucinations in clinically relevant contexts. This work investigates strategies for generating synthetic textual clinical notes, in terms of prompt design and medical metadata inclusion, and evaluates their impact on MM architectures toward enhancing performance in classification and cross-modal retrieval tasks. Experiments across several heterogeneous dermatology datasets demonstrate that synthetic clinical notes not only enhance classification performance, particularly under domain shift, but also unlock cross-modal retrieval capabilities, a downstream task that is not explicitly optimized during training.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21824v1" target="_blank"><h2>LYRA ultra-faints: The emergence of faint dwarf galaxies in the presence of an early Lyman-Werner background <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Shaun T. Brown, Azadeh Fattahi, Thales A. Gutcke, Sylvia Ploeckinger, Joaquin Sureda, Sownak Bose, Jessica E. Doppel, Rüdiger Pakmor, Adrian Jenkins<br><strong><u>Categories:</u></strong> astro-ph.GA, astro-ph.CO<br><strong><u>Comments:</u></strong> 21 pages, 9 figures, submitted to MNRAS<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> VAE (abstract)<br><p><strong><u>Abstract:</u></strong> We present a suite of zoom-in cosmological hydrodynamical simulations of dwarf galaxies using the LYRA galaxy formation model with an extremely high mass resolution of $4\, \mathrm{M_{\odot}}$, evolved to $z=0$. The suite contains 65 haloes selected from Local Group like environments, spanning $M_{\mathrm{200c}}=10^7$ to $5\times10^9\, \mathrm{M_{\odot}}$. The sample includes small ultra-faints with $M_\ast\sim100\, \mathrm{M_{\odot}}$ through to classical dwarfs with $M_\ast \sim 5\times10^6 \mathrm{M_{\odot}}$, as well as haloes that remain dark to the present day. We explore two prescriptions for the high-redshift ($z>7$) Lyman-Werner background (LWB), differing in intensity and redshift evolution. Star formation begins early ($z\gtrsim8$) in progenitors with $M_{\mathrm{200c}}\sim10^5$-$10^6 \mathrm{M_{\odot}}$, where molecular hydrogen enables warm moderate-density gas to efficiently cool. The LWB strongly influences the $z=0$ halo occupation fraction, shifting the dark-to-luminous transition from $M_{\mathrm{200c}}\sim10^7 \mathrm{M_{\odot}}$ (weaker LWB) to $M_{\mathrm{200c}}\sim10^8 \mathrm{M_{\odot}}$ (stronger LWB). Galaxies with $M_\ast\gtrsim10^5 \mathrm{M_{\odot}}$ are mostly insensitive to the LWB choice, whereas lower mass systems respond strongly, producing markedly different stellar mass-halo mass (SMHM) relations. The weaker LWB yields a very shallow SMHM slope with nearly constant scatter, while the stronger LWB introduces a pronounced break at $M_{\mathrm{200c}}\sim10^9 \mathrm{M_{\odot}}$, where haloes of similar mass host galaxies with $M_\ast\sim10^3$ to $10^5 \mathrm{M_{\odot}}$ or remain dark. Both models produce a minimum stellar mass floor at $M_\ast\sim10^3 \mathrm{M_{\odot}}$, originating from galaxies that undergo a single burst of star formation at high redshift before self-quenching from their first supernovae.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21678v1" target="_blank"><h2>Agentic Learner with Grow-and-Refine Multimodal Semantic Memory <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Weihao Bo, Shan Zhang, Yanpeng Sun, Jingjing Wu, Qunyi Xie, Xiao Tan, Kunbin Chen, Wei He, Xiaofan Li, Na Zhao, Jingdong Wang, Zechao Li<br><strong><u>Categories:</u></strong> cs.AI, cs.LG<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> MLLMs exhibit strong reasoning on isolated queries, yet they operate de novo -- solving each problem independently and often repeating the same mistakes. Existing memory-augmented agents mainly store past trajectories for reuse. However, trajectory-based memory suffers from brevity bias, gradually losing essential domain knowledge. More critically, even in truly multimodal problem-solving settings, it records only a single-modality trace of past behavior, failing to preserve how visual attention and logical reasoning jointly contributed to the solution. This is fundamentally misaligned with human cognition: semantic memory is both multimodal and integrated, preserving visual and abstract knowledge through coordinated but distinct representational streams. We thus introduce ViLoMem, a dual-stream memory framework that constructs compact, schema-based memory. It separately encodes visual distraction patterns and logical reasoning errors, enabling MLLMs to learn from their successful and failed experiences. Following a grow-and-refine principle, the system incrementally accumulates and updates multimodal semantic knowledge -- preserving stable, generalizable strategies while avoiding catastrophic forgetting. Across six multimodal benchmarks, ViLoMem consistently improves pass@1 accuracy and substantially reduces repeated visual and logical errors. Ablations confirm the necessity of dual-stream memory with explicit distraction--hallucination separation, demonstrating the value of error-aware multimodal memory for lifelong and cross-domain agentic learning. Our project page will be available at https://weihao-bo.github.io/ViLoMeo-page.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21675v1" target="_blank"><h2>On Evolution-Based Models for Experimentation Under Interference <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Sadegh Shirani, Mohsen Bayati<br><strong><u>Categories:</u></strong> stat.ML, cs.LG, cs.SI, econ.EM<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Causal effect estimation in networked systems is central to data-driven decision making. In such settings, interventions on one unit can spill over to others, and in complex physical or social systems, the interaction pathways driving these interference structures remain largely unobserved. We argue that for identifying population-level causal effects, it is not necessary to recover the exact network structure; instead, it suffices to characterize how those interactions contribute to the evolution of outcomes. Building on this principle, we study an evolution-based approach that investigates how outcomes change across observation rounds in response to interventions, hence compensating for missing network information. Using an exposure-mapping perspective, we give an axiomatic characterization of when the empirical distribution of outcomes follows a low-dimensional recursive equation, and identify minimal structural conditions under which such evolution mappings exist. We frame this as a distributional counterpart to difference-in-differences. Rather than assuming parallel paths for individual units, it exploits parallel evolution patterns across treatment scenarios to estimate counterfactual trajectories. A key insight is that treatment randomization plays a role beyond eliminating latent confounding; it induces an implicit sampling from hidden interference channels, enabling consistent learning about heterogeneous spillover effects. We highlight causal message passing as an instantiation of this method in dense networks while extending to more general interference structures, including influencer networks where a small set of units drives most spillovers. Finally, we discuss the limits of this approach, showing that strong temporal trends or endogenous interference can undermine identification.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21663v1" target="_blank"><h2>Attention-Guided Patch-Wise Sparse Adversarial Attacks on Vision-Language-Action Models <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Naifu Zhang, Wei Tao, Xi Xiao, Qianpu Sun, Yuxin Zheng, Wentao Mo, Peiqiang Wang, Nan Zhang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> attention (title, abstract)<br><p><strong><u>Abstract:</u></strong> In recent years, Vision-Language-Action (VLA) models in embodied intelligence have developed rapidly. However, existing adversarial attack methods require costly end-to-end training and often generate noticeable perturbation patches. To address these limitations, we propose ADVLA, a framework that directly applies adversarial perturbations on features projected from the visual encoder into the textual feature space. ADVLA efficiently disrupts downstream action predictions under low-amplitude constraints, and attention guidance allows the perturbations to be both focused and sparse. We introduce three strategies that enhance sensitivity, enforce sparsity, and concentrate perturbations. Experiments demonstrate that under an $L_{\infty}=4/255$ constraint, ADVLA combined with Top-K masking modifies less than 10% of the patches while achieving an attack success rate of nearly 100%. The perturbations are concentrated on critical regions, remain almost imperceptible in the overall image, and a single-step iteration takes only about 0.06 seconds, significantly outperforming conventional patch-based attacks. In summary, ADVLA effectively weakens downstream action predictions of VLA models under low-amplitude and locally sparse conditions, avoiding the high training costs and conspicuous perturbations of traditional patch attacks, and demonstrates unique effectiveness and practical value for attacking VLA feature spaces.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21635v1" target="_blank"><h2>Mechanisms of Non-Monotonic Scaling in Vision Transformers <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Anantha Padmanaban Krishna Kumar<br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV<br><strong><u>Comments:</u></strong> 16 pages total (11 pages main text, 1 pages references, 4 pages appendix), 5 figures, 11 tables. Code available atthis https URL<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)<br><p><strong><u>Abstract:</u></strong> Deeper Vision Transformers often perform worse than shallower ones, which challenges common scaling assumptions. Through a systematic empirical analysis of ViT-S, ViT-B, and ViT-L on ImageNet, we identify a consistent three-phase Cliff-Plateau-Climb pattern that governs how representations evolve with depth. We observe that better performance is associated with progressive marginalization of the [CLS] token, originally designed as a global aggregation hub, in favor of distributed consensus among patch tokens. We quantify patterns of information mixing with an Information Scrambling Index, and show that in ViT-L the information-task tradeoff emerges roughly 10 layers later than in ViT-B, and that these additional layers correlate with increased information diffusion rather than improved task performance. Taken together, these results suggest that transformer architectures in this regime may benefit more from carefully calibrated depth that executes clean phase transitions than from simply increasing parameter count. The Information Scrambling Index provides a useful diagnostic for existing models and suggests a potential design target for future architectures. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/Cliff-Plateau-Climb.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21631v2" target="_blank"><h2>Qwen3-VL Technical Report <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Shuai Bai, Yuxuan Cai, Ruizhe Chen, Keqin Chen, Xionghui Chen, Zesen Cheng, Lianghao Deng, Wei Ding, Chang Gao, Chunjiang Ge, Wenbin Ge, Zhifang Guo, Qidong Huang, Jie Huang, Fei Huang, Binyuan Hui, Shutong Jiang, Zhaohai Li, Mingsheng Li, Mei Li, Kaixin Li, Zicheng Lin, Junyang Lin, Xuejing Liu, Jiawei Liu, Chenglong Liu, Yang Liu, Dayiheng Liu, Shixuan Liu, Dunjie Lu, Ruilin Luo, Chenxu Lv, Rui Men, Lingchen Meng, Xuancheng Ren, Xingzhang Ren, Sibo Song, Yuchong Sun, Jun Tang, Jianhong Tu, Jianqiang Wan, Peng Wang, Pengfei Wang, Qiuyue Wang, Yuxuan Wang, Tianbao Xie, Yiheng Xu, Haiyang Xu, Jin Xu, Zhibo Yang, Mingkun Yang, Jianxin Yang, An Yang, Bowen Yu, Fei Zhang, Hang Zhang, Xi Zhang, Bo Zheng, Humen Zhong, Jingren Zhou, Fan Zhou, Jing Zhou, Yuanzhi Zhu, Ke Zhu<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> 42 pages<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)<br><p><strong><u>Abstract:</u></strong> We introduce Qwen3-VL, the most capable vision-language model in the Qwen series to date, achieving superior performance across a broad range of multimodal benchmarks. It natively supports interleaved contexts of up to 256K tokens, seamlessly integrating text, images, and video. The model family includes both dense (2B/4B/8B/32B) and mixture-of-experts (30B-A3B/235B-A22B) variants to accommodate diverse latency-quality trade-offs. Qwen3-VL delivers three core pillars: (i) markedly stronger pure-text understanding, surpassing comparable text-only backbones in several cases; (ii) robust long-context comprehension with a native 256K-token window for both text and interleaved multimodal inputs, enabling faithful retention, retrieval, and cross-referencing across long documents and videos; and (iii) advanced multimodal reasoning across single-image, multi-image, and video tasks, demonstrating leading performance on comprehensive evaluations such as MMMU and visual-math benchmarks (e.g., MathVista and MathVision). Architecturally, we introduce three key upgrades: (i) an enhanced interleaved-MRoPE for stronger spatial-temporal modeling across images and video; (ii) DeepStack integration, which effectively leverages multi-level ViT features to tighten vision-language alignment; and (iii) text-based time alignment for video, evolving from T-RoPE to explicit textual timestamp alignment for more precise temporal grounding. Under comparable token budgets and latency constraints, Qwen3-VL achieves superior performance in both dense and Mixture-of-Experts (MoE) architectures. We envision Qwen3-VL serving as a foundational engine for image-grounded reasoning, agentic decision-making, and multimodal code intelligence in real-world workflows.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21626v2" target="_blank"><h2>Scale-Agnostic Kolmogorov-Arnold Geometry in Neural Networks <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Mathew Vanherreweghe, Michael H. Freedman, Keith M. Adams<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)<br><p><strong><u>Abstract:</u></strong> Recent work by Freedman and Mulligan demonstrated that shallow multilayer perceptrons spontaneously develop Kolmogorov-Arnold geometric (KAG) structure during training on synthetic three-dimensional tasks. However, it remained unclear whether this phenomenon persists in realistic high-dimensional settings and what spatial properties this geometry exhibits.
  We extend KAG analysis to MNIST digit classification (784 dimensions) using 2-layer MLPs with systematic spatial analysis at multiple scales. We find that KAG emerges during training and appears consistently across spatial scales, from local 7-pixel neighborhoods to the full 28x28 image. This scale-agnostic property holds across different training procedures: both standard training and training with spatial augmentation produce the same qualitative pattern. These findings reveal that neural networks spontaneously develop organized, scale-invariant geometric structure during learning on realistic high-dimensional data.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21622v1" target="_blank"><h2>On the Origin of Algorithmic Progress in AI <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Hans Gundlach, Alex Fogelson, Jayson Lynch, Ana Trisovic, Jonathan Rosenfeld, Anmol Sandhu, Neil Thompson<br><strong><u>Categories:</u></strong> cs.LG, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Algorithms have been estimated to increase AI training FLOP efficiency by a factor of 22,000 between 2012 and 2023 [Ho et al., 2024]. Running small-scale ablation experiments on key innovations from this time period, we are able to account for less than 10x of these gains. Surveying the broader literature, we estimate that additional innovations not included in our ablations account for less than 10x, yielding a total under 100x. This leads us to conduct scaling experiments, which reveal that much of this efficiency gap can be explained by algorithms with scale-dependent efficiency improvements. In particular, we conduct scaling experiments between LSTMs and Transformers, finding exponent differences in their compute-optimal scaling law while finding little scaling difference for many other innovations. These experiments demonstrate that - contrary to standard assumptions - an algorithm's efficiency gains are tied to compute scale. Using experimental extrapolation and literature estimates, we account for 6,930x efficiency gains over the same time period, with the scale-dependent LSTM-to-Transformer transition accounting for the majority of gains. Our results indicate that algorithmic progress for small models has been far slower than previously assumed, and that measures of algorithmic efficiency are strongly reference-dependent.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21607v1" target="_blank"><h2>Beyond Accuracy: An Empirical Study of Uncertainty Estimation in Imputation <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Zarin Tahia Hossain, Mostafa Milani<br><strong><u>Categories:</u></strong> cs.DB, cs.LG<br><strong><u>Comments:</u></strong> To appear in conference proceedings<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)<br><p><strong><u>Abstract:</u></strong> Handling missing data is a central challenge in data-driven analysis. Modern imputation methods not only aim for accurate reconstruction but also differ in how they represent and quantify uncertainty. Yet, the reliability and calibration of these uncertainty estimates remain poorly understood. This paper presents a systematic empirical study of uncertainty in imputation, comparing representative methods from three major families: statistical (MICE, SoftImpute), distribution alignment (OT-Impute), and deep generative (GAIN, MIWAE, TabCSDI). Experiments span multiple datasets, missingness mechanisms (MCAR, MAR, MNAR), and missingness rates. Uncertainty is estimated through three complementary routes: multi-run variability, conditional sampling, and predictive-distribution modeling, and evaluated using calibration curves and the Expected Calibration Error (ECE). Results show that accuracy and calibration are often misaligned: models with high reconstruction accuracy do not necessarily yield reliable uncertainty. We analyze method-specific trade-offs among accuracy, calibration, and runtime, identify stable configurations, and offer guidelines for selecting uncertainty-aware imputers in data cleaning and downstream machine learning pipelines.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21594v1" target="_blank"><h2>Visualizing LLM Latent Space Geometry Through Dimensionality Reduction <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Alex Ning, Vainateya Rangaraju<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 24 pages, 16 figures<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (title, abstract), latent space (title, abstract), transformer (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> Large language models (LLMs) achieve state-of-the-art results across many natural language tasks, but their internal mechanisms remain difficult to interpret. In this work, we extract, process, and visualize latent state geometries in Transformer-based language models through dimensionality reduction. We capture layerwise activations at multiple points within Transformer blocks and enable systematic analysis through Principal Component Analysis (PCA) and Uniform Manifold Approximation (UMAP). We demonstrate experiments on GPT-2 and LLaMa models, where we uncover interesting geometric patterns in latent space. Notably, we identify a clear separation between attention and MLP component outputs across intermediate layers, a pattern not documented in prior work to our knowledge. We also characterize the high norm of latent states at the initial sequence position and visualize the layerwise evolution of latent states. Additionally, we demonstrate the high-dimensional helical structure of GPT-2's positional embeddings, the sequence-wise geometric patterns in LLaMa, and experiment with repeating token sequences. We aim to support systematic analysis of Transformer internals with the goal of enabling further reproducible interpretability research. We make our code available at https://github.com/Vainateya/Feature_Geometry_Visualization.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21581v1" target="_blank"><h2>Learning When to Stop: Adaptive Latent Reasoning via Reinforcement Learning <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Alex Ning, Yen-Ling Kuo, Gabe Gomes<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 13 pages, 6 figures<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Latent reasoning represents a new development in Transformer language models that has shown potential in compressing reasoning lengths compared to chain-of-thought reasoning. By directly passing the information-rich previous final latent state into the next sequence, latent reasoning removes the restriction to human language tokens as the medium for reasoning. We develop adaptive-length latent reasoning models and introduce a post-SFT reinforcement-learning methodology to optimize latent reasoning length by minimizing reasoning length while maintaining accuracy. This, in turn, further reduces compute usage and raises the bar on the compressive capabilities of latent reasoning models. Experiments on the Llama 3.2 1B model and the GSM8K-Aug dataset show a $52\%$ drop in total reasoning length with no penalty to accuracy. In future work, we plan to extend to additional models and datasets, analyze relationships between training coefficients, experiment with architecture variations, and continue our knowledge distillation for latent reasoning SFT efforts. We make our code and pretrained weights available at https://github.com/apning/adaptive-latent-reasoning.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21577v1" target="_blank"><h2>HarmonicAttack: An Adaptive Cross-Domain Audio Watermark Removal <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Kexin Li, Xiao Hu, Ilya Grishchenko, David Lie<br><strong><u>Categories:</u></strong> cs.SD, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract)<br><p><strong><u>Abstract:</u></strong> The availability of high-quality, AI-generated audio raises security challenges such as misinformation campaigns and voice-cloning fraud. A key defense against the misuse of AI-generated audio is by watermarking it, so that it can be easily distinguished from genuine audio. As those seeking to misuse AI-generated audio may thus seek to remove audio watermarks, studying effective watermark removal techniques is critical to being able to objectively evaluate the robustness of audio watermarks against removal. Previous watermark removal schemes either assume impractical knowledge of the watermarks they are designed to remove or are computationally expensive, potentially generating a false sense of confidence in current watermark schemes.
  We introduce HarmonicAttack, an efficient audio watermark removal method that only requires the basic ability to generate the watermarks from the targeted scheme and nothing else. With this, we are able to train a general watermark removal model that is able to remove the watermarks generated by the targeted scheme from any watermarked audio sample. HarmonicAttack employs a dual-path convolutional autoencoder that operates in both temporal and frequency domains, along with GAN-style training, to separate the watermark from the original audio. When evaluated against state-of-the-art watermark schemes AudioSeal, WavMark, and Silentcipher, HarmonicAttack demonstrates greater watermark removal ability than previous watermark removal methods with near real-time performance. Moreover, while HarmonicAttack requires training, we find that it is able to transfer to out-of-distribution samples with minimal degradation in performance.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21574v1" target="_blank"><h2>Multimodal Robust Prompt Distillation for 3D Point Cloud Models <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Xiang Gu, Liming Lu, Xu Zheng, Anan Du, Yongbin Zhou, Shuchao Pang<br><strong><u>Categories:</u></strong> cs.CV, cs.AI<br><strong><u>Comments:</u></strong> No comments<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)<br><p><strong><u>Abstract:</u></strong> Adversarial attacks pose a significant threat to learning-based 3D point cloud models, critically undermining their reliability in security-sensitive applications. Existing defense methods often suffer from (1) high computational overhead and (2) poor generalization ability across diverse attack types. To bridge these gaps, we propose a novel yet efficient teacher-student framework, namely Multimodal Robust Prompt Distillation (MRPD) for distilling robust 3D point cloud model. It learns lightweight prompts by aligning student point cloud model's features with robust embeddings from three distinct teachers: a vision model processing depth projections, a high-performance 3D model, and a text encoder. To ensure a reliable knowledge transfer, this distillation is guided by a confidence-gated mechanism which dynamically balances the contribution of all input modalities. Notably, since the distillation is all during the training stage, there is no additional computational cost at inference. Extensive experiments demonstrate that MRPD substantially outperforms state-of-the-art defense methods against a wide range of white-box and black-box attacks, while even achieving better performance on clean data. Our work presents a new, practical paradigm for building robust 3D vision systems by efficiently harnessing multimodal knowledge.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21567v1" target="_blank"><h2>Enhanced antineutrino emission from $β$ decay in core-collapse supernovae with self-consistent weak decay rates <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> T. Dasher, A. Ravlić, S. Lalit, E. O'Connor, K. Godbey<br><strong><u>Categories:</u></strong> astro-ph.HE, nucl-th<br><strong><u>Comments:</u></strong> 7 pages, 3 figures, includes Supplemental Material. Comments are welcome<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> VAE (title, abstract)<br><p><strong><u>Abstract:</u></strong> Nuclear weak-interaction rates are known to exert a prominent effect in the late-stages of stellar collapse. Despite their importance, most studies to date on core-collapse supernovae (CCSNe) have focused primarily on the effects of electron captures, generally neglecting $β$ decay contributions. In this Letter, we present the first CCSNe simulation incorporating global $β$ decay rates from a microscopic theory. These are enabled by a large-scale evaluation of both electron capture and $β$ decay rates, obtained self-consistently utilizing the relativistic energy density functional theory and finite-temperature quasiparticle random-phase approximation. We find a significant enhancement of antineutrino emissivity by more than 4 orders of magnitude due to the inclusion of $β$ decay rates, as well as 3 orders of magnitude for antineutrino luminosity. It is expected that these new rates could help us constrain the model uncertainties related to weak-interaction processes, improving the prediction of antineutrino signal during the final stages of stellar death and potentially influencing the late-stage evolution of massive stars.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21561v1" target="_blank"><h2>Machine Learning Approaches to Clinical Risk Prediction: Multi-Scale Temporal Alignment in Electronic Health Records <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Wei-Chen Chang, Lu Dai, Ting Xu<br><strong><u>Categories:</u></strong> cs.LG<br><strong><u>Comments:</u></strong> 5 pages, 3 figures<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), attention (abstract)<br><p><strong><u>Abstract:</u></strong> This study proposes a risk prediction method based on a Multi-Scale Temporal Alignment Network (MSTAN) to address the challenges of temporal irregularity, sampling interval differences, and multi-scale dynamic dependencies in Electronic Health Records (EHR). The method focuses on temporal feature modeling by introducing a learnable temporal alignment mechanism and a multi-scale convolutional feature extraction structure to jointly model long-term trends and short-term fluctuations in EHR sequences. At the input level, the model maps multi-source clinical features into a unified high-dimensional semantic space and employs temporal embedding and alignment modules to dynamically weight irregularly sampled data, reducing the impact of temporal distribution differences on model performance. The multi-scale feature extraction module then captures key patterns across different temporal granularities through multi-layer convolution and hierarchical fusion, achieving a fine-grained representation of patient states. Finally, an attention-based aggregation mechanism integrates global temporal dependencies to generate individual-level risk representations for disease risk prediction and health status assessment. Experiments conducted on publicly available EHR datasets show that the proposed model outperforms mainstream baselines in accuracy, recall, precision, and F1-Score, demonstrating the effectiveness and robustness of multi-scale temporal alignment in complex medical time-series analysis. This study provides a new solution for intelligent representation of high-dimensional asynchronous medical sequences and offers important technical support for EHR-driven clinical risk prediction.</p><br><hr><br><a href="https://arxiv.org/pdf/2511.21550v1" target="_blank"><h2>MMA: A Momentum Mamba Architecture for Human Activity Recognition with Inertial Sensors <span style="color: #999; font-size: 0.8em;">(seen before)</span></h2></a><strong><u>Authors:</u></strong> Thai-Khanh Nguyen, Uyen Vo, Tan M. Nguyen, Thieu N. Vo, Trung-Hieu Le, Cuong Pham<br><strong><u>Categories:</u></strong> cs.HC, cs.LG<br><strong><u>Comments:</u></strong> 14 pages, 5 pages<br><strong><u>Published:</u></strong> 2025-11-26<br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract), transformer (abstract)<br><p><strong><u>Abstract:</u></strong> Human activity recognition (HAR) from inertial sensors is essential for ubiquitous computing, mobile health, and ambient intelligence. Conventional deep models such as Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), and transformers have advanced HAR but remain limited by vanishing or exloding gradients, high computational cost, and difficulty in capturing long-range dependencies. Structured state-space models (SSMs) like Mamba address these challenges with linear complexity and effective temporal modeling, yet they are restricted to first-order dynamics without stable longterm memory mechanisms. We introduce Momentum Mamba, a momentum-augmented SSM that incorporates second-order dynamics to improve stability of information flow across time steps, robustness, and long-sequence modeling. Two extensions further expand its capacity: Complex Momentum Mamba for frequency-selective memory scaling. Experiments on multiple HAR benchmarks demonstrate consistent gains over vanilla Mamba and Transformer baselines in accuracy, robustness, and convergence speed. With only moderate increases in training cost, momentum-augmented SSMs offer a favorable accuracy-efficiency balance, establishing them as a scalable paradigm for HAR and a promising principal framework for broader sequence modeling applications.</p><br><hr><br><hr><p><em>Summary: Showing 167 papers (142 new, 25 seen before)</em></p></body></html>