<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'><style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 17 Jun 2025 to 19 Jun 2025</em></font><a href="http://arxiv.org/pdf/2506.15090v1" target="_blank"><h2>EMUSE: Evolutionary Map of the Universe Search Engine</h2></a><strong><u>Authors:</u></strong>  Nikhel Gupta, Zeeshan Hayder, Minh Huynh, Ray P. Norris, Lars Petersson, Andrew M. Hopkins, Simone Riggi, Bärbel S. Koribalski, Miroslav D. Filipović</br><strong><u>Categories:</u></strong> astro-ph.GA, astro-ph.CO, astro-ph.IM</br><strong><u>Comments:</u></strong> 19 pages, 9 figures, accepted for publication in PASA</br><p><strong><u>Abstract:</u></strong> We present EMUSE (Evolutionary Map of the Universe Search Engine), a tool
designed for searching specific radio sources within the extensive datasets of
the EMU (Evolutionary Map of the Universe) survey, with potential applications
to other Big Data challenges in astronomy. Built on a multimodal approach to
radio source classification and retrieval, EMUSE fine-tunes the OpenCLIP model
on curated radio galaxy datasets. Leveraging the power of foundation models,
our work integrates visual and textual embeddings to enable efficient and
flexible searches within large radio astronomical datasets. We fine-tune
OpenCLIP using a dataset of 2,900 radio galaxies, encompassing various
morphological classes, including FR-I, FR-II, FR-x, R-type, and other rare and
peculiar sources. The model is optimized using adapter-based fine-tuning,
ensuring computational efficiency while capturing the unique characteristics of
radio sources. The fine-tuned model is then deployed in EMUSE, allowing for
seamless image- and text-based queries over the EMU survey dataset. Our results
demonstrate the model's effectiveness in retrieving and classifying radio
sources, particularly in recognizing distinct morphological features. However,
challenges remain in identifying rare or previously unseen radio sources,
highlighting the need for expanded datasets and continuous refinement. This
study showcases the potential of multimodal machine learning in radio
astronomy, paving the way for more scalable and accurate search tools in the
field. The search engine is accessible at https://askap-emuse.streamlit.app/
and can be used locally by cloning the repository at
https://github.com/Nikhel1/EMUSE.</p></br><a href="http://arxiv.org/pdf/2506.14390v1" target="_blank"><h2>Enclosing Prototypical Variational Autoencoder for Explainable
  Out-of-Distribution Detection</h2></a><strong><u>Authors:</u></strong>  Conrad Orglmeister, Erik Bochinski, Volker Eiselein, Elvira Fleig</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> This preprint has not undergone peer review or any post-submission improvements or corrections. The Version of Record of this contribution is published in Computer Safety, Reliability and Security - SAFECOMP 2024 Workshops - DECSoS, SASSUR, TOASTS, and WAISE, and is available online atthis https URL</br><p><strong><u>Abstract:</u></strong> Understanding the decision-making and trusting the reliability of Deep
Machine Learning Models is crucial for adopting such methods to safety-relevant
applications. We extend self-explainable Prototypical Variational models with
autoencoder-based out-of-distribution (OOD) detection: A Variational
Autoencoder is applied to learn a meaningful latent space which can be used for
distance-based classification, likelihood estimation for OOD detection, and
reconstruction. The In-Distribution (ID) region is defined by a Gaussian
mixture distribution with learned prototypes representing the center of each
mode. Furthermore, a novel restriction loss is introduced that promotes a
compact ID region in the latent space without collapsing it into single points.
The reconstructive capabilities of the Autoencoder ensure the explainability of
the prototypes and the ID region of the classifier, further aiding the
discrimination of OOD samples. Extensive evaluations on common OOD detection
benchmarks as well as a large-scale dataset from a real-world railway
application demonstrate the usefulness of the approach, outperforming previous
methods.</p></br><a href="http://arxiv.org/pdf/2506.15060v1" target="_blank"><h2>GalaxyGenius: A Mock Galaxy Image Generator for Various Telescopes from
  Hydrodynamical Simulations</h2></a><strong><u>Authors:</u></strong>  Xingchen Zhou, Hang Yang, Nan Li, Qi Xiong, Furen Deng, Xian-Min Meng, Renhao Ye, Shiyin Shen, Peng Wei, Qifan Cui, Zizhao He, Ayodeji Ibitoye, Chengliang Wei, Yuedong Fang</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.CO, astro-ph.GA</br><strong><u>Comments:</u></strong> 22 pages, 15 figures, accepted for publication by A&A</br><p><strong><u>Abstract:</u></strong> To advance research on galaxies in the era of large-scale sky surveys, we
introduce GalaxyGenius, a Python package designed to produce synthetic galaxy
images tailored to different telescopes based on hydrodynamical simulations.
The package comprises three main modules: data preprocessing, ideal data cube
generation, and mock observation. Specifically, the preprocessing module
extracts necessary properties of star and gas particles for a selected subhalo
from hydrodynamical simulations and creates the execution file for the
following radiative transfer procedure. Subsequently, building on the above
information, the ideal data cube generation module executes a widely-used
radiative transfer project, specifically the SKIRT, to perform the SED
assignment for each particle and the radiative transfer procedure to produce an
IFU-like ideal data cube. Lastly, the mock observation module takes the ideal
data cube and applies the throughputs of aiming telescopes while also
incorporating the relevant instrumental effects, point spread functions (PSFs),
and background noise to generate desired mock observational images of galaxies.
To showcase the outcomes of GalaxyGenius, We create a series of mock images of
galaxies based on the IllustrisTNG and EAGLE simulations for both space and
ground-based surveys spanning from the ultraviolet to infrared wavelength
coverages, including CSST, Euclid, HST, JWST, Roman, and HSC. GalaxyGenius
offers a flexible framework developed to generate mock galaxy images with
customizable recipes. These generated images can serve as valuable references
for verifying and validating new approaches in astronomical research, and they
can also act as training sets for deep learning relevant studies where real
observational data are insufficient.</p></br><a href="http://arxiv.org/pdf/2506.14936v1" target="_blank"><h2>CALM: Contextual Analog Logic with Multimodality</h2></a><strong><u>Authors:</u></strong>  Maxwell J. Jacobson, Corey J. Maley, Yexiang Xue</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> In this work, we introduce Contextual Analog Logic with Multimodality (CALM).
CALM unites symbolic reasoning with neural generation, enabling systems to make
context-sensitive decisions grounded in real-world multi-modal data.
  Background: Classic bivalent logic systems cannot capture the nuance of human
decision-making. They also require human grounding in multi-modal environments,
which can be ad-hoc, rigid, and brittle. Neural networks are good at extracting
rich contextual information from multi-modal data, but lack interpretable
structures for reasoning.
  Objectives: CALM aims to bridge the gap between logic and neural perception,
creating an analog logic that can reason over multi-modal inputs. Without this
integration, AI systems remain either brittle or unstructured, unable to
generalize robustly to real-world tasks. In CALM, symbolic predicates evaluate
to analog truth values computed by neural networks and constrained search.
  Methods: CALM represents each predicate using a domain tree, which
iteratively refines its analog truth value when the contextual groundings of
its entities are determined. The iterative refinement is predicted by neural
networks capable of capturing multi-modal information and is filtered through a
symbolic reasoning module to ensure constraint satisfaction.
  Results: In fill-in-the-blank object placement tasks, CALM achieved 92.2%
accuracy, outperforming classical logic (86.3%) and LLM (59.4%) baselines. It
also demonstrated spatial heatmap generation aligned with logical constraints
and delicate human preferences, as shown by a human study.
  Conclusions: CALM demonstrates the potential to reason with logic structure
while aligning with preferences in multi-modal environments. It lays the
foundation for next-gen AI systems that require the precision and
interpretation of logic and the multimodal information processing of neural
networks.</p></br><a href="http://arxiv.org/pdf/2506.15230v1" target="_blank"><h2>Evolutionary models for the Very Massive Stars in the R136 cluster of 30
  Doradus in the Large Magellanic Cloud</h2></a><strong><u>Authors:</u></strong>  Z. Keszthelyi, S. A. Brands, A. de Koter, N. Langer, J. Puls</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.GA, astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> Accepted for publication in A&A</br><p><strong><u>Abstract:</u></strong> The cluster R136 in the LMC contains a population of stars in excess of 100
M$_\odot$, including R136a1, the most massive star known. Very Massive Stars
(VMSs) play an influential role in feedback processes and may potentially
produce exotic supernova types and black holes of tens of solar masses. The
evolutionary history and final fate of the three most luminous stars, R136a1,
R136a2, and R136a3, has been a puzzling issue. We aim to resolve this by
rotating single-star MESA models. We produce interpolated model grids and apply
a Markov-Chain Monte Carlo analysis to compare our models with observations.
The nature of supernova progenitors strongly depends on mass loss and the AM
coupling schemes. We predict no pair-instability and no GRB progenitors from
our fiducial model grid at LMC metallicity. The onset of Wolf-Rayet-type
mass-loss rates on the main sequence leads to a rapid decrease in stellar mass
and luminosity. The mass turnover implies that the evolutionary history can
only be inferred if additional constraints are available. We utilise the
surface helium abundance, which poses a conundrum: R136a1, the most luminous
star, is less enriched in helium than R136a2 and R136a3. We propose that this
can be explained if both R136a2 and R136a3 were initially more massive than
R136a1. From a rigorous confrontation of our models to
spectroscopically-derived observables, we estimate an initial mass of
346$\pm41$ M$_\odot$ for R136a1, and $\gtrsim$500 M$_\odot$ for R136a2 and
R136a3. Even though VMSs are only present in the youngest clusters below 2 Myr
of age, our study strengthens their role in local and galaxy evolution. At LMC
metallicity, they will be observable as helium-enriched massive stars after
their drastic mass loss, produced via single-star evolution. If the core
collapse leads to a supernova, it will be of Type Ib/c. [abridged]</p></br><a href="http://arxiv.org/pdf/2506.14368v1" target="_blank"><h2>VLBA astrometry of PSRs B0329+54 and B1133+16: Improved pulsar distances
  and comparison of global ionospheric models</h2></a><strong><u>Authors:</u></strong>  Ashish Kumar, Adam T. Deller, Pankaj Jain, Javier Moldón</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA, astro-ph.IM, astro-ph.SR</br><strong><u>Comments:</u></strong> Accepted for publication in PASA</br><p><strong><u>Abstract:</u></strong> Very long baseline interferometry (VLBI) astrometry is used to determine the
three-dimensional position and proper motion of astronomical objects. A typical
VLBI astrometric campaign generally includes around ten observations, making it
challenging to characterise systematic uncertainties. Our study on two bright
pulsars, B0329+54 and B1133+16, involves analysis of broadband Very Long
Baseline Array (VLBA) data over $\sim30$ epochs (spanning approximately $3.5\,
{\rm years}$). This extended dataset has significantly improved the precision
of the astrometric estimates of these pulsars. Our broadband study suggests
that, as expected, the primary contribution to systematic uncertainties in
L-band VLBI astrometry originates from the ionosphere. We have also assessed
the effectiveness of the modified TEC (total electron content) mapping
function, which converts vertical TEC to slant TEC, in correcting ionospheric
dispersive delays using global TEC maps. The parallax and proper motion
obtained from the multiple data sets, calibrated using the traditional and the
modified TEC mapping functions, are consistent. However, the reduced chi-square
values from least-squares fitting and precision of the fitted astrometric
parameters show no significant improvement, and hence, the effectiveness of the
new TEC mapping function on astrometry is unclear. For B0329+54, the refined
parallax estimate is $0.611^{+0.013}_{-0.013}\, {\rm mas}$, with best-fit
proper motion of $\mu_{\alpha} = 16.960^{+0.011}_{-0.010}\, {\rm mas\,
yr^{-1}}$ in R.A. and and $\mu_{\delta} = -10.382^{+0.022}_{-0.022}\, {\rm
mas\, yr^{-1}}$ in Dec. For B1133+16, the new estimated parallax is
$2.705^{+0.009}_{-0.009}\, {\rm mas}$, with proper motions of $\mu_{\alpha} =
-73.777^{+0.008}_{-0.008}\, {\rm mas\, yr^{-1}}$ and $\mu_{\delta} =
366.573^{+0.019}_{-0.019}\, {\rm mas\, yr^{-1}}$.</p></br><a href="http://arxiv.org/pdf/2506.14329v1" target="_blank"><h2>Adjustment for Confounding using Pre-Trained Representations</h2></a><strong><u>Authors:</u></strong>  Rickmer Schulte, David Rügamer, Thomas Nagler</br><strong><u>Categories:</u></strong> stat.ML, cs.AI, cs.LG, stat.CO, stat.ME</br><strong><u>Comments:</u></strong> Accepted at ICML 2025</br><p><strong><u>Abstract:</u></strong> There is growing interest in extending average treatment effect (ATE)
estimation to incorporate non-tabular data, such as images and text, which may
act as sources of confounding. Neglecting these effects risks biased results
and flawed scientific conclusions. However, incorporating non-tabular data
necessitates sophisticated feature extractors, often in combination with ideas
of transfer learning. In this work, we investigate how latent features from
pre-trained neural networks can be leveraged to adjust for sources of
confounding. We formalize conditions under which these latent features enable
valid adjustment and statistical inference in ATE estimation, demonstrating
results along the example of double machine learning. We discuss critical
challenges inherent to latent feature learning and downstream parameter
estimation arising from the high dimensionality and non-identifiability of
representations. Common structural assumptions for obtaining fast convergence
rates with additive or sparse linear models are shown to be unrealistic for
latent features. We argue, however, that neural networks are largely
insensitive to these issues. In particular, we show that neural networks can
achieve fast convergence rates by adapting to intrinsic notions of sparsity and
dimension of the learning problem.</p></br><a href="http://arxiv.org/pdf/2506.14113v1" target="_blank"><h2>SKOLR: Structured Koopman Operator Linear RNN for Time-Series
  Forecasting</h2></a><strong><u>Authors:</u></strong>  Yitian Zhang, Liheng Ma, Antonios Valkanas, Boris N. Oreshkin, Mark Coates</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Koopman operator theory provides a framework for nonlinear dynamical system
analysis and time-series forecasting by mapping dynamics to a space of
real-valued measurement functions, enabling a linear operator representation.
Despite the advantage of linearity, the operator is generally
infinite-dimensional. Therefore, the objective is to learn measurement
functions that yield a tractable finite-dimensional Koopman operator
approximation. In this work, we establish a connection between Koopman operator
approximation and linear Recurrent Neural Networks (RNNs), which have recently
demonstrated remarkable success in sequence modeling. We show that by
considering an extended state consisting of lagged observations, we can
establish an equivalence between a structured Koopman operator and linear RNN
updates. Building on this connection, we present SKOLR, which integrates a
learnable spectral decomposition of the input signal with a multilayer
perceptron (MLP) as the measurement functions and implements a structured
Koopman operator via a highly parallel linear RNN stack. Numerical experiments
on various forecasting benchmarks and dynamical systems show that this
streamlined, Koopman-theory-based design delivers exceptional performance.</p></br><a href="http://arxiv.org/pdf/2506.15408v1" target="_blank"><h2>Unifying VXAI: A Systematic Review and Framework for the Evaluation of
  Explainable AI</h2></a><strong><u>Authors:</u></strong>  David Dembinsky, Adriano Lucieri, Stanislav Frolov, Hiba Najjar, Ko Watanabe, Andreas Dengel</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Submitted to TMLR, under review</br><p><strong><u>Abstract:</u></strong> Modern AI systems frequently rely on opaque black-box models, most notably
Deep Neural Networks, whose performance stems from complex architectures with
millions of learned parameters. While powerful, their complexity poses a major
challenge to trustworthiness, particularly due to a lack of transparency.
Explainable AI (XAI) addresses this issue by providing human-understandable
explanations of model behavior. However, to ensure their usefulness and
trustworthiness, such explanations must be rigorously evaluated. Despite the
growing number of XAI methods, the field lacks standardized evaluation
protocols and consensus on appropriate metrics. To address this gap, we conduct
a systematic literature review following the Preferred Reporting Items for
Systematic Reviews and Meta-Analyses (PRISMA) guidelines and introduce a
unified framework for the eValuation of XAI (VXAI). We identify 362 relevant
publications and aggregate their contributions into 41 functionally similar
metric groups. In addition, we propose a three-dimensional categorization
scheme spanning explanation type, evaluation contextuality, and explanation
quality desiderata. Our framework provides the most comprehensive and
structured overview of VXAI to date. It supports systematic metric selection,
promotes comparability across methods, and offers a flexible foundation for
future extensions.</p></br><a href="http://arxiv.org/pdf/2506.14202v1" target="_blank"><h2>DiffusionBlocks: Blockwise Training for Generative Models via
  Score-Based Diffusion</h2></a><strong><u>Authors:</u></strong>  Makoto Shing, Takuya Akiba</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> To appear at TTODLer-FM Workshop of the 42nd International Conference on Machine Learning</br><p><strong><u>Abstract:</u></strong> Training large neural networks with end-to-end backpropagation creates
significant memory bottlenecks, limiting accessibility to state-of-the-art AI
research. We propose $\textit{DiffusionBlocks}$, a novel training framework
that interprets neural network blocks as performing denoising operations in a
continuous-time diffusion process. By partitioning the network into
independently trainable blocks and optimizing noise level assignments based on
equal cumulative probability mass, our approach achieves significant memory
efficiency while maintaining competitive performance compared to traditional
backpropagation in generative tasks. Experiments on image generation and
language modeling tasks demonstrate memory reduction proportional to the number
of blocks while achieving superior performance. DiffusionBlocks provides a
promising pathway for democratizing access to large-scale neural network
training with limited computational resources.</p></br><a href="http://arxiv.org/pdf/2506.15559v1" target="_blank"><h2>Towards Explainable Indoor Localization: Interpreting Neural Network
  Learning on Wi-Fi Fingerprints Using Logic Gates</h2></a><strong><u>Authors:</u></strong>  Danish Gufran, Sudeep Pasricha</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Indoor localization using deep learning (DL) has demonstrated strong accuracy
in mapping Wi-Fi RSS fingerprints to physical locations; however, most existing
DL frameworks function as black-box models, offering limited insight into how
predictions are made or how models respond to real-world noise over time. This
lack of interpretability hampers our ability to understand the impact of
temporal variations - caused by environmental dynamics - and to adapt models
for long-term reliability. To address this, we introduce LogNet, a novel logic
gate-based framework designed to interpret and enhance DL-based indoor
localization. LogNet enables transparent reasoning by identifying which access
points (APs) are most influential for each reference point (RP) and reveals how
environmental noise disrupts DL-driven localization decisions. This
interpretability allows us to trace and diagnose model failures and adapt DL
systems for more stable long-term deployments. Evaluations across multiple
real-world building floorplans and over two years of temporal variation show
that LogNet not only interprets the internal behavior of DL models but also
improves performance-achieving up to 1.1x to 2.8x lower localization error,
3.4x to 43.3x smaller model size, and 1.5x to 3.6x lower latency compared to
prior DL-based models.</p></br><a href="http://arxiv.org/pdf/2506.14438v1" target="_blank"><h2>sHGCN: Simplified hyperbolic graph convolutional neural networks</h2></a><strong><u>Authors:</u></strong>  Pol Arévalo, Alexis Molina, Álvaro Ciudad</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Hyperbolic geometry has emerged as a powerful tool for modeling complex,
structured data, particularly where hierarchical or tree-like relationships are
present. By enabling embeddings with lower distortion, hyperbolic neural
networks offer promising alternatives to Euclidean-based models for capturing
intricate data structures. Despite these advantages, they often face
performance challenges, particularly in computational efficiency and tasks
requiring high precision. In this work, we address these limitations by
simplifying key operations within hyperbolic neural networks, achieving notable
improvements in both runtime and performance. Our findings demonstrate that
streamlined hyperbolic operations can lead to substantial gains in
computational speed and predictive accuracy, making hyperbolic neural networks
a more viable choice for a broader range of applications.</p></br><a href="http://arxiv.org/pdf/2506.15309v1" target="_blank"><h2>Active Learning-Guided Seq2Seq Variational Autoencoder for Multi-target
  Inhibitor Generation</h2></a><strong><u>Authors:</u></strong>  Júlia Vilalta-Mor, Alexis Molina, Laura Ortega Varga, Isaac Filella-Merce, Victor Guallar</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, q-bio.BM</br><strong><u>Comments:</u></strong> 16 pages, 7 figures</br><p><strong><u>Abstract:</u></strong> Simultaneously optimizing molecules against multiple therapeutic targets
remains a profound challenge in drug discovery, particularly due to sparse
rewards and conflicting design constraints. We propose a structured active
learning (AL) paradigm integrating a sequence-to-sequence (Seq2Seq) variational
autoencoder (VAE) into iterative loops designed to balance chemical diversity,
molecular quality, and multi-target affinity. Our method alternates between
expanding chemically feasible regions of latent space and progressively
constraining molecules based on increasingly stringent multi-target docking
thresholds. In a proof-of-concept study targeting three related coronavirus
main proteases (SARS-CoV-2, SARS-CoV, MERS-CoV), our approach efficiently
generated a structurally diverse set of pan-inhibitor candidates. We
demonstrate that careful timing and strategic placement of chemical filters
within this active learning pipeline markedly enhance exploration of beneficial
chemical space, transforming the sparse-reward, multi-objective drug design
problem into an accessible computational task. Our framework thus provides a
generalizable roadmap for efficiently navigating complex polypharmacological
landscapes.</p></br><a href="http://arxiv.org/pdf/2506.14280v1" target="_blank"><h2>Improving LoRA with Variational Learning</h2></a><strong><u>Authors:</u></strong>  Bai Cong, Nico Daheim, Yuesong Shen, Rio Yokota, Mohammad Emtiyaz Khan, Thomas Möllenhoff</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL, stat.ML</br><strong><u>Comments:</u></strong> 16 pages, 4 figures</br><p><strong><u>Abstract:</u></strong> Bayesian methods have recently been used to improve LoRA finetuning and,
although they improve calibration, their effect on other metrics (such as
accuracy) is marginal and can sometimes even be detrimental. Moreover, Bayesian
methods also increase computational overheads and require additional tricks for
them to work well. Here, we fix these issues by using a recently proposed
variational algorithm called IVON. We show that IVON is easy to implement and
has similar costs to AdamW, and yet it can also drastically improve many
metrics by using a simple posterior pruning technique. We present extensive
results on billion-scale LLMs (Llama and Qwen series) going way beyond the
scale of existing applications of IVON. For example, we finetune a Llama-3.2-3B
model on a set of commonsense reasoning tasks and improve accuracy over AdamW
by 1.3% and reduce ECE by 5.4%, outperforming AdamW and other recent Bayesian
methods like Laplace-LoRA and BLoB. Overall, our results show that variational
learning with IVON can effectively improve LoRA finetuning.</p></br><a href="http://arxiv.org/pdf/2506.14262v1" target="_blank"><h2>Knowledge Adaptation as Posterior Correction</h2></a><strong><u>Authors:</u></strong>  Mohammad Emtiyaz Khan</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Adaptation is the holy grail of intelligence, but even the best AI models
(like GPT) lack the adaptivity of toddlers. So the question remains: how can
machines adapt quickly? Despite a lot of progress on model adaptation to
facilitate continual and federated learning, as well as model merging, editing,
unlearning, etc., little is known about the mechanisms by which machines can
naturally learn to adapt in a similar way as humans and animals. Here, we show
that all such adaptation methods can be seen as different ways of `correcting'
the approximate posteriors. More accurate posteriors lead to smaller
corrections, which in turn imply quicker adaptation. The result is obtained by
using a dual-perspective of the Bayesian Learning Rule of Khan and Rue (2023)
where interference created during adaptation is characterized by the
natural-gradient mismatch over the past data. We present many examples to
demonstrate the use of posterior-correction as a natural mechanism for the
machines to learn to adapt quickly.</p></br><a href="http://arxiv.org/pdf/2506.15025v1" target="_blank"><h2>Optimal Embedding Learning Rate in LLMs: The Effect of Vocabulary Size</h2></a><strong><u>Authors:</u></strong>  Soufiane Hayou, Liyuan Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL, stat.ML</br><strong><u>Comments:</u></strong> TD,LR: How to set the learning rate for emebdding layer in LLMs?</br><p><strong><u>Abstract:</u></strong> Pretraining large language models is a costly process. To make this process
more efficient, several methods have been proposed to optimize model
architecture/parametrization and hardware use. On the parametrization side,
$\mu P$ (Maximal Update Parametrization) parametrizes model weights and
learning rate (LR) in a way that makes hyperparameters (HPs) transferable with
width (embedding dimension): HPs can be tuned for a small model and used for
larger models without additional tuning. While $\mu$P showed impressive results
in practice, recent empirical studies have reported conflicting observations
when applied to LLMs. One limitation of the theory behind $\mu$P is the fact
that input dimension (vocabulary size in LLMs) is considered fixed when taking
the width to infinity. This is unrealistic since vocabulary size is generally
much larger than width in practice. In this work, we provide a theoretical
analysis of the effect of vocabulary size on training dynamics, and
subsequently show that as vocabulary size increases, the training dynamics
\emph{interpolate between the $\mu$P regime and another regime that we call
Large Vocab (LV) Regime}, where optimal scaling rules are different from those
predicted by $\mu$P. Our analysis reveals that in the LV regime, the optimal
embedding LR to hidden LR ratio should roughly scale as $\Theta(\sqrt{width})$,
surprisingly close to the empirical findings previously reported in the
literature, and different from the $\Theta(width)$ ratio predicted by $\mu$P.
We conduct several experiments to validate our theory, and pretrain a 1B model
from scratch to show the benefit of our suggested scaling rule for the
embedding LR.</p></br><a href="http://arxiv.org/pdf/2506.15079v1" target="_blank"><h2>Neural Canonical Polyadic Factorization for Traffic Analysis</h2></a><strong><u>Authors:</u></strong>  Yikai Hou, Peng Tang</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Modern intelligent transportation systems rely on accurate spatiotemporal
traffic analysis to optimize urban mobility and infrastructure resilience.
However, pervasive missing data caused by sensor failures and heterogeneous
sensing gaps fundamentally hinders reliable traffic modeling. This paper
proposes a Neural Canonical Polyadic Factorization (NCPF) model that synergizes
low-rank tensor algebra with deep representation learning for robust traffic
data imputation. The model innovatively embeds CP decomposition into neural
architecture through learnable embedding projections, where sparse traffic
tensors are encoded into dense latent factors across road segments, time
intervals, and mobility metrics. A hierarchical feature fusion mechanism
employs Hadamard products to explicitly model multilinear interactions, while
stacked multilayer perceptron layers nonlinearly refine these representations
to capture complex spatiotemporal couplings. Extensive evaluations on six urban
traffic datasets demonstrate NCPF's superiority over six state-of-the-art
baselines. By unifying CP decomposition's interpretable factor analysis with
neural network's nonlinear expressive power, NCPF provides a principled yet
flexible approaches for high-dimensional traffic data imputation, offering
critical support for next-generation transportation digital twins and adaptive
traffic control systems.</p></br><a href="http://arxiv.org/pdf/2506.15452v1" target="_blank"><h2>Warping and Matching Subsequences Between Time Series</h2></a><strong><u>Authors:</u></strong>  Simiao Lin, Wannes Meert, Pieter Robberechts, Hendrik Blockeel</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><p><strong><u>Abstract:</u></strong> Comparing time series is essential in various tasks such as clustering and
classification. While elastic distance measures that allow warping provide a
robust quantitative comparison, a qualitative comparison on top of them is
missing. Traditional visualizations focus on point-to-point alignment and do
not convey the broader structural relationships at the level of subsequences.
This limitation makes it difficult to understand how and where one time series
shifts, speeds up or slows down with respect to another. To address this, we
propose a novel technique that simplifies the warping path to highlight,
quantify and visualize key transformations (shift, compression, difference in
amplitude). By offering a clearer representation of how subsequences match
between time series, our method enhances interpretability in time series
comparison.</p></br><a href="http://arxiv.org/pdf/2506.14444v1" target="_blank"><h2>SAS in ESA Datalabs: A New Platform for XMM-Newton Analysis</h2></a><strong><u>Authors:</u></strong>  Esin G. Gulbahar, Camille M. Diez, Aitor Ibarra, Ivan Valtchanov, Richard Saxton, Ignacio de la Calle Perez, Jose Lopez-Miralles, Alejandro Gonzalez Ganzabal, Peter Kretschmar</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE</br><strong><u>Comments:</u></strong> 14 pages, 13 figures</br><p><strong><u>Abstract:</u></strong> XMM-Newton is a cornerstone mission of the European Space Agency (ESA) for
X-ray astronomy, providing high-quality X-ray data for astrophysical research
since the start of the century. Its Science Analysis System (SAS) has been a
reliable data reduction and analysis software, evolving throughout the years to
meet changing user needs, while incorporating new methods. This paper presents
the XMM-SAS Datalab, a tool within the cloud-based ESA Datalabs platform,
designed to enhance the interactivity and collaborative potential of SAS. By
integrating SAS with a modern, Python-based JupyterLab interface, it enables
shared analysis workspaces, removes the need for local software setup, and
provides faster access through containerised environments and preconfigured
libraries. Moving SAS to the cloud preserves a consistent software setup while
eliminating installation complexities, saving time and effort. A case study of
the X-ray binary Vela X-1 demonstrates that the Datalabs platform reliably
replicates local SAS outputs, with minimal deviations attributed to calibration
file versions. The XMM-SAS Datalab allows straightforward X-ray data analysis
with collaborative process, setting the way for future adaptations in e-science
platforms and multi-wavelength astronomy, while offering traceability and
reproducibility of scientific results.</p></br><a href="http://arxiv.org/pdf/2506.14764v1" target="_blank"><h2>Gravitational-wave background detection using machine learning</h2></a><strong><u>Authors:</u></strong>  Hugo Einsle, Marie-Anne Bizouard, Tania Regimbau, Mairi Sakellariadou</br><strong><u>Categories:</u></strong> gr-qc, astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> 17 pages, 7 figures</br><p><strong><u>Abstract:</u></strong> Extracting the faint gravitational-wave background (GWB) signal from dominant
detector noise and disentangling its %diverse astrophysical and cosmological
components remain significant challenges for traditional methods like
cross-correlation analysis. We propose a novel hybrid approach that combines
deep learning with Bayesian inference to identify and characterize the GWB more
rapidly than current techniques. Our method utilizes a custom-designed
multi-scale multi-headed autoencoder (MSMHAutoencoder) architecture to separate
GWB signals from detector noise, and subsequently Marcov Chain Monte Carlo
parameter estimation to disentangle the GWB components. Using simulated data
representative of the LIGO-Virgo-KAGRA network at design sensitivity, we show
that our MSMHAutoencoder can detect with high confidence (log noise Bayes
factor of 3) a GWB from binary black hole mergers with fractional energy
density $\Omega_{\text{BBH}} \approx 10^{-9}$ at 25 Hz. In the presence of such
an astrophysical GWB, we can simultaneously measure a cosmological component as
faint as $\Omega_{\text{Cosmo}} \approx 1.3 \times 10^{-10}$ using 47.4 days of
training data.</p></br></body>