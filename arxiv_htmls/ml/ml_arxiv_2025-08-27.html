<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 25 Aug 2025 to 27 Aug 2025</em></font><a href="http://arxiv.org/pdf/2508.18474v1" target="_blank"><h2>DRTA: Dynamic Reward Scaling for Reinforcement Learning in Time Series
  Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Bahareh Golchin, Banafsheh Rekabdar, Kunpeng Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (abstract), anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection in time series data is important for applications in
finance, healthcare, sensor networks, and industrial monitoring. Traditional
methods usually struggle with limited labeled data, high false-positive rates,
and difficulty generalizing to novel anomaly types. To overcome these
challenges, we propose a reinforcement learning-based framework that integrates
dynamic reward shaping, Variational Autoencoder (VAE), and active learning,
called DRTA. Our method uses an adaptive reward mechanism that balances
exploration and exploitation by dynamically scaling the effect of VAE-based
reconstruction error and classification rewards. This approach enables the
agent to detect anomalies effectively in low-label systems while maintaining
high precision and recall. Our experimental results on the Yahoo A1 and Yahoo
A2 benchmark datasets demonstrate that the proposed method consistently
outperforms state-of-the-art unsupervised and semi-supervised approaches. These
findings show that our framework is a scalable and efficient solution for
real-world anomaly detection tasks.</p></br><a href="http://arxiv.org/pdf/2508.18912v1" target="_blank"><h2>HOTSPOT-YOLO: A Lightweight Deep Learning Attention-Driven Model for
  Detecting Thermal Anomalies in Drone-Based Solar Photovoltaic Inspections</h2></a><strong><u>Authors:</u></strong>  Mahmoud Dhimish</br><strong><u>Categories:</u></strong> eess.IV, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), anomaly detection (abstract), neural network (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Thermal anomaly detection in solar photovoltaic (PV) systems is essential for
ensuring operational efficiency and reducing maintenance costs. In this study,
we developed and named HOTSPOT-YOLO, a lightweight artificial intelligence (AI)
model that integrates an efficient convolutional neural network backbone and
attention mechanisms to improve object detection. This model is specifically
designed for drone-based thermal inspections of PV systems, addressing the
unique challenges of detecting small and subtle thermal anomalies, such as
hotspots and defective modules, while maintaining real-time performance.
Experimental results demonstrate a mean average precision of 90.8%, reflecting
a significant improvement over baseline object detection models. With a reduced
computational load and robustness under diverse environmental conditions,
HOTSPOT-YOLO offers a scalable and reliable solution for large-scale PV
inspections. This work highlights the integration of advanced AI techniques
with practical engineering applications, revolutionizing automated fault
detection in renewable energy systems.</p></br><a href="http://arxiv.org/pdf/2508.18960v1" target="_blank"><h2>Enhancing compact convolutional transformers with super attention</h2></a><strong><u>Authors:</u></strong>  Simpenzwe Honore Leandre, Natenaile Asmamaw Shiferaw, Dillip Rout</br><strong><u>Categories:</u></strong> cs.CV, cs.LG</br><strong><u>Comments:</u></strong> 9 pages, 4 figures</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), transformer (title, abstract), attention (title, abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> In this paper, we propose a vision model that adopts token mixing,
sequence-pooling, and convolutional tokenizers to achieve state-of-the-art
performance and efficient inference in fixed context-length tasks. In the
CIFAR100 benchmark, our model significantly improves the baseline of the top 1%
and top 5% validation accuracy from 36.50% to 46.29% and 66.33% to 76.31%,
while being more efficient than the Scaled Dot Product Attention (SDPA)
transformers when the context length is less than the embedding dimension and
only 60% the size. In addition, the architecture demonstrates high training
stability and does not rely on techniques such as data augmentation like mixup,
positional embeddings, or learning rate scheduling. We make our code available
on Github.</p></br><a href="http://arxiv.org/pdf/2508.19097v1" target="_blank"><h2>Reasoning LLMs in the Medical Domain: A Literature Survey</h2></a><strong><u>Authors:</u></strong>  Armin Berger, Sarthak Khanna, David Berghaus, Rafet Sifa</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> The emergence of advanced reasoning capabilities in Large Language Models
(LLMs) marks a transformative development in healthcare applications. Beyond
merely expanding functional capabilities, these reasoning mechanisms enhance
decision transparency and explainability-critical requirements in medical
contexts. This survey examines the transformation of medical LLMs from basic
information retrieval tools to sophisticated clinical reasoning systems capable
of supporting complex healthcare decisions. We provide a thorough analysis of
the enabling technological foundations, with a particular focus on specialized
prompting techniques like Chain-of-Thought and recent breakthroughs in
Reinforcement Learning exemplified by DeepSeek-R1. Our investigation evaluates
purpose-built medical frameworks while also examining emerging paradigms such
as multi-agent collaborative systems and innovative prompting architectures.
The survey critically assesses current evaluation methodologies for medical
validation and addresses persistent challenges in field interpretation
limitations, bias mitigation strategies, patient safety frameworks, and
integration of multimodal clinical data. Through this survey, we seek to
establish a roadmap for developing reliable LLMs that can serve as effective
partners in clinical practice and medical research.</p></br><a href="http://arxiv.org/pdf/2508.18922v1" target="_blank"><h2>HierCVAE: Hierarchical Attention-Driven Conditional Variational
  Autoencoders for Multi-Scale Temporal Modeling</h2></a><strong><u>Authors:</u></strong>  Yao Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, 62-08, I.2.6</br><strong><u>Comments:</u></strong> 10 pages, 6 figures</br><strong><u>Matching Keywords:</u></strong> variational autoencoder (abstract), VAE (title, abstract), latent space (abstract), multi-modal (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Temporal modeling in complex systems requires capturing dependencies across
multiple time scales while managing inherent uncertainties. We propose
HierCVAE, a novel architecture that integrates hierarchical attention
mechanisms with conditional variational autoencoders to address these
challenges. HierCVAE employs a three-tier attention structure (local, global,
cross-temporal) combined with multi-modal condition encoding to capture
temporal, statistical, and trend information. The approach incorporates
ResFormer blocks in the latent space and provides explicit uncertainty
quantification via prediction heads. Through evaluations on energy consumption
datasets, HierCVAE demonstrates a 15-40% improvement in prediction accuracy and
superior uncertainty calibration compared to state-of-the-art methods,
excelling in long-term forecasting and complex multi-variate dependencies.</p></br><a href="http://arxiv.org/pdf/2508.19019v1" target="_blank"><h2>Metric Matters: A Formal Evaluation of Similarity Measures in Active
  Learning for Cyber Threat Intelligence</h2></a><strong><u>Authors:</u></strong>  Sidahmed Benabderrahmane, Talal Rahwan</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NE</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Advanced Persistent Threats (APTs) pose a severe challenge to cyber defense
due to their stealthy behavior and the extreme class imbalance inherent in
detection datasets. To address these issues, we propose a novel active
learning-based anomaly detection framework that leverages similarity search to
iteratively refine the decision space. Built upon an Attention-Based
Autoencoder, our approach uses feature-space similarity to identify normal-like
and anomaly-like instances, thereby enhancing model robustness with minimal
oracle supervision. Crucially, we perform a formal evaluation of various
similarity measures to understand their influence on sample selection and
anomaly ranking effectiveness. Through experiments on diverse datasets,
including DARPA Transparent Computing APT traces, we demonstrate that the
choice of similarity metric significantly impacts model convergence, anomaly
detection accuracy, and label efficiency. Our results offer actionable insights
for selecting similarity functions in active learning pipelines tailored for
threat intelligence and cyber defense.</p></br><a href="http://arxiv.org/pdf/2508.18903v1" target="_blank"><h2>Distance-informed Neural Processes</h2></a><strong><u>Authors:</u></strong>  Aishwarya Venkataramanan, Joachim Denzler</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 22 pages</br><strong><u>Matching Keywords:</u></strong> latent space (abstract)</br><p><strong><u>Abstract:</u></strong> We propose the Distance-informed Neural Process (DNP), a novel variant of
Neural Processes that improves uncertainty estimation by combining global and
distance-aware local latent structures. Standard Neural Processes (NPs) often
rely on a global latent variable and struggle with uncertainty calibration and
capturing local data dependencies. DNP addresses these limitations by
introducing a global latent variable to model task-level variations and a local
latent variable to capture input similarity within a distance-preserving latent
space. This is achieved through bi-Lipschitz regularization, which bounds
distortions in input relationships and encourages the preservation of relative
distances in the latent space. This modeling approach allows DNP to produce
better-calibrated uncertainty estimates and more effectively distinguish in-
from out-of-distribution data. Empirical results demonstrate that DNP achieves
strong predictive performance and improved uncertainty calibration across
regression and classification tasks.</p></br></body>