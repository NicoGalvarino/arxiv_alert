<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 17 Sep 2025 to 19 Sep 2025</em></font><a href="http://arxiv.org/pdf/2509.14472v1" target="_blank"><h2>H-Alpha Anomalyzer: An Explainable Anomaly Detector for Solar H-Alpha
  Observations</h2></a><strong><u>Authors:</u></strong>  Mahsa Khazaei, Azim Ahmadzadeh, Alexei Pevtsov, Luca Bertello, Alexander Pevtsov</br><strong><u>Categories:</u></strong> cs.LG, astro-ph.IM, astro-ph.SR</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title)</br><p><strong><u>Abstract:</u></strong> The plethora of space-borne and ground-based observatories has provided
astrophysicists with an unprecedented volume of data, which can only be
processed at scale using advanced computing algorithms. Consequently, ensuring
the quality of data fed into machine learning (ML) models is critical. The
H$\alpha$ observations from the GONG network represent one such data stream,
producing several observations per minute, 24/7, since 2010. In this study, we
introduce a lightweight (non-ML) anomaly-detection algorithm, called H-Alpha
Anomalyzer, designed to identify anomalous observations based on user-defined
criteria. Unlike many black-box algorithms, our approach highlights exactly
which regions triggered the anomaly flag and quantifies the corresponding
anomaly likelihood. For our comparative analysis, we also created and released
a dataset of 2,000 observations, equally divided between anomalous and
non-anomalous cases. Our results demonstrate that the proposed model not only
outperforms existing methods but also provides explainability, enabling
qualitative evaluation by domain experts.</p></br><a href="http://arxiv.org/pdf/2509.15010v1" target="_blank"><h2>First IACT Waveform Analysis Based on Deep Convolutional Neural Networks
  Using CTLearn</h2></a><strong><u>Authors:</u></strong>  T. Miener, L. Burmistrov, B. Lacave, A. Cerviño</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> Presented at the 39th International Cosmic Ray Conference (ICRC 2025), 2025</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Imaging atmospheric Cherenkov telescopes (IACTs) detect extended air showers
(EASs) generated when very-high-energy (VHE) gamma rays or cosmic rays interact
with the Earth's atmosphere. Cherenkov photons produced during an EAS are
captured by fast-imaging cameras, which record both the spatial and temporal
development of the shower, along with calorimetric data. By analyzing these
recordings, the properties of the original VHE particle-such as its type,
energy, and direction of arrival-can be reconstructed through machine learning
techniques. This contribution focuses on the Large-Sized Telescopes (LSTs) of
the Cherenkov Telescope Array Observatory, a next-generation ground-based
gamma-ray observatory. LSTs are responsible for reconstructing lower-energy
gamma rays in the tens of GeV range. We explore a novel event reconstruction
technique based on deep convolutional neural networks (CNNs) applied on
calibrated and cleaned waveforms of the IACT camera pixels using CTLearn. Our
approach explicitly incorporates the time development of the shower, enabling a
more accurate reconstruction of the event. This method eliminates the need for
charge integration or handcrafted feature extraction, allowing the model to
directly learn from waveform data.</p></br><a href="http://arxiv.org/pdf/2509.15198v1" target="_blank"><h2>Explaining deep learning for ECG using time-localized clusters</h2></a><strong><u>Authors:</u></strong>  Ahcène Boubekki, Konstantinos Patlatzoglou, Joseph Barker, Fu Siong Ng, Antônio H. Ribeiro</br><strong><u>Categories:</u></strong> cs.LG, stat.AP, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Deep learning has significantly advanced electrocardiogram (ECG) analysis,
enabling automatic annotation, disease screening, and prognosis beyond
traditional clinical capabilities. However, understanding these models remains
a challenge, limiting interpretation and gaining knowledge from these
developments. In this work, we propose a novel interpretability method for
convolutional neural networks applied to ECG analysis. Our approach extracts
time-localized clusters from the model's internal representations, segmenting
the ECG according to the learned characteristics while quantifying the
uncertainty of these representations. This allows us to visualize how different
waveform regions contribute to the model's predictions and assess the certainty
of its decisions. By providing a structured and interpretable view of deep
learning models for ECG, our method enhances trust in AI-driven diagnostics and
facilitates the discovery of clinically relevant electrophysiological patterns.</p></br><a href="http://arxiv.org/pdf/2509.15024v1" target="_blank"><h2>Attention Beyond Neighborhoods: Reviving Transformer for Graph
  Clustering</h2></a><strong><u>Authors:</u></strong>  Xuanting Xie, Bingheng Li, Erlin Pan, Rui Hou, Wenyu Chen, Zhao Kang</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NI</br><strong><u>Comments:</u></strong> 9 pages, 5 figures</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Attention mechanisms have become a cornerstone in modern neural networks,
driving breakthroughs across diverse domains. However, their application to
graph structured data, where capturing topological connections is essential,
remains underexplored and underperforming compared to Graph Neural Networks
(GNNs), particularly in the graph clustering task. GNN tends to overemphasize
neighborhood aggregation, leading to a homogenization of node representations.
Conversely, Transformer tends to over globalize, highlighting distant nodes at
the expense of meaningful local patterns. This dichotomy raises a key question:
Is attention inherently redundant for unsupervised graph learning? To address
this, we conduct a comprehensive empirical analysis, uncovering the
complementary weaknesses of GNN and Transformer in graph clustering. Motivated
by these insights, we propose the Attentive Graph Clustering Network (AGCN) a
novel architecture that reinterprets the notion that graph is attention. AGCN
directly embeds the attention mechanism into the graph structure, enabling
effective global information extraction while maintaining sensitivity to local
topological cues. Our framework incorporates theoretical analysis to contrast
AGCN behavior with GNN and Transformer and introduces two innovations: (1) a KV
cache mechanism to improve computational efficiency, and (2) a pairwise margin
contrastive loss to boost the discriminative capacity of the attention space.
Extensive experimental results demonstrate that AGCN outperforms
state-of-the-art methods.</p></br><a href="http://arxiv.org/pdf/2509.14987v1" target="_blank"><h2>Blockchain-Enabled Explainable AI for Trusted Healthcare Systems</h2></a><strong><u>Authors:</u></strong>  Md Talha Mohsin</br><strong><u>Categories:</u></strong> cs.CR, cs.AI, cs.LG</br><strong><u>Comments:</u></strong> 6 Pages, 4 Figures</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper introduces a Blockchain-Integrated Explainable AI Framework (BXHF)
for healthcare systems to tackle two essential challenges confronting health
information networks: safe data exchange and comprehensible AI-driven clinical
decision-making. Our architecture incorporates blockchain, ensuring patient
records are immutable, auditable, and tamper-proof, alongside Explainable AI
(XAI) methodologies that yield transparent and clinically relevant model
predictions. By incorporating security assurances and interpretability
requirements into a unified optimization pipeline, BXHF ensures both data-level
trust (by verified and encrypted record sharing) and decision-level trust (with
auditable and clinically aligned explanations). Its hybrid edge-cloud
architecture allows for federated computation across different institutions,
enabling collaborative analytics while protecting patient privacy. We
demonstrate the framework's applicability through use cases such as
cross-border clinical research networks, uncommon illness detection and
high-risk intervention decision support. By ensuring transparency,
auditability, and regulatory compliance, BXHF improves the credibility, uptake,
and effectiveness of AI in healthcare, laying the groundwork for safer and more
reliable clinical decision-making.</p></br><a href="http://arxiv.org/pdf/2509.14942v1" target="_blank"><h2>Explainable AI for Infection Prevention and Control: Modeling CPE
  Acquisition and Patient Outcomes in an Irish Hospital with Transformers</h2></a><strong><u>Authors:</u></strong>  Minh-Khoi Pham, Tai Tan Mai, Martin Crane, Rob Brennan, Marie E. Ward, Una Geary, Declan Byrne, Brian O Connell, Colm Bergin, Donncha Creagh, Nick McDonald, Marija Bezbradica</br><strong><u>Categories:</u></strong> cs.AI, cs.LG</br><strong><u>Comments:</u></strong> Accepted to BMC Medical Informatics and Decision Making on September 18th 2025</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title, abstract), transformer (title, abstract)</br><p><strong><u>Abstract:</u></strong> Carbapenemase-Producing Enterobacteriace poses a critical concern for
infection prevention and control in hospitals. However, predictive modeling of
previously highlighted CPE-associated risks such as readmission, mortality, and
extended length of stay (LOS) remains underexplored, particularly with modern
deep learning approaches. This study introduces an eXplainable AI modeling
framework to investigate CPE impact on patient outcomes from Electronic Medical
Records data of an Irish hospital. We analyzed an inpatient dataset from an
Irish acute hospital, incorporating diagnostic codes, ward transitions, patient
demographics, infection-related variables and contact network features. Several
Transformer-based architectures were benchmarked alongside traditional machine
learning models. Clinical outcomes were predicted, and XAI techniques were
applied to interpret model decisions. Our framework successfully demonstrated
the utility of Transformer-based models, with TabTransformer consistently
outperforming baselines across multiple clinical prediction tasks, especially
for CPE acquisition (AUROC and sensitivity). We found infection-related
features, including historical hospital exposure, admission context, and
network centrality measures, to be highly influential in predicting patient
outcomes and CPE acquisition risk. Explainability analyses revealed that
features like "Area of Residence", "Admission Ward" and prior admissions are
key risk factors. Network variables like "Ward PageRank" also ranked highly,
reflecting the potential value of structural exposure information. This study
presents a robust and explainable AI framework for analyzing complex EMR data
to identify key risk factors and predict CPE-related outcomes. Our findings
underscore the superior performance of the Transformer models and highlight the
importance of diverse clinical and network features.</p></br><a href="http://arxiv.org/pdf/2509.15058v1" target="_blank"><h2>Communication Efficient Split Learning of ViTs with Attention-based
  Double Compression</h2></a><strong><u>Authors:</u></strong>  Federico Alvetreti, Jary Pomponi, Paolo Di Lorenzo, Simone Scardapane</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> This paper proposes a novel communication-efficient Split Learning (SL)
framework, named Attention-based Double Compression (ADC), which reduces the
communication overhead required for transmitting intermediate Vision
Transformers activations during the SL training process. ADC incorporates two
parallel compression strategies. The first one merges samples' activations that
are similar, based on the average attention score calculated in the last client
layer; this strategy is class-agnostic, meaning that it can also merge samples
having different classes, without losing generalization ability nor decreasing
final results. The second strategy follows the first and discards the least
meaningful tokens, further reducing the communication cost. Combining these
strategies not only allows for sending less during the forward pass, but also
the gradients are naturally compressed, allowing the whole model to be trained
without additional tuning or approximations of the gradients. Simulation
results demonstrate that Attention-based Double Compression outperforms
state-of-the-art SL frameworks by significantly reducing communication
overheads while maintaining high accuracy.</p></br><a href="http://arxiv.org/pdf/2509.14294v1" target="_blank"><h2>Monitoring Machine Learning Systems: A Multivocal Literature Review</h2></a><strong><u>Authors:</u></strong>  Hira Naveed, Scott Barnett, Chetan Arora, John Grundy, Hourieh Khalajzadeh, Omar Haggag</br><strong><u>Categories:</u></strong> cs.SE, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> literature review (title, abstract)</br><p><strong><u>Abstract:</u></strong> Context: Dynamic production environments make it challenging to maintain
reliable machine learning (ML) systems. Runtime issues, such as changes in data
patterns or operating contexts, that degrade model performance are a common
occurrence in production settings. Monitoring enables early detection and
mitigation of these runtime issues, helping maintain users' trust and prevent
unwanted consequences for organizations. Aim: This study aims to provide a
comprehensive overview of the ML monitoring literature. Method: We conducted a
multivocal literature review (MLR) following the well established guidelines by
Garousi to investigate various aspects of ML monitoring approaches in 136
papers. Results: We analyzed selected studies based on four key areas: (1) the
motivations, goals, and context; (2) the monitored aspects, specific
techniques, metrics, and tools; (3) the contributions and benefits; and (4) the
current limitations. We also discuss several insights found in the studies,
their implications, and recommendations for future research and practice.
Conclusion: Our MLR identifies and summarizes ML monitoring practices and gaps,
emphasizing similarities and disconnects between formal and gray literature.
Our study is valuable for both academics and practitioners, as it helps select
appropriate solutions, highlights limitations in current approaches, and
provides future directions for research and tool development.</p></br><a href="http://arxiv.org/pdf/2509.15033v1" target="_blank"><h2>Beyond Marginals: Learning Joint Spatio-Temporal Patterns for
  Multivariate Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Padmaksha Roy, Almuatazbellah Boker, Lamine Mili</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), latent space (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> In this paper, we aim to improve multivariate anomaly detection (AD) by
modeling the \textit{time-varying non-linear spatio-temporal correlations}
found in multivariate time series data . In multivariate time series data, an
anomaly may be indicated by the simultaneous deviation of interrelated time
series from their expected collective behavior, even when no individual time
series exhibits a clearly abnormal pattern on its own. In many existing
approaches, time series variables are assumed to be (conditionally)
independent, which oversimplifies real-world interactions. Our approach
addresses this by modeling joint dependencies in the latent space and
decoupling the modeling of \textit{marginal distributions, temporal dynamics,
and inter-variable dependencies}. We use a transformer encoder to capture
temporal patterns, and to model spatial (inter-variable) dependencies, we fit a
multi-variate likelihood and a copula. The temporal and the spatial components
are trained jointly in a latent space using a self-supervised contrastive
learning objective to learn meaningful feature representations to separate
normal and anomaly samples.</p></br><a href="http://arxiv.org/pdf/2509.14423v1" target="_blank"><h2>200,000+ Deep Learning Inferred Periods of Stellar Variability from The
  All-Sky Automated Survey for Supernovae</h2></a><strong><u>Authors:</u></strong>  Meir E. Schochet, Penelope Planet, Zachary R. Claytor, Jamie Tayar, Adina D. Feinstein</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.GA, astro-ph.IM</br><strong><u>Comments:</u></strong> 27 pages, 19 figures, 5 tables. Submitted to AAS Journals</br><strong><u>Matching Keywords:</u></strong> VAE (title, abstract), convolutional (abstract)</br><p><strong><u>Abstract:</u></strong> Stars exhibit a range of variability periods that depend on their mass, age,
and evolutionary stage. For space-based photometric data, convolutional neural
networks (CNNs) have demonstrated success in recovering and measuring periodic
variability from photometric missions like Kepler and TESS. All-sky
ground-based surveys can have similar if not longer baselines than space-based
missions, however these datasets are more challenging to work with due to
irregular sampling, more complex systematics, and larger data gaps. In this
work, we demonstrate that CNNs can be used to derive variability periods from
ground-based surveys. From the All-Sky Automated Survey for Supernovae
(ASAS-SN) we recover 208,260 variability periods between 1-30 days,
approximately 60% of which are new detections. We recover periods for active
RSCVn, anomalous sub-subgiants, and cool dwarfs that are consistent with
previously measured rotation periods, while periods for stars above the Kraft
break are generally spurious. We also identify periodic signals in tens of
thousands of giants stars which correspond to frequencies of stellar
oscillations rather than rotation. Our results highlight that CNNs can be used
on sparsely sampled ground-based photometry and may prove useful for upcoming
observations from the Vera C. Rubin Observatory's Legacy Survey of Space and
Time (LSST).</p></br><a href="http://arxiv.org/pdf/2509.14863v1" target="_blank"><h2>Exploring the Global-to-Local Attention Scheme in Graph Transformers: An
  Empirical Study</h2></a><strong><u>Authors:</u></strong>  Zhengwei Wang, Gang Wu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), transformer (title, abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph Transformers (GTs) show considerable potential in graph representation
learning. The architecture of GTs typically integrates Graph Neural Networks
(GNNs) with global attention mechanisms either in parallel or as a precursor to
attention mechanisms, yielding a local-and-global or local-to-global attention
scheme. However, as the global attention mechanism primarily captures
long-range dependencies between nodes, these integration schemes may suffer
from information loss, where the local neighborhood information learned by GNN
could be diluted by the attention mechanism. Therefore, we propose G2LFormer,
featuring a novel global-to-local attention scheme where the shallow network
layers use attention mechanisms to capture global information, while the deeper
layers employ GNN modules to learn local structural information, thereby
preventing nodes from ignoring their immediate neighbors. An effective
cross-layer information fusion strategy is introduced to allow local layers to
retain beneficial information from global layers and alleviate information
loss, with acceptable trade-offs in scalability. To validate the feasibility of
the global-to-local attention scheme, we compare G2LFormer with
state-of-the-art linear GTs and GNNs on node-level and graph-level tasks. The
results indicate that G2LFormer exhibits excellent performance while keeping
linear complexity.</p></br></body>