<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 31 Jul 2025 to 04 Aug 2025</em></font><a href="http://arxiv.org/pdf/2508.00665v1" target="_blank"><h2>Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI</h2></a><strong><u>Authors:</u></strong>  Maryam Mosleh, Marie Devlin, Ellis Solaiman</br><strong><u>Categories:</u></strong> cs.AI, cs.HC, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), explainability (abstract), explainable (title, abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.</p></br><a href="http://arxiv.org/pdf/2508.00047v1" target="_blank"><h2>TriP-LLM: A Tri-Branch Patch-wise Large Language Model Framework for
  Time-Series Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Yuan-Cheng Yu, Yen-Chieh Ouyang, Chun-An Lin</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> 11 pages, 2 figures</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Time-series anomaly detection plays a central role across a wide range of
application domains. With the increasing proliferation of the Internet of
Things (IoT) and smart manufacturing, time-series data has dramatically
increased in both scale and dimensionality. This growth has exposed the
limitations of traditional statistical methods in handling the high
heterogeneity and complexity of such data. Inspired by the recent success of
large language models (LLMs) in multimodal tasks across language and vision
domains, we propose a novel unsupervised anomaly detection framework: A
Tri-Branch Patch-wise Large Language Model Framework for Time-Series Anomaly
Detection (TriP-LLM). TriP-LLM integrates local and global temporal features
through a tri-branch design-Patching, Selection, and Global-to encode the input
time series into patch-wise tokens, which are then processed by a frozen,
pretrained LLM. A lightweight patch-wise decoder reconstructs the input, from
which anomaly scores are derived. We evaluate TriP-LLM on several public
benchmark datasets using PATE, a recently proposed threshold-free evaluation
metric, and conduct all comparisons within a unified open-source framework to
ensure fairness. Experimental results show that TriP-LLM consistently
outperforms recent state-of-the-art methods across all datasets, demonstrating
strong detection capabilities. Furthermore, through extensive ablation studies,
we verify the substantial contribution of the LLM to the overall architecture.
Compared to LLM-based approaches using Channel Independence (CI) patch
processing, TriP-LLM achieves significantly lower memory consumption, making it
more suitable for GPU memory-constrained environments. All code and model
checkpoints are publicly available on https://github.com/YYZStart/TriP-LLM.git</p></br><a href="http://arxiv.org/pdf/2508.00758v1" target="_blank"><h2>Diffusion-Scheduled Denoising Autoencoders for Anomaly Detection in
  Tabular Data</h2></a><strong><u>Authors:</u></strong>  Timur Sattarov, Marco Schreyer, Damian Borth</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 22 pages, 16 figures, 7 tables, preprint version</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection in tabular data remains challenging due to complex feature
interactions and the scarcity of anomalous examples. Denoising autoencoders
rely on fixed-magnitude noise, limiting adaptability to diverse data
distributions. Diffusion models introduce scheduled noise and iterative
denoising, but lack explicit reconstruction mappings. We propose the
Diffusion-Scheduled Denoising Autoencoder (DDAE), a framework that integrates
diffusion-based noise scheduling and contrastive learning into the encoding
process to improve anomaly detection. We evaluated DDAE on 57 datasets from
ADBench. Our method outperforms in semi-supervised settings and achieves
competitive results in unsupervised settings, improving PR-AUC by up to 65%
(9%) and ROC-AUC by 16% (6%) over state-of-the-art autoencoder (diffusion)
model baselines. We observed that higher noise levels benefit unsupervised
training, while lower noise with linear scheduling is optimal in
semi-supervised settings. These findings underscore the importance of
principled noise strategies in tabular anomaly detection.</p></br><a href="http://arxiv.org/pdf/2508.00736v1" target="_blank"><h2>A normalizing flow approach for the inference of star cluster properties
  from unresolved broadband photometry I: Comparison to spectral energy
  distribution fitting</h2></a><strong><u>Authors:</u></strong>  Daniel Walter, Victor F. Ksoll, Ralf S. Klessen, Mederic Boquien, Aida Wofford, Francesco Belfiore, Daniel A. Dale, Kathryn Grasha, David A. Thilker, Leonardo Ubeda, Thomas G. Williams</br><strong><u>Categories:</u></strong> astro-ph.GA, astro-ph.IM</br><strong><u>Comments:</u></strong> 13 pages, 10 figures, submitted to A&A</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), invertible neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Estimating properties of star clusters from unresolved broadband photometry
is a challenging problem that is classically tackled by spectral energy
distribution (SED) fitting methods that are based on simple stellar population
(SSP) models. However, because of their exponential scaling, grid-based methods
suffer from computational limitations. In addition, stochastic latent variables
in the model can make the computation of the likelihood function intractable.
These limitations can be overcome by modern generative deep learning methods
that offer flexible and powerful tools for modeling high-dimensional posterior
distributions and fast inference from learned data. We present a normalizing
flow approach for the inference of cluster age, mass, and reddening from Hubble
Space Telescope (HST) broadband photometry. In particular, we explore our
network's behavior on an inference problem that has been analyzed in previous
works. We used the SED modeling code CIGALE to create a dataset of synthetic
photometric observations for $5 \times 10^6$ mock star clusters. Subsequently,
this data set was used to train a coupling-based flow in the form of a
conditional invertible neural network (cINN) to predict posterior probability
distributions for cluster age, mass, and reddening from photometric
observations. We predicted cluster parameters for the 'Physics at High Angular
resolution in Nearby GalaxieS' (PHANGS) Data Release 3 catalog. To evaluate the
capabilities of the network, we compared our results to the publicly available
PHANGS estimates and found that the estimates agree reasonably well. We
demonstrate that normalizing flow methods can be a viable tool for the
inference of cluster parameters, and argue that this approach is especially
useful when latent variables make the computation of the likelihood intractable
and in scenarios that require efficient density estimation.</p></br><a href="http://arxiv.org/pdf/2508.00507v1" target="_blank"><h2>Court of LLMs: Evidence-Augmented Generation via Multi-LLM Collaboration
  for Text-Attributed Graph Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Yiming Xu, Jiarun Chen, Zhen Peng, Zihan Chen, Qika Lin, Lan Ma, Bin Shi, Bo Dong</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Accepted by ACM Multimedia 2025 (MM '25)</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The natural combination of intricate topological structures and rich textual
information in text-attributed graphs (TAGs) opens up a novel perspective for
graph anomaly detection (GAD). However, existing GAD methods primarily focus on
designing complex optimization objectives within the graph domain, overlooking
the complementary value of the textual modality, whose features are often
encoded by shallow embedding techniques, such as bag-of-words or skip-gram, so
that semantic context related to anomalies may be missed. To unleash the
enormous potential of textual modality, large language models (LLMs) have
emerged as promising alternatives due to their strong semantic understanding
and reasoning capabilities. Nevertheless, their application to TAG anomaly
detection remains nascent, and they struggle to encode high-order structural
information inherent in graphs due to input length constraints. For
high-quality anomaly detection in TAGs, we propose CoLL, a novel framework that
combines LLMs and graph neural networks (GNNs) to leverage their complementary
strengths. CoLL employs multi-LLM collaboration for evidence-augmented
generation to capture anomaly-relevant contexts while delivering human-readable
rationales for detected anomalies. Moreover, CoLL integrates a GNN equipped
with a gating mechanism to adaptively fuse textual features with evidence while
preserving high-order topological information. Extensive experiments
demonstrate the superiority of CoLL, achieving an average improvement of 13.37%
in AP. This study opens a new avenue for incorporating LLMs in advancing GAD.</p></br><a href="http://arxiv.org/pdf/2508.00664v1" target="_blank"><h2>DP-DGAD: A Generalist Dynamic Graph Anomaly Detector with Dynamic
  Prototypes</h2></a><strong><u>Authors:</u></strong>  Jialun Zheng, Jie Liu, Jiannong Cao, Xiao Wang, Hanchen Yang, Yankai Chen, Philip S. Yu</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> Dynamic graph anomaly detection (DGAD) is essential for identifying anomalies
in evolving graphs across domains such as finance, traffic, and social
networks. Recently, generalist graph anomaly detection (GAD) models have shown
promising results. They are pretrained on multiple source datasets and
generalize across domains. While effective on static graphs, they struggle to
capture evolving anomalies in dynamic graphs. Moreover, the continuous
emergence of new domains and the lack of labeled data further challenge
generalist DGAD. Effective cross-domain DGAD requires both domain-specific and
domain-agnostic anomalous patterns. Importantly, these patterns evolve
temporally within and across domains. Building on these insights, we propose a
DGAD model with Dynamic Prototypes (DP) to capture evolving domain-specific and
domain-agnostic patterns. Firstly, DP-DGAD extracts dynamic prototypes, i.e.,
evolving representations of normal and anomalous patterns, from temporal
ego-graphs and stores them in a memory buffer. The buffer is selectively
updated to retain general, domain-agnostic patterns while incorporating new
domain-specific ones. Then, an anomaly scorer compares incoming data with
dynamic prototypes to flag both general and domain-specific anomalies. Finally,
DP-DGAD employs confidence-based pseudo-labeling for effective self-supervised
adaptation in target domains. Extensive experiments demonstrate
state-of-the-art performance across ten real-world datasets from different
domains.</p></br><a href="http://arxiv.org/pdf/2508.00513v1" target="_blank"><h2>Text-Attributed Graph Anomaly Detection via Multi-Scale Cross- and
  Uni-Modal Contrastive Learning</h2></a><strong><u>Authors:</u></strong>  Yiming Xu, Xu Hua, Zhen Peng, Bin Shi, Jiarun Chen, Xingbo Fu, Song Wang, Bo Dong</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> Accepted by ECAI 2025</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> The widespread application of graph data in various high-risk scenarios has
increased attention to graph anomaly detection (GAD). Faced with real-world
graphs that often carry node descriptions in the form of raw text sequences,
termed text-attributed graphs (TAGs), existing graph anomaly detection
pipelines typically involve shallow embedding techniques to encode such textual
information into features, and then rely on complex self-supervised tasks
within the graph domain to detect anomalies. However, this text encoding
process is separated from the anomaly detection training objective in the graph
domain, making it difficult to ensure that the extracted textual features focus
on GAD-relevant information, seriously constraining the detection capability.
How to seamlessly integrate raw text and graph topology to unleash the vast
potential of cross-modal data in TAGs for anomaly detection poses a challenging
issue. This paper presents a novel end-to-end paradigm for text-attributed
graph anomaly detection, named CMUCL. We simultaneously model data from both
text and graph structures, and jointly train text and graph encoders by
leveraging cross-modal and uni-modal multi-scale consistency to uncover
potential anomaly-related information. Accordingly, we design an anomaly score
estimator based on inconsistency mining to derive node-specific anomaly scores.
Considering the lack of benchmark datasets tailored for anomaly detection on
TAGs, we release 8 datasets to facilitate future research. Extensive
evaluations show that CMUCL significantly advances in text-attributed graph
anomaly detection, delivering an 11.13% increase in average accuracy (AP) over
the suboptimal.</p></br><a href="http://arxiv.org/pdf/2508.00580v1" target="_blank"><h2>OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on
  Planetary Rovers Using RGB, Depth, and Thermal Imagery</h2></a><strong><u>Authors:</u></strong>  Raul Castilla-Arquillo, Carlos Perez-del-Pulgar, Levin Gerdes, Alfonso Garcia-Cerezo, Miguel A. Olivares-Mendez</br><strong><u>Categories:</u></strong> cs.RO, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), multimodal (title, abstract), multimodality (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Robot navigation in unstructured environments requires multimodal perception
systems that can support safe navigation. Multimodality enables the integration
of complementary information collected by different sensors. However, this
information must be processed by machine learning algorithms specifically
designed to leverage heterogeneous data. Furthermore, it is necessary to
identify which sensor modalities are most informative for navigation in the
target environment. In Martian exploration, thermal imagery has proven valuable
for assessing terrain safety due to differences in thermal behaviour between
soil types. This work presents OmniUnet, a transformer-based neural network
architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T)
imagery. A custom multimodal sensor housing was developed using 3D printing and
mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a
multimodal dataset in the Bardenas semi-desert in northern Spain. This location
serves as a representative environment of the Martian surface, featuring
terrain types such as sand, bedrock, and compact soil. A subset of this dataset
was manually labeled to support supervised training of the network. The model
was evaluated both quantitatively and qualitatively, achieving a pixel accuracy
of 80.37% and demonstrating strong performance in segmenting complex
unstructured terrain. Inference tests yielded an average prediction time of 673
ms on a resource-constrained computer (Jetson Orin Nano), confirming its
suitability for on-robot deployment. The software implementation of the network
and the labeled dataset have been made publicly available to support future
research in multimodal terrain perception for planetary robotics.</p></br><a href="http://arxiv.org/pdf/2508.00037v1" target="_blank"><h2>Predicting Large-scale Urban Network Dynamics with Energy-informed Graph
  Neural Diffusion</h2></a><strong><u>Authors:</u></strong>  Tong Nie, Jian Sun, Wei Ma</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Accepted at IEEE Transactions on Industrial Informatics</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), neural network (abstract), transformer (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Networked urban systems facilitate the flow of people, resources, and
services, and are essential for economic and social interactions. These systems
often involve complex processes with unknown governing rules, observed by
sensor-based time series. To aid decision-making in industrial and engineering
contexts, data-driven predictive models are used to forecast spatiotemporal
dynamics of urban systems. Current models such as graph neural networks have
shown promise but face a trade-off between efficacy and efficiency due to
computational demands. Hence, their applications in large-scale networks still
require further efforts. This paper addresses this trade-off challenge by
drawing inspiration from physical laws to inform essential model designs that
align with fundamental principles and avoid architectural redundancy. By
understanding both micro- and macro-processes, we present a principled
interpretable neural diffusion scheme based on Transformer-like structures
whose attention layers are induced by low-dimensional embeddings. The proposed
scalable spatiotemporal Transformer (ScaleSTF), with linear complexity, is
validated on large-scale urban systems including traffic flow, solar power, and
smart meters, showing state-of-the-art performance and remarkable scalability.
Our results constitute a fresh perspective on the dynamics prediction in
large-scale urban networks.</p></br><a href="http://arxiv.org/pdf/2508.00415v1" target="_blank"><h2>Transforming Credit Risk Analysis: A Time-Series-Driven ResE-BiLSTM
  Framework for Post-Loan Default Detection</h2></a><strong><u>Authors:</u></strong>  Yue Yang, Yuxiang Lin, Ying Zhang, Zihan Su, Chang Chuan Goh, Tangtangfang Fang, Anthony Graham Bellotti, Boon Giin Lee</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Prediction of post-loan default is an important task in credit risk
management, and can be addressed by detection of financial anomalies using
machine learning. This study introduces a ResE-BiLSTM model, using a sliding
window technique, and is evaluated on 44 independent cohorts from the extensive
Freddie Mac US mortgage dataset, to improve prediction performance. The
ResE-BiLSTM is compared with five baseline models: Long Short-Term Memory
(LSTM), BiLSTM, Gated Recurrent Units (GRU), Convolutional Neural Networks
(CNN), and Recurrent Neural Networks (RNN), across multiple metrics, including
Accuracy, Precision, Recall, F1, and AUC. An ablation study was conducted to
evaluate the contribution of individual components in the ResE-BiLSTM
architecture. Additionally, SHAP analysis was employed to interpret the
underlying features the model relied upon for its predictions. Experimental
results demonstrate that ResE-BiLSTM achieves superior predictive performance
compared to baseline models, underscoring its practical value and applicability
in real-world scenarios.</p></br><a href="http://arxiv.org/pdf/2508.00615v1" target="_blank"><h2>Similarity-Based Self-Construct Graph Model for Predicting Patient
  Criticalness Using Graph Neural Networks and EHR Data</h2></a><strong><u>Authors:</u></strong>  Mukesh Kumar Sahu, Pinki Roy</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (title), multi-modal (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Accurately predicting the criticalness of ICU patients (such as in-ICU
mortality risk) is vital for early intervention in critical care. However,
conventional models often treat each patient in isolation and struggle to
exploit the relational structure in Electronic Health Records (EHR). We propose
a Similarity-Based Self-Construct Graph Model (SBSCGM) that dynamically builds
a patient similarity graph from multi-modal EHR data, and a HybridGraphMedGNN
architecture that operates on this graph to predict patient mortality and a
continuous criticalness score. SBSCGM uses a hybrid similarity measure
(combining feature-based and structural similarities) to connect patients with
analogous clinical profiles in real-time. The HybridGraphMedGNN integrates
Graph Convolutional Network (GCN), GraphSAGE, and Graph Attention Network (GAT)
layers to learn robust patient representations, leveraging both local and
global graph patterns. In experiments on 6,000 ICU stays from the MIMIC-III
dataset, our model achieves state-of-the-art performance (AUC-ROC $0.94$)
outperforming baseline classifiers and single-type GNN models. We also
demonstrate improved precision/recall and show that the attention mechanism
provides interpretable insights into model predictions. Our framework offers a
scalable and interpretable solution for critical care risk prediction, with
potential to support clinicians in real-world ICU deployment.</p></br><a href="http://arxiv.org/pdf/2508.00381v1" target="_blank"><h2>Advancing Welding Defect Detection in Maritime Operations via
  Adapt-WeldNet and Defect Detection Interpretability Analysis</h2></a><strong><u>Authors:</u></strong>  Kamal Basha S, Athira Nambiar</br><strong><u>Categories:</u></strong> cs.CV, cs.AI, cs.CE, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (abstract), neural network (abstract), transfer learning (abstract)</br><p><strong><u>Abstract:</u></strong> Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.</p></br><a href="http://arxiv.org/pdf/2508.00120v1" target="_blank"><h2>AdapDISCOM: An Adaptive Sparse Regression Method for High-Dimensional
  Multimodal Data With Block-Wise Missingness and Measurement Errors</h2></a><strong><u>Authors:</u></strong>  Abdoul O. Diakité, Claudia Moreau, Gleb Bezgin, Nikhil Bhagwat, Pedro Rosa-Neto, Jean-Baptiste Poline, Simon Girard, Amadou Barry, for the Alzheimers Disease Neuroimaging Initiative</br><strong><u>Categories:</u></strong> stat.ME, stat.ML</br><strong><u>Comments:</u></strong> 49 pages, 4 figures</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal high-dimensional data are increasingly prevalent in biomedical
research, yet they are often compromised by block-wise missingness and
measurement errors, posing significant challenges for statistical inference and
prediction. We propose AdapDISCOM, a novel adaptive direct sparse regression
method that simultaneously addresses these two pervasive issues. Building on
the DISCOM framework, AdapDISCOM introduces modality-specific weighting schemes
to account for heterogeneity in data structures and error magnitudes across
modalities. We establish the theoretical properties of AdapDISCOM, including
model selection consistency and convergence rates under sub-Gaussian and
heavy-tailed settings, and develop robust and computationally efficient
variants (AdapDISCOM-Huber and Fast-AdapDISCOM). Extensive simulations
demonstrate that AdapDISCOM consistently outperforms existing methods such as
DISCOM, SCOM, and CoCoLasso, particularly under heterogeneous contamination and
heavy-tailed distributions. Finally, we apply AdapDISCOM to Alzheimers Disease
Neuroimaging Initiative (ADNI) data, demonstrating improved prediction of
cognitive scores and reliable selection of established biomarkers, even with
substantial missingness and measurement errors. AdapDISCOM provides a flexible,
robust, and scalable framework for high-dimensional multimodal data analysis
under realistic data imperfections.</p></br><a href="http://arxiv.org/pdf/2508.00141v1" target="_blank"><h2>INSPIRE-GNN: Intelligent Sensor Placement to Improve Sparse Bicycling
  Network Prediction via Reinforcement Learning Boosted Graph Neural Networks</h2></a><strong><u>Authors:</u></strong>  Mohit Gupta, Debjit Bhowmick, Rhys Newbury, Meead Saberi, Shirui Pan, Ben Beck</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), convolutional (abstract), neural network (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Accurate link-level bicycling volume estimation is essential for sustainable
urban transportation planning. However, many cities face significant challenges
of high data sparsity due to limited bicycling count sensor coverage. To
address this issue, we propose INSPIRE-GNN, a novel Reinforcement Learning
(RL)-boosted hybrid Graph Neural Network (GNN) framework designed to optimize
sensor placement and improve link-level bicycling volume estimation in
data-sparse environments. INSPIRE-GNN integrates Graph Convolutional Networks
(GCN) and Graph Attention Networks (GAT) with a Deep Q-Network (DQN)-based RL
agent, enabling a data-driven strategic selection of sensor locations to
maximize estimation performance. Applied to Melbourne's bicycling network,
comprising 15,933 road segments with sensor coverage on only 141 road segments
(99% sparsity) - INSPIRE-GNN demonstrates significant improvements in volume
estimation by strategically selecting additional sensor locations in
deployments of 50, 100, 200 and 500 sensors. Our framework outperforms
traditional heuristic methods for sensor placement such as betweenness
centrality, closeness centrality, observed bicycling activity and random
placement, across key metrics such as Mean Squared Error (MSE), Root Mean
Squared Error (RMSE) and Mean Absolute Error (MAE). Furthermore, our
experiments benchmark INSPIRE-GNN against standard machine learning and deep
learning models in the bicycle volume estimation performance, underscoring its
effectiveness. Our proposed framework provides transport planners actionable
insights to effectively expand sensor networks, optimize sensor placement and
maximize volume estimation accuracy and reliability of bicycling data for
informed transportation planning decisions.</p></br><a href="http://arxiv.org/pdf/2508.00785v1" target="_blank"><h2>Explainable AI and Machine Learning for Exam-based Student Evaluation:
  Causal and Predictive Analysis of Socio-academic and Economic Factors</h2></a><strong><u>Authors:</u></strong>  Bushra Akter, Md Biplob Hosen, Sabbir Ahmed, Mehrin Anannya, Md. Farhad Hossain</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> Academic performance depends on a multivariable nexus of socio-academic and
financial factors. This study investigates these influences to develop
effective strategies for optimizing students' CGPA. To achieve this, we
reviewed various literature to identify key influencing factors and constructed
an initial hypothetical causal graph based on the findings. Additionally, an
online survey was conducted, where 1,050 students participated, providing
comprehensive data for analysis. Rigorous data preprocessing techniques,
including cleaning and visualization, ensured data quality before analysis.
Causal analysis validated the relationships among variables, offering deeper
insights into their direct and indirect effects on CGPA. Regression models were
implemented for CGPA prediction, while classification models categorized
students based on performance levels. Ridge Regression demonstrated strong
predictive accuracy, achieving a Mean Absolute Error of 0.12 and a Mean Squared
Error of 0.023. Random Forest outperformed in classification, attaining an
F1-score near perfection and an accuracy of 98.68%. Explainable AI techniques
such as SHAP, LIME, and Interpret enhanced model interpretability, highlighting
critical factors such as study hours, scholarships, parental education, and
prior academic performance. The study culminated in the development of a
web-based application that provides students with personalized insights,
allowing them to predict academic performance, identify areas for improvement,
and make informed decisions to enhance their outcomes.</p></br><a href="http://arxiv.org/pdf/2508.00760v1" target="_blank"><h2>MMBERT: Scaled Mixture-of-Experts Multimodal BERT for Robust Chinese
  Hate Speech Detection under Cloaking Perturbations</h2></a><strong><u>Authors:</u></strong>  Qiyao Xue, Yuchen Dou, Ryan Shi, Xiang Lorraine Li, Wei Gao</br><strong><u>Categories:</u></strong> cs.CL, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Hate speech detection on Chinese social networks presents distinct
challenges, particularly due to the widespread use of cloaking techniques
designed to evade conventional text-based detection systems. Although large
language models (LLMs) have recently improved hate speech detection
capabilities, the majority of existing work has concentrated on English
datasets, with limited attention given to multimodal strategies in the Chinese
context. In this study, we propose MMBERT, a novel BERT-based multimodal
framework that integrates textual, speech, and visual modalities through a
Mixture-of-Experts (MoE) architecture. To address the instability associated
with directly integrating MoE into BERT-based models, we develop a progressive
three-stage training paradigm. MMBERT incorporates modality-specific experts, a
shared self-attention mechanism, and a router-based expert allocation strategy
to enhance robustness against adversarial perturbations. Empirical results in
several Chinese hate speech datasets show that MMBERT significantly surpasses
fine-tuned BERT-based encoder models, fine-tuned LLMs, and LLMs utilizing
in-context learning approaches.</p></br><a href="http://arxiv.org/pdf/2507.23768v1" target="_blank"><h2>Formal Bayesian Transfer Learning via the Total Risk Prior</h2></a><strong><u>Authors:</u></strong>  Nathan Wycoff, Ali Arab, Lisa O. Singh</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transfer learning (title, abstract)</br><p><strong><u>Abstract:</u></strong> In analyses with severe data-limitations, augmenting the target dataset with
information from ancillary datasets in the application domain, called source
datasets, can lead to significantly improved statistical procedures. However,
existing methods for this transfer learning struggle to deal with situations
where the source datasets are also limited and not guaranteed to be
well-aligned with the target dataset. A typical strategy is to use the
empirical loss minimizer on the source data as a prior mean for the target
parameters, which places the estimation of source parameters outside of the
Bayesian formalism. Our key conceptual contribution is to use a risk minimizer
conditional on source parameters instead. This allows us to construct a single
joint prior distribution for all parameters from the source datasets as well as
the target dataset. As a consequence, we benefit from full Bayesian uncertainty
quantification and can perform model averaging via Gibbs sampling over
indicator variables governing the inclusion of each source dataset. We show how
a particular instantiation of our prior leads to a Bayesian Lasso in a
transformed coordinate system and discuss computational techniques to scale our
approach to moderately sized datasets. We also demonstrate that recently
proposed minimax-frequentist transfer learning techniques may be viewed as an
approximate Maximum a Posteriori approach to our model. Finally, we demonstrate
superior predictive performance relative to the frequentist baseline on a
genetics application, especially when the source data are limited.</p></br><a href="http://arxiv.org/pdf/2508.00286v1" target="_blank"><h2>Toward using explainable data-driven surrogate models for treating
  performance-based seismic design as an inverse engineering problem</h2></a><strong><u>Authors:</u></strong>  Mohsen Zaker Esteghamati</br><strong><u>Categories:</u></strong> cs.LG, stat.AP, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (title), explainable (title, abstract)</br><p><strong><u>Abstract:</u></strong> This study presents a methodology to treat performance-based seismic design
as an inverse engineering problem, where design parameters are directly derived
to achieve specific performance objectives. By implementing explainable machine
learning models, this methodology directly maps design variables and
performance metrics, tackling computational inefficiencies of performance-based
design. The resultant machine learning model is integrated as an evaluation
function into a genetic optimization algorithm to solve the inverse problem.
The developed methodology is then applied to two different inventories of steel
and concrete moment frames in Los Angeles and Charleston to obtain sectional
properties of frame members that minimize expected annualized seismic loss in
terms of repair costs. The results show high accuracy of the surrogate models
(e.g., R2> 90%) across a diverse set of building types, geometries, seismic
design, and site hazard, where the optimization algorithm could identify the
optimum values of members' properties for a fixed set of geometric variables,
consistent with engineering principles.</p></br><a href="http://arxiv.org/pdf/2508.00040v1" target="_blank"><h2>Regime-Aware Conditional Neural Processes with Multi-Criteria Decision
  Support for Operational Electricity Price Forecasting</h2></a><strong><u>Authors:</u></strong>  Abhinav Das, Stephan Schlüter</br><strong><u>Categories:</u></strong> cs.LG, math.PR, stat.AP, stat.ML, 60J20, 68T07</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> This work integrates Bayesian regime detection with conditional neural
processes for 24-hour electricity price prediction in the German market. Our
methodology integrates regime detection using a disentangled sticky
hierarchical Dirichlet process hidden Markov model (DS-HDP-HMM) applied to
daily electricity prices. Each identified regime is subsequently modeled by an
independent conditional neural process (CNP), trained to learn localized
mappings from input contexts to 24-dimensional hourly price trajectories, with
final predictions computed as regime-weighted mixtures of these CNP outputs. We
rigorously evaluate R-NP against deep neural networks (DNN) and Lasso estimated
auto-regressive (LEAR) models by integrating their forecasts into diverse
battery storage optimization frameworks, including price arbitrage, risk
management, grid services, and cost minimization. This operational utility
assessment revealed complex performance trade-offs: LEAR often yielded superior
absolute profits or lower costs, while DNN showed exceptional optimality in
specific cost-minimization contexts. Recognizing that raw prediction accuracy
doesn't always translate to optimal operational outcomes, we employed TOPSIS as
a comprehensive multi-criteria evaluation layer. Our TOPSIS analysis identified
LEAR as the top-ranked model for 2021, but crucially, our proposed R-NP model
emerged as the most balanced and preferred solution for 2021, 2022 and 2023.</p></br><a href="http://arxiv.org/pdf/2507.23632v1" target="_blank"><h2>On the Expressiveness of Softmax Attention: A Recurrent Neural Network
  Perspective</h2></a><strong><u>Authors:</u></strong>  Gabriel Mongaras, Eric C. Larson</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transformer (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Since its introduction, softmax attention has become the backbone of modern
transformer architectures due to its expressiveness and scalability across a
wide range of tasks. However, the main drawback of softmax attention is the
quadratic memory requirement and computational complexity with respect to the
sequence length. By replacing the softmax nonlinearity, linear attention and
similar methods have been introduced to avoid the quadratic bottleneck of
softmax attention. Despite these linear forms of attention being derived from
the original softmax formulation, they typically lag in terms of downstream
accuracy. While strong intuition of the softmax nonlinearity on the query and
key inner product suggests that it has desirable properties compared to other
nonlinearities, the question of why this discrepancy exists still remains
unanswered. This work demonstrates that linear attention is an approximation of
softmax attention by deriving the recurrent form of softmax attention. Using
this form, each part of softmax attention can be described in the language of
recurrent neural networks (RNNs). Describing softmax attention as an RNN allows
for the ablation of the components of softmax attention to understand the
importance of each part and how they interact. In this way, our work helps
explain why softmax attention is more expressive than its counterparts.</p></br><a href="http://arxiv.org/pdf/2508.00576v1" target="_blank"><h2>MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal
  Interactions in Multimodal AI Models</h2></a><strong><u>Authors:</u></strong>  Zhanliang Wang, Kai Wang</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.</p></br><a href="http://arxiv.org/pdf/2508.00716v1" target="_blank"><h2>Nested Graph Pseudo-Label Refinement for Noisy Label Domain Adaptation
  Learning</h2></a><strong><u>Authors:</u></strong>  Yingxu Wang, Mengzhu Wang, Zhichao Huang, Suyu Liu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> domain adaptation (title, abstract)</br><p><strong><u>Abstract:</u></strong> Graph Domain Adaptation (GDA) facilitates knowledge transfer from labeled
source graphs to unlabeled target graphs by learning domain-invariant
representations, which is essential in applications such as molecular property
prediction and social network analysis. However, most existing GDA methods rely
on the assumption of clean source labels, which rarely holds in real-world
scenarios where annotation noise is pervasive. This label noise severely
impairs feature alignment and degrades adaptation performance under domain
shifts. To address this challenge, we propose Nested Graph Pseudo-Label
Refinement (NeGPR), a novel framework tailored for graph-level domain
adaptation with noisy labels. NeGPR first pretrains dual branches, i.e.,
semantic and topology branches, by enforcing neighborhood consistency in the
feature space, thereby reducing the influence of noisy supervision. To bridge
domain gaps, NeGPR employs a nested refinement mechanism in which one branch
selects high-confidence target samples to guide the adaptation of the other,
enabling progressive cross-domain learning. Furthermore, since pseudo-labels
may still contain noise and the pre-trained branches are already overfitted to
the noisy labels in the source domain, NeGPR incorporates a noise-aware
regularization strategy. This regularization is theoretically proven to
mitigate the adverse effects of pseudo-label noise, even under the presence of
source overfitting, thus enhancing the robustness of the adaptation process.
Extensive experiments on benchmark datasets demonstrate that NeGPR consistently
outperforms state-of-the-art methods under severe label noise, achieving gains
of up to 12.7% in accuracy.</p></br><a href="http://arxiv.org/pdf/2507.23449v1" target="_blank"><h2>Manifold-regularised Signature Kernel Large-Margin $\ell_p$-SVDD for
  Multidimensional Time Series Anomaly Detection</h2></a><strong><u>Authors:</u></strong>  Shervin Rahimzadeh Arashloo</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> We generalise the recently introduced large-margin $\ell_p$-SVDD approach to
exploit the geometry of data distribution via manifold regularising and a
signature kernel representation for time series anomaly detection.
Specifically, we formulate a manifold-regularised variant of the $\ell_p$-SVDD
method to encourage label smoothness on the underlying manifold to capture
structural information for improved detection performance. Drawing on an
existing Representer theorem, we then provide an effective optimisation
technique for the proposed method and show that it can benefit from the
signature kernel to capture time series complexities for anomaly detection.
  We theoretically study the proposed approach using Rademacher complexities to
analyse its generalisation performance and also provide an experimental
assessment of the proposed method across various data sets to compare its
performance against other methods.</p></br><a href="http://arxiv.org/pdf/2507.23676v1" target="_blank"><h2>DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for
  Microbiome Data</h2></a><strong><u>Authors:</u></strong>  Rabeya Tus Sadia, Qiang Cheng</br><strong><u>Categories:</u></strong> cs.LG, cs.CV</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> VAE (abstract), multimodal (title), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> Microbiome data analysis is essential for understanding host health and
disease, yet its inherent sparsity and noise pose major challenges for accurate
imputation, hindering downstream tasks such as biomarker discovery. Existing
imputation methods, including recent diffusion-based models, often fail to
capture the complex interdependencies between microbial taxa and overlook
contextual metadata that can inform imputation. We introduce DepMicroDiff, a
novel framework that combines diffusion-based generative modeling with a
Dependency-Aware Transformer (DAT) to explicitly capture both mutual pairwise
dependencies and autoregressive relationships. DepMicroDiff is further enhanced
by VAE-based pretraining across diverse cancer datasets and conditioning on
patient metadata encoded via a large language model (LLM). Experiments on TCGA
microbiome datasets show that DepMicroDiff substantially outperforms
state-of-the-art baselines, achieving higher Pearson correlation (up to 0.712),
cosine similarity (up to 0.812), and lower RMSE and MAE across multiple cancer
types, demonstrating its robustness and generalizability for microbiome
imputation.</p></br><a href="http://arxiv.org/pdf/2508.00754v1" target="_blank"><h2>A Simple and Effective Method for Uncertainty Quantification and OOD
  Detection</h2></a><strong><u>Authors:</u></strong>  Yaxin Ma, Benjamin Colburn, Jose C. Principe</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Bayesian neural networks and deep ensemble methods have been proposed for
uncertainty quantification; however, they are computationally intensive and
require large storage. By utilizing a single deterministic model, we can solve
the above issue. We propose an effective method based on feature space density
to quantify uncertainty for distributional shifts and out-of-distribution (OOD)
detection. Specifically, we leverage the information potential field derived
from kernel density estimation to approximate the feature space density of the
training set. By comparing this density with the feature space representation
of test samples, we can effectively determine whether a distributional shift
has occurred. Experiments were conducted on a 2D synthetic dataset (Two Moons
and Three Spirals) as well as an OOD detection task (CIFAR-10 vs. SVHN). The
results demonstrate that our method outperforms baseline models.</p></br><a href="http://arxiv.org/pdf/2508.00658v1" target="_blank"><h2>Multi-Band Variable-Lag Granger Causality: A Unified Framework for
  Causal Time Series Inference across Frequencies</h2></a><strong><u>Authors:</u></strong>  Chakattrai Sookkongwaree, Tattep Lakmuang, Chainarong Amornbunchornvej</br><strong><u>Categories:</u></strong> cs.AI, cs.LG, econ.EM, stat.ME</br><strong><u>Comments:</u></strong> First draft</br><strong><u>Matching Keywords:</u></strong> causality (title, abstract)</br><p><strong><u>Abstract:</u></strong> Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.</p></br><a href="http://arxiv.org/pdf/2508.00071v1" target="_blank"><h2>Exploration of groups and outliers in Gaia RVS stellar spectra with
  metric learning</h2></a><strong><u>Authors:</u></strong>  Yarden Eilat Bloch, Dovi Poznanski, Nick L. J. Cox, Emmanuel Bernhard, Iain McDonald, Manuela Rauch, Albert Zijlstra</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.IM</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), dimensionality reduction (abstract)</br><p><strong><u>Abstract:</u></strong> The Gaia mission is transforming our view of the Milky Way by providing
distances towards a billion stars, and much more. The third data release
includes nearly a million spectra from its Radial Velocity Spectrometer (RVS).
Identifying unexpected features in such vast datasets presents a significant
challenge. It is impossible to visually inspect all of the spectra and
difficult to analyze them in a comprehensive way. In order to supplement
traditional analysis approaches, and in order to facilitate deeper insights
from these spectra, we present a new dataset together with an interactive
portal that applies established self-supervised metric learning techniques,
dimensionality reduction, and anomaly detection, to allow researchers to
visualize, analyze, and interact with the Gaia RVS spectra in straightforward
but under-utilized manner. We demonstrate a few example interactions with the
dataset, examining groupings and the most unusual RVS spectra, according to our
metric. This combination of methodology and public availability enables broader
exploration, and may reveal yet-to-be-discovered stellar phenomena.</p></br><a href="http://arxiv.org/pdf/2507.23536v1" target="_blank"><h2>From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices</h2></a><strong><u>Authors:</u></strong>  Georg Slamanig, Francesco Corti, Olga Saukh</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Parameter-efficient fine-tuning (PEFT) methods reduce the computational costs
of updating deep learning models by minimizing the number of additional
parameters used to adapt a model to a down- stream task. While extensively
researched in large language models (LLMs), their application to smaller models
used on edge devices, such as convolutional neural networks, remains
underexplored. This paper benchmarks and analyzes popular PEFT methods on
convolutional architectures typically deployed in resource-constrained edge
environments. We evaluate LoRA, DoRA, and GaLore for updating standard and
depthwise convolutional architectures to handle distribution shifts and
accommodate unseen classes. We utilize recently proposed PyTorch profilers to
compare the updated model performance and computational costs of these PEFT
methods with traditional fine-tuning approaches. With resource efficiency in
mind, we investigate their update behavior across different rank dimensions. We
find that the evaluated PEFT methods are only half as memory-efficient when
applied to depthwise-separable convolution architectures, compared to their
efficiency with LLMs. Conversely, when targeting convolu- tional architectures
optimized for edge deployment, adapter-based PEFT methods can reduce floating
point operations (FLOPs) during model updates by up to 95%. These insights
offer valuable guidance for selecting PEFT methods based on hardware
constraints, performance requirements, and application needs. Our code is
online.</p></br><a href="http://arxiv.org/pdf/2508.00098v1" target="_blank"><h2>Stress-Aware Resilient Neural Training</h2></a><strong><u>Authors:</u></strong>  Ashkan Shakarami, Yousef Yeganeh, Azade Farshad, Lorenzo Nicole, Stefano Ghidoni, Nassir Navab</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV</br><strong><u>Comments:</u></strong> 16 pages, 11 figures</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> This paper introduces Stress-Aware Learning, a resilient neural training
paradigm in which deep neural networks dynamically adjust their optimization
behavior - whether under stable training regimes or in settings with uncertain
dynamics - based on the concept of Temporary (Elastic) and Permanent (Plastic)
Deformation, inspired by structural fatigue in materials science. To
instantiate this concept, we propose Plastic Deformation Optimizer, a
stress-aware mechanism that injects adaptive noise into model parameters
whenever an internal stress signal - reflecting stagnation in training loss and
accuracy - indicates persistent optimization difficulty. This enables the model
to escape sharp minima and converge toward flatter, more generalizable regions
of the loss landscape. Experiments across six architectures, four optimizers,
and seven vision benchmarks demonstrate improved robustness and generalization
with minimal computational overhead. The code and 3D visuals will be available
on GitHub: https://github.com/Stress-Aware-Learning/SAL.</p></br><a href="http://arxiv.org/pdf/2507.23217v1" target="_blank"><h2>Zero-Shot Document Understanding using Pseudo Table of Contents-Guided
  Retrieval-Augmented Generation</h2></a><strong><u>Authors:</u></strong>  Hyeon Seong Jeong, Sangwoo Jo, Byeong Hyun Yoon, Yoonseok Heo, Haedong Jeong, Taehoon Kim</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Understanding complex multimodal documents remains challenging due to their
structural inconsistencies and limited training data availability. We introduce
\textit{DocsRay}, a training-free document understanding system that integrates
pseudo Table of Contents (TOC) generation with hierarchical Retrieval-Augmented
Generation (RAG). Our approach leverages multimodal Large Language Models'
(LLMs) native capabilities to seamlessly process documents containing diverse
elements such as text, images, charts, and tables without requiring specialized
models or additional training. DocsRay's framework synergistically combines
three key techniques: (1) a semantic structuring module using prompt-based LLM
interactions to generate a hierarchical pseudo-TOC, (2) zero-shot multimodal
analysis that converts diverse document elements into unified, text-centric
representations using the inherent capabilities of multimodal LLMs, and (3) an
efficient two-stage hierarchical retrieval system that reduces retrieval
complexity from $O(N)$ to $O(S + k_1 \cdot N_s)$. Evaluated on documents
averaging 49.4 pages and 20,971 textual tokens, DocsRay reduced query latency
from 3.89 to 2.12 seconds, achieving a 45% efficiency improvement. On the
MMLongBench-Doc benchmark, DocsRay-Pro attains an accuracy of 64.7%,
substantially surpassing previous state-of-the-art results.</p></br><a href="http://arxiv.org/pdf/2507.23638v1" target="_blank"><h2>OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature
  Gradient Analysis and Reinforcement Learning-Based Trust Weighting</h2></a><strong><u>Authors:</u></strong>  Mohammad Karami, Fatemeh Ghassemi, Hamed Kebriaei, Hamid Azadegan</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> VAE (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Federated Learning (FL) enables collaborative model training across
distributed medical institutions while preserving patient privacy, but remains
vulnerable to Byzantine attacks and statistical heterogeneity. We present
OptiGradTrust, a comprehensive defense framework that evaluates gradient
updates through a novel six-dimensional fingerprint including VAE
reconstruction error, cosine similarity metrics, $L_2$ norm, sign-consistency
ratio, and Monte Carlo Shapley value, which drive a hybrid RL-attention module
for adaptive trust scoring. To address convergence challenges under data
heterogeneity, we develop FedBN-Prox (FedBN-P), combining Federated Batch
Normalization with proximal regularization for optimal accuracy-convergence
trade-offs. Extensive evaluation across MNIST, CIFAR-10, and Alzheimer's MRI
datasets under various Byzantine attack scenarios demonstrates significant
improvements over state-of-the-art defenses, achieving up to +1.6 percentage
points over FLGuard under non-IID conditions while maintaining robust
performance against diverse attack patterns through our adaptive learning
approach.</p></br><a href="http://arxiv.org/pdf/2508.00674v1" target="_blank"><h2>Context-Aware Visualization for Explainable AI Recommendations in Social
  Media: A Vision for User-Aligned Explanations</h2></a><strong><u>Authors:</u></strong>  Banan Alkhateeb, Ellis Solaiman</br><strong><u>Categories:</u></strong> cs.AI, cs.HC, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (abstract), explainable (title)</br><p><strong><u>Abstract:</u></strong> Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.</p></br><a href="http://arxiv.org/pdf/2508.00039v1" target="_blank"><h2>Hybrid LSTM-Transformer Models for Profiling Highway-Railway Grade
  Crossings</h2></a><strong><u>Authors:</u></strong>  Kaustav Chatterjee, Joshua Q. Li, Fatemeh Ansari, Masud Rana Munna, Kundan Parajulee, Jared Schwennesen</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)</br><p><strong><u>Abstract:</u></strong> Hump crossings, or high-profile Highway Railway Grade Crossings (HRGCs), pose
safety risks to highway vehicles due to potential hang-ups. These crossings
typically result from post-construction railway track maintenance activities or
non-compliance with design guidelines for HRGC vertical alignments.
Conventional methods for measuring HRGC profiles are costly, time-consuming,
traffic-disruptive, and present safety challenges. To address these issues,
this research employed advanced, cost-effective techniques and innovative
modeling approaches for HRGC profile measurement. A novel hybrid deep learning
framework combining Long Short-Term Memory (LSTM) and Transformer architectures
was developed by utilizing instrumentation and ground truth data.
Instrumentation data were gathered using a highway testing vehicle equipped
with Inertial Measurement Unit (IMU) and Global Positioning System (GPS)
sensors, while ground truth data were obtained via an industrial-standard
walking profiler. Field data was collected at the Red Rock Railroad Corridor in
Oklahoma. Three advanced deep learning models Transformer-LSTM sequential
(model 1), LSTM-Transformer sequential (model 2), and LSTM-Transformer parallel
(model 3) were evaluated to identify the most efficient architecture. Models 2
and 3 outperformed the others and were deployed to generate 2D/3D HRGC
profiles. The deep learning models demonstrated significant potential to
enhance highway and railroad safety by enabling rapid and accurate assessment
of HRGC hang-up susceptibility.</p></br><a href="http://arxiv.org/pdf/2507.23559v1" target="_blank"><h2>Barycentric subspace analysis of network-valued data</h2></a><strong><u>Authors:</u></strong>  Elodie Maignant, Xavier Pennec, Alain Trouvé, Anna Calissano</br><strong><u>Categories:</u></strong> math.DG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> dimensionality reduction (abstract)</br><p><strong><u>Abstract:</u></strong> Certain data are naturally modeled by networks or weighted graphs, be they
arterial networks or mobility networks. When there is no canonical labeling of
the nodes across the dataset, we talk about unlabeled networks. In this paper,
we focus on the question of dimensionality reduction for this type of data.
More specifically, we address the issue of interpreting the feature subspace
constructed by dimensionality reduction methods. Most existing methods for
network-valued data are derived from principal component analysis (PCA) and
therefore rely on subspaces generated by a set of vectors, which we identify as
a major limitation in terms of interpretability. Instead, we propose to
implement the method called barycentric subspace analysis (BSA), which relies
on subspaces generated by a set of points. In order to provide a
computationally feasible framework for BSA, we introduce a novel embedding for
unlabeled networks where we replace their usual representation by equivalence
classes of isomorphic networks with that by equivalence classes of cospectral
networks. We then illustrate BSA on simulated and real-world datasets, and
compare it to tangent PCA.</p></br><a href="http://arxiv.org/pdf/2507.23501v1" target="_blank"><h2>Directional Ensemble Aggregation for Actor-Critics</h2></a><strong><u>Authors:</u></strong>  Nicklas Werge, Yi-Shan Wu, Bahareh Tasdighi, Melih Kandemir</br><strong><u>Categories:</u></strong> cs.LG, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)</br><p><strong><u>Abstract:</u></strong> Off-policy reinforcement learning in continuous control tasks depends
critically on accurate $Q$-value estimates. Conservative aggregation over
ensembles, such as taking the minimum, is commonly used to mitigate
overestimation bias. However, these static rules are coarse, discard valuable
information from the ensemble, and cannot adapt to task-specific needs or
different learning regimes. We propose Directional Ensemble Aggregation (DEA),
an aggregation method that adaptively combines $Q$-value estimates in
actor-critic frameworks. DEA introduces two fully learnable directional
parameters: one that modulates critic-side conservatism and another that guides
actor-side policy exploration. Both parameters are learned using ensemble
disagreement-weighted Bellman errors, which weight each sample solely by the
direction of its Bellman error. This directional learning mechanism allows DEA
to adjust conservatism and exploration in a data-driven way, adapting
aggregation to both uncertainty levels and the phase of training. We evaluate
DEA across continuous control benchmarks and learning regimes - from
interactive to sample-efficient - and demonstrate its effectiveness over static
ensemble strategies.</p></br><a href="http://arxiv.org/pdf/2507.23535v1" target="_blank"><h2>Transparent AI: The Case for Interpretability and Explainability</h2></a><strong><u>Authors:</u></strong>  Dhanesh Ramachandram, Himanshu Joshi, Judy Zhu, Dhari Gandhi, Lucas Hartman, Ananya Raval</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CY</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> explainability (title)</br><p><strong><u>Abstract:</u></strong> As artificial intelligence systems increasingly inform high-stakes decisions
across sectors, transparency has become foundational to responsible and
trustworthy AI implementation. Leveraging our role as a leading institute in
advancing AI research and enabling industry adoption, we present key insights
and lessons learned from practical interpretability applications across diverse
domains. This paper offers actionable strategies and implementation guidance
tailored to organizations at varying stages of AI maturity, emphasizing the
integration of interpretability as a core design principle rather than a
retrospective add-on.</p></br><a href="http://arxiv.org/pdf/2508.00247v1" target="_blank"><h2>Sinusoidal Approximation Theorem for Kolmogorov-Arnold Networks</h2></a><strong><u>Authors:</u></strong>  Sergei Gleyzer, Hanh Nguyen, Dinesh P. Ramakrishnan, Eric A. F. Reinhardt</br><strong><u>Categories:</u></strong> stat.ML, cs.LG, cs.NA, math.NA</br><strong><u>Comments:</u></strong> 15 pages, 3 figures</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The Kolmogorov-Arnold representation theorem states that any continuous
multivariable function can be exactly represented as a finite superposition of
continuous single variable functions. Subsequent simplifications of this
representation involve expressing these functions as parameterized sums of a
smaller number of unique monotonic functions. These developments led to the
proof of the universal approximation capabilities of multilayer perceptron
networks with sigmoidal activations, forming the alternative theoretical
direction of most modern neural networks.
  Kolmogorov-Arnold Networks (KANs) have been recently proposed as an
alternative to multilayer perceptrons. KANs feature learnable nonlinear
activations applied directly to input values, modeled as weighted sums of basis
spline functions. This approach replaces the linear transformations and
sigmoidal post-activations used in traditional perceptrons. Subsequent works
have explored alternatives to spline-based activations. In this work, we
propose a novel KAN variant by replacing both the inner and outer functions in
the Kolmogorov-Arnold representation with weighted sinusoidal functions of
learnable frequencies. Inspired by simplifications introduced by Lorentz and
Sprecher, we fix the phases of the sinusoidal activations to linearly spaced
constant values and provide a proof of its theoretical validity. We also
conduct numerical experiments to evaluate its performance on a range of
multivariable functions, comparing it with fixed-frequency Fourier transform
methods and multilayer perceptrons (MLPs). We show that it outperforms the
fixed-frequency Fourier transform and achieves comparable performance to MLPs.</p></br><a href="http://arxiv.org/pdf/2507.23691v1" target="_blank"><h2>Accretion Regimes of Neutrino-Cooled Flows onto Black Holes</h2></a><strong><u>Authors:</u></strong>  Javiera Hernández-Morales, Daniel M. Siegel</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.GA, astro-ph.SR, gr-qc</br><strong><u>Comments:</u></strong> 39 pages, 12 figures</br><strong><u>Matching Keywords:</u></strong> VAE (abstract)</br><p><strong><u>Abstract:</u></strong> Neutrino-cooled accretion disks can form in the aftermath of neutron-star
mergers as well as during the collapse of rapidly rotating massive stars
(collapsars) and the accretion-induced collapse of rapidly rotating white
dwarfs. Due to Pauli blocking as electrons become degenerate at sufficiently
high accretion rates $\dot{M}$, the resulting 'self-neutronization' of the
dissociated accreting plasma makes these astrophysical systems promising
sources of rapid neutron capture nucleosynthesis (the r-process). We present a
one-dimensional general-relativistic, viscous-hydrodynamic model of
neutrino-cooled accretion disks around black holes. With collapsars,
super-collapsars and very massive star collapse in mind, we chart the
composition of the accretion flow and systematically explore different
radiatively efficient and inefficient accretion regimes with increasing $\dot
M$, across a vast parameter space of $\dot{M}\sim 10^{-6}-10^6 M_\odot
\,\text{s}^{-1}$, black hole masses of $M_\bullet\sim 1 - 10^4 M_\odot$ and
dimensionless spins of $\chi_\bullet \in [0,1)$, as well as $\alpha$-viscosity
values of $\alpha\sim 10^{-3}-1$. We show that these accretion regimes are
separated by characteristic thresholds $\dot{M}_{\rm char}$ that follow power
laws $\dot M_{\rm char}\propto M_{\bullet}^\alpha \alpha^\beta$ and that can be
understood based on analytic approximations we derive. We find that outflows
from such disks are promising sites of r-process nucleosynthesis up to
$M_\bullet \lesssim 3000 M_\odot$. These give rise to lanthanide-bearing 'red'
super-kilonovae transients mostly for $M_\bullet \lesssim 200-500 M_\odot$ and
lanthanide suppressed 'blue' super-kilonovae for larger $M_\bullet$.
Proton-rich outflows can develop specifically for large black hole masses
($M_\bullet \gtrsim 100 M_\odot$) in certain accretion regimes, which may give
rise to proton-rich isotopes via the $\nu$p-process.</p></br></body>