<link href='https://fonts.googleapis.com/css?family=Montserrat' rel='stylesheet'>
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [['$','$']],
            processEscapes: true
        },
        "HTML-CSS": {
            availableFonts: ["TeX"]
        }
    });
    </script>
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <style>     body {font-family: 'Montserrat'; background: #F3F3F3; width: 740px; margin: 0 auto; line-height: 150%; margin-top: 50px; font-size: 15px}         h1 {font-size: 70px}         a {color: #45ABC2}         em {font-size: 120%} </style><h1><center>ArXiv Alert</center></h1><font color='#DDAD5C'><em>Update: from 10 Jul 2025 to 14 Jul 2025</em></font><a href="http://arxiv.org/pdf/2507.08177v1" target="_blank"><h2>Rethinking Spatio-Temporal Anomaly Detection: A Vision for
  Causality-Driven Cybersecurity</h2></a><strong><u>Authors:</u></strong>  Arun Vignesh Malarkkan, Haoyue Bai, Xinyuan Wang, Anjali Kaushik, Dongjie Wang, Yanjie Fu</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.ET, cs.NE, F.2.2, I.2.7, I.2.4, I.2.1</br><strong><u>Comments:</u></strong> 5 pages, 1 figure, Under Review in Vision Paper Track-ACM SIGSPATIAL 2025</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract), anomaly detection (title, abstract), explainable (abstract), multi-modal (abstract), multi-modality (abstract), causality (title, abstract)</br><p><strong><u>Abstract:</u></strong> As cyber-physical systems grow increasingly interconnected and spatially
distributed, ensuring their resilience against evolving cyberattacks has become
a critical priority. Spatio-Temporal Anomaly detection plays an important role
in ensuring system security and operational integrity. However, current
data-driven approaches, largely driven by black-box deep learning, face
challenges in interpretability, adaptability to distribution shifts, and
robustness under evolving system dynamics. In this paper, we advocate for a
causal learning perspective to advance anomaly detection in spatially
distributed infrastructures that grounds detection in structural cause-effect
relationships. We identify and formalize three key directions: causal graph
profiling, multi-view fusion, and continual causal graph learning, each
offering distinct advantages in uncovering dynamic cause-effect structures
across time and space. Drawing on real-world insights from systems such as
water treatment infrastructures, we illustrate how causal models provide early
warning signals and root cause attribution, addressing the limitations of
black-box detectors. Looking ahead, we outline the future research agenda
centered on multi-modality, generative AI-driven, and scalable adaptive causal
frameworks. Our objective is to lay a new research trajectory toward scalable,
adaptive, explainable, and spatially grounded anomaly detection systems. We
hope to inspire a paradigm shift in cybersecurity research, promoting
causality-driven approaches to address evolving threats in interconnected
infrastructures.</p></br><a href="http://arxiv.org/pdf/2507.07713v1" target="_blank"><h2>Generative Neural Network for Simulating Radio Emission from Extensive
  Air Showers</h2></a><strong><u>Authors:</u></strong>  Pranav Sampathkumar, Tim Huege, Andreas Haungs, Ralph Engel</br><strong><u>Categories:</u></strong> astro-ph.HE, astro-ph.IM</br><strong><u>Comments:</u></strong> 39th International Cosmic Ray Conference (ICRC2025) Proceeding</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Cosmic ray shower detection using large radio arrays has gained significant
traction in recent years. With massive improvements in signal modelling and
microscopic simulations, the analysis of incoming events is still severely
limited by the simulation cost of radio emission to interpret the data. In this
work, we show that a neural network can be used for simulating such radio
pulses. We also demonstrate how such a neural network can be used for
$X_\mathrm{max}$ reconstruction, while retaining comparable resolution to using
full Monte-Carlo CORSIKA/CoREAS simulations for radio emission.</p></br><a href="http://arxiv.org/pdf/2507.08235v1" target="_blank"><h2>InsightBuild: LLM-Powered Causal Reasoning in Smart Building Systems</h2></a><strong><u>Authors:</u></strong>  Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> causality (abstract)</br><p><strong><u>Abstract:</u></strong> Smart buildings generate vast streams of sensor and control data, but
facility managers often lack clear explanations for anomalous energy usage. We
propose InsightBuild, a two-stage framework that integrates causality analysis
with a fine-tuned large language model (LLM) to provide human-readable, causal
explanations of energy consumption patterns. First, a lightweight causal
inference module applies Granger causality tests and structural causal
discovery on building telemetry (e.g., temperature, HVAC settings, occupancy)
drawn from Google Smart Buildings and Berkeley Office datasets. Next, an LLM,
fine-tuned on aligned pairs of sensor-level causes and textual explanations,
receives as input the detected causal relations and generates concise,
actionable explanations. We evaluate InsightBuild on two real-world datasets
(Google: 2017-2022; Berkeley: 2018-2020), using expert-annotated ground-truth
causes for a held-out set of anomalies. Our results demonstrate that combining
explicit causal discovery with LLM-based natural language generation yields
clear, precise explanations that assist facility managers in diagnosing and
mitigating energy inefficiencies.</p></br><a href="http://arxiv.org/pdf/2507.08518v1" target="_blank"><h2>Data Depth as a Risk</h2></a><strong><u>Authors:</u></strong>  Arturo Castellanos, Pavlo Mozharovskyi</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract)</br><p><strong><u>Abstract:</u></strong> Data depths are score functions that quantify in an unsupervised fashion how
central is a point inside a distribution, with numerous applications such as
anomaly detection, multivariate or functional data analysis, arising across
various fields. The halfspace depth was the first depth to aim at generalising
the notion of quantile beyond the univariate case. Among the existing variety
of depth definitions, it remains one of the most used notions of data depth.
Taking a different angle from the quantile point of view, we show that the
halfspace depth can also be regarded as the minimum loss of a set of
classifiers for a specific labelling of the points. By changing the loss or the
set of classifiers considered, this new angle naturally leads to a family of
"loss depths", extending to well-studied classifiers such as, e.g., SVM or
logistic regression, among others. This framework directly inherits
computational efficiency of existing machine learning algorithms as well as
their fast statistical convergence rates, and opens the data depth realm to the
high-dimensional setting. Furthermore, the new loss depths highlight a
connection between the dataset and the right amount of complexity or simplicity
of the classifiers. The simplicity of classifiers as well as the interpretation
as a risk makes our new kind of data depth easy to explain, yet efficient for
anomaly detection, as is shown by experiments.</p></br><a href="http://arxiv.org/pdf/2507.08121v1" target="_blank"><h2>Quasi-Random Physics-informed Neural Networks</h2></a><strong><u>Authors:</u></strong>  Tianchi Yu, Ivan Oseledets</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.NA, math.NA</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract)</br><p><strong><u>Abstract:</u></strong> Physics-informed neural networks have shown promise in solving partial
differential equations (PDEs) by integrating physical constraints into neural
network training, but their performance is sensitive to the sampling of points.
Based on the impressive performance of quasi Monte-Carlo methods in high
dimensional problems, this paper proposes Quasi-Random Physics-Informed Neural
Networks (QRPINNs), which use low-discrepancy sequences for sampling instead of
random points directly from the domain. Theoretically, QRPINNs have been proven
to have a better convergence rate than PINNs. Empirically, experiments
demonstrate that QRPINNs significantly outperform PINNs and some representative
adaptive sampling methods, especially in high-dimensional PDEs. Furthermore,
combining QRPINNs with adaptive sampling can further improve the performance.</p></br><a href="http://arxiv.org/pdf/2507.07559v1" target="_blank"><h2>Real-Time Decorrelation-Based Anomaly Detection for Multivariate Time
  Series</h2></a><strong><u>Authors:</u></strong>  Amirhossein Sadough, Mahyar Shahsavari, Mark Wijtvliet, Marcel van Gerven</br><strong><u>Categories:</u></strong> cs.LG, cs.SY, eess.SP, eess.SY</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (title, abstract)</br><p><strong><u>Abstract:</u></strong> Anomaly detection (AD) plays a vital role across a wide range of real-world
domains by identifying data instances that deviate from expected patterns,
potentially signaling critical events such as system failures, fraudulent
activities, or rare medical conditions. The demand for real-time AD has surged
with the rise of the (Industrial) Internet of Things, where massive volumes of
multivariate sensor data must be processed instantaneously. Real-time AD
requires methods that not only handle high-dimensional streaming data but also
operate in a single-pass manner, without the burden of storing historical
instances, thereby ensuring minimal memory usage and fast decision-making. We
propose DAD, a novel real-time decorrelation-based anomaly detection method for
multivariate time series, based on an online decorrelation learning approach.
Unlike traditional proximity-based or reconstruction-based detectors that
process entire data or windowed instances, DAD dynamically learns and monitors
the correlation structure of data sample by sample in a single pass, enabling
efficient and effective detection. To support more realistic benchmarking
practices, we also introduce a practical hyperparameter tuning strategy
tailored for real-time anomaly detection scenarios. Extensive experiments on
widely used benchmark datasets demonstrate that DAD achieves the most
consistent and superior performance across diverse anomaly types compared to
state-of-the-art methods. Crucially, its robustness to increasing
dimensionality makes it particularly well-suited for real-time,
high-dimensional data streams. Ultimately, DAD not only strikes an optimal
balance between detection efficacy and computational efficiency but also sets a
new standard for real-time, memory-constrained anomaly detection.</p></br><a href="http://arxiv.org/pdf/2507.07622v1" target="_blank"><h2>TransformEEG: Towards Improving Model Generalizability in Deep
  Learning-based EEG Parkinson's Disease Detection</h2></a><strong><u>Authors:</u></strong>  Federico Del Pup, Riccardo Brun, Filippo Iotti, Edoardo Paccagnella, Mattia Pezzato, Sabrina Bertozzo, Andrea Zanola, Louis Fabrice Tshimanga, Henning Müller, Manfredo Atzori</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> Submitted for possible publication. GitHub repository: seethis https URL</br><strong><u>Matching Keywords:</u></strong> convolutional (abstract), transformer (abstract), attention (abstract), data augmentation (abstract)</br><p><strong><u>Abstract:</u></strong> Electroencephalography (EEG) is establishing itself as an important,
low-cost, noninvasive diagnostic tool for the early detection of Parkinson's
Disease (PD). In this context, EEG-based Deep Learning (DL) models have shown
promising results due to their ability to discover highly nonlinear patterns
within the signal. However, current state-of-the-art DL models suffer from poor
generalizability caused by high inter-subject variability. This high
variability underscores the need for enhancing model generalizability by
developing new architectures better tailored to EEG data. This paper introduces
TransformEEG, a hybrid Convolutional-Transformer designed for Parkinson's
disease detection using EEG data. Unlike transformer models based on the EEGNet
structure, TransformEEG incorporates a depthwise convolutional tokenizer. This
tokenizer is specialized in generating tokens composed by channel-specific
features, which enables more effective feature mixing within the self-attention
layers of the transformer encoder. To evaluate the proposed model, four public
datasets comprising 290 subjects (140 PD patients, 150 healthy controls) were
harmonized and aggregated. A 10-outer, 10-inner Nested-Leave-N-Subjects-Out
(N-LNSO) cross-validation was performed to provide an unbiased comparison
against seven other consolidated EEG deep learning models. TransformEEG
achieved the highest balanced accuracy's median (78.45%) as well as the lowest
interquartile range (6.37%) across all the N-LNSO partitions. When combined
with data augmentation and threshold correction, median accuracy increased to
80.10%, with an interquartile range of 5.74%. In conclusion, TransformEEG
produces more consistent and less skewed results. It demonstrates a substantial
reduction in variability and more reliable PD detection using EEG data compared
to the other investigated models.</p></br><a href="http://arxiv.org/pdf/2507.08133v1" target="_blank"><h2>newASTROGAM -- The New MeV to GeV Gamma-ray Observatory</h2></a><strong><u>Authors:</u></strong>  D. Berge, M. N. Mazziotta, M. Tavani, V. Tatischeff, U. Oberlack</br><strong><u>Categories:</u></strong> astro-ph.IM, astro-ph.HE</br><strong><u>Comments:</u></strong> 9 pages, 4 figures, Proceedings of the 39th International Cosmic Ray Conference (ICRC2025), PoS 572 (2025)</br><strong><u>Matching Keywords:</u></strong> VAE (abstract)</br><p><strong><u>Abstract:</u></strong> newASTROGAM is a breakthrough mission concept for the study of the
non-thermal Universe from space with gamma rays in the energy range from 15 keV
to 3 GeV. It is based on advanced space-proven detector technologies, which
will achieve unprecedented sensitivity, angular and energy resolution combined
with polarimetric capability. Since the MeV gamma-ray energy range is the most
under-explored electromagnetic window to the Universe, a mission in this energy
range can for the first time sensitively address fundamental astrophysics
questions connected to the physics of compact objects and merger events, jets
and their environments, supernovae and the origin of the elements, potentially
constrain the nature of dark matter and many more science objectives. The
mission will detect and follow-up many of the key sources of multi-messenger
astronomy in the 2040s.
  newASTROGAM provides an unprecedentedly broad energy coverage from keV to GeV
energies. The payload concept consists of a Silicon tracker combined with a
crystal calorimeter. Both detectors are surrounded by an anti-coincidence
detector to reject charged cosmic rays. In addition, a thin X-ray coded mask
provides very good imaging capabilities. Such a mission can uniquely detect
gamma rays via the photoelectric effect, Compton scattering and
electron-positron pair production. newASTROGAM is proposed to the ESA call for
medium-class mission ideas (M8).</p></br><a href="http://arxiv.org/pdf/2507.07452v1" target="_blank"><h2>Advanced Northern Tracks Selection using a Graph Convolutional Neural
  Network for the IceCube Neutrino Observatory</h2></a><strong><u>Authors:</u></strong>  Philipp Soldin, Shuyang Deng, Lasse Düser, Philipp Fürst</br><strong><u>Categories:</u></strong> astro-ph.HE</br><strong><u>Comments:</u></strong> Presented at the 39th International Cosmic Ray Conference (ICRC2025)</br><strong><u>Matching Keywords:</u></strong> convolutional (title, abstract), neural network (abstract)</br><p><strong><u>Abstract:</u></strong> The IceCube Neutrino Observatory is a cubic-kilometer detector located in the
Antarctic ice at the geographic South Pole. It reads out over 5,000
photomultiplier tubes (PMTs) to detect Cherenkov light produced by secondary
particles, enabling IceCube to identify both atmospheric and astrophysical
neutrinos. One of the main challenges in this effort is effectively
distinguishing between muons induced by neutrinos and those generated by
cosmic-ray air showers. To address this challenge, the Advanced Northern Tracks
Selection (ANTS) employs a graph convolutional neural network. This network is
designed to utilize both the sensor data and the geometric arrangement of the
detector's photomultiplier tubes (PMTs). By representing each module as a node
in a graph and extracting features from each module, the network can capture
and integrate both local and global features. This work details the
implementation of the network architecture and highlights the improvements in
background rejection efficiency compared to existing methods for selecting muon
tracks.</p></br><a href="http://arxiv.org/pdf/2507.08637v1" target="_blank"><h2>Scaling Attention to Very Long Sequences in Linear Time with
  Wavelet-Enhanced Random Spectral Attention (WERSA)</h2></a><strong><u>Authors:</u></strong>  Vincenzo Dentamaro</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CL</br><strong><u>Comments:</u></strong> 10 pages, 1 figure</br><strong><u>Matching Keywords:</u></strong> transformer (abstract), attention (title, abstract)</br><p><strong><u>Abstract:</u></strong> Transformer models are computationally costly on long sequences since regular
attention has quadratic $O(n^2)$ time complexity. We introduce Wavelet-Enhanced
Random Spectral Attention (WERSA), a novel mechanism of linear $O(n)$ time
complexity that is pivotal to enable successful long-sequence processing
without the performance trade-off. WERSA merges content-adaptive random
spectral features together with multi-resolution Haar wavelets and learnable
parameters to selectively attend to informative scales of data while preserving
linear efficiency.
  Large-scale comparisons \textbf{on single GPU} and across various benchmarks
(vision, NLP, hierarchical reasoning) and various attention mechanisms (like
Multiheaded Attention, Flash-Attention-2, FNet, Linformer, Performer,
Waveformer), reveal uniform advantages of WERSA. It achieves best accuracy in
all tests. On ArXiv classification, WERSA improves accuracy over vanilla
attention by 1.2\% (86.2\% vs 85.0\%) while cutting training time by 81\% (296s
vs 1554s) and FLOPS by 73.4\% (26.2G vs 98.4G). Significantly, WERSA excels
where vanilla and FlashAttention-2 fail: on ArXiv-128k's extremely lengthy
sequences, it achieves best accuracy (79.1\%) and AUC (0.979) among viable
methods, operating on data that gives Out-Of-Memory errors to quadratic methods
while being \textbf{twice as fast} as Waveformer, its next-best competitor.
  By significantly reducing computational loads without compromising accuracy,
WERSA makes possible more practical, more affordable, long-context models, in
particular on low-resource hardware, for more sustainable and more scalable AI
development.</p></br><a href="http://arxiv.org/pdf/2507.07367v1" target="_blank"><h2>Platform for Representation and Integration of multimodal Molecular
  Embeddings</h2></a><strong><u>Authors:</u></strong>  Erika Yilin Zheng, Yu Yan, Baradwaj Simha Sankar, Ethan Ji, Steven Swee, Irsyad Adam, Ding Wang, Alexander Russell Pelletier, Alex Bui, Wei Wang, Peipei Ping</br><strong><u>Categories:</u></strong> q-bio.BM, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Existing machine learning methods for molecular (e.g., gene) embeddings are
restricted to specific tasks or data modalities, limiting their effectiveness
within narrow domains. As a result, they fail to capture the full breadth of
gene functions and interactions across diverse biological contexts. In this
study, we have systematically evaluated knowledge representations of
biomolecules across multiple dimensions representing a task-agnostic manner
spanning three major data sources, including omics experimental data,
literature-derived text data, and knowledge graph-based representations. To
distinguish between meaningful biological signals from chance correlations, we
devised an adjusted variant of Singular Vector Canonical Correlation Analysis
(SVCCA) that quantifies signal redundancy and complementarity across different
data modalities and sources. These analyses reveal that existing embeddings
capture largely non-overlapping molecular signals, highlighting the value of
embedding integration. Building on this insight, we propose Platform for
Representation and Integration of multimodal Molecular Embeddings (PRISME), a
machine learning based workflow using an autoencoder to integrate these
heterogeneous embeddings into a unified multimodal representation. We validated
this approach across various benchmark tasks, where PRISME demonstrated
consistent performance, and outperformed individual embedding methods in
missing value imputations. This new framework supports comprehensive modeling
of biomolecules, advancing the development of robust, broadly applicable
multimodal embeddings optimized for downstream biomedical machine learning
applications.</p></br><a href="http://arxiv.org/pdf/2507.08340v1" target="_blank"><h2>Single-Domain Generalization for Multimodal Cross-Cancer Prognosis via
  Dirac Rebalancer and Distribution Entanglement</h2></a><strong><u>Authors:</u></strong>  Jia-Xuan Jiang, Jiashuai Liu, Hongtao Wu, Yifeng Wu, Zhong Wang, Qi Bi, Yefeng Zheng</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> Accepted by ACMMM 25</br><strong><u>Matching Keywords:</u></strong> latent space (abstract), multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Deep learning has shown remarkable performance in integrating multimodal data
for survival prediction. However, existing multimodal methods mainly focus on
single cancer types and overlook the challenge of generalization across
cancers. In this work, we are the first to reveal that multimodal prognosis
models often generalize worse than unimodal ones in cross-cancer scenarios,
despite the critical need for such robustness in clinical practice. To address
this, we propose a new task: Cross-Cancer Single Domain Generalization for
Multimodal Prognosis, which evaluates whether models trained on a single cancer
type can generalize to unseen cancers. We identify two key challenges: degraded
features from weaker modalities and ineffective multimodal integration. To
tackle these, we introduce two plug-and-play modules: Sparse Dirac Information
Rebalancer (SDIR) and Cancer-aware Distribution Entanglement (CADE). SDIR
mitigates the dominance of strong features by applying Bernoulli-based
sparsification and Dirac-inspired stabilization to enhance weaker modality
signals. CADE, designed to synthesize the target domain distribution, fuses
local morphological cues and global gene expression in latent space.
Experiments on a four-cancer-type benchmark demonstrate superior
generalization, laying the foundation for practical, robust cross-cancer
multimodal prognosis. Code is available at
https://github.com/HopkinsKwong/MCCSDG</p></br><a href="http://arxiv.org/pdf/2507.07579v1" target="_blank"><h2>NexViTAD: Few-shot Unsupervised Cross-Domain Defect Detection via Vision
  Foundation Models and Multi-Task Learning</h2></a><strong><u>Authors:</u></strong>  Tianwei Mu, Feiyu Duan, Bo Zhou, Dan Xue, Manhong Huang</br><strong><u>Categories:</u></strong> cs.CV, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> anomaly detection (abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> This paper presents a novel few-shot cross-domain anomaly detection
framework, Nexus Vision Transformer for Anomaly Detection (NexViTAD), based on
vision foundation models, which effectively addresses domain-shift challenges
in industrial anomaly detection through innovative shared subspace projection
mechanisms and multi-task learning (MTL) module. The main innovations include:
(1) a hierarchical adapter module that adaptively fuses complementary features
from Hiera and DINO-v2 pre-trained models, constructing more robust feature
representations; (2) a shared subspace projection strategy that enables
effective cross-domain knowledge transfer through bottleneck dimension
constraints and skip connection mechanisms; (3) a MTL Decoder architecture
supports simultaneous processing of multiple source domains, significantly
enhancing model generalization capabilities; (4) an anomaly score inference
method based on Sinkhorn-K-means clustering, combined with Gaussian filtering
and adaptive threshold processing for precise pixel level. Valuated on the
MVTec AD dataset, NexViTAD delivers state-of-the-art performance with an AUC of
97.5%, AP of 70.4%, and PRO of 95.2% in the target domains, surpassing other
recent models, marking a transformative advance in cross-domain defect
detection.</p></br><a href="http://arxiv.org/pdf/2507.08217v1" target="_blank"><h2>Quantum Federated Learning for Multimodal Data: A Modality-Agnostic
  Approach</h2></a><strong><u>Authors:</u></strong>  Atit Pokharel, Ratun Rahman, Thomas Morris, Dinh C. Nguyen</br><strong><u>Categories:</u></strong> cs.AI</br><strong><u>Comments:</u></strong> This paper was presented at BEAM with CVPR 2025</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract)</br><p><strong><u>Abstract:</u></strong> Quantum federated learning (QFL) has been recently introduced to enable a
distributed privacy-preserving quantum machine learning (QML) model training
across quantum processors (clients). Despite recent research efforts, existing
QFL frameworks predominantly focus on unimodal systems, limiting their
applicability to real-world tasks that often naturally involve multiple
modalities. To fill this significant gap, we present for the first time a novel
multimodal approach specifically tailored for the QFL setting with the
intermediate fusion using quantum entanglement. Furthermore, to address a major
bottleneck in multimodal QFL, where the absence of certain modalities during
training can degrade model performance, we introduce a Missing Modality
Agnostic (MMA) mechanism that isolates untrained quantum circuits, ensuring
stable training without corrupted states. Simulation results demonstrate that
the proposed multimodal QFL method with MMA yields an improvement in accuracy
of 6.84% in independent and identically distributed (IID) and 7.25% in non-IID
data distributions compared to the state-of-the-art methods.</p></br><a href="http://arxiv.org/pdf/2507.07820v1" target="_blank"><h2>AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a
  Paradigm Shift</h2></a><strong><u>Authors:</u></strong>  Eunsu Baek, Keondo Park, Jeonggil Ko, Min-hwan Oh, Taesik Gong, Hyung-Sin Kim</br><strong><u>Categories:</u></strong> cs.AI, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (abstract)</br><p><strong><u>Abstract:</u></strong> Current AI advances largely rely on scaling neural models and expanding
training datasets to achieve generalization and robustness. Despite notable
successes, this paradigm incurs significant environmental, economic, and
ethical costs, limiting sustainability and equitable access. Inspired by
biological sensory systems, where adaptation occurs dynamically at the input
(e.g., adjusting pupil size, refocusing vision)--we advocate for adaptive
sensing as a necessary and foundational shift. Adaptive sensing proactively
modulates sensor parameters (e.g., exposure, sensitivity, multimodal
configurations) at the input level, significantly mitigating covariate shifts
and improving efficiency. Empirical evidence from recent studies demonstrates
that adaptive sensing enables small models (e.g., EfficientNet-B0) to surpass
substantially larger models (e.g., OpenCLIP-H) trained with significantly more
data and compute. We (i) outline a roadmap for broadly integrating adaptive
sensing into real-world applications spanning humanoid, healthcare, autonomous
systems, agriculture, and environmental monitoring, (ii) critically assess
technical and ethical integration challenges, and (iii) propose targeted
research directions, such as standardized benchmarks, real-time adaptive
algorithms, multimodal integration, and privacy-preserving methods.
Collectively, these efforts aim to transition the AI community toward
sustainable, robust, and equitable artificial intelligence systems.</p></br><a href="http://arxiv.org/pdf/2507.08153v1" target="_blank"><h2>ALCo-FM: Adaptive Long-Context Foundation Model for Accident Prediction</h2></a><strong><u>Authors:</u></strong>  Pinaki Prasad Guha Neogi, Ahmad Mohammadshirazi, Rajiv Ramnath</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> multimodal (abstract), transformer (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> Traffic accidents are rare, yet high-impact events that require long-context
multimodal reasoning for accurate risk forecasting. In this paper, we introduce
ALCo-FM, a unified adaptive long-context foundation model that computes a
volatility pre-score to dynamically select context windows for input data and
encodes and fuses these multimodal data via shallow cross attention. Following
a local GAT layer and a BigBird-style sparse global transformer over H3
hexagonal grids, coupled with Monte Carlo dropout for confidence, the model
yields superior, well-calibrated predictions. Trained on data from 15 US cities
with a class-weighted loss to counter label imbalance, and fine-tuned with
minimal data on held-out cities, ALCo-FM achieves 0.94 accuracy, 0.92 F1, and
an ECE of 0.04, outperforming more than 20 state-of-the-art baselines in
large-scale urban risk prediction. Code and dataset are available at:
https://github.com/PinakiPrasad12/ALCo-FM</p></br><a href="http://arxiv.org/pdf/2507.07867v1" target="_blank"><h2>Re-Bottleneck: Latent Re-Structuring for Neural Audio Autoencoders</h2></a><strong><u>Authors:</u></strong>  Dimitrios Bralios, Jonah Casebeer, Paris Smaragdis</br><strong><u>Categories:</u></strong> cs.SD, cs.LG, eess.AS</br><strong><u>Comments:</u></strong> Accepted at IEEE MLSP 2025</br><strong><u>Matching Keywords:</u></strong> latent space (abstract)</br><p><strong><u>Abstract:</u></strong> Neural audio codecs and autoencoders have emerged as versatile models for
audio compression, transmission, feature-extraction, and latent-space
generation. However, a key limitation is that most are trained to maximize
reconstruction fidelity, often neglecting the specific latent structure
necessary for optimal performance in diverse downstream applications. We
propose a simple, post-hoc framework to address this by modifying the
bottleneck of a pre-trained autoencoder. Our method introduces a
"Re-Bottleneck", an inner bottleneck trained exclusively through latent space
losses to instill user-defined structure. We demonstrate the framework's
effectiveness in three experiments. First, we enforce an ordering on latent
channels without sacrificing reconstruction quality. Second, we align latents
with semantic embeddings, analyzing the impact on downstream diffusion
modeling. Third, we introduce equivariance, ensuring that a filtering operation
on the input waveform directly corresponds to a specific transformation in the
latent space. Ultimately, our Re-Bottleneck framework offers a flexible and
efficient way to tailor representations of neural audio models, enabling them
to seamlessly meet the varied demands of different applications with minimal
additional training.</p></br><a href="http://arxiv.org/pdf/2507.07485v1" target="_blank"><h2>Resolving Token-Space Gradient Conflicts: Token Space Manipulation for
  Transformer-Based Multi-Task Learning</h2></a><strong><u>Authors:</u></strong>  Wooseong Jeong, Kuk-Jin Yoon</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, cs.CV</br><strong><u>Comments:</u></strong> Accepted at ICCV 2025</br><strong><u>Matching Keywords:</u></strong> transformer (title, abstract)</br><p><strong><u>Abstract:</u></strong> Multi-Task Learning (MTL) enables multiple tasks to be learned within a
shared network, but differences in objectives across tasks can cause negative
transfer, where the learning of one task degrades another task's performance.
While pre-trained transformers significantly improve MTL performance, their
fixed network capacity and rigid structure limit adaptability. Previous dynamic
network architectures attempt to address this but are inefficient as they
directly convert shared parameters into task-specific ones. We propose Dynamic
Token Modulation and Expansion (DTME-MTL), a framework applicable to any
transformer-based MTL architecture. DTME-MTL enhances adaptability and reduces
overfitting by identifying gradient conflicts in token space and applying
adaptive solutions based on conflict type. Unlike prior methods that mitigate
negative transfer by duplicating network parameters, DTME-MTL operates entirely
in token space, enabling efficient adaptation without excessive parameter
growth. Extensive experiments demonstrate that DTME-MTL consistently improves
multi-task performance with minimal computational overhead, offering a scalable
and effective solution for enhancing transformer-based MTL models.</p></br><a href="http://arxiv.org/pdf/2507.08238v1" target="_blank"><h2>Self-Supervised Learning-Based Multimodal Prediction on Prosocial
  Behavior Intentions</h2></a><strong><u>Authors:</u></strong>  Abinay Reddy Naini, Zhaobo K. Zheng, Teruhisa Misu, Kumar Akash</br><strong><u>Categories:</u></strong> cs.LG</br><strong><u>Comments:</u></strong> 5 pages, 4 figures, published at ICASSP 2025</br><strong><u>Matching Keywords:</u></strong> multimodal (title, abstract), multi-modal (abstract)</br><p><strong><u>Abstract:</u></strong> Human state detection and behavior prediction have seen significant
advancements with the rise of machine learning and multimodal sensing
technologies. However, predicting prosocial behavior intentions in mobility
scenarios, such as helping others on the road, is an underexplored area.
Current research faces a major limitation. There are no large, labeled datasets
available for prosocial behavior, and small-scale datasets make it difficult to
train deep-learning models effectively. To overcome this, we propose a
self-supervised learning approach that harnesses multi-modal data from existing
physiological and behavioral datasets. By pre-training our model on diverse
tasks and fine-tuning it with a smaller, manually labeled prosocial behavior
dataset, we significantly enhance its performance. This method addresses the
data scarcity issue, providing a more effective benchmark for prosocial
behavior prediction, and offering valuable insights for improving intelligent
vehicle systems and human-machine interaction.</p></br><a href="http://arxiv.org/pdf/2507.07432v1" target="_blank"><h2>Neural networks leverage nominally quantum and post-quantum
  representations</h2></a><strong><u>Authors:</u></strong>  Paul M. Riechers, Thomas J. Elliott, Adam S. Shai</br><strong><u>Categories:</u></strong> cs.LG, quant-ph</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (title, abstract), transformer (abstract)</br><p><strong><u>Abstract:</u></strong> We show that deep neural networks, including transformers and RNNs,
pretrained as usual on next-token prediction, intrinsically discover and
represent beliefs over 'quantum' and 'post-quantum' low-dimensional generative
models of their training data -- as if performing iterative Bayesian updates
over the latent state of this world model during inference as they observe more
context. Notably, neural nets easily find these representation whereas there is
no finite classical circuit that would do the job. The corresponding geometric
relationships among neural activations induced by different input sequences are
found to be largely independent of neural-network architecture. Each point in
this geometry corresponds to a history-induced probability density over all
possible futures, and the relative displacement of these points reflects the
difference in mechanism and magnitude for how these distinct pasts affect the
future.</p></br><a href="http://arxiv.org/pdf/2507.07405v1" target="_blank"><h2>HGMP:Heterogeneous Graph Multi-Task Prompt Learning</h2></a><strong><u>Authors:</u></strong>  Pengfei Jiao, Jialong Ni, Di Jin, Xuan Guo, Huan Liu, Hongjiang Chen, Yanxian Bi</br><strong><u>Categories:</u></strong> cs.LG, cs.AI</br><strong><u>Comments:</u></strong> The 25th International Joint Conference on Artificial Intelligence (IJCAI-25)</br><strong><u>Matching Keywords:</u></strong> neural network (abstract), attention (abstract)</br><p><strong><u>Abstract:</u></strong> The pre-training and fine-tuning methods have gained widespread attention in
the field of heterogeneous graph neural networks due to their ability to
leverage large amounts of unlabeled data during the pre-training phase,
allowing the model to learn rich structural features. However, these methods
face the issue of a mismatch between the pre-trained model and downstream
tasks, leading to suboptimal performance in certain application scenarios.
Prompt learning methods have emerged as a new direction in heterogeneous graph
tasks, as they allow flexible adaptation of task representations to address
target inconsistency. Building on this idea, this paper proposes a novel
multi-task prompt framework for the heterogeneous graph domain, named HGMP.
First, to bridge the gap between the pre-trained model and downstream tasks, we
reformulate all downstream tasks into a unified graph-level task format. Next,
we address the limitations of existing graph prompt learning methods, which
struggle to integrate contrastive pre-training strategies in the heterogeneous
graph domain. We design a graph-level contrastive pre-training strategy to
better leverage heterogeneous information and enhance performance in multi-task
scenarios. Finally, we introduce heterogeneous feature prompts, which enhance
model performance by refining the representation of input graph features.
Experimental results on public datasets show that our proposed method adapts
well to various tasks and significantly outperforms baseline methods.</p></br><a href="http://arxiv.org/pdf/2507.08760v1" target="_blank"><h2>Recent Advances in Understanding R-Process Nucleosynthesis in Metal-Poor
  Stars and Stellar Systems</h2></a><strong><u>Authors:</u></strong>  Avrajit Bandyopadhyay, Timothy C. Beers</br><strong><u>Categories:</u></strong> astro-ph.SR, astro-ph.GA, astro-ph.HE</br><strong><u>Comments:</u></strong> 26 pages, 8 figures; Published in the journal Universe; This article belongs to the Special Issue "Advances in Nuclear Astrophysics"</br><strong><u>Matching Keywords:</u></strong> VAE (abstract)</br><p><strong><u>Abstract:</u></strong> The rapid neutron-capture process (r-process) is responsible for the creation
of roughly half of the elements heavier than iron, including precious metals
like silver, gold, and platinum, as well as radioactive elements such as
thorium and uranium. Despite its importance, the nature of the astrophysical
sites where the r-process occurs, and the detailed mechanisms of its formation,
remain elusive. The key to resolving these mysteries lies in the study of
chemical signatures preserved in ancient, metal-poor stars. In this review, we
explore r-process nucleosynthesis, focusing on the sites, progenitors, and
formation mechanisms. We discuss the role of potential astrophysical sites such
as neutron star mergers, core-collapse supernovae, magneto-rotational
supernovae, and collapsars, that can play a key role in producing the heavy
elements. We also highlight the importance of studying these signatures through
high-resolution spectroscopic surveys, stellar archaeology, and multi-messenger
astronomy. Recent advancements, such as the gravitational wave event GW170817
and detection of the r-process in the ejecta of its associated kilonovae, have
established neutron star mergers as one of the confirmed sites. However,
questions remain regarding whether they are the only sites that could have
contributed in early epochs or if additional sources are needed to explain the
signatures of r-process found in the oldest stars. Additionally, there are
strong indications pointing towards additional sources of r-process-rich nuclei
in the context of Galactic evolutionary timescales. This review summarizes what
has been learned so far, the challenges that remain, and the exciting prospects
for future discoveries. The increasing synergy between observational
facilities, computational models, and large-scale surveys is poised to
transform our understanding of r-process nucleosynthesis in the coming years.</p></br><a href="http://arxiv.org/pdf/2507.08738v1" target="_blank"><h2>Adaptive Nonlinear Vector Autoregression: Robust Forecasting for Noisy
  Chaotic Time Series</h2></a><strong><u>Authors:</u></strong>  Azimov Sherkhon, Susana Lopez-Moreno, Eric Dolores-Cuenca, Sieun Lee, Sangil Kim</br><strong><u>Categories:</u></strong> cs.LG, cs.AI, math.DS, 68T07, 37M10, 00A79, 37M22, 65P20</br><strong><u>Comments:</u></strong> 15 pages, 10 figures</br><strong><u>Matching Keywords:</u></strong> data-driven (abstract)</br><p><strong><u>Abstract:</u></strong> Nonlinear vector autoregression (NVAR) and reservoir computing (RC) have
shown promise in forecasting chaotic dynamical systems, such as the Lorenz-63
model and El Nino-Southern Oscillation. However, their reliance on fixed
nonlinearities - polynomial expansions in NVAR or random feature maps in RC -
limits their adaptability to high noise or real-world data. These methods also
scale poorly in high-dimensional settings due to costly matrix inversion during
readout computation. We propose an adaptive NVAR model that combines
delay-embedded linear inputs with features generated by a shallow, learnable
multi-layer perceptron (MLP). The MLP and linear readout are jointly trained
using gradient-based optimization, enabling the model to learn data-driven
nonlinearities while preserving a simple readout structure. Unlike standard
NVAR, our approach avoids the need for an exhaustive and sensitive grid search
over ridge and delay parameters. Instead, tuning is restricted to neural
network hyperparameters, improving scalability. Initial experiments on chaotic
systems tested under noise-free and synthetically noisy conditions showed that
the adaptive model outperformed the standard NVAR in predictive accuracy and
showed robust forecasting under noisy conditions with a lower observation
frequency.</p></br><a href="http://arxiv.org/pdf/2507.08261v1" target="_blank"><h2>Admissibility of Stein Shrinkage for Batch Normalization in the Presence
  of Adversarial Attacks</h2></a><strong><u>Authors:</u></strong>  Sofia Ivolgina, P. Thomas Fletcher, Baba C. Vemuri</br><strong><u>Categories:</u></strong> stat.ML, cs.LG</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Batch normalization (BN) is a ubiquitous operation in deep neural networks
used primarily to achieve stability and regularization during network training.
BN involves feature map centering and scaling using sample means and variances,
respectively. Since these statistics are being estimated across the feature
maps within a batch, this problem is ideally suited for the application of
Stein's shrinkage estimation, which leads to a better, in the
mean-squared-error sense, estimate of the mean and variance of the batch. In
this paper, we prove that the Stein shrinkage estimator for the mean and
variance dominates over the sample mean and variance estimators in the presence
of adversarial attacks when modeling these attacks using sub-Gaussian
distributions. This facilitates and justifies the application of Stein
shrinkage to estimate the mean and variance parameters in BN and use it in
image classification (segmentation) tasks with and without adversarial attacks.
We present SOTA performance results using this Stein corrected batch norm in a
standard ResNet architecture applied to the task of image classification using
CIFAR-10 data, 3D CNN on PPMI (neuroimaging) data and image segmentation using
HRNet on Cityscape data with and without adversarial attacks.</p></br><a href="http://arxiv.org/pdf/2507.08239v1" target="_blank"><h2>Data Generation without Function Estimation</h2></a><strong><u>Authors:</u></strong>  Hadi Daneshmand, Ashkan Soleymani</br><strong><u>Categories:</u></strong> cs.LG, math-ph, math.MP, math.OC, stat.ML</br><strong><u>Comments:</u></strong> No comments</br><strong><u>Matching Keywords:</u></strong> neural network (abstract)</br><p><strong><u>Abstract:</u></strong> Estimating the score function (or other population-density-dependent
functions) is a fundamental component of most generative models. However, such
function estimation is computationally and statistically challenging. Can we
avoid function estimation for data generation? We propose an estimation-free
generative method: A set of points whose locations are deterministically
updated with (inverse) gradient descent can transport a uniform distribution to
arbitrary data distribution, in the mean field regime, without function
estimation, training neural networks, and even noise injection. The proposed
method is built upon recent advances in the physics of interacting particles.
We show, both theoretically and experimentally, that these advances can be
leveraged to develop novel generative methods.</p></br></body>